Running experiment with attn_quant=Symmetric_UINT4
Namespace(model='deit_small', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=1024, val_batchsize=128, num_workers=8, intsoftmax_exp_n=15, intgelu_exp_n=29, attn_quant='Symmetric_UINT4')
Model: deit_small_patch16_224
IntSoftmax | n:  15
IntGELU    | n:  29
IntSoftmax | n:  15
IntGELU    | n:  29
IntSoftmax | n:  15
IntGELU    | n:  29
IntSoftmax | n:  15
IntGELU    | n:  29
IntSoftmax | n:  15
IntGELU    | n:  29
IntSoftmax | n:  15
IntGELU    | n:  29
IntSoftmax | n:  15
IntGELU    | n:  29
IntSoftmax | n:  15
IntGELU    | n:  29
IntSoftmax | n:  15
IntGELU    | n:  29
IntSoftmax | n:  15
IntGELU    | n:  29
IntSoftmax | n:  15
IntGELU    | n:  29
IntSoftmax | n:  15
IntGELU    | n:  29
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 149
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : Symmetric_UINT4
    Number of QuantMatMul: 24
................................calib done
Test: [  0/391]	Time  3.011 ( 3.011)	Acc@1  28.91 ( 28.91)	Acc@5  35.94 ( 35.94)
Test: [ 50/391]	Time  0.897 ( 0.938)	Acc@1  25.78 ( 19.32)	Acc@5  39.84 ( 27.25)
Test: [100/391]	Time  0.898 ( 0.918)	Acc@1  31.25 ( 20.09)	Acc@5  50.78 ( 33.63)
Test: [150/391]	Time  0.896 ( 0.911)	Acc@1   2.34 ( 18.24)	Acc@5   7.03 ( 31.29)
Test: [200/391]	Time  0.897 ( 0.907)	Acc@1   5.47 ( 16.46)	Acc@5  13.28 ( 27.99)
Test: [250/391]	Time  0.896 ( 0.905)	Acc@1   4.69 ( 14.68)	Acc@5  14.84 ( 25.48)
Test: [300/391]	Time  0.899 ( 0.904)	Acc@1  14.84 ( 13.74)	Acc@5  19.53 ( 23.87)
Test: [350/391]	Time  0.896 ( 0.903)	Acc@1   9.38 ( 13.10)	Acc@5  17.19 ( 22.99)
Test: [390/391]	Time  0.649 ( 0.902)	Acc@1  17.50 ( 12.27)	Acc@5  23.75 ( 21.50)
 * Prec@1 12.266 Prec@5 21.502
Time: 367.39
-----------------------------------------------------
Running experiment with attn_quant=Symmetric_UINT8
Namespace(model='deit_small', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=1024, val_batchsize=128, num_workers=8, intsoftmax_exp_n=15, intgelu_exp_n=29, attn_quant='Symmetric_UINT8')
Model: deit_small_patch16_224
IntSoftmax | n:  15
IntGELU    | n:  29
IntSoftmax | n:  15
IntGELU    | n:  29
IntSoftmax | n:  15
IntGELU    | n:  29
IntSoftmax | n:  15
IntGELU    | n:  29
IntSoftmax | n:  15
IntGELU    | n:  29
IntSoftmax | n:  15
IntGELU    | n:  29
IntSoftmax | n:  15
IntGELU    | n:  29
IntSoftmax | n:  15
IntGELU    | n:  29
IntSoftmax | n:  15
IntGELU    | n:  29
IntSoftmax | n:  15
IntGELU    | n:  29
IntSoftmax | n:  15
IntGELU    | n:  29
IntSoftmax | n:  15
IntGELU    | n:  29
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 149
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : Symmetric_UINT8
    Number of QuantMatMul: 24
................................calib done
Test: [  0/391]	Time  3.136 ( 3.136)	Acc@1  91.41 ( 91.41)	Acc@5  98.44 ( 98.44)
Test: [ 50/391]	Time  0.892 ( 0.936)	Acc@1  94.53 ( 83.15)	Acc@5  99.22 ( 95.82)
Test: [100/391]	Time  0.894 ( 0.915)	Acc@1  85.16 ( 81.88)	Acc@5  96.88 ( 96.06)
Test: [150/391]	Time  0.892 ( 0.907)	Acc@1  75.78 ( 81.89)	Acc@5  96.09 ( 96.09)
Test: [200/391]	Time  0.892 ( 0.904)	Acc@1  71.88 ( 79.06)	Acc@5  93.75 ( 94.64)
Test: [250/391]	Time  0.892 ( 0.902)	Acc@1  82.03 ( 77.84)	Acc@5  90.62 ( 93.92)
Test: [300/391]	Time  0.894 ( 0.900)	Acc@1  80.47 ( 76.97)	Acc@5  92.19 ( 93.22)
Test: [350/391]	Time  0.892 ( 0.899)	Acc@1  71.88 ( 76.21)	Acc@5  89.06 ( 92.86)
Test: [390/391]	Time  0.643 ( 0.898)	Acc@1  56.25 ( 76.22)	Acc@5  90.00 ( 92.89)
 * Prec@1 76.220 Prec@5 92.892
Time: 365.66
-----------------------------------------------------
Running experiment with attn_quant=Log2_half_Quantizer
Namespace(model='deit_small', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=1024, val_batchsize=128, num_workers=8, intsoftmax_exp_n=15, intgelu_exp_n=29, attn_quant='Log2_half_Quantizer')
Model: deit_small_patch16_224
IntSoftmax | n:  15
IntGELU    | n:  29
IntSoftmax | n:  15
IntGELU    | n:  29
IntSoftmax | n:  15
IntGELU    | n:  29
IntSoftmax | n:  15
IntGELU    | n:  29
IntSoftmax | n:  15
IntGELU    | n:  29
IntSoftmax | n:  15
IntGELU    | n:  29
IntSoftmax | n:  15
IntGELU    | n:  29
IntSoftmax | n:  15
IntGELU    | n:  29
IntSoftmax | n:  15
IntGELU    | n:  29
IntSoftmax | n:  15
IntGELU    | n:  29
IntSoftmax | n:  15
IntGELU    | n:  29
IntSoftmax | n:  15
IntGELU    | n:  29
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 12
    - type : Log2_half_Quantizer
    Number of QuantMatMul: 24
................................calib done
Test: [  0/391]	Time  3.542 ( 3.542)	Acc@1  89.06 ( 89.06)	Acc@5  99.22 ( 99.22)
Test: [ 50/391]	Time  1.285 ( 1.329)	Acc@1  96.09 ( 83.27)	Acc@5  99.22 ( 95.85)
Test: [100/391]	Time  1.285 ( 1.307)	Acc@1  84.38 ( 82.00)	Acc@5  96.88 ( 96.02)
Test: [150/391]	Time  1.285 ( 1.300)	Acc@1  77.34 ( 81.93)	Acc@5  94.53 ( 96.06)
Test: [200/391]	Time  1.285 ( 1.296)	Acc@1  73.44 ( 79.34)	Acc@5  92.97 ( 94.65)
Test: [250/391]	Time  1.284 ( 1.294)	Acc@1  85.16 ( 78.16)	Acc@5  90.62 ( 93.89)
Test: [300/391]	Time  1.286 ( 1.292)	Acc@1  82.03 ( 77.16)	Acc@5  91.41 ( 93.18)
Test: [350/391]	Time  1.286 ( 1.291)	Acc@1  66.41 ( 76.40)	Acc@5  89.84 ( 92.78)
Test: [390/391]	Time  0.890 ( 1.290)	Acc@1  56.25 ( 76.28)	Acc@5  90.00 ( 92.82)
 * Prec@1 76.280 Prec@5 92.822
Time: 522.53
-----------------------------------------------------
Running experiment with attn_quant=Log2Quantizer
Namespace(model='deit_small', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=1024, val_batchsize=128, num_workers=8, intsoftmax_exp_n=15, intgelu_exp_n=29, attn_quant='Log2Quantizer')
Model: deit_small_patch16_224
IntSoftmax | n:  15
IntGELU    | n:  29
IntSoftmax | n:  15
IntGELU    | n:  29
IntSoftmax | n:  15
IntGELU    | n:  29
IntSoftmax | n:  15
IntGELU    | n:  29
IntSoftmax | n:  15
IntGELU    | n:  29
IntSoftmax | n:  15
IntGELU    | n:  29
IntSoftmax | n:  15
IntGELU    | n:  29
IntSoftmax | n:  15
IntGELU    | n:  29
IntSoftmax | n:  15
IntGELU    | n:  29
IntSoftmax | n:  15
IntGELU    | n:  29
IntSoftmax | n:  15
IntGELU    | n:  29
IntSoftmax | n:  15
IntGELU    | n:  29
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : Log2Quantizer
    Number of QuantMatMul: 24
................................calib done
Test: [  0/391]	Time  3.064 ( 3.064)	Acc@1  86.72 ( 86.72)	Acc@5  98.44 ( 98.44)
Test: [ 50/391]	Time  0.882 ( 0.923)	Acc@1  96.09 ( 82.49)	Acc@5 100.00 ( 95.51)
Test: [100/391]	Time  0.882 ( 0.902)	Acc@1  85.16 ( 81.29)	Acc@5  96.88 ( 95.68)
Test: [150/391]	Time  0.881 ( 0.895)	Acc@1  74.22 ( 81.29)	Acc@5  94.53 ( 95.79)
Test: [200/391]	Time  0.880 ( 0.891)	Acc@1  74.22 ( 78.63)	Acc@5  92.97 ( 94.33)
Test: [250/391]	Time  0.880 ( 0.889)	Acc@1  85.94 ( 77.50)	Acc@5  90.62 ( 93.62)
Test: [300/391]	Time  0.882 ( 0.888)	Acc@1  81.25 ( 76.57)	Acc@5  92.19 ( 92.99)
Test: [350/391]	Time  0.881 ( 0.887)	Acc@1  74.22 ( 75.76)	Acc@5  87.50 ( 92.62)
Test: [390/391]	Time  0.636 ( 0.885)	Acc@1  55.00 ( 75.77)	Acc@5  90.00 ( 92.69)
 * Prec@1 75.766 Prec@5 92.686
Time: 361.14
-----------------------------------------------------
Running experiment with attn_quant=LogSqrt2Quantizer
Namespace(model='deit_small', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=1024, val_batchsize=128, num_workers=8, intsoftmax_exp_n=15, intgelu_exp_n=29, attn_quant='LogSqrt2Quantizer')
Model: deit_small_patch16_224
IntSoftmax | n:  15
IntGELU    | n:  29
IntSoftmax | n:  15
IntGELU    | n:  29
IntSoftmax | n:  15
IntGELU    | n:  29
IntSoftmax | n:  15
IntGELU    | n:  29
IntSoftmax | n:  15
IntGELU    | n:  29
IntSoftmax | n:  15
IntGELU    | n:  29
IntSoftmax | n:  15
IntGELU    | n:  29
IntSoftmax | n:  15
IntGELU    | n:  29
IntSoftmax | n:  15
IntGELU    | n:  29
IntSoftmax | n:  15
IntGELU    | n:  29
IntSoftmax | n:  15
IntGELU    | n:  29
IntSoftmax | n:  15
IntGELU    | n:  29
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : LogSqrt2Quantizer
    Number of QuantMatMul: 24
................................calib done
Test: [  0/391]	Time  3.035 ( 3.035)	Acc@1  89.06 ( 89.06)	Acc@5  98.44 ( 98.44)
Test: [ 50/391]	Time  0.906 ( 0.948)	Acc@1  94.53 ( 83.50)	Acc@5  99.22 ( 96.29)
Test: [100/391]	Time  0.908 ( 0.928)	Acc@1  85.94 ( 82.09)	Acc@5  97.66 ( 96.43)
Test: [150/391]	Time  0.907 ( 0.921)	Acc@1  75.78 ( 82.15)	Acc@5  97.66 ( 96.44)
Test: [200/391]	Time  0.906 ( 0.917)	Acc@1  75.78 ( 79.47)	Acc@5  92.97 ( 94.85)
Test: [250/391]	Time  0.907 ( 0.915)	Acc@1  83.59 ( 78.18)	Acc@5  89.06 ( 94.08)
Test: [300/391]	Time  0.909 ( 0.914)	Acc@1  78.91 ( 77.25)	Acc@5  91.41 ( 93.45)
Test: [350/391]	Time  0.907 ( 0.913)	Acc@1  70.31 ( 76.48)	Acc@5  89.84 ( 93.00)
Test: [390/391]	Time  0.651 ( 0.911)	Acc@1  52.50 ( 76.41)	Acc@5  91.25 ( 93.02)
 * Prec@1 76.412 Prec@5 93.020
Time: 371.25
-----------------------------------------------------
Running experiment with attn_quant=NoQuant
Namespace(model='deit_small', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=1024, val_batchsize=128, num_workers=8, intsoftmax_exp_n=15, intgelu_exp_n=29, attn_quant='NoQuant')
Model: deit_small_patch16_224
IntSoftmax | n:  15
IntGELU    | n:  29
IntSoftmax | n:  15
IntGELU    | n:  29
IntSoftmax | n:  15
IntGELU    | n:  29
IntSoftmax | n:  15
IntGELU    | n:  29
IntSoftmax | n:  15
IntGELU    | n:  29
IntSoftmax | n:  15
IntGELU    | n:  29
IntSoftmax | n:  15
IntGELU    | n:  29
IntSoftmax | n:  15
IntGELU    | n:  29
IntSoftmax | n:  15
IntGELU    | n:  29
IntSoftmax | n:  15
IntGELU    | n:  29
IntSoftmax | n:  15
IntGELU    | n:  29
IntSoftmax | n:  15
IntGELU    | n:  29
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
................................calib done
Test: [  0/391]	Time  2.910 ( 2.910)	Acc@1  88.28 ( 88.28)	Acc@5  99.22 ( 99.22)
Test: [ 50/391]	Time  0.849 ( 0.891)	Acc@1  94.53 ( 83.07)	Acc@5  99.22 ( 95.88)
Test: [100/391]	Time  0.851 ( 0.871)	Acc@1  85.16 ( 81.89)	Acc@5  96.09 ( 96.10)
Test: [150/391]	Time  0.849 ( 0.864)	Acc@1  75.78 ( 81.93)	Acc@5  96.88 ( 96.27)
Test: [200/391]	Time  0.849 ( 0.860)	Acc@1  72.66 ( 79.41)	Acc@5  92.97 ( 94.85)
Test: [250/391]	Time  0.850 ( 0.858)	Acc@1  86.72 ( 78.09)	Acc@5  90.62 ( 94.02)
Test: [300/391]	Time  0.852 ( 0.857)	Acc@1  80.47 ( 77.09)	Acc@5  91.41 ( 93.42)
Test: [350/391]	Time  0.850 ( 0.856)	Acc@1  67.97 ( 76.34)	Acc@5  85.94 ( 93.00)
Test: [390/391]	Time  0.616 ( 0.855)	Acc@1  53.75 ( 76.31)	Acc@5  87.50 ( 93.02)
 * Prec@1 76.314 Prec@5 93.018
Time: 348.41
-----------------------------------------------------
