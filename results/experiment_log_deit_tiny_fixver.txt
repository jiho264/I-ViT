Running experiment with attn_quant=Symmetric_UINT4
Namespace(model='deit_tiny', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=1024, val_batchsize=128, num_workers=8, intsoftmax_exp_n=15, intgelu_exp_n=23, attn_quant='Symmetric_UINT4')
Model: deit_tiny_patch16_224
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 149
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : Symmetric_UINT4
    Number of QuantMatMul: 24
................................calib done
Test: [  0/391]	Time  3.631 ( 3.631)	Acc@1  37.50 ( 37.50)	Acc@5  55.47 ( 55.47)
Test: [ 50/391]	Time  1.213 ( 1.257)	Acc@1  28.91 ( 23.19)	Acc@5  60.94 ( 39.75)
Test: [100/391]	Time  1.425 ( 1.256)	Acc@1  30.47 ( 24.24)	Acc@5  57.81 ( 44.93)
Test: [150/391]	Time  1.205 ( 1.335)	Acc@1   5.47 ( 22.68)	Acc@5  18.75 ( 42.23)
Test: [200/391]	Time  1.200 ( 1.304)	Acc@1   1.56 ( 20.17)	Acc@5  13.28 ( 37.78)
Test: [250/391]	Time  1.202 ( 1.286)	Acc@1  12.50 ( 18.04)	Acc@5  28.12 ( 34.55)
Test: [300/391]	Time  1.221 ( 1.274)	Acc@1  16.41 ( 16.77)	Acc@5  32.81 ( 32.55)
Test: [350/391]	Time  1.203 ( 1.265)	Acc@1  13.28 ( 15.92)	Acc@5  31.25 ( 31.08)
Test: [390/391]	Time  1.015 ( 1.260)	Acc@1  10.00 ( 15.12)	Acc@5  18.75 ( 29.76)
 * Prec@1 15.120 Prec@5 29.760
Time: 514.78
-----------------------------------------------------
Running experiment with attn_quant=Symmetric_UINT8
Namespace(model='deit_tiny', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=1024, val_batchsize=128, num_workers=8, intsoftmax_exp_n=15, intgelu_exp_n=23, attn_quant='Symmetric_UINT8')
Model: deit_tiny_patch16_224
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 149
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : Symmetric_UINT8
    Number of QuantMatMul: 24
................................calib done
Test: [  0/391]	Time  3.727 ( 3.727)	Acc@1  89.84 ( 89.84)	Acc@5  96.09 ( 96.09)
Test: [ 50/391]	Time  0.746 ( 1.007)	Acc@1  90.62 ( 77.96)	Acc@5  96.88 ( 92.77)
Test: [100/391]	Time  1.230 ( 0.929)	Acc@1  79.69 ( 75.97)	Acc@5  94.53 ( 93.33)
Test: [150/391]	Time  1.211 ( 1.023)	Acc@1  67.97 ( 75.88)	Acc@5  94.53 ( 93.48)
Test: [200/391]	Time  1.205 ( 1.070)	Acc@1  61.72 ( 72.66)	Acc@5  92.97 ( 91.74)
Test: [250/391]	Time  1.199 ( 1.097)	Acc@1  81.25 ( 71.19)	Acc@5  91.41 ( 90.66)
Test: [300/391]	Time  1.208 ( 1.116)	Acc@1  71.09 ( 69.97)	Acc@5  84.38 ( 89.86)
Test: [350/391]	Time  1.202 ( 1.130)	Acc@1  65.62 ( 68.98)	Acc@5  85.94 ( 89.24)
Test: [390/391]	Time  0.999 ( 1.138)	Acc@1  45.00 ( 69.20)	Acc@5  80.00 ( 89.40)
 * Prec@1 69.198 Prec@5 89.396
Time: 478.83
-----------------------------------------------------
Running experiment with attn_quant=Log2_half_Int_Quantizer
Namespace(model='deit_tiny', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=1024, val_batchsize=128, num_workers=8, intsoftmax_exp_n=15, intgelu_exp_n=23, attn_quant='Log2_half_Int_Quantizer')
Model: deit_tiny_patch16_224
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 12
    - type : Log2_half_Int_Quantizer
    Number of QuantMatMul: 24
................................calib done
Test: [  0/391]	Time  4.105 ( 4.105)	Acc@1  89.84 ( 89.84)	Acc@5  96.88 ( 96.88)
Test: [ 50/391]	Time  1.602 ( 1.618)	Acc@1  89.84 ( 78.20)	Acc@5  98.44 ( 93.23)
Test: [100/391]	Time  1.573 ( 1.599)	Acc@1  80.47 ( 76.21)	Acc@5  93.75 ( 93.70)
Test: [150/391]	Time  1.113 ( 1.436)	Acc@1  71.09 ( 75.94)	Acc@5  96.09 ( 93.93)
Test: [200/391]	Time  1.702 ( 1.475)	Acc@1  60.94 ( 73.03)	Acc@5  91.41 ( 92.20)
Test: [250/391]	Time  1.669 ( 1.520)	Acc@1  83.59 ( 71.69)	Acc@5  92.19 ( 91.16)
Test: [300/391]	Time  1.696 ( 1.549)	Acc@1  73.44 ( 70.43)	Acc@5  85.94 ( 90.36)
Test: [350/391]	Time  1.688 ( 1.570)	Acc@1  69.53 ( 69.53)	Acc@5  85.94 ( 89.68)
Test: [390/391]	Time  1.390 ( 1.583)	Acc@1  46.25 ( 69.68)	Acc@5  81.25 ( 89.77)
 * Prec@1 69.680 Prec@5 89.772
Time: 655.56
-----------------------------------------------------
Running experiment with attn_quant=Log2_Int_Quantizer
Namespace(model='deit_tiny', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=1024, val_batchsize=128, num_workers=8, intsoftmax_exp_n=15, intgelu_exp_n=23, attn_quant='Log2_Int_Quantizer')
Model: deit_tiny_patch16_224
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : Log2_Int_Quantizer
    Number of QuantMatMul: 24
................................calib done
Test: [  0/391]	Time  3.786 ( 3.786)	Acc@1  58.59 ( 58.59)	Acc@5  81.25 ( 81.25)
Test: [ 50/391]	Time  1.679 ( 1.714)	Acc@1  72.66 ( 51.09)	Acc@5  91.41 ( 72.47)
Test: [100/391]	Time  1.684 ( 1.694)	Acc@1  41.41 ( 47.51)	Acc@5  70.31 ( 70.35)
Test: [150/391]	Time  1.664 ( 1.687)	Acc@1  50.00 ( 46.79)	Acc@5  74.22 ( 69.91)
Test: [200/391]	Time  1.695 ( 1.683)	Acc@1  25.00 ( 44.55)	Acc@5  50.00 ( 68.04)
Test: [250/391]	Time  1.637 ( 1.681)	Acc@1  64.84 ( 43.43)	Acc@5  81.25 ( 66.83)
Test: [300/391]	Time  0.794 ( 1.576)	Acc@1  43.75 ( 42.23)	Acc@5  72.66 ( 65.76)
Test: [350/391]	Time  1.689 ( 1.590)	Acc@1  21.09 ( 41.07)	Acc@5  44.53 ( 64.69)
Test: [390/391]	Time  1.370 ( 1.600)	Acc@1  21.25 ( 41.51)	Acc@5  51.25 ( 65.19)
 * Prec@1 41.506 Prec@5 65.190
Time: 666.60
-----------------------------------------------------
Running experiment with attn_quant=Log2_Int_Quantizer_nonscaling
Namespace(model='deit_tiny', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=1024, val_batchsize=128, num_workers=8, intsoftmax_exp_n=15, intgelu_exp_n=23, attn_quant='Log2_Int_Quantizer_nonscaling')
Model: deit_tiny_patch16_224
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : Log2_Int_Quantizer_nonscaling
    Number of QuantMatMul: 24
................................calib done
Test: [  0/391]	Time  3.932 ( 3.932)	Acc@1  87.50 ( 87.50)	Acc@5  97.66 ( 97.66)
Test: [ 50/391]	Time  1.666 ( 1.686)	Acc@1  84.38 ( 72.79)	Acc@5  96.09 ( 90.84)
Test: [100/391]	Time  1.672 ( 1.666)	Acc@1  78.12 ( 71.60)	Acc@5  94.53 ( 91.61)
Test: [150/391]	Time  1.643 ( 1.657)	Acc@1  64.84 ( 71.57)	Acc@5  95.31 ( 91.67)
Test: [200/391]	Time  1.642 ( 1.654)	Acc@1  45.31 ( 67.63)	Acc@5  76.56 ( 88.99)
Test: [250/391]	Time  1.652 ( 1.651)	Acc@1  75.78 ( 65.91)	Acc@5  86.72 ( 87.47)
Test: [300/391]	Time  1.646 ( 1.651)	Acc@1  63.28 ( 64.36)	Acc@5  78.12 ( 86.25)
Test: [350/391]	Time  1.658 ( 1.650)	Acc@1  69.53 ( 63.13)	Acc@5  83.59 ( 85.31)
Test: [390/391]	Time  1.310 ( 1.649)	Acc@1  37.50 ( 63.33)	Acc@5  73.75 ( 85.46)
 * Prec@1 63.328 Prec@5 85.462
Time: 685.71
-----------------------------------------------------
Running experiment with attn_quant=Log2Quantizer
Namespace(model='deit_tiny', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=1024, val_batchsize=128, num_workers=8, intsoftmax_exp_n=15, intgelu_exp_n=23, attn_quant='Log2Quantizer')
Model: deit_tiny_patch16_224
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : Log2Quantizer
    Number of QuantMatMul: 24
................................calib done
Test: [  0/391]	Time  3.489 ( 3.489)	Acc@1  88.28 ( 88.28)	Acc@5  96.09 ( 96.09)
Test: [ 50/391]	Time  1.285 ( 0.889)	Acc@1  89.84 ( 76.41)	Acc@5  96.88 ( 92.31)
Test: [100/391]	Time  1.297 ( 1.102)	Acc@1  77.34 ( 74.75)	Acc@5  95.31 ( 92.84)
Test: [150/391]	Time  1.342 ( 1.175)	Acc@1  66.41 ( 74.69)	Acc@5  94.53 ( 92.96)
Test: [200/391]	Time  1.318 ( 1.211)	Acc@1  57.81 ( 71.42)	Acc@5  89.06 ( 91.06)
Test: [250/391]	Time  1.321 ( 1.232)	Acc@1  79.69 ( 69.86)	Acc@5  92.19 ( 89.87)
Test: [300/391]	Time  1.333 ( 1.247)	Acc@1  72.66 ( 68.57)	Acc@5  84.38 ( 89.02)
Test: [350/391]	Time  1.333 ( 1.257)	Acc@1  63.28 ( 67.54)	Acc@5  84.38 ( 88.31)
Test: [390/391]	Time  1.133 ( 1.263)	Acc@1  43.75 ( 67.69)	Acc@5  81.25 ( 88.50)
 * Prec@1 67.694 Prec@5 88.498
Time: 512.42
-----------------------------------------------------
Running experiment with attn_quant=LogSqrt2Quantizer
Namespace(model='deit_tiny', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=1024, val_batchsize=128, num_workers=8, intsoftmax_exp_n=15, intgelu_exp_n=23, attn_quant='LogSqrt2Quantizer')
Model: deit_tiny_patch16_224
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : LogSqrt2Quantizer
    Number of QuantMatMul: 24
................................calib done
Test: [  0/391]	Time  3.686 ( 3.686)	Acc@1  88.28 ( 88.28)	Acc@5  96.09 ( 96.09)
Test: [ 50/391]	Time  1.377 ( 1.384)	Acc@1  89.06 ( 77.96)	Acc@5  96.88 ( 93.23)
Test: [100/391]	Time  1.345 ( 1.359)	Acc@1  80.47 ( 76.01)	Acc@5  94.53 ( 93.63)
Test: [150/391]	Time  1.343 ( 1.351)	Acc@1  69.53 ( 75.87)	Acc@5  95.31 ( 93.72)
Test: [200/391]	Time  0.476 ( 1.336)	Acc@1  60.94 ( 72.81)	Acc@5  88.28 ( 91.86)
Test: [250/391]	Time  0.777 ( 1.205)	Acc@1  81.25 ( 71.31)	Acc@5  92.97 ( 90.82)
Test: [300/391]	Time  1.190 ( 1.200)	Acc@1  71.88 ( 69.99)	Acc@5  84.38 ( 89.93)
Test: [350/391]	Time  1.192 ( 1.199)	Acc@1  71.09 ( 69.06)	Acc@5  88.28 ( 89.29)
Test: [390/391]	Time  1.010 ( 1.198)	Acc@1  43.75 ( 69.19)	Acc@5  80.00 ( 89.40)
 * Prec@1 69.188 Prec@5 89.396
Time: 506.47
-----------------------------------------------------
Running experiment with attn_quant=NoQuant
Namespace(model='deit_tiny', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=1024, val_batchsize=128, num_workers=8, intsoftmax_exp_n=15, intgelu_exp_n=23, attn_quant='NoQuant')
Model: deit_tiny_patch16_224
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
................................calib done
Test: [  0/391]	Time  3.628 ( 3.628)	Acc@1  89.06 ( 89.06)	Acc@5  96.88 ( 96.88)
Test: [ 50/391]	Time  1.139 ( 1.194)	Acc@1  90.62 ( 77.96)	Acc@5  96.88 ( 93.31)
Test: [100/391]	Time  1.152 ( 1.170)	Acc@1  76.56 ( 76.20)	Acc@5  94.53 ( 93.69)
Test: [150/391]	Time  1.150 ( 1.161)	Acc@1  68.75 ( 76.22)	Acc@5  95.31 ( 93.74)
Test: [200/391]	Time  1.169 ( 1.157)	Acc@1  61.72 ( 73.01)	Acc@5  91.41 ( 92.00)
Test: [250/391]	Time  1.147 ( 1.154)	Acc@1  82.03 ( 71.50)	Acc@5  91.41 ( 91.01)
Test: [300/391]	Time  1.133 ( 1.152)	Acc@1  72.66 ( 70.31)	Acc@5  85.16 ( 90.15)
Test: [350/391]	Time  0.724 ( 1.093)	Acc@1  70.31 ( 69.29)	Acc@5  85.94 ( 89.51)
Test: [390/391]	Time  0.967 ( 1.075)	Acc@1  48.75 ( 69.50)	Acc@5  78.75 ( 89.65)
 * Prec@1 69.498 Prec@5 89.652
Time: 452.75
-----------------------------------------------------
