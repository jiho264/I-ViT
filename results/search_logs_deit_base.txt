Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=0, intgelu_exp_n=0
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=0, intgelu_exp_n=0, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  0
IntGELU    | n:  0
IntSoftmax | n:  0
IntGELU    | n:  0
IntSoftmax | n:  0
IntGELU    | n:  0
IntSoftmax | n:  0
IntGELU    | n:  0
IntSoftmax | n:  0
IntGELU    | n:  0
IntSoftmax | n:  0
IntGELU    | n:  0
IntSoftmax | n:  0
IntGELU    | n:  0
IntSoftmax | n:  0
IntGELU    | n:  0
IntSoftmax | n:  0
IntGELU    | n:  0
IntSoftmax | n:  0
IntGELU    | n:  0
IntSoftmax | n:  0
IntGELU    | n:  0
IntSoftmax | n:  0
IntGELU    | n:  0
.calib done
Test: [  0/391]	Time  3.949 ( 3.949)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.89
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=0, intgelu_exp_n=1
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=0, intgelu_exp_n=1, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  0
IntGELU    | n:  1
IntSoftmax | n:  0
IntGELU    | n:  1
IntSoftmax | n:  0
IntGELU    | n:  1
IntSoftmax | n:  0
IntGELU    | n:  1
IntSoftmax | n:  0
IntGELU    | n:  1
IntSoftmax | n:  0
IntGELU    | n:  1
IntSoftmax | n:  0
IntGELU    | n:  1
IntSoftmax | n:  0
IntGELU    | n:  1
IntSoftmax | n:  0
IntGELU    | n:  1
IntSoftmax | n:  0
IntGELU    | n:  1
IntSoftmax | n:  0
IntGELU    | n:  1
IntSoftmax | n:  0
IntGELU    | n:  1
.calib done
Test: [  0/391]	Time  3.868 ( 3.868)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.80
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=0, intgelu_exp_n=2
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=0, intgelu_exp_n=2, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  0
IntGELU    | n:  2
IntSoftmax | n:  0
IntGELU    | n:  2
IntSoftmax | n:  0
IntGELU    | n:  2
IntSoftmax | n:  0
IntGELU    | n:  2
IntSoftmax | n:  0
IntGELU    | n:  2
IntSoftmax | n:  0
IntGELU    | n:  2
IntSoftmax | n:  0
IntGELU    | n:  2
IntSoftmax | n:  0
IntGELU    | n:  2
IntSoftmax | n:  0
IntGELU    | n:  2
IntSoftmax | n:  0
IntGELU    | n:  2
IntSoftmax | n:  0
IntGELU    | n:  2
IntSoftmax | n:  0
IntGELU    | n:  2
.calib done
Test: [  0/391]	Time  3.986 ( 3.986)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.99
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=0, intgelu_exp_n=3
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=0, intgelu_exp_n=3, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  0
IntGELU    | n:  3
IntSoftmax | n:  0
IntGELU    | n:  3
IntSoftmax | n:  0
IntGELU    | n:  3
IntSoftmax | n:  0
IntGELU    | n:  3
IntSoftmax | n:  0
IntGELU    | n:  3
IntSoftmax | n:  0
IntGELU    | n:  3
IntSoftmax | n:  0
IntGELU    | n:  3
IntSoftmax | n:  0
IntGELU    | n:  3
IntSoftmax | n:  0
IntGELU    | n:  3
IntSoftmax | n:  0
IntGELU    | n:  3
IntSoftmax | n:  0
IntGELU    | n:  3
IntSoftmax | n:  0
IntGELU    | n:  3
.calib done
Test: [  0/391]	Time  3.851 ( 3.851)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.75
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=0, intgelu_exp_n=4
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=0, intgelu_exp_n=4, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  0
IntGELU    | n:  4
IntSoftmax | n:  0
IntGELU    | n:  4
IntSoftmax | n:  0
IntGELU    | n:  4
IntSoftmax | n:  0
IntGELU    | n:  4
IntSoftmax | n:  0
IntGELU    | n:  4
IntSoftmax | n:  0
IntGELU    | n:  4
IntSoftmax | n:  0
IntGELU    | n:  4
IntSoftmax | n:  0
IntGELU    | n:  4
IntSoftmax | n:  0
IntGELU    | n:  4
IntSoftmax | n:  0
IntGELU    | n:  4
IntSoftmax | n:  0
IntGELU    | n:  4
IntSoftmax | n:  0
IntGELU    | n:  4
.calib done
Test: [  0/391]	Time  3.864 ( 3.864)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.78
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=0, intgelu_exp_n=5
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=0, intgelu_exp_n=5, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  0
IntGELU    | n:  5
IntSoftmax | n:  0
IntGELU    | n:  5
IntSoftmax | n:  0
IntGELU    | n:  5
IntSoftmax | n:  0
IntGELU    | n:  5
IntSoftmax | n:  0
IntGELU    | n:  5
IntSoftmax | n:  0
IntGELU    | n:  5
IntSoftmax | n:  0
IntGELU    | n:  5
IntSoftmax | n:  0
IntGELU    | n:  5
IntSoftmax | n:  0
IntGELU    | n:  5
IntSoftmax | n:  0
IntGELU    | n:  5
IntSoftmax | n:  0
IntGELU    | n:  5
IntSoftmax | n:  0
IntGELU    | n:  5
.calib done
Test: [  0/391]	Time  3.906 ( 3.906)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.84
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=0, intgelu_exp_n=6
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=0, intgelu_exp_n=6, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  0
IntGELU    | n:  6
IntSoftmax | n:  0
IntGELU    | n:  6
IntSoftmax | n:  0
IntGELU    | n:  6
IntSoftmax | n:  0
IntGELU    | n:  6
IntSoftmax | n:  0
IntGELU    | n:  6
IntSoftmax | n:  0
IntGELU    | n:  6
IntSoftmax | n:  0
IntGELU    | n:  6
IntSoftmax | n:  0
IntGELU    | n:  6
IntSoftmax | n:  0
IntGELU    | n:  6
IntSoftmax | n:  0
IntGELU    | n:  6
IntSoftmax | n:  0
IntGELU    | n:  6
IntSoftmax | n:  0
IntGELU    | n:  6
.calib done
Test: [  0/391]	Time  3.908 ( 3.908)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.82
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=0, intgelu_exp_n=7
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=0, intgelu_exp_n=7, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  0
IntGELU    | n:  7
IntSoftmax | n:  0
IntGELU    | n:  7
IntSoftmax | n:  0
IntGELU    | n:  7
IntSoftmax | n:  0
IntGELU    | n:  7
IntSoftmax | n:  0
IntGELU    | n:  7
IntSoftmax | n:  0
IntGELU    | n:  7
IntSoftmax | n:  0
IntGELU    | n:  7
IntSoftmax | n:  0
IntGELU    | n:  7
IntSoftmax | n:  0
IntGELU    | n:  7
IntSoftmax | n:  0
IntGELU    | n:  7
IntSoftmax | n:  0
IntGELU    | n:  7
IntSoftmax | n:  0
IntGELU    | n:  7
.calib done
Test: [  0/391]	Time  3.795 ( 3.795)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.73
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=0, intgelu_exp_n=8
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=0, intgelu_exp_n=8, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  0
IntGELU    | n:  8
IntSoftmax | n:  0
IntGELU    | n:  8
IntSoftmax | n:  0
IntGELU    | n:  8
IntSoftmax | n:  0
IntGELU    | n:  8
IntSoftmax | n:  0
IntGELU    | n:  8
IntSoftmax | n:  0
IntGELU    | n:  8
IntSoftmax | n:  0
IntGELU    | n:  8
IntSoftmax | n:  0
IntGELU    | n:  8
IntSoftmax | n:  0
IntGELU    | n:  8
IntSoftmax | n:  0
IntGELU    | n:  8
IntSoftmax | n:  0
IntGELU    | n:  8
IntSoftmax | n:  0
IntGELU    | n:  8
.calib done
Test: [  0/391]	Time  3.912 ( 3.912)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.84
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=0, intgelu_exp_n=9
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=0, intgelu_exp_n=9, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  0
IntGELU    | n:  9
IntSoftmax | n:  0
IntGELU    | n:  9
IntSoftmax | n:  0
IntGELU    | n:  9
IntSoftmax | n:  0
IntGELU    | n:  9
IntSoftmax | n:  0
IntGELU    | n:  9
IntSoftmax | n:  0
IntGELU    | n:  9
IntSoftmax | n:  0
IntGELU    | n:  9
IntSoftmax | n:  0
IntGELU    | n:  9
IntSoftmax | n:  0
IntGELU    | n:  9
IntSoftmax | n:  0
IntGELU    | n:  9
IntSoftmax | n:  0
IntGELU    | n:  9
IntSoftmax | n:  0
IntGELU    | n:  9
.calib done
Test: [  0/391]	Time  3.847 ( 3.847)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.77
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=0, intgelu_exp_n=10
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=0, intgelu_exp_n=10, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  0
IntGELU    | n:  10
IntSoftmax | n:  0
IntGELU    | n:  10
IntSoftmax | n:  0
IntGELU    | n:  10
IntSoftmax | n:  0
IntGELU    | n:  10
IntSoftmax | n:  0
IntGELU    | n:  10
IntSoftmax | n:  0
IntGELU    | n:  10
IntSoftmax | n:  0
IntGELU    | n:  10
IntSoftmax | n:  0
IntGELU    | n:  10
IntSoftmax | n:  0
IntGELU    | n:  10
IntSoftmax | n:  0
IntGELU    | n:  10
IntSoftmax | n:  0
IntGELU    | n:  10
IntSoftmax | n:  0
IntGELU    | n:  10
.calib done
Test: [  0/391]	Time  3.883 ( 3.883)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.80
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=0, intgelu_exp_n=11
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=0, intgelu_exp_n=11, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  0
IntGELU    | n:  11
IntSoftmax | n:  0
IntGELU    | n:  11
IntSoftmax | n:  0
IntGELU    | n:  11
IntSoftmax | n:  0
IntGELU    | n:  11
IntSoftmax | n:  0
IntGELU    | n:  11
IntSoftmax | n:  0
IntGELU    | n:  11
IntSoftmax | n:  0
IntGELU    | n:  11
IntSoftmax | n:  0
IntGELU    | n:  11
IntSoftmax | n:  0
IntGELU    | n:  11
IntSoftmax | n:  0
IntGELU    | n:  11
IntSoftmax | n:  0
IntGELU    | n:  11
IntSoftmax | n:  0
IntGELU    | n:  11
.calib done
Test: [  0/391]	Time  3.867 ( 3.867)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.74
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=0, intgelu_exp_n=12
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=0, intgelu_exp_n=12, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  0
IntGELU    | n:  12
IntSoftmax | n:  0
IntGELU    | n:  12
IntSoftmax | n:  0
IntGELU    | n:  12
IntSoftmax | n:  0
IntGELU    | n:  12
IntSoftmax | n:  0
IntGELU    | n:  12
IntSoftmax | n:  0
IntGELU    | n:  12
IntSoftmax | n:  0
IntGELU    | n:  12
IntSoftmax | n:  0
IntGELU    | n:  12
IntSoftmax | n:  0
IntGELU    | n:  12
IntSoftmax | n:  0
IntGELU    | n:  12
IntSoftmax | n:  0
IntGELU    | n:  12
IntSoftmax | n:  0
IntGELU    | n:  12
.calib done
Test: [  0/391]	Time  3.955 ( 3.955)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.92
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=0, intgelu_exp_n=13
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=0, intgelu_exp_n=13, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  0
IntGELU    | n:  13
IntSoftmax | n:  0
IntGELU    | n:  13
IntSoftmax | n:  0
IntGELU    | n:  13
IntSoftmax | n:  0
IntGELU    | n:  13
IntSoftmax | n:  0
IntGELU    | n:  13
IntSoftmax | n:  0
IntGELU    | n:  13
IntSoftmax | n:  0
IntGELU    | n:  13
IntSoftmax | n:  0
IntGELU    | n:  13
IntSoftmax | n:  0
IntGELU    | n:  13
IntSoftmax | n:  0
IntGELU    | n:  13
IntSoftmax | n:  0
IntGELU    | n:  13
IntSoftmax | n:  0
IntGELU    | n:  13
.calib done
Test: [  0/391]	Time  3.842 ( 3.842)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.80
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=0, intgelu_exp_n=14
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=0, intgelu_exp_n=14, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  0
IntGELU    | n:  14
IntSoftmax | n:  0
IntGELU    | n:  14
IntSoftmax | n:  0
IntGELU    | n:  14
IntSoftmax | n:  0
IntGELU    | n:  14
IntSoftmax | n:  0
IntGELU    | n:  14
IntSoftmax | n:  0
IntGELU    | n:  14
IntSoftmax | n:  0
IntGELU    | n:  14
IntSoftmax | n:  0
IntGELU    | n:  14
IntSoftmax | n:  0
IntGELU    | n:  14
IntSoftmax | n:  0
IntGELU    | n:  14
IntSoftmax | n:  0
IntGELU    | n:  14
IntSoftmax | n:  0
IntGELU    | n:  14
.calib done
Test: [  0/391]	Time  3.675 ( 3.675)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.64
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=0, intgelu_exp_n=15
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=0, intgelu_exp_n=15, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  0
IntGELU    | n:  15
IntSoftmax | n:  0
IntGELU    | n:  15
IntSoftmax | n:  0
IntGELU    | n:  15
IntSoftmax | n:  0
IntGELU    | n:  15
IntSoftmax | n:  0
IntGELU    | n:  15
IntSoftmax | n:  0
IntGELU    | n:  15
IntSoftmax | n:  0
IntGELU    | n:  15
IntSoftmax | n:  0
IntGELU    | n:  15
IntSoftmax | n:  0
IntGELU    | n:  15
IntSoftmax | n:  0
IntGELU    | n:  15
IntSoftmax | n:  0
IntGELU    | n:  15
IntSoftmax | n:  0
IntGELU    | n:  15
.calib done
Test: [  0/391]	Time  3.895 ( 3.895)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.79
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=0, intgelu_exp_n=16
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=0, intgelu_exp_n=16, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  0
IntGELU    | n:  16
IntSoftmax | n:  0
IntGELU    | n:  16
IntSoftmax | n:  0
IntGELU    | n:  16
IntSoftmax | n:  0
IntGELU    | n:  16
IntSoftmax | n:  0
IntGELU    | n:  16
IntSoftmax | n:  0
IntGELU    | n:  16
IntSoftmax | n:  0
IntGELU    | n:  16
IntSoftmax | n:  0
IntGELU    | n:  16
IntSoftmax | n:  0
IntGELU    | n:  16
IntSoftmax | n:  0
IntGELU    | n:  16
IntSoftmax | n:  0
IntGELU    | n:  16
IntSoftmax | n:  0
IntGELU    | n:  16
.calib done
Test: [  0/391]	Time  3.629 ( 3.629)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.58
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=0, intgelu_exp_n=17
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=0, intgelu_exp_n=17, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  0
IntGELU    | n:  17
IntSoftmax | n:  0
IntGELU    | n:  17
IntSoftmax | n:  0
IntGELU    | n:  17
IntSoftmax | n:  0
IntGELU    | n:  17
IntSoftmax | n:  0
IntGELU    | n:  17
IntSoftmax | n:  0
IntGELU    | n:  17
IntSoftmax | n:  0
IntGELU    | n:  17
IntSoftmax | n:  0
IntGELU    | n:  17
IntSoftmax | n:  0
IntGELU    | n:  17
IntSoftmax | n:  0
IntGELU    | n:  17
IntSoftmax | n:  0
IntGELU    | n:  17
IntSoftmax | n:  0
IntGELU    | n:  17
.calib done
Test: [  0/391]	Time  3.821 ( 3.821)	Acc@1   0.00 (  0.00)	Acc@5   0.78 (  0.78)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.781
Time: 8.73
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=0, intgelu_exp_n=18
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=0, intgelu_exp_n=18, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  0
IntGELU    | n:  18
IntSoftmax | n:  0
IntGELU    | n:  18
IntSoftmax | n:  0
IntGELU    | n:  18
IntSoftmax | n:  0
IntGELU    | n:  18
IntSoftmax | n:  0
IntGELU    | n:  18
IntSoftmax | n:  0
IntGELU    | n:  18
IntSoftmax | n:  0
IntGELU    | n:  18
IntSoftmax | n:  0
IntGELU    | n:  18
IntSoftmax | n:  0
IntGELU    | n:  18
IntSoftmax | n:  0
IntGELU    | n:  18
IntSoftmax | n:  0
IntGELU    | n:  18
IntSoftmax | n:  0
IntGELU    | n:  18
.calib done
Test: [  0/391]	Time  3.793 ( 3.793)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.80
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=0, intgelu_exp_n=19
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=0, intgelu_exp_n=19, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  0
IntGELU    | n:  19
IntSoftmax | n:  0
IntGELU    | n:  19
IntSoftmax | n:  0
IntGELU    | n:  19
IntSoftmax | n:  0
IntGELU    | n:  19
IntSoftmax | n:  0
IntGELU    | n:  19
IntSoftmax | n:  0
IntGELU    | n:  19
IntSoftmax | n:  0
IntGELU    | n:  19
IntSoftmax | n:  0
IntGELU    | n:  19
IntSoftmax | n:  0
IntGELU    | n:  19
IntSoftmax | n:  0
IntGELU    | n:  19
IntSoftmax | n:  0
IntGELU    | n:  19
IntSoftmax | n:  0
IntGELU    | n:  19
.calib done
Test: [  0/391]	Time  3.961 ( 3.961)	Acc@1   0.00 (  0.00)	Acc@5   1.56 (  1.56)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 1.562
Time: 8.91
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=0, intgelu_exp_n=20
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=0, intgelu_exp_n=20, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  0
IntGELU    | n:  20
IntSoftmax | n:  0
IntGELU    | n:  20
IntSoftmax | n:  0
IntGELU    | n:  20
IntSoftmax | n:  0
IntGELU    | n:  20
IntSoftmax | n:  0
IntGELU    | n:  20
IntSoftmax | n:  0
IntGELU    | n:  20
IntSoftmax | n:  0
IntGELU    | n:  20
IntSoftmax | n:  0
IntGELU    | n:  20
IntSoftmax | n:  0
IntGELU    | n:  20
IntSoftmax | n:  0
IntGELU    | n:  20
IntSoftmax | n:  0
IntGELU    | n:  20
IntSoftmax | n:  0
IntGELU    | n:  20
.calib done
Test: [  0/391]	Time  3.929 ( 3.929)	Acc@1   0.00 (  0.00)	Acc@5   2.34 (  2.34)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 2.344
Time: 8.91
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=0, intgelu_exp_n=21
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=0, intgelu_exp_n=21, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  0
IntGELU    | n:  21
IntSoftmax | n:  0
IntGELU    | n:  21
IntSoftmax | n:  0
IntGELU    | n:  21
IntSoftmax | n:  0
IntGELU    | n:  21
IntSoftmax | n:  0
IntGELU    | n:  21
IntSoftmax | n:  0
IntGELU    | n:  21
IntSoftmax | n:  0
IntGELU    | n:  21
IntSoftmax | n:  0
IntGELU    | n:  21
IntSoftmax | n:  0
IntGELU    | n:  21
IntSoftmax | n:  0
IntGELU    | n:  21
IntSoftmax | n:  0
IntGELU    | n:  21
IntSoftmax | n:  0
IntGELU    | n:  21
.calib done
Test: [  0/391]	Time  3.669 ( 3.669)	Acc@1   0.00 (  0.00)	Acc@5   0.78 (  0.78)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.781
Time: 8.64
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=0, intgelu_exp_n=22
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=0, intgelu_exp_n=22, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  0
IntGELU    | n:  22
IntSoftmax | n:  0
IntGELU    | n:  22
IntSoftmax | n:  0
IntGELU    | n:  22
IntSoftmax | n:  0
IntGELU    | n:  22
IntSoftmax | n:  0
IntGELU    | n:  22
IntSoftmax | n:  0
IntGELU    | n:  22
IntSoftmax | n:  0
IntGELU    | n:  22
IntSoftmax | n:  0
IntGELU    | n:  22
IntSoftmax | n:  0
IntGELU    | n:  22
IntSoftmax | n:  0
IntGELU    | n:  22
IntSoftmax | n:  0
IntGELU    | n:  22
IntSoftmax | n:  0
IntGELU    | n:  22
.calib done
Test: [  0/391]	Time  3.803 ( 3.803)	Acc@1   0.00 (  0.00)	Acc@5   3.12 (  3.12)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 3.125
Time: 8.78
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=0, intgelu_exp_n=23
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=0, intgelu_exp_n=23, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  0
IntGELU    | n:  23
IntSoftmax | n:  0
IntGELU    | n:  23
IntSoftmax | n:  0
IntGELU    | n:  23
IntSoftmax | n:  0
IntGELU    | n:  23
IntSoftmax | n:  0
IntGELU    | n:  23
IntSoftmax | n:  0
IntGELU    | n:  23
IntSoftmax | n:  0
IntGELU    | n:  23
IntSoftmax | n:  0
IntGELU    | n:  23
IntSoftmax | n:  0
IntGELU    | n:  23
IntSoftmax | n:  0
IntGELU    | n:  23
IntSoftmax | n:  0
IntGELU    | n:  23
IntSoftmax | n:  0
IntGELU    | n:  23
.calib done
Test: [  0/391]	Time  3.890 ( 3.890)	Acc@1   0.00 (  0.00)	Acc@5   2.34 (  2.34)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 2.344
Time: 8.83
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=0, intgelu_exp_n=24
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=0, intgelu_exp_n=24, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  0
IntGELU    | n:  24
IntSoftmax | n:  0
IntGELU    | n:  24
IntSoftmax | n:  0
IntGELU    | n:  24
IntSoftmax | n:  0
IntGELU    | n:  24
IntSoftmax | n:  0
IntGELU    | n:  24
IntSoftmax | n:  0
IntGELU    | n:  24
IntSoftmax | n:  0
IntGELU    | n:  24
IntSoftmax | n:  0
IntGELU    | n:  24
IntSoftmax | n:  0
IntGELU    | n:  24
IntSoftmax | n:  0
IntGELU    | n:  24
IntSoftmax | n:  0
IntGELU    | n:  24
IntSoftmax | n:  0
IntGELU    | n:  24
.calib done
Test: [  0/391]	Time  3.660 ( 3.660)	Acc@1   0.00 (  0.00)	Acc@5   3.12 (  3.12)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 3.125
Time: 8.56
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=0, intgelu_exp_n=25
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=0, intgelu_exp_n=25, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  0
IntGELU    | n:  25
IntSoftmax | n:  0
IntGELU    | n:  25
IntSoftmax | n:  0
IntGELU    | n:  25
IntSoftmax | n:  0
IntGELU    | n:  25
IntSoftmax | n:  0
IntGELU    | n:  25
IntSoftmax | n:  0
IntGELU    | n:  25
IntSoftmax | n:  0
IntGELU    | n:  25
IntSoftmax | n:  0
IntGELU    | n:  25
IntSoftmax | n:  0
IntGELU    | n:  25
IntSoftmax | n:  0
IntGELU    | n:  25
IntSoftmax | n:  0
IntGELU    | n:  25
IntSoftmax | n:  0
IntGELU    | n:  25
.calib done
Test: [  0/391]	Time  3.994 ( 3.994)	Acc@1   0.00 (  0.00)	Acc@5   5.47 (  5.47)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 5.469
Time: 8.96
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=0, intgelu_exp_n=26
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=0, intgelu_exp_n=26, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  0
IntGELU    | n:  26
IntSoftmax | n:  0
IntGELU    | n:  26
IntSoftmax | n:  0
IntGELU    | n:  26
IntSoftmax | n:  0
IntGELU    | n:  26
IntSoftmax | n:  0
IntGELU    | n:  26
IntSoftmax | n:  0
IntGELU    | n:  26
IntSoftmax | n:  0
IntGELU    | n:  26
IntSoftmax | n:  0
IntGELU    | n:  26
IntSoftmax | n:  0
IntGELU    | n:  26
IntSoftmax | n:  0
IntGELU    | n:  26
IntSoftmax | n:  0
IntGELU    | n:  26
IntSoftmax | n:  0
IntGELU    | n:  26
.calib done
Test: [  0/391]	Time  3.945 ( 3.945)	Acc@1   0.00 (  0.00)	Acc@5   3.91 (  3.91)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 3.906
Time: 8.90
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=0, intgelu_exp_n=27
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=0, intgelu_exp_n=27, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  0
IntGELU    | n:  27
IntSoftmax | n:  0
IntGELU    | n:  27
IntSoftmax | n:  0
IntGELU    | n:  27
IntSoftmax | n:  0
IntGELU    | n:  27
IntSoftmax | n:  0
IntGELU    | n:  27
IntSoftmax | n:  0
IntGELU    | n:  27
IntSoftmax | n:  0
IntGELU    | n:  27
IntSoftmax | n:  0
IntGELU    | n:  27
IntSoftmax | n:  0
IntGELU    | n:  27
IntSoftmax | n:  0
IntGELU    | n:  27
IntSoftmax | n:  0
IntGELU    | n:  27
IntSoftmax | n:  0
IntGELU    | n:  27
.calib done
Test: [  0/391]	Time  3.883 ( 3.883)	Acc@1   0.00 (  0.00)	Acc@5   3.12 (  3.12)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 3.125
Time: 8.79
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=0, intgelu_exp_n=28
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=0, intgelu_exp_n=28, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  0
IntGELU    | n:  28
IntSoftmax | n:  0
IntGELU    | n:  28
IntSoftmax | n:  0
IntGELU    | n:  28
IntSoftmax | n:  0
IntGELU    | n:  28
IntSoftmax | n:  0
IntGELU    | n:  28
IntSoftmax | n:  0
IntGELU    | n:  28
IntSoftmax | n:  0
IntGELU    | n:  28
IntSoftmax | n:  0
IntGELU    | n:  28
IntSoftmax | n:  0
IntGELU    | n:  28
IntSoftmax | n:  0
IntGELU    | n:  28
IntSoftmax | n:  0
IntGELU    | n:  28
IntSoftmax | n:  0
IntGELU    | n:  28
.calib done
Test: [  0/391]	Time  3.991 ( 3.991)	Acc@1   0.00 (  0.00)	Acc@5   4.69 (  4.69)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 4.688
Time: 8.92
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=0, intgelu_exp_n=29
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=0, intgelu_exp_n=29, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  0
IntGELU    | n:  29
IntSoftmax | n:  0
IntGELU    | n:  29
IntSoftmax | n:  0
IntGELU    | n:  29
IntSoftmax | n:  0
IntGELU    | n:  29
IntSoftmax | n:  0
IntGELU    | n:  29
IntSoftmax | n:  0
IntGELU    | n:  29
IntSoftmax | n:  0
IntGELU    | n:  29
IntSoftmax | n:  0
IntGELU    | n:  29
IntSoftmax | n:  0
IntGELU    | n:  29
IntSoftmax | n:  0
IntGELU    | n:  29
IntSoftmax | n:  0
IntGELU    | n:  29
IntSoftmax | n:  0
IntGELU    | n:  29
.calib done
Test: [  0/391]	Time  3.785 ( 3.785)	Acc@1   0.00 (  0.00)	Acc@5   0.78 (  0.78)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.781
Time: 8.72
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=0, intgelu_exp_n=30
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=0, intgelu_exp_n=30, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  0
IntGELU    | n:  30
IntSoftmax | n:  0
IntGELU    | n:  30
IntSoftmax | n:  0
IntGELU    | n:  30
IntSoftmax | n:  0
IntGELU    | n:  30
IntSoftmax | n:  0
IntGELU    | n:  30
IntSoftmax | n:  0
IntGELU    | n:  30
IntSoftmax | n:  0
IntGELU    | n:  30
IntSoftmax | n:  0
IntGELU    | n:  30
IntSoftmax | n:  0
IntGELU    | n:  30
IntSoftmax | n:  0
IntGELU    | n:  30
IntSoftmax | n:  0
IntGELU    | n:  30
IntSoftmax | n:  0
IntGELU    | n:  30
.calib done
Test: [  0/391]	Time  3.648 ( 3.648)	Acc@1   3.12 (  3.12)	Acc@5   6.25 (  6.25)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 3.125 Prec@5 6.250
Time: 8.60
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=0, intgelu_exp_n=31
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=0, intgelu_exp_n=31, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  0
IntGELU    | n:  31
IntSoftmax | n:  0
IntGELU    | n:  31
IntSoftmax | n:  0
IntGELU    | n:  31
IntSoftmax | n:  0
IntGELU    | n:  31
IntSoftmax | n:  0
IntGELU    | n:  31
IntSoftmax | n:  0
IntGELU    | n:  31
IntSoftmax | n:  0
IntGELU    | n:  31
IntSoftmax | n:  0
IntGELU    | n:  31
IntSoftmax | n:  0
IntGELU    | n:  31
IntSoftmax | n:  0
IntGELU    | n:  31
IntSoftmax | n:  0
IntGELU    | n:  31
IntSoftmax | n:  0
IntGELU    | n:  31
.calib done
Test: [  0/391]	Time  3.914 ( 3.914)	Acc@1   0.78 (  0.78)	Acc@5   0.78 (  0.78)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.781 Prec@5 0.781
Time: 8.89
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=1, intgelu_exp_n=0
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=1, intgelu_exp_n=0, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  1
IntGELU    | n:  0
IntSoftmax | n:  1
IntGELU    | n:  0
IntSoftmax | n:  1
IntGELU    | n:  0
IntSoftmax | n:  1
IntGELU    | n:  0
IntSoftmax | n:  1
IntGELU    | n:  0
IntSoftmax | n:  1
IntGELU    | n:  0
IntSoftmax | n:  1
IntGELU    | n:  0
IntSoftmax | n:  1
IntGELU    | n:  0
IntSoftmax | n:  1
IntGELU    | n:  0
IntSoftmax | n:  1
IntGELU    | n:  0
IntSoftmax | n:  1
IntGELU    | n:  0
IntSoftmax | n:  1
IntGELU    | n:  0
.calib done
Test: [  0/391]	Time  3.845 ( 3.845)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.81
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=1, intgelu_exp_n=1
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=1, intgelu_exp_n=1, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  1
IntGELU    | n:  1
IntSoftmax | n:  1
IntGELU    | n:  1
IntSoftmax | n:  1
IntGELU    | n:  1
IntSoftmax | n:  1
IntGELU    | n:  1
IntSoftmax | n:  1
IntGELU    | n:  1
IntSoftmax | n:  1
IntGELU    | n:  1
IntSoftmax | n:  1
IntGELU    | n:  1
IntSoftmax | n:  1
IntGELU    | n:  1
IntSoftmax | n:  1
IntGELU    | n:  1
IntSoftmax | n:  1
IntGELU    | n:  1
IntSoftmax | n:  1
IntGELU    | n:  1
IntSoftmax | n:  1
IntGELU    | n:  1
.calib done
Test: [  0/391]	Time  3.723 ( 3.723)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.68
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=1, intgelu_exp_n=2
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=1, intgelu_exp_n=2, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  1
IntGELU    | n:  2
IntSoftmax | n:  1
IntGELU    | n:  2
IntSoftmax | n:  1
IntGELU    | n:  2
IntSoftmax | n:  1
IntGELU    | n:  2
IntSoftmax | n:  1
IntGELU    | n:  2
IntSoftmax | n:  1
IntGELU    | n:  2
IntSoftmax | n:  1
IntGELU    | n:  2
IntSoftmax | n:  1
IntGELU    | n:  2
IntSoftmax | n:  1
IntGELU    | n:  2
IntSoftmax | n:  1
IntGELU    | n:  2
IntSoftmax | n:  1
IntGELU    | n:  2
IntSoftmax | n:  1
IntGELU    | n:  2
.calib done
Test: [  0/391]	Time  3.809 ( 3.809)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.77
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=1, intgelu_exp_n=3
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=1, intgelu_exp_n=3, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  1
IntGELU    | n:  3
IntSoftmax | n:  1
IntGELU    | n:  3
IntSoftmax | n:  1
IntGELU    | n:  3
IntSoftmax | n:  1
IntGELU    | n:  3
IntSoftmax | n:  1
IntGELU    | n:  3
IntSoftmax | n:  1
IntGELU    | n:  3
IntSoftmax | n:  1
IntGELU    | n:  3
IntSoftmax | n:  1
IntGELU    | n:  3
IntSoftmax | n:  1
IntGELU    | n:  3
IntSoftmax | n:  1
IntGELU    | n:  3
IntSoftmax | n:  1
IntGELU    | n:  3
IntSoftmax | n:  1
IntGELU    | n:  3
.calib done
Test: [  0/391]	Time  3.844 ( 3.844)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.82
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=1, intgelu_exp_n=4
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=1, intgelu_exp_n=4, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  1
IntGELU    | n:  4
IntSoftmax | n:  1
IntGELU    | n:  4
IntSoftmax | n:  1
IntGELU    | n:  4
IntSoftmax | n:  1
IntGELU    | n:  4
IntSoftmax | n:  1
IntGELU    | n:  4
IntSoftmax | n:  1
IntGELU    | n:  4
IntSoftmax | n:  1
IntGELU    | n:  4
IntSoftmax | n:  1
IntGELU    | n:  4
IntSoftmax | n:  1
IntGELU    | n:  4
IntSoftmax | n:  1
IntGELU    | n:  4
IntSoftmax | n:  1
IntGELU    | n:  4
IntSoftmax | n:  1
IntGELU    | n:  4
.calib done
Test: [  0/391]	Time  3.694 ( 3.694)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.63
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=1, intgelu_exp_n=5
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=1, intgelu_exp_n=5, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  1
IntGELU    | n:  5
IntSoftmax | n:  1
IntGELU    | n:  5
IntSoftmax | n:  1
IntGELU    | n:  5
IntSoftmax | n:  1
IntGELU    | n:  5
IntSoftmax | n:  1
IntGELU    | n:  5
IntSoftmax | n:  1
IntGELU    | n:  5
IntSoftmax | n:  1
IntGELU    | n:  5
IntSoftmax | n:  1
IntGELU    | n:  5
IntSoftmax | n:  1
IntGELU    | n:  5
IntSoftmax | n:  1
IntGELU    | n:  5
IntSoftmax | n:  1
IntGELU    | n:  5
IntSoftmax | n:  1
IntGELU    | n:  5
.calib done
Test: [  0/391]	Time  3.636 ( 3.636)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.59
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=1, intgelu_exp_n=6
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=1, intgelu_exp_n=6, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  1
IntGELU    | n:  6
IntSoftmax | n:  1
IntGELU    | n:  6
IntSoftmax | n:  1
IntGELU    | n:  6
IntSoftmax | n:  1
IntGELU    | n:  6
IntSoftmax | n:  1
IntGELU    | n:  6
IntSoftmax | n:  1
IntGELU    | n:  6
IntSoftmax | n:  1
IntGELU    | n:  6
IntSoftmax | n:  1
IntGELU    | n:  6
IntSoftmax | n:  1
IntGELU    | n:  6
IntSoftmax | n:  1
IntGELU    | n:  6
IntSoftmax | n:  1
IntGELU    | n:  6
IntSoftmax | n:  1
IntGELU    | n:  6
.calib done
Test: [  0/391]	Time  3.759 ( 3.759)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.70
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=1, intgelu_exp_n=7
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=1, intgelu_exp_n=7, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  1
IntGELU    | n:  7
IntSoftmax | n:  1
IntGELU    | n:  7
IntSoftmax | n:  1
IntGELU    | n:  7
IntSoftmax | n:  1
IntGELU    | n:  7
IntSoftmax | n:  1
IntGELU    | n:  7
IntSoftmax | n:  1
IntGELU    | n:  7
IntSoftmax | n:  1
IntGELU    | n:  7
IntSoftmax | n:  1
IntGELU    | n:  7
IntSoftmax | n:  1
IntGELU    | n:  7
IntSoftmax | n:  1
IntGELU    | n:  7
IntSoftmax | n:  1
IntGELU    | n:  7
IntSoftmax | n:  1
IntGELU    | n:  7
.calib done
Test: [  0/391]	Time  3.936 ( 3.936)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.92
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=1, intgelu_exp_n=8
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=1, intgelu_exp_n=8, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  1
IntGELU    | n:  8
IntSoftmax | n:  1
IntGELU    | n:  8
IntSoftmax | n:  1
IntGELU    | n:  8
IntSoftmax | n:  1
IntGELU    | n:  8
IntSoftmax | n:  1
IntGELU    | n:  8
IntSoftmax | n:  1
IntGELU    | n:  8
IntSoftmax | n:  1
IntGELU    | n:  8
IntSoftmax | n:  1
IntGELU    | n:  8
IntSoftmax | n:  1
IntGELU    | n:  8
IntSoftmax | n:  1
IntGELU    | n:  8
IntSoftmax | n:  1
IntGELU    | n:  8
IntSoftmax | n:  1
IntGELU    | n:  8
.calib done
Test: [  0/391]	Time  3.883 ( 3.883)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.85
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=1, intgelu_exp_n=9
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=1, intgelu_exp_n=9, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  1
IntGELU    | n:  9
IntSoftmax | n:  1
IntGELU    | n:  9
IntSoftmax | n:  1
IntGELU    | n:  9
IntSoftmax | n:  1
IntGELU    | n:  9
IntSoftmax | n:  1
IntGELU    | n:  9
IntSoftmax | n:  1
IntGELU    | n:  9
IntSoftmax | n:  1
IntGELU    | n:  9
IntSoftmax | n:  1
IntGELU    | n:  9
IntSoftmax | n:  1
IntGELU    | n:  9
IntSoftmax | n:  1
IntGELU    | n:  9
IntSoftmax | n:  1
IntGELU    | n:  9
IntSoftmax | n:  1
IntGELU    | n:  9
.calib done
Test: [  0/391]	Time  3.935 ( 3.935)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.80
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=1, intgelu_exp_n=10
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=1, intgelu_exp_n=10, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  1
IntGELU    | n:  10
IntSoftmax | n:  1
IntGELU    | n:  10
IntSoftmax | n:  1
IntGELU    | n:  10
IntSoftmax | n:  1
IntGELU    | n:  10
IntSoftmax | n:  1
IntGELU    | n:  10
IntSoftmax | n:  1
IntGELU    | n:  10
IntSoftmax | n:  1
IntGELU    | n:  10
IntSoftmax | n:  1
IntGELU    | n:  10
IntSoftmax | n:  1
IntGELU    | n:  10
IntSoftmax | n:  1
IntGELU    | n:  10
IntSoftmax | n:  1
IntGELU    | n:  10
IntSoftmax | n:  1
IntGELU    | n:  10
.calib done
Test: [  0/391]	Time  3.896 ( 3.896)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.82
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=1, intgelu_exp_n=11
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=1, intgelu_exp_n=11, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  1
IntGELU    | n:  11
IntSoftmax | n:  1
IntGELU    | n:  11
IntSoftmax | n:  1
IntGELU    | n:  11
IntSoftmax | n:  1
IntGELU    | n:  11
IntSoftmax | n:  1
IntGELU    | n:  11
IntSoftmax | n:  1
IntGELU    | n:  11
IntSoftmax | n:  1
IntGELU    | n:  11
IntSoftmax | n:  1
IntGELU    | n:  11
IntSoftmax | n:  1
IntGELU    | n:  11
IntSoftmax | n:  1
IntGELU    | n:  11
IntSoftmax | n:  1
IntGELU    | n:  11
IntSoftmax | n:  1
IntGELU    | n:  11
.calib done
Test: [  0/391]	Time  3.827 ( 3.827)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.77
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=1, intgelu_exp_n=12
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=1, intgelu_exp_n=12, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  1
IntGELU    | n:  12
IntSoftmax | n:  1
IntGELU    | n:  12
IntSoftmax | n:  1
IntGELU    | n:  12
IntSoftmax | n:  1
IntGELU    | n:  12
IntSoftmax | n:  1
IntGELU    | n:  12
IntSoftmax | n:  1
IntGELU    | n:  12
IntSoftmax | n:  1
IntGELU    | n:  12
IntSoftmax | n:  1
IntGELU    | n:  12
IntSoftmax | n:  1
IntGELU    | n:  12
IntSoftmax | n:  1
IntGELU    | n:  12
IntSoftmax | n:  1
IntGELU    | n:  12
IntSoftmax | n:  1
IntGELU    | n:  12
.calib done
Test: [  0/391]	Time  3.688 ( 3.688)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.68
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=1, intgelu_exp_n=13
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=1, intgelu_exp_n=13, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  1
IntGELU    | n:  13
IntSoftmax | n:  1
IntGELU    | n:  13
IntSoftmax | n:  1
IntGELU    | n:  13
IntSoftmax | n:  1
IntGELU    | n:  13
IntSoftmax | n:  1
IntGELU    | n:  13
IntSoftmax | n:  1
IntGELU    | n:  13
IntSoftmax | n:  1
IntGELU    | n:  13
IntSoftmax | n:  1
IntGELU    | n:  13
IntSoftmax | n:  1
IntGELU    | n:  13
IntSoftmax | n:  1
IntGELU    | n:  13
IntSoftmax | n:  1
IntGELU    | n:  13
IntSoftmax | n:  1
IntGELU    | n:  13
.calib done
Test: [  0/391]	Time  3.968 ( 3.968)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.93
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=1, intgelu_exp_n=14
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=1, intgelu_exp_n=14, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  1
IntGELU    | n:  14
IntSoftmax | n:  1
IntGELU    | n:  14
IntSoftmax | n:  1
IntGELU    | n:  14
IntSoftmax | n:  1
IntGELU    | n:  14
IntSoftmax | n:  1
IntGELU    | n:  14
IntSoftmax | n:  1
IntGELU    | n:  14
IntSoftmax | n:  1
IntGELU    | n:  14
IntSoftmax | n:  1
IntGELU    | n:  14
IntSoftmax | n:  1
IntGELU    | n:  14
IntSoftmax | n:  1
IntGELU    | n:  14
IntSoftmax | n:  1
IntGELU    | n:  14
IntSoftmax | n:  1
IntGELU    | n:  14
.calib done
Test: [  0/391]	Time  3.934 ( 3.934)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.91
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=1, intgelu_exp_n=15
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=1, intgelu_exp_n=15, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  1
IntGELU    | n:  15
IntSoftmax | n:  1
IntGELU    | n:  15
IntSoftmax | n:  1
IntGELU    | n:  15
IntSoftmax | n:  1
IntGELU    | n:  15
IntSoftmax | n:  1
IntGELU    | n:  15
IntSoftmax | n:  1
IntGELU    | n:  15
IntSoftmax | n:  1
IntGELU    | n:  15
IntSoftmax | n:  1
IntGELU    | n:  15
IntSoftmax | n:  1
IntGELU    | n:  15
IntSoftmax | n:  1
IntGELU    | n:  15
IntSoftmax | n:  1
IntGELU    | n:  15
IntSoftmax | n:  1
IntGELU    | n:  15
.calib done
Test: [  0/391]	Time  3.900 ( 3.900)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.79
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=1, intgelu_exp_n=16
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=1, intgelu_exp_n=16, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  1
IntGELU    | n:  16
IntSoftmax | n:  1
IntGELU    | n:  16
IntSoftmax | n:  1
IntGELU    | n:  16
IntSoftmax | n:  1
IntGELU    | n:  16
IntSoftmax | n:  1
IntGELU    | n:  16
IntSoftmax | n:  1
IntGELU    | n:  16
IntSoftmax | n:  1
IntGELU    | n:  16
IntSoftmax | n:  1
IntGELU    | n:  16
IntSoftmax | n:  1
IntGELU    | n:  16
IntSoftmax | n:  1
IntGELU    | n:  16
IntSoftmax | n:  1
IntGELU    | n:  16
IntSoftmax | n:  1
IntGELU    | n:  16
.calib done
Test: [  0/391]	Time  3.815 ( 3.815)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.80
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=1, intgelu_exp_n=17
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=1, intgelu_exp_n=17, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  1
IntGELU    | n:  17
IntSoftmax | n:  1
IntGELU    | n:  17
IntSoftmax | n:  1
IntGELU    | n:  17
IntSoftmax | n:  1
IntGELU    | n:  17
IntSoftmax | n:  1
IntGELU    | n:  17
IntSoftmax | n:  1
IntGELU    | n:  17
IntSoftmax | n:  1
IntGELU    | n:  17
IntSoftmax | n:  1
IntGELU    | n:  17
IntSoftmax | n:  1
IntGELU    | n:  17
IntSoftmax | n:  1
IntGELU    | n:  17
IntSoftmax | n:  1
IntGELU    | n:  17
IntSoftmax | n:  1
IntGELU    | n:  17
.calib done
Test: [  0/391]	Time  3.897 ( 3.897)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.83
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=1, intgelu_exp_n=18
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=1, intgelu_exp_n=18, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  1
IntGELU    | n:  18
IntSoftmax | n:  1
IntGELU    | n:  18
IntSoftmax | n:  1
IntGELU    | n:  18
IntSoftmax | n:  1
IntGELU    | n:  18
IntSoftmax | n:  1
IntGELU    | n:  18
IntSoftmax | n:  1
IntGELU    | n:  18
IntSoftmax | n:  1
IntGELU    | n:  18
IntSoftmax | n:  1
IntGELU    | n:  18
IntSoftmax | n:  1
IntGELU    | n:  18
IntSoftmax | n:  1
IntGELU    | n:  18
IntSoftmax | n:  1
IntGELU    | n:  18
IntSoftmax | n:  1
IntGELU    | n:  18
.calib done
Test: [  0/391]	Time  3.964 ( 3.964)	Acc@1   0.00 (  0.00)	Acc@5   0.78 (  0.78)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.781
Time: 8.90
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=1, intgelu_exp_n=19
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=1, intgelu_exp_n=19, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  1
IntGELU    | n:  19
IntSoftmax | n:  1
IntGELU    | n:  19
IntSoftmax | n:  1
IntGELU    | n:  19
IntSoftmax | n:  1
IntGELU    | n:  19
IntSoftmax | n:  1
IntGELU    | n:  19
IntSoftmax | n:  1
IntGELU    | n:  19
IntSoftmax | n:  1
IntGELU    | n:  19
IntSoftmax | n:  1
IntGELU    | n:  19
IntSoftmax | n:  1
IntGELU    | n:  19
IntSoftmax | n:  1
IntGELU    | n:  19
IntSoftmax | n:  1
IntGELU    | n:  19
IntSoftmax | n:  1
IntGELU    | n:  19
.calib done
Test: [  0/391]	Time  3.848 ( 3.848)	Acc@1   0.00 (  0.00)	Acc@5   3.12 (  3.12)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 3.125
Time: 8.79
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=1, intgelu_exp_n=20
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=1, intgelu_exp_n=20, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  1
IntGELU    | n:  20
IntSoftmax | n:  1
IntGELU    | n:  20
IntSoftmax | n:  1
IntGELU    | n:  20
IntSoftmax | n:  1
IntGELU    | n:  20
IntSoftmax | n:  1
IntGELU    | n:  20
IntSoftmax | n:  1
IntGELU    | n:  20
IntSoftmax | n:  1
IntGELU    | n:  20
IntSoftmax | n:  1
IntGELU    | n:  20
IntSoftmax | n:  1
IntGELU    | n:  20
IntSoftmax | n:  1
IntGELU    | n:  20
IntSoftmax | n:  1
IntGELU    | n:  20
IntSoftmax | n:  1
IntGELU    | n:  20
.calib done
Test: [  0/391]	Time  3.947 ( 3.947)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.88
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=1, intgelu_exp_n=21
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=1, intgelu_exp_n=21, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  1
IntGELU    | n:  21
IntSoftmax | n:  1
IntGELU    | n:  21
IntSoftmax | n:  1
IntGELU    | n:  21
IntSoftmax | n:  1
IntGELU    | n:  21
IntSoftmax | n:  1
IntGELU    | n:  21
IntSoftmax | n:  1
IntGELU    | n:  21
IntSoftmax | n:  1
IntGELU    | n:  21
IntSoftmax | n:  1
IntGELU    | n:  21
IntSoftmax | n:  1
IntGELU    | n:  21
IntSoftmax | n:  1
IntGELU    | n:  21
IntSoftmax | n:  1
IntGELU    | n:  21
IntSoftmax | n:  1
IntGELU    | n:  21
.calib done
Test: [  0/391]	Time  3.757 ( 3.757)	Acc@1   0.00 (  0.00)	Acc@5   3.12 (  3.12)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 3.125
Time: 8.69
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=1, intgelu_exp_n=22
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=1, intgelu_exp_n=22, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  1
IntGELU    | n:  22
IntSoftmax | n:  1
IntGELU    | n:  22
IntSoftmax | n:  1
IntGELU    | n:  22
IntSoftmax | n:  1
IntGELU    | n:  22
IntSoftmax | n:  1
IntGELU    | n:  22
IntSoftmax | n:  1
IntGELU    | n:  22
IntSoftmax | n:  1
IntGELU    | n:  22
IntSoftmax | n:  1
IntGELU    | n:  22
IntSoftmax | n:  1
IntGELU    | n:  22
IntSoftmax | n:  1
IntGELU    | n:  22
IntSoftmax | n:  1
IntGELU    | n:  22
IntSoftmax | n:  1
IntGELU    | n:  22
.calib done
Test: [  0/391]	Time  3.967 ( 3.967)	Acc@1   0.00 (  0.00)	Acc@5   3.12 (  3.12)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 3.125
Time: 8.90
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=1, intgelu_exp_n=23
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=1, intgelu_exp_n=23, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  1
IntGELU    | n:  23
IntSoftmax | n:  1
IntGELU    | n:  23
IntSoftmax | n:  1
IntGELU    | n:  23
IntSoftmax | n:  1
IntGELU    | n:  23
IntSoftmax | n:  1
IntGELU    | n:  23
IntSoftmax | n:  1
IntGELU    | n:  23
IntSoftmax | n:  1
IntGELU    | n:  23
IntSoftmax | n:  1
IntGELU    | n:  23
IntSoftmax | n:  1
IntGELU    | n:  23
IntSoftmax | n:  1
IntGELU    | n:  23
IntSoftmax | n:  1
IntGELU    | n:  23
IntSoftmax | n:  1
IntGELU    | n:  23
.calib done
Test: [  0/391]	Time  4.002 ( 4.002)	Acc@1   0.00 (  0.00)	Acc@5   2.34 (  2.34)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 2.344
Time: 9.03
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=1, intgelu_exp_n=24
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=1, intgelu_exp_n=24, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  1
IntGELU    | n:  24
IntSoftmax | n:  1
IntGELU    | n:  24
IntSoftmax | n:  1
IntGELU    | n:  24
IntSoftmax | n:  1
IntGELU    | n:  24
IntSoftmax | n:  1
IntGELU    | n:  24
IntSoftmax | n:  1
IntGELU    | n:  24
IntSoftmax | n:  1
IntGELU    | n:  24
IntSoftmax | n:  1
IntGELU    | n:  24
IntSoftmax | n:  1
IntGELU    | n:  24
IntSoftmax | n:  1
IntGELU    | n:  24
IntSoftmax | n:  1
IntGELU    | n:  24
IntSoftmax | n:  1
IntGELU    | n:  24
.calib done
Test: [  0/391]	Time  3.891 ( 3.891)	Acc@1   0.00 (  0.00)	Acc@5   3.91 (  3.91)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 3.906
Time: 8.88
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=1, intgelu_exp_n=25
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=1, intgelu_exp_n=25, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  1
IntGELU    | n:  25
IntSoftmax | n:  1
IntGELU    | n:  25
IntSoftmax | n:  1
IntGELU    | n:  25
IntSoftmax | n:  1
IntGELU    | n:  25
IntSoftmax | n:  1
IntGELU    | n:  25
IntSoftmax | n:  1
IntGELU    | n:  25
IntSoftmax | n:  1
IntGELU    | n:  25
IntSoftmax | n:  1
IntGELU    | n:  25
IntSoftmax | n:  1
IntGELU    | n:  25
IntSoftmax | n:  1
IntGELU    | n:  25
IntSoftmax | n:  1
IntGELU    | n:  25
IntSoftmax | n:  1
IntGELU    | n:  25
.calib done
Test: [  0/391]	Time  3.981 ( 3.981)	Acc@1   0.00 (  0.00)	Acc@5   3.12 (  3.12)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 3.125
Time: 8.93
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=1, intgelu_exp_n=26
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=1, intgelu_exp_n=26, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  1
IntGELU    | n:  26
IntSoftmax | n:  1
IntGELU    | n:  26
IntSoftmax | n:  1
IntGELU    | n:  26
IntSoftmax | n:  1
IntGELU    | n:  26
IntSoftmax | n:  1
IntGELU    | n:  26
IntSoftmax | n:  1
IntGELU    | n:  26
IntSoftmax | n:  1
IntGELU    | n:  26
IntSoftmax | n:  1
IntGELU    | n:  26
IntSoftmax | n:  1
IntGELU    | n:  26
IntSoftmax | n:  1
IntGELU    | n:  26
IntSoftmax | n:  1
IntGELU    | n:  26
IntSoftmax | n:  1
IntGELU    | n:  26
.calib done
Test: [  0/391]	Time  3.969 ( 3.969)	Acc@1   0.00 (  0.00)	Acc@5   2.34 (  2.34)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 2.344
Time: 8.87
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=1, intgelu_exp_n=27
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=1, intgelu_exp_n=27, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  1
IntGELU    | n:  27
IntSoftmax | n:  1
IntGELU    | n:  27
IntSoftmax | n:  1
IntGELU    | n:  27
IntSoftmax | n:  1
IntGELU    | n:  27
IntSoftmax | n:  1
IntGELU    | n:  27
IntSoftmax | n:  1
IntGELU    | n:  27
IntSoftmax | n:  1
IntGELU    | n:  27
IntSoftmax | n:  1
IntGELU    | n:  27
IntSoftmax | n:  1
IntGELU    | n:  27
IntSoftmax | n:  1
IntGELU    | n:  27
IntSoftmax | n:  1
IntGELU    | n:  27
IntSoftmax | n:  1
IntGELU    | n:  27
.calib done
Test: [  0/391]	Time  3.875 ( 3.875)	Acc@1   0.00 (  0.00)	Acc@5   3.12 (  3.12)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 3.125
Time: 8.81
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=1, intgelu_exp_n=28
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=1, intgelu_exp_n=28, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  1
IntGELU    | n:  28
IntSoftmax | n:  1
IntGELU    | n:  28
IntSoftmax | n:  1
IntGELU    | n:  28
IntSoftmax | n:  1
IntGELU    | n:  28
IntSoftmax | n:  1
IntGELU    | n:  28
IntSoftmax | n:  1
IntGELU    | n:  28
IntSoftmax | n:  1
IntGELU    | n:  28
IntSoftmax | n:  1
IntGELU    | n:  28
IntSoftmax | n:  1
IntGELU    | n:  28
IntSoftmax | n:  1
IntGELU    | n:  28
IntSoftmax | n:  1
IntGELU    | n:  28
IntSoftmax | n:  1
IntGELU    | n:  28
.calib done
Test: [  0/391]	Time  3.711 ( 3.711)	Acc@1   0.00 (  0.00)	Acc@5   1.56 (  1.56)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 1.562
Time: 8.66
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=1, intgelu_exp_n=29
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=1, intgelu_exp_n=29, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  1
IntGELU    | n:  29
IntSoftmax | n:  1
IntGELU    | n:  29
IntSoftmax | n:  1
IntGELU    | n:  29
IntSoftmax | n:  1
IntGELU    | n:  29
IntSoftmax | n:  1
IntGELU    | n:  29
IntSoftmax | n:  1
IntGELU    | n:  29
IntSoftmax | n:  1
IntGELU    | n:  29
IntSoftmax | n:  1
IntGELU    | n:  29
IntSoftmax | n:  1
IntGELU    | n:  29
IntSoftmax | n:  1
IntGELU    | n:  29
IntSoftmax | n:  1
IntGELU    | n:  29
IntSoftmax | n:  1
IntGELU    | n:  29
.calib done
Test: [  0/391]	Time  3.878 ( 3.878)	Acc@1   0.00 (  0.00)	Acc@5   0.78 (  0.78)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.781
Time: 8.83
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=1, intgelu_exp_n=30
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=1, intgelu_exp_n=30, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  1
IntGELU    | n:  30
IntSoftmax | n:  1
IntGELU    | n:  30
IntSoftmax | n:  1
IntGELU    | n:  30
IntSoftmax | n:  1
IntGELU    | n:  30
IntSoftmax | n:  1
IntGELU    | n:  30
IntSoftmax | n:  1
IntGELU    | n:  30
IntSoftmax | n:  1
IntGELU    | n:  30
IntSoftmax | n:  1
IntGELU    | n:  30
IntSoftmax | n:  1
IntGELU    | n:  30
IntSoftmax | n:  1
IntGELU    | n:  30
IntSoftmax | n:  1
IntGELU    | n:  30
IntSoftmax | n:  1
IntGELU    | n:  30
.calib done
Test: [  0/391]	Time  3.627 ( 3.627)	Acc@1   4.69 (  4.69)	Acc@5   8.59 (  8.59)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 4.688 Prec@5 8.594
Time: 8.62
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=1, intgelu_exp_n=31
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=1, intgelu_exp_n=31, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  1
IntGELU    | n:  31
IntSoftmax | n:  1
IntGELU    | n:  31
IntSoftmax | n:  1
IntGELU    | n:  31
IntSoftmax | n:  1
IntGELU    | n:  31
IntSoftmax | n:  1
IntGELU    | n:  31
IntSoftmax | n:  1
IntGELU    | n:  31
IntSoftmax | n:  1
IntGELU    | n:  31
IntSoftmax | n:  1
IntGELU    | n:  31
IntSoftmax | n:  1
IntGELU    | n:  31
IntSoftmax | n:  1
IntGELU    | n:  31
IntSoftmax | n:  1
IntGELU    | n:  31
IntSoftmax | n:  1
IntGELU    | n:  31
.calib done
Test: [  0/391]	Time  4.002 ( 4.002)	Acc@1   0.00 (  0.00)	Acc@5   1.56 (  1.56)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 1.562
Time: 8.91
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=2, intgelu_exp_n=0
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=2, intgelu_exp_n=0, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  2
IntGELU    | n:  0
IntSoftmax | n:  2
IntGELU    | n:  0
IntSoftmax | n:  2
IntGELU    | n:  0
IntSoftmax | n:  2
IntGELU    | n:  0
IntSoftmax | n:  2
IntGELU    | n:  0
IntSoftmax | n:  2
IntGELU    | n:  0
IntSoftmax | n:  2
IntGELU    | n:  0
IntSoftmax | n:  2
IntGELU    | n:  0
IntSoftmax | n:  2
IntGELU    | n:  0
IntSoftmax | n:  2
IntGELU    | n:  0
IntSoftmax | n:  2
IntGELU    | n:  0
IntSoftmax | n:  2
IntGELU    | n:  0
.calib done
Test: [  0/391]	Time  4.066 ( 4.066)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 9.02
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=2, intgelu_exp_n=1
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=2, intgelu_exp_n=1, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  2
IntGELU    | n:  1
IntSoftmax | n:  2
IntGELU    | n:  1
IntSoftmax | n:  2
IntGELU    | n:  1
IntSoftmax | n:  2
IntGELU    | n:  1
IntSoftmax | n:  2
IntGELU    | n:  1
IntSoftmax | n:  2
IntGELU    | n:  1
IntSoftmax | n:  2
IntGELU    | n:  1
IntSoftmax | n:  2
IntGELU    | n:  1
IntSoftmax | n:  2
IntGELU    | n:  1
IntSoftmax | n:  2
IntGELU    | n:  1
IntSoftmax | n:  2
IntGELU    | n:  1
IntSoftmax | n:  2
IntGELU    | n:  1
.calib done
Test: [  0/391]	Time  3.900 ( 3.900)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.79
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=2, intgelu_exp_n=2
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=2, intgelu_exp_n=2, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  2
IntGELU    | n:  2
IntSoftmax | n:  2
IntGELU    | n:  2
IntSoftmax | n:  2
IntGELU    | n:  2
IntSoftmax | n:  2
IntGELU    | n:  2
IntSoftmax | n:  2
IntGELU    | n:  2
IntSoftmax | n:  2
IntGELU    | n:  2
IntSoftmax | n:  2
IntGELU    | n:  2
IntSoftmax | n:  2
IntGELU    | n:  2
IntSoftmax | n:  2
IntGELU    | n:  2
IntSoftmax | n:  2
IntGELU    | n:  2
IntSoftmax | n:  2
IntGELU    | n:  2
IntSoftmax | n:  2
IntGELU    | n:  2
.calib done
Test: [  0/391]	Time  3.772 ( 3.772)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.68
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=2, intgelu_exp_n=3
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=2, intgelu_exp_n=3, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  2
IntGELU    | n:  3
IntSoftmax | n:  2
IntGELU    | n:  3
IntSoftmax | n:  2
IntGELU    | n:  3
IntSoftmax | n:  2
IntGELU    | n:  3
IntSoftmax | n:  2
IntGELU    | n:  3
IntSoftmax | n:  2
IntGELU    | n:  3
IntSoftmax | n:  2
IntGELU    | n:  3
IntSoftmax | n:  2
IntGELU    | n:  3
IntSoftmax | n:  2
IntGELU    | n:  3
IntSoftmax | n:  2
IntGELU    | n:  3
IntSoftmax | n:  2
IntGELU    | n:  3
IntSoftmax | n:  2
IntGELU    | n:  3
.calib done
Test: [  0/391]	Time  3.938 ( 3.938)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.80
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=2, intgelu_exp_n=4
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=2, intgelu_exp_n=4, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  2
IntGELU    | n:  4
IntSoftmax | n:  2
IntGELU    | n:  4
IntSoftmax | n:  2
IntGELU    | n:  4
IntSoftmax | n:  2
IntGELU    | n:  4
IntSoftmax | n:  2
IntGELU    | n:  4
IntSoftmax | n:  2
IntGELU    | n:  4
IntSoftmax | n:  2
IntGELU    | n:  4
IntSoftmax | n:  2
IntGELU    | n:  4
IntSoftmax | n:  2
IntGELU    | n:  4
IntSoftmax | n:  2
IntGELU    | n:  4
IntSoftmax | n:  2
IntGELU    | n:  4
IntSoftmax | n:  2
IntGELU    | n:  4
.calib done
Test: [  0/391]	Time  3.937 ( 3.937)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.86
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=2, intgelu_exp_n=5
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=2, intgelu_exp_n=5, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  2
IntGELU    | n:  5
IntSoftmax | n:  2
IntGELU    | n:  5
IntSoftmax | n:  2
IntGELU    | n:  5
IntSoftmax | n:  2
IntGELU    | n:  5
IntSoftmax | n:  2
IntGELU    | n:  5
IntSoftmax | n:  2
IntGELU    | n:  5
IntSoftmax | n:  2
IntGELU    | n:  5
IntSoftmax | n:  2
IntGELU    | n:  5
IntSoftmax | n:  2
IntGELU    | n:  5
IntSoftmax | n:  2
IntGELU    | n:  5
IntSoftmax | n:  2
IntGELU    | n:  5
IntSoftmax | n:  2
IntGELU    | n:  5
.calib done
Test: [  0/391]	Time  3.810 ( 3.810)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.77
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=2, intgelu_exp_n=6
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=2, intgelu_exp_n=6, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  2
IntGELU    | n:  6
IntSoftmax | n:  2
IntGELU    | n:  6
IntSoftmax | n:  2
IntGELU    | n:  6
IntSoftmax | n:  2
IntGELU    | n:  6
IntSoftmax | n:  2
IntGELU    | n:  6
IntSoftmax | n:  2
IntGELU    | n:  6
IntSoftmax | n:  2
IntGELU    | n:  6
IntSoftmax | n:  2
IntGELU    | n:  6
IntSoftmax | n:  2
IntGELU    | n:  6
IntSoftmax | n:  2
IntGELU    | n:  6
IntSoftmax | n:  2
IntGELU    | n:  6
IntSoftmax | n:  2
IntGELU    | n:  6
.calib done
Test: [  0/391]	Time  4.061 ( 4.061)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 9.02
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=2, intgelu_exp_n=7
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=2, intgelu_exp_n=7, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  2
IntGELU    | n:  7
IntSoftmax | n:  2
IntGELU    | n:  7
IntSoftmax | n:  2
IntGELU    | n:  7
IntSoftmax | n:  2
IntGELU    | n:  7
IntSoftmax | n:  2
IntGELU    | n:  7
IntSoftmax | n:  2
IntGELU    | n:  7
IntSoftmax | n:  2
IntGELU    | n:  7
IntSoftmax | n:  2
IntGELU    | n:  7
IntSoftmax | n:  2
IntGELU    | n:  7
IntSoftmax | n:  2
IntGELU    | n:  7
IntSoftmax | n:  2
IntGELU    | n:  7
IntSoftmax | n:  2
IntGELU    | n:  7
.calib done
Test: [  0/391]	Time  3.648 ( 3.648)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.62
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=2, intgelu_exp_n=8
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=2, intgelu_exp_n=8, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  2
IntGELU    | n:  8
IntSoftmax | n:  2
IntGELU    | n:  8
IntSoftmax | n:  2
IntGELU    | n:  8
IntSoftmax | n:  2
IntGELU    | n:  8
IntSoftmax | n:  2
IntGELU    | n:  8
IntSoftmax | n:  2
IntGELU    | n:  8
IntSoftmax | n:  2
IntGELU    | n:  8
IntSoftmax | n:  2
IntGELU    | n:  8
IntSoftmax | n:  2
IntGELU    | n:  8
IntSoftmax | n:  2
IntGELU    | n:  8
IntSoftmax | n:  2
IntGELU    | n:  8
IntSoftmax | n:  2
IntGELU    | n:  8
.calib done
Test: [  0/391]	Time  3.955 ( 3.955)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.90
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=2, intgelu_exp_n=9
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=2, intgelu_exp_n=9, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  2
IntGELU    | n:  9
IntSoftmax | n:  2
IntGELU    | n:  9
IntSoftmax | n:  2
IntGELU    | n:  9
IntSoftmax | n:  2
IntGELU    | n:  9
IntSoftmax | n:  2
IntGELU    | n:  9
IntSoftmax | n:  2
IntGELU    | n:  9
IntSoftmax | n:  2
IntGELU    | n:  9
IntSoftmax | n:  2
IntGELU    | n:  9
IntSoftmax | n:  2
IntGELU    | n:  9
IntSoftmax | n:  2
IntGELU    | n:  9
IntSoftmax | n:  2
IntGELU    | n:  9
IntSoftmax | n:  2
IntGELU    | n:  9
.calib done
Test: [  0/391]	Time  3.893 ( 3.893)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.89
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=2, intgelu_exp_n=10
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=2, intgelu_exp_n=10, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  2
IntGELU    | n:  10
IntSoftmax | n:  2
IntGELU    | n:  10
IntSoftmax | n:  2
IntGELU    | n:  10
IntSoftmax | n:  2
IntGELU    | n:  10
IntSoftmax | n:  2
IntGELU    | n:  10
IntSoftmax | n:  2
IntGELU    | n:  10
IntSoftmax | n:  2
IntGELU    | n:  10
IntSoftmax | n:  2
IntGELU    | n:  10
IntSoftmax | n:  2
IntGELU    | n:  10
IntSoftmax | n:  2
IntGELU    | n:  10
IntSoftmax | n:  2
IntGELU    | n:  10
IntSoftmax | n:  2
IntGELU    | n:  10
.calib done
Test: [  0/391]	Time  3.828 ( 3.828)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.70
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=2, intgelu_exp_n=11
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=2, intgelu_exp_n=11, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  2
IntGELU    | n:  11
IntSoftmax | n:  2
IntGELU    | n:  11
IntSoftmax | n:  2
IntGELU    | n:  11
IntSoftmax | n:  2
IntGELU    | n:  11
IntSoftmax | n:  2
IntGELU    | n:  11
IntSoftmax | n:  2
IntGELU    | n:  11
IntSoftmax | n:  2
IntGELU    | n:  11
IntSoftmax | n:  2
IntGELU    | n:  11
IntSoftmax | n:  2
IntGELU    | n:  11
IntSoftmax | n:  2
IntGELU    | n:  11
IntSoftmax | n:  2
IntGELU    | n:  11
IntSoftmax | n:  2
IntGELU    | n:  11
.calib done
Test: [  0/391]	Time  3.979 ( 3.979)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.95
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=2, intgelu_exp_n=12
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=2, intgelu_exp_n=12, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  2
IntGELU    | n:  12
IntSoftmax | n:  2
IntGELU    | n:  12
IntSoftmax | n:  2
IntGELU    | n:  12
IntSoftmax | n:  2
IntGELU    | n:  12
IntSoftmax | n:  2
IntGELU    | n:  12
IntSoftmax | n:  2
IntGELU    | n:  12
IntSoftmax | n:  2
IntGELU    | n:  12
IntSoftmax | n:  2
IntGELU    | n:  12
IntSoftmax | n:  2
IntGELU    | n:  12
IntSoftmax | n:  2
IntGELU    | n:  12
IntSoftmax | n:  2
IntGELU    | n:  12
IntSoftmax | n:  2
IntGELU    | n:  12
.calib done
Test: [  0/391]	Time  3.895 ( 3.895)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.91
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=2, intgelu_exp_n=13
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=2, intgelu_exp_n=13, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  2
IntGELU    | n:  13
IntSoftmax | n:  2
IntGELU    | n:  13
IntSoftmax | n:  2
IntGELU    | n:  13
IntSoftmax | n:  2
IntGELU    | n:  13
IntSoftmax | n:  2
IntGELU    | n:  13
IntSoftmax | n:  2
IntGELU    | n:  13
IntSoftmax | n:  2
IntGELU    | n:  13
IntSoftmax | n:  2
IntGELU    | n:  13
IntSoftmax | n:  2
IntGELU    | n:  13
IntSoftmax | n:  2
IntGELU    | n:  13
IntSoftmax | n:  2
IntGELU    | n:  13
IntSoftmax | n:  2
IntGELU    | n:  13
.calib done
Test: [  0/391]	Time  3.872 ( 3.872)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.85
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=2, intgelu_exp_n=14
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=2, intgelu_exp_n=14, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  2
IntGELU    | n:  14
IntSoftmax | n:  2
IntGELU    | n:  14
IntSoftmax | n:  2
IntGELU    | n:  14
IntSoftmax | n:  2
IntGELU    | n:  14
IntSoftmax | n:  2
IntGELU    | n:  14
IntSoftmax | n:  2
IntGELU    | n:  14
IntSoftmax | n:  2
IntGELU    | n:  14
IntSoftmax | n:  2
IntGELU    | n:  14
IntSoftmax | n:  2
IntGELU    | n:  14
IntSoftmax | n:  2
IntGELU    | n:  14
IntSoftmax | n:  2
IntGELU    | n:  14
IntSoftmax | n:  2
IntGELU    | n:  14
.calib done
Test: [  0/391]	Time  3.959 ( 3.959)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.90
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=2, intgelu_exp_n=15
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=2, intgelu_exp_n=15, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  2
IntGELU    | n:  15
IntSoftmax | n:  2
IntGELU    | n:  15
IntSoftmax | n:  2
IntGELU    | n:  15
IntSoftmax | n:  2
IntGELU    | n:  15
IntSoftmax | n:  2
IntGELU    | n:  15
IntSoftmax | n:  2
IntGELU    | n:  15
IntSoftmax | n:  2
IntGELU    | n:  15
IntSoftmax | n:  2
IntGELU    | n:  15
IntSoftmax | n:  2
IntGELU    | n:  15
IntSoftmax | n:  2
IntGELU    | n:  15
IntSoftmax | n:  2
IntGELU    | n:  15
IntSoftmax | n:  2
IntGELU    | n:  15
.calib done
Test: [  0/391]	Time  3.931 ( 3.931)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.94
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=2, intgelu_exp_n=16
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=2, intgelu_exp_n=16, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  2
IntGELU    | n:  16
IntSoftmax | n:  2
IntGELU    | n:  16
IntSoftmax | n:  2
IntGELU    | n:  16
IntSoftmax | n:  2
IntGELU    | n:  16
IntSoftmax | n:  2
IntGELU    | n:  16
IntSoftmax | n:  2
IntGELU    | n:  16
IntSoftmax | n:  2
IntGELU    | n:  16
IntSoftmax | n:  2
IntGELU    | n:  16
IntSoftmax | n:  2
IntGELU    | n:  16
IntSoftmax | n:  2
IntGELU    | n:  16
IntSoftmax | n:  2
IntGELU    | n:  16
IntSoftmax | n:  2
IntGELU    | n:  16
.calib done
Test: [  0/391]	Time  3.846 ( 3.846)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.84
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=2, intgelu_exp_n=17
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=2, intgelu_exp_n=17, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  2
IntGELU    | n:  17
IntSoftmax | n:  2
IntGELU    | n:  17
IntSoftmax | n:  2
IntGELU    | n:  17
IntSoftmax | n:  2
IntGELU    | n:  17
IntSoftmax | n:  2
IntGELU    | n:  17
IntSoftmax | n:  2
IntGELU    | n:  17
IntSoftmax | n:  2
IntGELU    | n:  17
IntSoftmax | n:  2
IntGELU    | n:  17
IntSoftmax | n:  2
IntGELU    | n:  17
IntSoftmax | n:  2
IntGELU    | n:  17
IntSoftmax | n:  2
IntGELU    | n:  17
IntSoftmax | n:  2
IntGELU    | n:  17
.calib done
Test: [  0/391]	Time  3.966 ( 3.966)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.90
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=2, intgelu_exp_n=18
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=2, intgelu_exp_n=18, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  2
IntGELU    | n:  18
IntSoftmax | n:  2
IntGELU    | n:  18
IntSoftmax | n:  2
IntGELU    | n:  18
IntSoftmax | n:  2
IntGELU    | n:  18
IntSoftmax | n:  2
IntGELU    | n:  18
IntSoftmax | n:  2
IntGELU    | n:  18
IntSoftmax | n:  2
IntGELU    | n:  18
IntSoftmax | n:  2
IntGELU    | n:  18
IntSoftmax | n:  2
IntGELU    | n:  18
IntSoftmax | n:  2
IntGELU    | n:  18
IntSoftmax | n:  2
IntGELU    | n:  18
IntSoftmax | n:  2
IntGELU    | n:  18
.calib done
Test: [  0/391]	Time  3.674 ( 3.674)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.64
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=2, intgelu_exp_n=19
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=2, intgelu_exp_n=19, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  2
IntGELU    | n:  19
IntSoftmax | n:  2
IntGELU    | n:  19
IntSoftmax | n:  2
IntGELU    | n:  19
IntSoftmax | n:  2
IntGELU    | n:  19
IntSoftmax | n:  2
IntGELU    | n:  19
IntSoftmax | n:  2
IntGELU    | n:  19
IntSoftmax | n:  2
IntGELU    | n:  19
IntSoftmax | n:  2
IntGELU    | n:  19
IntSoftmax | n:  2
IntGELU    | n:  19
IntSoftmax | n:  2
IntGELU    | n:  19
IntSoftmax | n:  2
IntGELU    | n:  19
IntSoftmax | n:  2
IntGELU    | n:  19
.calib done
Test: [  0/391]	Time  3.959 ( 3.959)	Acc@1   0.00 (  0.00)	Acc@5   1.56 (  1.56)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 1.562
Time: 8.92
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=2, intgelu_exp_n=20
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=2, intgelu_exp_n=20, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  2
IntGELU    | n:  20
IntSoftmax | n:  2
IntGELU    | n:  20
IntSoftmax | n:  2
IntGELU    | n:  20
IntSoftmax | n:  2
IntGELU    | n:  20
IntSoftmax | n:  2
IntGELU    | n:  20
IntSoftmax | n:  2
IntGELU    | n:  20
IntSoftmax | n:  2
IntGELU    | n:  20
IntSoftmax | n:  2
IntGELU    | n:  20
IntSoftmax | n:  2
IntGELU    | n:  20
IntSoftmax | n:  2
IntGELU    | n:  20
IntSoftmax | n:  2
IntGELU    | n:  20
IntSoftmax | n:  2
IntGELU    | n:  20
.calib done
Test: [  0/391]	Time  3.767 ( 3.767)	Acc@1   0.00 (  0.00)	Acc@5   3.91 (  3.91)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 3.906
Time: 8.73
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=2, intgelu_exp_n=21
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=2, intgelu_exp_n=21, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  2
IntGELU    | n:  21
IntSoftmax | n:  2
IntGELU    | n:  21
IntSoftmax | n:  2
IntGELU    | n:  21
IntSoftmax | n:  2
IntGELU    | n:  21
IntSoftmax | n:  2
IntGELU    | n:  21
IntSoftmax | n:  2
IntGELU    | n:  21
IntSoftmax | n:  2
IntGELU    | n:  21
IntSoftmax | n:  2
IntGELU    | n:  21
IntSoftmax | n:  2
IntGELU    | n:  21
IntSoftmax | n:  2
IntGELU    | n:  21
IntSoftmax | n:  2
IntGELU    | n:  21
IntSoftmax | n:  2
IntGELU    | n:  21
.calib done
Test: [  0/391]	Time  3.927 ( 3.927)	Acc@1   0.00 (  0.00)	Acc@5   2.34 (  2.34)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 2.344
Time: 8.89
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=2, intgelu_exp_n=22
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=2, intgelu_exp_n=22, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  2
IntGELU    | n:  22
IntSoftmax | n:  2
IntGELU    | n:  22
IntSoftmax | n:  2
IntGELU    | n:  22
IntSoftmax | n:  2
IntGELU    | n:  22
IntSoftmax | n:  2
IntGELU    | n:  22
IntSoftmax | n:  2
IntGELU    | n:  22
IntSoftmax | n:  2
IntGELU    | n:  22
IntSoftmax | n:  2
IntGELU    | n:  22
IntSoftmax | n:  2
IntGELU    | n:  22
IntSoftmax | n:  2
IntGELU    | n:  22
IntSoftmax | n:  2
IntGELU    | n:  22
IntSoftmax | n:  2
IntGELU    | n:  22
.calib done
Test: [  0/391]	Time  3.902 ( 3.902)	Acc@1   0.00 (  0.00)	Acc@5   4.69 (  4.69)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 4.688
Time: 8.86
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=2, intgelu_exp_n=23
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=2, intgelu_exp_n=23, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  2
IntGELU    | n:  23
IntSoftmax | n:  2
IntGELU    | n:  23
IntSoftmax | n:  2
IntGELU    | n:  23
IntSoftmax | n:  2
IntGELU    | n:  23
IntSoftmax | n:  2
IntGELU    | n:  23
IntSoftmax | n:  2
IntGELU    | n:  23
IntSoftmax | n:  2
IntGELU    | n:  23
IntSoftmax | n:  2
IntGELU    | n:  23
IntSoftmax | n:  2
IntGELU    | n:  23
IntSoftmax | n:  2
IntGELU    | n:  23
IntSoftmax | n:  2
IntGELU    | n:  23
IntSoftmax | n:  2
IntGELU    | n:  23
.calib done
Test: [  0/391]	Time  4.021 ( 4.021)	Acc@1   0.00 (  0.00)	Acc@5   5.47 (  5.47)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 5.469
Time: 8.98
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=2, intgelu_exp_n=24
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=2, intgelu_exp_n=24, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  2
IntGELU    | n:  24
IntSoftmax | n:  2
IntGELU    | n:  24
IntSoftmax | n:  2
IntGELU    | n:  24
IntSoftmax | n:  2
IntGELU    | n:  24
IntSoftmax | n:  2
IntGELU    | n:  24
IntSoftmax | n:  2
IntGELU    | n:  24
IntSoftmax | n:  2
IntGELU    | n:  24
IntSoftmax | n:  2
IntGELU    | n:  24
IntSoftmax | n:  2
IntGELU    | n:  24
IntSoftmax | n:  2
IntGELU    | n:  24
IntSoftmax | n:  2
IntGELU    | n:  24
IntSoftmax | n:  2
IntGELU    | n:  24
.calib done
Test: [  0/391]	Time  3.775 ( 3.775)	Acc@1   0.78 (  0.78)	Acc@5   2.34 (  2.34)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.781 Prec@5 2.344
Time: 8.66
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=2, intgelu_exp_n=25
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=2, intgelu_exp_n=25, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  2
IntGELU    | n:  25
IntSoftmax | n:  2
IntGELU    | n:  25
IntSoftmax | n:  2
IntGELU    | n:  25
IntSoftmax | n:  2
IntGELU    | n:  25
IntSoftmax | n:  2
IntGELU    | n:  25
IntSoftmax | n:  2
IntGELU    | n:  25
IntSoftmax | n:  2
IntGELU    | n:  25
IntSoftmax | n:  2
IntGELU    | n:  25
IntSoftmax | n:  2
IntGELU    | n:  25
IntSoftmax | n:  2
IntGELU    | n:  25
IntSoftmax | n:  2
IntGELU    | n:  25
IntSoftmax | n:  2
IntGELU    | n:  25
.calib done
Test: [  0/391]	Time  3.831 ( 3.831)	Acc@1   0.00 (  0.00)	Acc@5   9.38 (  9.38)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 9.375
Time: 8.83
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=2, intgelu_exp_n=26
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=2, intgelu_exp_n=26, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  2
IntGELU    | n:  26
IntSoftmax | n:  2
IntGELU    | n:  26
IntSoftmax | n:  2
IntGELU    | n:  26
IntSoftmax | n:  2
IntGELU    | n:  26
IntSoftmax | n:  2
IntGELU    | n:  26
IntSoftmax | n:  2
IntGELU    | n:  26
IntSoftmax | n:  2
IntGELU    | n:  26
IntSoftmax | n:  2
IntGELU    | n:  26
IntSoftmax | n:  2
IntGELU    | n:  26
IntSoftmax | n:  2
IntGELU    | n:  26
IntSoftmax | n:  2
IntGELU    | n:  26
IntSoftmax | n:  2
IntGELU    | n:  26
.calib done
Test: [  0/391]	Time  4.060 ( 4.060)	Acc@1   0.00 (  0.00)	Acc@5   9.38 (  9.38)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 9.375
Time: 9.03
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=2, intgelu_exp_n=27
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=2, intgelu_exp_n=27, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  2
IntGELU    | n:  27
IntSoftmax | n:  2
IntGELU    | n:  27
IntSoftmax | n:  2
IntGELU    | n:  27
IntSoftmax | n:  2
IntGELU    | n:  27
IntSoftmax | n:  2
IntGELU    | n:  27
IntSoftmax | n:  2
IntGELU    | n:  27
IntSoftmax | n:  2
IntGELU    | n:  27
IntSoftmax | n:  2
IntGELU    | n:  27
IntSoftmax | n:  2
IntGELU    | n:  27
IntSoftmax | n:  2
IntGELU    | n:  27
IntSoftmax | n:  2
IntGELU    | n:  27
IntSoftmax | n:  2
IntGELU    | n:  27
.calib done
Test: [  0/391]	Time  3.977 ( 3.977)	Acc@1   0.00 (  0.00)	Acc@5   6.25 (  6.25)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 6.250
Time: 8.88
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=2, intgelu_exp_n=28
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=2, intgelu_exp_n=28, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  2
IntGELU    | n:  28
IntSoftmax | n:  2
IntGELU    | n:  28
IntSoftmax | n:  2
IntGELU    | n:  28
IntSoftmax | n:  2
IntGELU    | n:  28
IntSoftmax | n:  2
IntGELU    | n:  28
IntSoftmax | n:  2
IntGELU    | n:  28
IntSoftmax | n:  2
IntGELU    | n:  28
IntSoftmax | n:  2
IntGELU    | n:  28
IntSoftmax | n:  2
IntGELU    | n:  28
IntSoftmax | n:  2
IntGELU    | n:  28
IntSoftmax | n:  2
IntGELU    | n:  28
IntSoftmax | n:  2
IntGELU    | n:  28
.calib done
Test: [  0/391]	Time  3.642 ( 3.642)	Acc@1   0.00 (  0.00)	Acc@5   7.03 (  7.03)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 7.031
Time: 8.52
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=2, intgelu_exp_n=29
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=2, intgelu_exp_n=29, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  2
IntGELU    | n:  29
IntSoftmax | n:  2
IntGELU    | n:  29
IntSoftmax | n:  2
IntGELU    | n:  29
IntSoftmax | n:  2
IntGELU    | n:  29
IntSoftmax | n:  2
IntGELU    | n:  29
IntSoftmax | n:  2
IntGELU    | n:  29
IntSoftmax | n:  2
IntGELU    | n:  29
IntSoftmax | n:  2
IntGELU    | n:  29
IntSoftmax | n:  2
IntGELU    | n:  29
IntSoftmax | n:  2
IntGELU    | n:  29
IntSoftmax | n:  2
IntGELU    | n:  29
IntSoftmax | n:  2
IntGELU    | n:  29
.calib done
Test: [  0/391]	Time  3.868 ( 3.868)	Acc@1   0.78 (  0.78)	Acc@5   5.47 (  5.47)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.781 Prec@5 5.469
Time: 8.84
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=2, intgelu_exp_n=30
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=2, intgelu_exp_n=30, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  2
IntGELU    | n:  30
IntSoftmax | n:  2
IntGELU    | n:  30
IntSoftmax | n:  2
IntGELU    | n:  30
IntSoftmax | n:  2
IntGELU    | n:  30
IntSoftmax | n:  2
IntGELU    | n:  30
IntSoftmax | n:  2
IntGELU    | n:  30
IntSoftmax | n:  2
IntGELU    | n:  30
IntSoftmax | n:  2
IntGELU    | n:  30
IntSoftmax | n:  2
IntGELU    | n:  30
IntSoftmax | n:  2
IntGELU    | n:  30
IntSoftmax | n:  2
IntGELU    | n:  30
IntSoftmax | n:  2
IntGELU    | n:  30
.calib done
Test: [  0/391]	Time  3.986 ( 3.986)	Acc@1   2.34 (  2.34)	Acc@5   9.38 (  9.38)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 2.344 Prec@5 9.375
Time: 8.92
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=2, intgelu_exp_n=31
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=2, intgelu_exp_n=31, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  2
IntGELU    | n:  31
IntSoftmax | n:  2
IntGELU    | n:  31
IntSoftmax | n:  2
IntGELU    | n:  31
IntSoftmax | n:  2
IntGELU    | n:  31
IntSoftmax | n:  2
IntGELU    | n:  31
IntSoftmax | n:  2
IntGELU    | n:  31
IntSoftmax | n:  2
IntGELU    | n:  31
IntSoftmax | n:  2
IntGELU    | n:  31
IntSoftmax | n:  2
IntGELU    | n:  31
IntSoftmax | n:  2
IntGELU    | n:  31
IntSoftmax | n:  2
IntGELU    | n:  31
IntSoftmax | n:  2
IntGELU    | n:  31
.calib done
Test: [  0/391]	Time  3.885 ( 3.885)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.91
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=3, intgelu_exp_n=0
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=3, intgelu_exp_n=0, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  3
IntGELU    | n:  0
IntSoftmax | n:  3
IntGELU    | n:  0
IntSoftmax | n:  3
IntGELU    | n:  0
IntSoftmax | n:  3
IntGELU    | n:  0
IntSoftmax | n:  3
IntGELU    | n:  0
IntSoftmax | n:  3
IntGELU    | n:  0
IntSoftmax | n:  3
IntGELU    | n:  0
IntSoftmax | n:  3
IntGELU    | n:  0
IntSoftmax | n:  3
IntGELU    | n:  0
IntSoftmax | n:  3
IntGELU    | n:  0
IntSoftmax | n:  3
IntGELU    | n:  0
IntSoftmax | n:  3
IntGELU    | n:  0
.calib done
Test: [  0/391]	Time  3.769 ( 3.769)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.71
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=3, intgelu_exp_n=1
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=3, intgelu_exp_n=1, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  3
IntGELU    | n:  1
IntSoftmax | n:  3
IntGELU    | n:  1
IntSoftmax | n:  3
IntGELU    | n:  1
IntSoftmax | n:  3
IntGELU    | n:  1
IntSoftmax | n:  3
IntGELU    | n:  1
IntSoftmax | n:  3
IntGELU    | n:  1
IntSoftmax | n:  3
IntGELU    | n:  1
IntSoftmax | n:  3
IntGELU    | n:  1
IntSoftmax | n:  3
IntGELU    | n:  1
IntSoftmax | n:  3
IntGELU    | n:  1
IntSoftmax | n:  3
IntGELU    | n:  1
IntSoftmax | n:  3
IntGELU    | n:  1
.calib done
Test: [  0/391]	Time  4.015 ( 4.015)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.94
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=3, intgelu_exp_n=2
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=3, intgelu_exp_n=2, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  3
IntGELU    | n:  2
IntSoftmax | n:  3
IntGELU    | n:  2
IntSoftmax | n:  3
IntGELU    | n:  2
IntSoftmax | n:  3
IntGELU    | n:  2
IntSoftmax | n:  3
IntGELU    | n:  2
IntSoftmax | n:  3
IntGELU    | n:  2
IntSoftmax | n:  3
IntGELU    | n:  2
IntSoftmax | n:  3
IntGELU    | n:  2
IntSoftmax | n:  3
IntGELU    | n:  2
IntSoftmax | n:  3
IntGELU    | n:  2
IntSoftmax | n:  3
IntGELU    | n:  2
IntSoftmax | n:  3
IntGELU    | n:  2
.calib done
Test: [  0/391]	Time  3.849 ( 3.849)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.87
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=3, intgelu_exp_n=3
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=3, intgelu_exp_n=3, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  3
IntGELU    | n:  3
IntSoftmax | n:  3
IntGELU    | n:  3
IntSoftmax | n:  3
IntGELU    | n:  3
IntSoftmax | n:  3
IntGELU    | n:  3
IntSoftmax | n:  3
IntGELU    | n:  3
IntSoftmax | n:  3
IntGELU    | n:  3
IntSoftmax | n:  3
IntGELU    | n:  3
IntSoftmax | n:  3
IntGELU    | n:  3
IntSoftmax | n:  3
IntGELU    | n:  3
IntSoftmax | n:  3
IntGELU    | n:  3
IntSoftmax | n:  3
IntGELU    | n:  3
IntSoftmax | n:  3
IntGELU    | n:  3
.calib done
Test: [  0/391]	Time  3.899 ( 3.899)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.82
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=3, intgelu_exp_n=4
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=3, intgelu_exp_n=4, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  3
IntGELU    | n:  4
IntSoftmax | n:  3
IntGELU    | n:  4
IntSoftmax | n:  3
IntGELU    | n:  4
IntSoftmax | n:  3
IntGELU    | n:  4
IntSoftmax | n:  3
IntGELU    | n:  4
IntSoftmax | n:  3
IntGELU    | n:  4
IntSoftmax | n:  3
IntGELU    | n:  4
IntSoftmax | n:  3
IntGELU    | n:  4
IntSoftmax | n:  3
IntGELU    | n:  4
IntSoftmax | n:  3
IntGELU    | n:  4
IntSoftmax | n:  3
IntGELU    | n:  4
IntSoftmax | n:  3
IntGELU    | n:  4
.calib done
Test: [  0/391]	Time  3.864 ( 3.864)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.84
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=3, intgelu_exp_n=5
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=3, intgelu_exp_n=5, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  3
IntGELU    | n:  5
IntSoftmax | n:  3
IntGELU    | n:  5
IntSoftmax | n:  3
IntGELU    | n:  5
IntSoftmax | n:  3
IntGELU    | n:  5
IntSoftmax | n:  3
IntGELU    | n:  5
IntSoftmax | n:  3
IntGELU    | n:  5
IntSoftmax | n:  3
IntGELU    | n:  5
IntSoftmax | n:  3
IntGELU    | n:  5
IntSoftmax | n:  3
IntGELU    | n:  5
IntSoftmax | n:  3
IntGELU    | n:  5
IntSoftmax | n:  3
IntGELU    | n:  5
IntSoftmax | n:  3
IntGELU    | n:  5
.calib done
Test: [  0/391]	Time  3.872 ( 3.872)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.81
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=3, intgelu_exp_n=6
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=3, intgelu_exp_n=6, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  3
IntGELU    | n:  6
IntSoftmax | n:  3
IntGELU    | n:  6
IntSoftmax | n:  3
IntGELU    | n:  6
IntSoftmax | n:  3
IntGELU    | n:  6
IntSoftmax | n:  3
IntGELU    | n:  6
IntSoftmax | n:  3
IntGELU    | n:  6
IntSoftmax | n:  3
IntGELU    | n:  6
IntSoftmax | n:  3
IntGELU    | n:  6
IntSoftmax | n:  3
IntGELU    | n:  6
IntSoftmax | n:  3
IntGELU    | n:  6
IntSoftmax | n:  3
IntGELU    | n:  6
IntSoftmax | n:  3
IntGELU    | n:  6
.calib done
Test: [  0/391]	Time  3.681 ( 3.681)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.67
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=3, intgelu_exp_n=7
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=3, intgelu_exp_n=7, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  3
IntGELU    | n:  7
IntSoftmax | n:  3
IntGELU    | n:  7
IntSoftmax | n:  3
IntGELU    | n:  7
IntSoftmax | n:  3
IntGELU    | n:  7
IntSoftmax | n:  3
IntGELU    | n:  7
IntSoftmax | n:  3
IntGELU    | n:  7
IntSoftmax | n:  3
IntGELU    | n:  7
IntSoftmax | n:  3
IntGELU    | n:  7
IntSoftmax | n:  3
IntGELU    | n:  7
IntSoftmax | n:  3
IntGELU    | n:  7
IntSoftmax | n:  3
IntGELU    | n:  7
IntSoftmax | n:  3
IntGELU    | n:  7
.calib done
Test: [  0/391]	Time  3.876 ( 3.876)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.80
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=3, intgelu_exp_n=8
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=3, intgelu_exp_n=8, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  3
IntGELU    | n:  8
IntSoftmax | n:  3
IntGELU    | n:  8
IntSoftmax | n:  3
IntGELU    | n:  8
IntSoftmax | n:  3
IntGELU    | n:  8
IntSoftmax | n:  3
IntGELU    | n:  8
IntSoftmax | n:  3
IntGELU    | n:  8
IntSoftmax | n:  3
IntGELU    | n:  8
IntSoftmax | n:  3
IntGELU    | n:  8
IntSoftmax | n:  3
IntGELU    | n:  8
IntSoftmax | n:  3
IntGELU    | n:  8
IntSoftmax | n:  3
IntGELU    | n:  8
IntSoftmax | n:  3
IntGELU    | n:  8
.calib done
Test: [  0/391]	Time  3.674 ( 3.674)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.58
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=3, intgelu_exp_n=9
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=3, intgelu_exp_n=9, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  3
IntGELU    | n:  9
IntSoftmax | n:  3
IntGELU    | n:  9
IntSoftmax | n:  3
IntGELU    | n:  9
IntSoftmax | n:  3
IntGELU    | n:  9
IntSoftmax | n:  3
IntGELU    | n:  9
IntSoftmax | n:  3
IntGELU    | n:  9
IntSoftmax | n:  3
IntGELU    | n:  9
IntSoftmax | n:  3
IntGELU    | n:  9
IntSoftmax | n:  3
IntGELU    | n:  9
IntSoftmax | n:  3
IntGELU    | n:  9
IntSoftmax | n:  3
IntGELU    | n:  9
IntSoftmax | n:  3
IntGELU    | n:  9
.calib done
Test: [  0/391]	Time  3.949 ( 3.949)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.86
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=3, intgelu_exp_n=10
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=3, intgelu_exp_n=10, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  3
IntGELU    | n:  10
IntSoftmax | n:  3
IntGELU    | n:  10
IntSoftmax | n:  3
IntGELU    | n:  10
IntSoftmax | n:  3
IntGELU    | n:  10
IntSoftmax | n:  3
IntGELU    | n:  10
IntSoftmax | n:  3
IntGELU    | n:  10
IntSoftmax | n:  3
IntGELU    | n:  10
IntSoftmax | n:  3
IntGELU    | n:  10
IntSoftmax | n:  3
IntGELU    | n:  10
IntSoftmax | n:  3
IntGELU    | n:  10
IntSoftmax | n:  3
IntGELU    | n:  10
IntSoftmax | n:  3
IntGELU    | n:  10
.calib done
Test: [  0/391]	Time  3.880 ( 3.880)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.80
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=3, intgelu_exp_n=11
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=3, intgelu_exp_n=11, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  3
IntGELU    | n:  11
IntSoftmax | n:  3
IntGELU    | n:  11
IntSoftmax | n:  3
IntGELU    | n:  11
IntSoftmax | n:  3
IntGELU    | n:  11
IntSoftmax | n:  3
IntGELU    | n:  11
IntSoftmax | n:  3
IntGELU    | n:  11
IntSoftmax | n:  3
IntGELU    | n:  11
IntSoftmax | n:  3
IntGELU    | n:  11
IntSoftmax | n:  3
IntGELU    | n:  11
IntSoftmax | n:  3
IntGELU    | n:  11
IntSoftmax | n:  3
IntGELU    | n:  11
IntSoftmax | n:  3
IntGELU    | n:  11
.calib done
Test: [  0/391]	Time  3.958 ( 3.958)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.82
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=3, intgelu_exp_n=12
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=3, intgelu_exp_n=12, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  3
IntGELU    | n:  12
IntSoftmax | n:  3
IntGELU    | n:  12
IntSoftmax | n:  3
IntGELU    | n:  12
IntSoftmax | n:  3
IntGELU    | n:  12
IntSoftmax | n:  3
IntGELU    | n:  12
IntSoftmax | n:  3
IntGELU    | n:  12
IntSoftmax | n:  3
IntGELU    | n:  12
IntSoftmax | n:  3
IntGELU    | n:  12
IntSoftmax | n:  3
IntGELU    | n:  12
IntSoftmax | n:  3
IntGELU    | n:  12
IntSoftmax | n:  3
IntGELU    | n:  12
IntSoftmax | n:  3
IntGELU    | n:  12
.calib done
Test: [  0/391]	Time  3.876 ( 3.876)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.81
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=3, intgelu_exp_n=13
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=3, intgelu_exp_n=13, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  3
IntGELU    | n:  13
IntSoftmax | n:  3
IntGELU    | n:  13
IntSoftmax | n:  3
IntGELU    | n:  13
IntSoftmax | n:  3
IntGELU    | n:  13
IntSoftmax | n:  3
IntGELU    | n:  13
IntSoftmax | n:  3
IntGELU    | n:  13
IntSoftmax | n:  3
IntGELU    | n:  13
IntSoftmax | n:  3
IntGELU    | n:  13
IntSoftmax | n:  3
IntGELU    | n:  13
IntSoftmax | n:  3
IntGELU    | n:  13
IntSoftmax | n:  3
IntGELU    | n:  13
IntSoftmax | n:  3
IntGELU    | n:  13
.calib done
Test: [  0/391]	Time  3.854 ( 3.854)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.81
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=3, intgelu_exp_n=14
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=3, intgelu_exp_n=14, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  3
IntGELU    | n:  14
IntSoftmax | n:  3
IntGELU    | n:  14
IntSoftmax | n:  3
IntGELU    | n:  14
IntSoftmax | n:  3
IntGELU    | n:  14
IntSoftmax | n:  3
IntGELU    | n:  14
IntSoftmax | n:  3
IntGELU    | n:  14
IntSoftmax | n:  3
IntGELU    | n:  14
IntSoftmax | n:  3
IntGELU    | n:  14
IntSoftmax | n:  3
IntGELU    | n:  14
IntSoftmax | n:  3
IntGELU    | n:  14
IntSoftmax | n:  3
IntGELU    | n:  14
IntSoftmax | n:  3
IntGELU    | n:  14
.calib done
Test: [  0/391]	Time  3.682 ( 3.682)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.64
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=3, intgelu_exp_n=15
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=3, intgelu_exp_n=15, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  3
IntGELU    | n:  15
IntSoftmax | n:  3
IntGELU    | n:  15
IntSoftmax | n:  3
IntGELU    | n:  15
IntSoftmax | n:  3
IntGELU    | n:  15
IntSoftmax | n:  3
IntGELU    | n:  15
IntSoftmax | n:  3
IntGELU    | n:  15
IntSoftmax | n:  3
IntGELU    | n:  15
IntSoftmax | n:  3
IntGELU    | n:  15
IntSoftmax | n:  3
IntGELU    | n:  15
IntSoftmax | n:  3
IntGELU    | n:  15
IntSoftmax | n:  3
IntGELU    | n:  15
IntSoftmax | n:  3
IntGELU    | n:  15
.calib done
Test: [  0/391]	Time  3.988 ( 3.988)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.97
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=3, intgelu_exp_n=16
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=3, intgelu_exp_n=16, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  3
IntGELU    | n:  16
IntSoftmax | n:  3
IntGELU    | n:  16
IntSoftmax | n:  3
IntGELU    | n:  16
IntSoftmax | n:  3
IntGELU    | n:  16
IntSoftmax | n:  3
IntGELU    | n:  16
IntSoftmax | n:  3
IntGELU    | n:  16
IntSoftmax | n:  3
IntGELU    | n:  16
IntSoftmax | n:  3
IntGELU    | n:  16
IntSoftmax | n:  3
IntGELU    | n:  16
IntSoftmax | n:  3
IntGELU    | n:  16
IntSoftmax | n:  3
IntGELU    | n:  16
IntSoftmax | n:  3
IntGELU    | n:  16
.calib done
Test: [  0/391]	Time  3.878 ( 3.878)	Acc@1   0.00 (  0.00)	Acc@5   1.56 (  1.56)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 1.562
Time: 8.83
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=3, intgelu_exp_n=17
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=3, intgelu_exp_n=17, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  3
IntGELU    | n:  17
IntSoftmax | n:  3
IntGELU    | n:  17
IntSoftmax | n:  3
IntGELU    | n:  17
IntSoftmax | n:  3
IntGELU    | n:  17
IntSoftmax | n:  3
IntGELU    | n:  17
IntSoftmax | n:  3
IntGELU    | n:  17
IntSoftmax | n:  3
IntGELU    | n:  17
IntSoftmax | n:  3
IntGELU    | n:  17
IntSoftmax | n:  3
IntGELU    | n:  17
IntSoftmax | n:  3
IntGELU    | n:  17
IntSoftmax | n:  3
IntGELU    | n:  17
IntSoftmax | n:  3
IntGELU    | n:  17
.calib done
Test: [  0/391]	Time  3.757 ( 3.757)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.74
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=3, intgelu_exp_n=18
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=3, intgelu_exp_n=18, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  3
IntGELU    | n:  18
IntSoftmax | n:  3
IntGELU    | n:  18
IntSoftmax | n:  3
IntGELU    | n:  18
IntSoftmax | n:  3
IntGELU    | n:  18
IntSoftmax | n:  3
IntGELU    | n:  18
IntSoftmax | n:  3
IntGELU    | n:  18
IntSoftmax | n:  3
IntGELU    | n:  18
IntSoftmax | n:  3
IntGELU    | n:  18
IntSoftmax | n:  3
IntGELU    | n:  18
IntSoftmax | n:  3
IntGELU    | n:  18
IntSoftmax | n:  3
IntGELU    | n:  18
IntSoftmax | n:  3
IntGELU    | n:  18
.calib done
Test: [  0/391]	Time  3.702 ( 3.702)	Acc@1   0.00 (  0.00)	Acc@5   1.56 (  1.56)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 1.562
Time: 8.65
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=3, intgelu_exp_n=19
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=3, intgelu_exp_n=19, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  3
IntGELU    | n:  19
IntSoftmax | n:  3
IntGELU    | n:  19
IntSoftmax | n:  3
IntGELU    | n:  19
IntSoftmax | n:  3
IntGELU    | n:  19
IntSoftmax | n:  3
IntGELU    | n:  19
IntSoftmax | n:  3
IntGELU    | n:  19
IntSoftmax | n:  3
IntGELU    | n:  19
IntSoftmax | n:  3
IntGELU    | n:  19
IntSoftmax | n:  3
IntGELU    | n:  19
IntSoftmax | n:  3
IntGELU    | n:  19
IntSoftmax | n:  3
IntGELU    | n:  19
IntSoftmax | n:  3
IntGELU    | n:  19
.calib done
Test: [  0/391]	Time  3.954 ( 3.954)	Acc@1   0.00 (  0.00)	Acc@5   1.56 (  1.56)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 1.562
Time: 8.89
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=3, intgelu_exp_n=20
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=3, intgelu_exp_n=20, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  3
IntGELU    | n:  20
IntSoftmax | n:  3
IntGELU    | n:  20
IntSoftmax | n:  3
IntGELU    | n:  20
IntSoftmax | n:  3
IntGELU    | n:  20
IntSoftmax | n:  3
IntGELU    | n:  20
IntSoftmax | n:  3
IntGELU    | n:  20
IntSoftmax | n:  3
IntGELU    | n:  20
IntSoftmax | n:  3
IntGELU    | n:  20
IntSoftmax | n:  3
IntGELU    | n:  20
IntSoftmax | n:  3
IntGELU    | n:  20
IntSoftmax | n:  3
IntGELU    | n:  20
IntSoftmax | n:  3
IntGELU    | n:  20
.calib done
Test: [  0/391]	Time  3.695 ( 3.695)	Acc@1   0.00 (  0.00)	Acc@5   2.34 (  2.34)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 2.344
Time: 8.77
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=3, intgelu_exp_n=21
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=3, intgelu_exp_n=21, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  3
IntGELU    | n:  21
IntSoftmax | n:  3
IntGELU    | n:  21
IntSoftmax | n:  3
IntGELU    | n:  21
IntSoftmax | n:  3
IntGELU    | n:  21
IntSoftmax | n:  3
IntGELU    | n:  21
IntSoftmax | n:  3
IntGELU    | n:  21
IntSoftmax | n:  3
IntGELU    | n:  21
IntSoftmax | n:  3
IntGELU    | n:  21
IntSoftmax | n:  3
IntGELU    | n:  21
IntSoftmax | n:  3
IntGELU    | n:  21
IntSoftmax | n:  3
IntGELU    | n:  21
IntSoftmax | n:  3
IntGELU    | n:  21
.calib done
Test: [  0/391]	Time  3.782 ( 3.782)	Acc@1   2.34 (  2.34)	Acc@5   9.38 (  9.38)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 2.344 Prec@5 9.375
Time: 8.74
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=3, intgelu_exp_n=22
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=3, intgelu_exp_n=22, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  3
IntGELU    | n:  22
IntSoftmax | n:  3
IntGELU    | n:  22
IntSoftmax | n:  3
IntGELU    | n:  22
IntSoftmax | n:  3
IntGELU    | n:  22
IntSoftmax | n:  3
IntGELU    | n:  22
IntSoftmax | n:  3
IntGELU    | n:  22
IntSoftmax | n:  3
IntGELU    | n:  22
IntSoftmax | n:  3
IntGELU    | n:  22
IntSoftmax | n:  3
IntGELU    | n:  22
IntSoftmax | n:  3
IntGELU    | n:  22
IntSoftmax | n:  3
IntGELU    | n:  22
IntSoftmax | n:  3
IntGELU    | n:  22
.calib done
Test: [  0/391]	Time  3.954 ( 3.954)	Acc@1   0.78 (  0.78)	Acc@5   3.12 (  3.12)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.781 Prec@5 3.125
Time: 8.91
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=3, intgelu_exp_n=23
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=3, intgelu_exp_n=23, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  3
IntGELU    | n:  23
IntSoftmax | n:  3
IntGELU    | n:  23
IntSoftmax | n:  3
IntGELU    | n:  23
IntSoftmax | n:  3
IntGELU    | n:  23
IntSoftmax | n:  3
IntGELU    | n:  23
IntSoftmax | n:  3
IntGELU    | n:  23
IntSoftmax | n:  3
IntGELU    | n:  23
IntSoftmax | n:  3
IntGELU    | n:  23
IntSoftmax | n:  3
IntGELU    | n:  23
IntSoftmax | n:  3
IntGELU    | n:  23
IntSoftmax | n:  3
IntGELU    | n:  23
IntSoftmax | n:  3
IntGELU    | n:  23
.calib done
Test: [  0/391]	Time  3.711 ( 3.711)	Acc@1   2.34 (  2.34)	Acc@5  14.84 ( 14.84)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 2.344 Prec@5 14.844
Time: 8.62
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=3, intgelu_exp_n=24
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=3, intgelu_exp_n=24, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  3
IntGELU    | n:  24
IntSoftmax | n:  3
IntGELU    | n:  24
IntSoftmax | n:  3
IntGELU    | n:  24
IntSoftmax | n:  3
IntGELU    | n:  24
IntSoftmax | n:  3
IntGELU    | n:  24
IntSoftmax | n:  3
IntGELU    | n:  24
IntSoftmax | n:  3
IntGELU    | n:  24
IntSoftmax | n:  3
IntGELU    | n:  24
IntSoftmax | n:  3
IntGELU    | n:  24
IntSoftmax | n:  3
IntGELU    | n:  24
IntSoftmax | n:  3
IntGELU    | n:  24
IntSoftmax | n:  3
IntGELU    | n:  24
.calib done
Test: [  0/391]	Time  3.877 ( 3.877)	Acc@1   1.56 (  1.56)	Acc@5   3.91 (  3.91)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 1.562 Prec@5 3.906
Time: 8.81
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=3, intgelu_exp_n=25
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=3, intgelu_exp_n=25, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  3
IntGELU    | n:  25
IntSoftmax | n:  3
IntGELU    | n:  25
IntSoftmax | n:  3
IntGELU    | n:  25
IntSoftmax | n:  3
IntGELU    | n:  25
IntSoftmax | n:  3
IntGELU    | n:  25
IntSoftmax | n:  3
IntGELU    | n:  25
IntSoftmax | n:  3
IntGELU    | n:  25
IntSoftmax | n:  3
IntGELU    | n:  25
IntSoftmax | n:  3
IntGELU    | n:  25
IntSoftmax | n:  3
IntGELU    | n:  25
IntSoftmax | n:  3
IntGELU    | n:  25
IntSoftmax | n:  3
IntGELU    | n:  25
.calib done
Test: [  0/391]	Time  3.648 ( 3.648)	Acc@1   1.56 (  1.56)	Acc@5  17.97 ( 17.97)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 1.562 Prec@5 17.969
Time: 8.61
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=3, intgelu_exp_n=26
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=3, intgelu_exp_n=26, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  3
IntGELU    | n:  26
IntSoftmax | n:  3
IntGELU    | n:  26
IntSoftmax | n:  3
IntGELU    | n:  26
IntSoftmax | n:  3
IntGELU    | n:  26
IntSoftmax | n:  3
IntGELU    | n:  26
IntSoftmax | n:  3
IntGELU    | n:  26
IntSoftmax | n:  3
IntGELU    | n:  26
IntSoftmax | n:  3
IntGELU    | n:  26
IntSoftmax | n:  3
IntGELU    | n:  26
IntSoftmax | n:  3
IntGELU    | n:  26
IntSoftmax | n:  3
IntGELU    | n:  26
IntSoftmax | n:  3
IntGELU    | n:  26
.calib done
Test: [  0/391]	Time  3.913 ( 3.913)	Acc@1   0.00 (  0.00)	Acc@5   7.03 (  7.03)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 7.031
Time: 8.82
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=3, intgelu_exp_n=27
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=3, intgelu_exp_n=27, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  3
IntGELU    | n:  27
IntSoftmax | n:  3
IntGELU    | n:  27
IntSoftmax | n:  3
IntGELU    | n:  27
IntSoftmax | n:  3
IntGELU    | n:  27
IntSoftmax | n:  3
IntGELU    | n:  27
IntSoftmax | n:  3
IntGELU    | n:  27
IntSoftmax | n:  3
IntGELU    | n:  27
IntSoftmax | n:  3
IntGELU    | n:  27
IntSoftmax | n:  3
IntGELU    | n:  27
IntSoftmax | n:  3
IntGELU    | n:  27
IntSoftmax | n:  3
IntGELU    | n:  27
IntSoftmax | n:  3
IntGELU    | n:  27
.calib done
Test: [  0/391]	Time  3.917 ( 3.917)	Acc@1   1.56 (  1.56)	Acc@5  11.72 ( 11.72)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 1.562 Prec@5 11.719
Time: 8.91
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=3, intgelu_exp_n=28
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=3, intgelu_exp_n=28, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  3
IntGELU    | n:  28
IntSoftmax | n:  3
IntGELU    | n:  28
IntSoftmax | n:  3
IntGELU    | n:  28
IntSoftmax | n:  3
IntGELU    | n:  28
IntSoftmax | n:  3
IntGELU    | n:  28
IntSoftmax | n:  3
IntGELU    | n:  28
IntSoftmax | n:  3
IntGELU    | n:  28
IntSoftmax | n:  3
IntGELU    | n:  28
IntSoftmax | n:  3
IntGELU    | n:  28
IntSoftmax | n:  3
IntGELU    | n:  28
IntSoftmax | n:  3
IntGELU    | n:  28
IntSoftmax | n:  3
IntGELU    | n:  28
.calib done
Test: [  0/391]	Time  3.924 ( 3.924)	Acc@1   3.12 (  3.12)	Acc@5  19.53 ( 19.53)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 3.125 Prec@5 19.531
Time: 8.89
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=3, intgelu_exp_n=29
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=3, intgelu_exp_n=29, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  3
IntGELU    | n:  29
IntSoftmax | n:  3
IntGELU    | n:  29
IntSoftmax | n:  3
IntGELU    | n:  29
IntSoftmax | n:  3
IntGELU    | n:  29
IntSoftmax | n:  3
IntGELU    | n:  29
IntSoftmax | n:  3
IntGELU    | n:  29
IntSoftmax | n:  3
IntGELU    | n:  29
IntSoftmax | n:  3
IntGELU    | n:  29
IntSoftmax | n:  3
IntGELU    | n:  29
IntSoftmax | n:  3
IntGELU    | n:  29
IntSoftmax | n:  3
IntGELU    | n:  29
IntSoftmax | n:  3
IntGELU    | n:  29
.calib done
Test: [  0/391]	Time  4.010 ( 4.010)	Acc@1   0.00 (  0.00)	Acc@5   7.81 (  7.81)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 7.812
Time: 8.95
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=3, intgelu_exp_n=30
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=3, intgelu_exp_n=30, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  3
IntGELU    | n:  30
IntSoftmax | n:  3
IntGELU    | n:  30
IntSoftmax | n:  3
IntGELU    | n:  30
IntSoftmax | n:  3
IntGELU    | n:  30
IntSoftmax | n:  3
IntGELU    | n:  30
IntSoftmax | n:  3
IntGELU    | n:  30
IntSoftmax | n:  3
IntGELU    | n:  30
IntSoftmax | n:  3
IntGELU    | n:  30
IntSoftmax | n:  3
IntGELU    | n:  30
IntSoftmax | n:  3
IntGELU    | n:  30
IntSoftmax | n:  3
IntGELU    | n:  30
IntSoftmax | n:  3
IntGELU    | n:  30
.calib done
Test: [  0/391]	Time  3.683 ( 3.683)	Acc@1  12.50 ( 12.50)	Acc@5  22.66 ( 22.66)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 12.500 Prec@5 22.656
Time: 8.70
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=3, intgelu_exp_n=31
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=3, intgelu_exp_n=31, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  3
IntGELU    | n:  31
IntSoftmax | n:  3
IntGELU    | n:  31
IntSoftmax | n:  3
IntGELU    | n:  31
IntSoftmax | n:  3
IntGELU    | n:  31
IntSoftmax | n:  3
IntGELU    | n:  31
IntSoftmax | n:  3
IntGELU    | n:  31
IntSoftmax | n:  3
IntGELU    | n:  31
IntSoftmax | n:  3
IntGELU    | n:  31
IntSoftmax | n:  3
IntGELU    | n:  31
IntSoftmax | n:  3
IntGELU    | n:  31
IntSoftmax | n:  3
IntGELU    | n:  31
IntSoftmax | n:  3
IntGELU    | n:  31
.calib done
Test: [  0/391]	Time  3.854 ( 3.854)	Acc@1   1.56 (  1.56)	Acc@5   3.91 (  3.91)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 1.562 Prec@5 3.906
Time: 8.80
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=4, intgelu_exp_n=0
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=4, intgelu_exp_n=0, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  4
IntGELU    | n:  0
IntSoftmax | n:  4
IntGELU    | n:  0
IntSoftmax | n:  4
IntGELU    | n:  0
IntSoftmax | n:  4
IntGELU    | n:  0
IntSoftmax | n:  4
IntGELU    | n:  0
IntSoftmax | n:  4
IntGELU    | n:  0
IntSoftmax | n:  4
IntGELU    | n:  0
IntSoftmax | n:  4
IntGELU    | n:  0
IntSoftmax | n:  4
IntGELU    | n:  0
IntSoftmax | n:  4
IntGELU    | n:  0
IntSoftmax | n:  4
IntGELU    | n:  0
IntSoftmax | n:  4
IntGELU    | n:  0
.calib done
Test: [  0/391]	Time  3.860 ( 3.860)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.83
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=4, intgelu_exp_n=1
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=4, intgelu_exp_n=1, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  4
IntGELU    | n:  1
IntSoftmax | n:  4
IntGELU    | n:  1
IntSoftmax | n:  4
IntGELU    | n:  1
IntSoftmax | n:  4
IntGELU    | n:  1
IntSoftmax | n:  4
IntGELU    | n:  1
IntSoftmax | n:  4
IntGELU    | n:  1
IntSoftmax | n:  4
IntGELU    | n:  1
IntSoftmax | n:  4
IntGELU    | n:  1
IntSoftmax | n:  4
IntGELU    | n:  1
IntSoftmax | n:  4
IntGELU    | n:  1
IntSoftmax | n:  4
IntGELU    | n:  1
IntSoftmax | n:  4
IntGELU    | n:  1
.calib done
Test: [  0/391]	Time  3.859 ( 3.859)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.81
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=4, intgelu_exp_n=2
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=4, intgelu_exp_n=2, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  4
IntGELU    | n:  2
IntSoftmax | n:  4
IntGELU    | n:  2
IntSoftmax | n:  4
IntGELU    | n:  2
IntSoftmax | n:  4
IntGELU    | n:  2
IntSoftmax | n:  4
IntGELU    | n:  2
IntSoftmax | n:  4
IntGELU    | n:  2
IntSoftmax | n:  4
IntGELU    | n:  2
IntSoftmax | n:  4
IntGELU    | n:  2
IntSoftmax | n:  4
IntGELU    | n:  2
IntSoftmax | n:  4
IntGELU    | n:  2
IntSoftmax | n:  4
IntGELU    | n:  2
IntSoftmax | n:  4
IntGELU    | n:  2
.calib done
Test: [  0/391]	Time  3.734 ( 3.734)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.59
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=4, intgelu_exp_n=3
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=4, intgelu_exp_n=3, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  4
IntGELU    | n:  3
IntSoftmax | n:  4
IntGELU    | n:  3
IntSoftmax | n:  4
IntGELU    | n:  3
IntSoftmax | n:  4
IntGELU    | n:  3
IntSoftmax | n:  4
IntGELU    | n:  3
IntSoftmax | n:  4
IntGELU    | n:  3
IntSoftmax | n:  4
IntGELU    | n:  3
IntSoftmax | n:  4
IntGELU    | n:  3
IntSoftmax | n:  4
IntGELU    | n:  3
IntSoftmax | n:  4
IntGELU    | n:  3
IntSoftmax | n:  4
IntGELU    | n:  3
IntSoftmax | n:  4
IntGELU    | n:  3
.calib done
Test: [  0/391]	Time  3.880 ( 3.880)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.85
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=4, intgelu_exp_n=4
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=4, intgelu_exp_n=4, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  4
IntGELU    | n:  4
IntSoftmax | n:  4
IntGELU    | n:  4
IntSoftmax | n:  4
IntGELU    | n:  4
IntSoftmax | n:  4
IntGELU    | n:  4
IntSoftmax | n:  4
IntGELU    | n:  4
IntSoftmax | n:  4
IntGELU    | n:  4
IntSoftmax | n:  4
IntGELU    | n:  4
IntSoftmax | n:  4
IntGELU    | n:  4
IntSoftmax | n:  4
IntGELU    | n:  4
IntSoftmax | n:  4
IntGELU    | n:  4
IntSoftmax | n:  4
IntGELU    | n:  4
IntSoftmax | n:  4
IntGELU    | n:  4
.calib done
Test: [  0/391]	Time  3.852 ( 3.852)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.82
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=4, intgelu_exp_n=5
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=4, intgelu_exp_n=5, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  4
IntGELU    | n:  5
IntSoftmax | n:  4
IntGELU    | n:  5
IntSoftmax | n:  4
IntGELU    | n:  5
IntSoftmax | n:  4
IntGELU    | n:  5
IntSoftmax | n:  4
IntGELU    | n:  5
IntSoftmax | n:  4
IntGELU    | n:  5
IntSoftmax | n:  4
IntGELU    | n:  5
IntSoftmax | n:  4
IntGELU    | n:  5
IntSoftmax | n:  4
IntGELU    | n:  5
IntSoftmax | n:  4
IntGELU    | n:  5
IntSoftmax | n:  4
IntGELU    | n:  5
IntSoftmax | n:  4
IntGELU    | n:  5
.calib done
Test: [  0/391]	Time  3.903 ( 3.903)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.83
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=4, intgelu_exp_n=6
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=4, intgelu_exp_n=6, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  4
IntGELU    | n:  6
IntSoftmax | n:  4
IntGELU    | n:  6
IntSoftmax | n:  4
IntGELU    | n:  6
IntSoftmax | n:  4
IntGELU    | n:  6
IntSoftmax | n:  4
IntGELU    | n:  6
IntSoftmax | n:  4
IntGELU    | n:  6
IntSoftmax | n:  4
IntGELU    | n:  6
IntSoftmax | n:  4
IntGELU    | n:  6
IntSoftmax | n:  4
IntGELU    | n:  6
IntSoftmax | n:  4
IntGELU    | n:  6
IntSoftmax | n:  4
IntGELU    | n:  6
IntSoftmax | n:  4
IntGELU    | n:  6
.calib done
Test: [  0/391]	Time  3.926 ( 3.926)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.84
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=4, intgelu_exp_n=7
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=4, intgelu_exp_n=7, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  4
IntGELU    | n:  7
IntSoftmax | n:  4
IntGELU    | n:  7
IntSoftmax | n:  4
IntGELU    | n:  7
IntSoftmax | n:  4
IntGELU    | n:  7
IntSoftmax | n:  4
IntGELU    | n:  7
IntSoftmax | n:  4
IntGELU    | n:  7
IntSoftmax | n:  4
IntGELU    | n:  7
IntSoftmax | n:  4
IntGELU    | n:  7
IntSoftmax | n:  4
IntGELU    | n:  7
IntSoftmax | n:  4
IntGELU    | n:  7
IntSoftmax | n:  4
IntGELU    | n:  7
IntSoftmax | n:  4
IntGELU    | n:  7
.calib done
Test: [  0/391]	Time  3.927 ( 3.927)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.89
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=4, intgelu_exp_n=8
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=4, intgelu_exp_n=8, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  4
IntGELU    | n:  8
IntSoftmax | n:  4
IntGELU    | n:  8
IntSoftmax | n:  4
IntGELU    | n:  8
IntSoftmax | n:  4
IntGELU    | n:  8
IntSoftmax | n:  4
IntGELU    | n:  8
IntSoftmax | n:  4
IntGELU    | n:  8
IntSoftmax | n:  4
IntGELU    | n:  8
IntSoftmax | n:  4
IntGELU    | n:  8
IntSoftmax | n:  4
IntGELU    | n:  8
IntSoftmax | n:  4
IntGELU    | n:  8
IntSoftmax | n:  4
IntGELU    | n:  8
IntSoftmax | n:  4
IntGELU    | n:  8
.calib done
Test: [  0/391]	Time  3.952 ( 3.952)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.87
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=4, intgelu_exp_n=9
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=4, intgelu_exp_n=9, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  4
IntGELU    | n:  9
IntSoftmax | n:  4
IntGELU    | n:  9
IntSoftmax | n:  4
IntGELU    | n:  9
IntSoftmax | n:  4
IntGELU    | n:  9
IntSoftmax | n:  4
IntGELU    | n:  9
IntSoftmax | n:  4
IntGELU    | n:  9
IntSoftmax | n:  4
IntGELU    | n:  9
IntSoftmax | n:  4
IntGELU    | n:  9
IntSoftmax | n:  4
IntGELU    | n:  9
IntSoftmax | n:  4
IntGELU    | n:  9
IntSoftmax | n:  4
IntGELU    | n:  9
IntSoftmax | n:  4
IntGELU    | n:  9
.calib done
Test: [  0/391]	Time  3.930 ( 3.930)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.92
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=4, intgelu_exp_n=10
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=4, intgelu_exp_n=10, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  4
IntGELU    | n:  10
IntSoftmax | n:  4
IntGELU    | n:  10
IntSoftmax | n:  4
IntGELU    | n:  10
IntSoftmax | n:  4
IntGELU    | n:  10
IntSoftmax | n:  4
IntGELU    | n:  10
IntSoftmax | n:  4
IntGELU    | n:  10
IntSoftmax | n:  4
IntGELU    | n:  10
IntSoftmax | n:  4
IntGELU    | n:  10
IntSoftmax | n:  4
IntGELU    | n:  10
IntSoftmax | n:  4
IntGELU    | n:  10
IntSoftmax | n:  4
IntGELU    | n:  10
IntSoftmax | n:  4
IntGELU    | n:  10
.calib done
Test: [  0/391]	Time  3.870 ( 3.870)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.82
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=4, intgelu_exp_n=11
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=4, intgelu_exp_n=11, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  4
IntGELU    | n:  11
IntSoftmax | n:  4
IntGELU    | n:  11
IntSoftmax | n:  4
IntGELU    | n:  11
IntSoftmax | n:  4
IntGELU    | n:  11
IntSoftmax | n:  4
IntGELU    | n:  11
IntSoftmax | n:  4
IntGELU    | n:  11
IntSoftmax | n:  4
IntGELU    | n:  11
IntSoftmax | n:  4
IntGELU    | n:  11
IntSoftmax | n:  4
IntGELU    | n:  11
IntSoftmax | n:  4
IntGELU    | n:  11
IntSoftmax | n:  4
IntGELU    | n:  11
IntSoftmax | n:  4
IntGELU    | n:  11
.calib done
Test: [  0/391]	Time  3.712 ( 3.712)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.63
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=4, intgelu_exp_n=12
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=4, intgelu_exp_n=12, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  4
IntGELU    | n:  12
IntSoftmax | n:  4
IntGELU    | n:  12
IntSoftmax | n:  4
IntGELU    | n:  12
IntSoftmax | n:  4
IntGELU    | n:  12
IntSoftmax | n:  4
IntGELU    | n:  12
IntSoftmax | n:  4
IntGELU    | n:  12
IntSoftmax | n:  4
IntGELU    | n:  12
IntSoftmax | n:  4
IntGELU    | n:  12
IntSoftmax | n:  4
IntGELU    | n:  12
IntSoftmax | n:  4
IntGELU    | n:  12
IntSoftmax | n:  4
IntGELU    | n:  12
IntSoftmax | n:  4
IntGELU    | n:  12
.calib done
Test: [  0/391]	Time  3.793 ( 3.793)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.75
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=4, intgelu_exp_n=13
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=4, intgelu_exp_n=13, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  4
IntGELU    | n:  13
IntSoftmax | n:  4
IntGELU    | n:  13
IntSoftmax | n:  4
IntGELU    | n:  13
IntSoftmax | n:  4
IntGELU    | n:  13
IntSoftmax | n:  4
IntGELU    | n:  13
IntSoftmax | n:  4
IntGELU    | n:  13
IntSoftmax | n:  4
IntGELU    | n:  13
IntSoftmax | n:  4
IntGELU    | n:  13
IntSoftmax | n:  4
IntGELU    | n:  13
IntSoftmax | n:  4
IntGELU    | n:  13
IntSoftmax | n:  4
IntGELU    | n:  13
IntSoftmax | n:  4
IntGELU    | n:  13
.calib done
Test: [  0/391]	Time  3.959 ( 3.959)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.99
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=4, intgelu_exp_n=14
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=4, intgelu_exp_n=14, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  4
IntGELU    | n:  14
IntSoftmax | n:  4
IntGELU    | n:  14
IntSoftmax | n:  4
IntGELU    | n:  14
IntSoftmax | n:  4
IntGELU    | n:  14
IntSoftmax | n:  4
IntGELU    | n:  14
IntSoftmax | n:  4
IntGELU    | n:  14
IntSoftmax | n:  4
IntGELU    | n:  14
IntSoftmax | n:  4
IntGELU    | n:  14
IntSoftmax | n:  4
IntGELU    | n:  14
IntSoftmax | n:  4
IntGELU    | n:  14
IntSoftmax | n:  4
IntGELU    | n:  14
IntSoftmax | n:  4
IntGELU    | n:  14
.calib done
Test: [  0/391]	Time  3.866 ( 3.866)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.82
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=4, intgelu_exp_n=15
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=4, intgelu_exp_n=15, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  4
IntGELU    | n:  15
IntSoftmax | n:  4
IntGELU    | n:  15
IntSoftmax | n:  4
IntGELU    | n:  15
IntSoftmax | n:  4
IntGELU    | n:  15
IntSoftmax | n:  4
IntGELU    | n:  15
IntSoftmax | n:  4
IntGELU    | n:  15
IntSoftmax | n:  4
IntGELU    | n:  15
IntSoftmax | n:  4
IntGELU    | n:  15
IntSoftmax | n:  4
IntGELU    | n:  15
IntSoftmax | n:  4
IntGELU    | n:  15
IntSoftmax | n:  4
IntGELU    | n:  15
IntSoftmax | n:  4
IntGELU    | n:  15
.calib done
Test: [  0/391]	Time  3.820 ( 3.820)	Acc@1   0.00 (  0.00)	Acc@5   1.56 (  1.56)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 1.562
Time: 8.80
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=4, intgelu_exp_n=16
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=4, intgelu_exp_n=16, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  4
IntGELU    | n:  16
IntSoftmax | n:  4
IntGELU    | n:  16
IntSoftmax | n:  4
IntGELU    | n:  16
IntSoftmax | n:  4
IntGELU    | n:  16
IntSoftmax | n:  4
IntGELU    | n:  16
IntSoftmax | n:  4
IntGELU    | n:  16
IntSoftmax | n:  4
IntGELU    | n:  16
IntSoftmax | n:  4
IntGELU    | n:  16
IntSoftmax | n:  4
IntGELU    | n:  16
IntSoftmax | n:  4
IntGELU    | n:  16
IntSoftmax | n:  4
IntGELU    | n:  16
IntSoftmax | n:  4
IntGELU    | n:  16
.calib done
Test: [  0/391]	Time  3.937 ( 3.937)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.87
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=4, intgelu_exp_n=17
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=4, intgelu_exp_n=17, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  4
IntGELU    | n:  17
IntSoftmax | n:  4
IntGELU    | n:  17
IntSoftmax | n:  4
IntGELU    | n:  17
IntSoftmax | n:  4
IntGELU    | n:  17
IntSoftmax | n:  4
IntGELU    | n:  17
IntSoftmax | n:  4
IntGELU    | n:  17
IntSoftmax | n:  4
IntGELU    | n:  17
IntSoftmax | n:  4
IntGELU    | n:  17
IntSoftmax | n:  4
IntGELU    | n:  17
IntSoftmax | n:  4
IntGELU    | n:  17
IntSoftmax | n:  4
IntGELU    | n:  17
IntSoftmax | n:  4
IntGELU    | n:  17
.calib done
Test: [  0/391]	Time  3.680 ( 3.680)	Acc@1   0.00 (  0.00)	Acc@5   0.78 (  0.78)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.781
Time: 8.72
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=4, intgelu_exp_n=18
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=4, intgelu_exp_n=18, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  4
IntGELU    | n:  18
IntSoftmax | n:  4
IntGELU    | n:  18
IntSoftmax | n:  4
IntGELU    | n:  18
IntSoftmax | n:  4
IntGELU    | n:  18
IntSoftmax | n:  4
IntGELU    | n:  18
IntSoftmax | n:  4
IntGELU    | n:  18
IntSoftmax | n:  4
IntGELU    | n:  18
IntSoftmax | n:  4
IntGELU    | n:  18
IntSoftmax | n:  4
IntGELU    | n:  18
IntSoftmax | n:  4
IntGELU    | n:  18
IntSoftmax | n:  4
IntGELU    | n:  18
IntSoftmax | n:  4
IntGELU    | n:  18
.calib done
Test: [  0/391]	Time  4.016 ( 4.016)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.95
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=4, intgelu_exp_n=19
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=4, intgelu_exp_n=19, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  4
IntGELU    | n:  19
IntSoftmax | n:  4
IntGELU    | n:  19
IntSoftmax | n:  4
IntGELU    | n:  19
IntSoftmax | n:  4
IntGELU    | n:  19
IntSoftmax | n:  4
IntGELU    | n:  19
IntSoftmax | n:  4
IntGELU    | n:  19
IntSoftmax | n:  4
IntGELU    | n:  19
IntSoftmax | n:  4
IntGELU    | n:  19
IntSoftmax | n:  4
IntGELU    | n:  19
IntSoftmax | n:  4
IntGELU    | n:  19
IntSoftmax | n:  4
IntGELU    | n:  19
IntSoftmax | n:  4
IntGELU    | n:  19
.calib done
Test: [  0/391]	Time  3.877 ( 3.877)	Acc@1   0.00 (  0.00)	Acc@5   2.34 (  2.34)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 2.344
Time: 8.82
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=4, intgelu_exp_n=20
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=4, intgelu_exp_n=20, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  4
IntGELU    | n:  20
IntSoftmax | n:  4
IntGELU    | n:  20
IntSoftmax | n:  4
IntGELU    | n:  20
IntSoftmax | n:  4
IntGELU    | n:  20
IntSoftmax | n:  4
IntGELU    | n:  20
IntSoftmax | n:  4
IntGELU    | n:  20
IntSoftmax | n:  4
IntGELU    | n:  20
IntSoftmax | n:  4
IntGELU    | n:  20
IntSoftmax | n:  4
IntGELU    | n:  20
IntSoftmax | n:  4
IntGELU    | n:  20
IntSoftmax | n:  4
IntGELU    | n:  20
IntSoftmax | n:  4
IntGELU    | n:  20
.calib done
Test: [  0/391]	Time  3.741 ( 3.741)	Acc@1   4.69 (  4.69)	Acc@5   9.38 (  9.38)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 4.688 Prec@5 9.375
Time: 8.67
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=4, intgelu_exp_n=21
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=4, intgelu_exp_n=21, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  4
IntGELU    | n:  21
IntSoftmax | n:  4
IntGELU    | n:  21
IntSoftmax | n:  4
IntGELU    | n:  21
IntSoftmax | n:  4
IntGELU    | n:  21
IntSoftmax | n:  4
IntGELU    | n:  21
IntSoftmax | n:  4
IntGELU    | n:  21
IntSoftmax | n:  4
IntGELU    | n:  21
IntSoftmax | n:  4
IntGELU    | n:  21
IntSoftmax | n:  4
IntGELU    | n:  21
IntSoftmax | n:  4
IntGELU    | n:  21
IntSoftmax | n:  4
IntGELU    | n:  21
IntSoftmax | n:  4
IntGELU    | n:  21
.calib done
Test: [  0/391]	Time  3.662 ( 3.662)	Acc@1   0.78 (  0.78)	Acc@5   4.69 (  4.69)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.781 Prec@5 4.688
Time: 8.62
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=4, intgelu_exp_n=22
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=4, intgelu_exp_n=22, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  4
IntGELU    | n:  22
IntSoftmax | n:  4
IntGELU    | n:  22
IntSoftmax | n:  4
IntGELU    | n:  22
IntSoftmax | n:  4
IntGELU    | n:  22
IntSoftmax | n:  4
IntGELU    | n:  22
IntSoftmax | n:  4
IntGELU    | n:  22
IntSoftmax | n:  4
IntGELU    | n:  22
IntSoftmax | n:  4
IntGELU    | n:  22
IntSoftmax | n:  4
IntGELU    | n:  22
IntSoftmax | n:  4
IntGELU    | n:  22
IntSoftmax | n:  4
IntGELU    | n:  22
IntSoftmax | n:  4
IntGELU    | n:  22
.calib done
Test: [  0/391]	Time  3.835 ( 3.835)	Acc@1   2.34 (  2.34)	Acc@5   7.81 (  7.81)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 2.344 Prec@5 7.812
Time: 8.77
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=4, intgelu_exp_n=23
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=4, intgelu_exp_n=23, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  4
IntGELU    | n:  23
IntSoftmax | n:  4
IntGELU    | n:  23
IntSoftmax | n:  4
IntGELU    | n:  23
IntSoftmax | n:  4
IntGELU    | n:  23
IntSoftmax | n:  4
IntGELU    | n:  23
IntSoftmax | n:  4
IntGELU    | n:  23
IntSoftmax | n:  4
IntGELU    | n:  23
IntSoftmax | n:  4
IntGELU    | n:  23
IntSoftmax | n:  4
IntGELU    | n:  23
IntSoftmax | n:  4
IntGELU    | n:  23
IntSoftmax | n:  4
IntGELU    | n:  23
IntSoftmax | n:  4
IntGELU    | n:  23
.calib done
Test: [  0/391]	Time  3.974 ( 3.974)	Acc@1   3.12 (  3.12)	Acc@5  12.50 ( 12.50)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 3.125 Prec@5 12.500
Time: 8.95
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=4, intgelu_exp_n=24
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=4, intgelu_exp_n=24, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  4
IntGELU    | n:  24
IntSoftmax | n:  4
IntGELU    | n:  24
IntSoftmax | n:  4
IntGELU    | n:  24
IntSoftmax | n:  4
IntGELU    | n:  24
IntSoftmax | n:  4
IntGELU    | n:  24
IntSoftmax | n:  4
IntGELU    | n:  24
IntSoftmax | n:  4
IntGELU    | n:  24
IntSoftmax | n:  4
IntGELU    | n:  24
IntSoftmax | n:  4
IntGELU    | n:  24
IntSoftmax | n:  4
IntGELU    | n:  24
IntSoftmax | n:  4
IntGELU    | n:  24
IntSoftmax | n:  4
IntGELU    | n:  24
.calib done
Test: [  0/391]	Time  3.834 ( 3.834)	Acc@1   3.12 (  3.12)	Acc@5  13.28 ( 13.28)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 3.125 Prec@5 13.281
Time: 8.78
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=4, intgelu_exp_n=25
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=4, intgelu_exp_n=25, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  4
IntGELU    | n:  25
IntSoftmax | n:  4
IntGELU    | n:  25
IntSoftmax | n:  4
IntGELU    | n:  25
IntSoftmax | n:  4
IntGELU    | n:  25
IntSoftmax | n:  4
IntGELU    | n:  25
IntSoftmax | n:  4
IntGELU    | n:  25
IntSoftmax | n:  4
IntGELU    | n:  25
IntSoftmax | n:  4
IntGELU    | n:  25
IntSoftmax | n:  4
IntGELU    | n:  25
IntSoftmax | n:  4
IntGELU    | n:  25
IntSoftmax | n:  4
IntGELU    | n:  25
IntSoftmax | n:  4
IntGELU    | n:  25
.calib done
Test: [  0/391]	Time  3.902 ( 3.902)	Acc@1   5.47 (  5.47)	Acc@5  18.75 ( 18.75)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 5.469 Prec@5 18.750
Time: 8.90
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=4, intgelu_exp_n=26
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=4, intgelu_exp_n=26, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  4
IntGELU    | n:  26
IntSoftmax | n:  4
IntGELU    | n:  26
IntSoftmax | n:  4
IntGELU    | n:  26
IntSoftmax | n:  4
IntGELU    | n:  26
IntSoftmax | n:  4
IntGELU    | n:  26
IntSoftmax | n:  4
IntGELU    | n:  26
IntSoftmax | n:  4
IntGELU    | n:  26
IntSoftmax | n:  4
IntGELU    | n:  26
IntSoftmax | n:  4
IntGELU    | n:  26
IntSoftmax | n:  4
IntGELU    | n:  26
IntSoftmax | n:  4
IntGELU    | n:  26
IntSoftmax | n:  4
IntGELU    | n:  26
.calib done
Test: [  0/391]	Time  3.962 ( 3.962)	Acc@1   5.47 (  5.47)	Acc@5  21.09 ( 21.09)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 5.469 Prec@5 21.094
Time: 8.89
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=4, intgelu_exp_n=27
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=4, intgelu_exp_n=27, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  4
IntGELU    | n:  27
IntSoftmax | n:  4
IntGELU    | n:  27
IntSoftmax | n:  4
IntGELU    | n:  27
IntSoftmax | n:  4
IntGELU    | n:  27
IntSoftmax | n:  4
IntGELU    | n:  27
IntSoftmax | n:  4
IntGELU    | n:  27
IntSoftmax | n:  4
IntGELU    | n:  27
IntSoftmax | n:  4
IntGELU    | n:  27
IntSoftmax | n:  4
IntGELU    | n:  27
IntSoftmax | n:  4
IntGELU    | n:  27
IntSoftmax | n:  4
IntGELU    | n:  27
IntSoftmax | n:  4
IntGELU    | n:  27
.calib done
Test: [  0/391]	Time  3.843 ( 3.843)	Acc@1  13.28 ( 13.28)	Acc@5  25.00 ( 25.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 13.281 Prec@5 25.000
Time: 8.83
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=4, intgelu_exp_n=28
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=4, intgelu_exp_n=28, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  4
IntGELU    | n:  28
IntSoftmax | n:  4
IntGELU    | n:  28
IntSoftmax | n:  4
IntGELU    | n:  28
IntSoftmax | n:  4
IntGELU    | n:  28
IntSoftmax | n:  4
IntGELU    | n:  28
IntSoftmax | n:  4
IntGELU    | n:  28
IntSoftmax | n:  4
IntGELU    | n:  28
IntSoftmax | n:  4
IntGELU    | n:  28
IntSoftmax | n:  4
IntGELU    | n:  28
IntSoftmax | n:  4
IntGELU    | n:  28
IntSoftmax | n:  4
IntGELU    | n:  28
IntSoftmax | n:  4
IntGELU    | n:  28
.calib done
Test: [  0/391]	Time  3.927 ( 3.927)	Acc@1  14.84 ( 14.84)	Acc@5  28.91 ( 28.91)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 14.844 Prec@5 28.906
Time: 8.83
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=4, intgelu_exp_n=29
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=4, intgelu_exp_n=29, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  4
IntGELU    | n:  29
IntSoftmax | n:  4
IntGELU    | n:  29
IntSoftmax | n:  4
IntGELU    | n:  29
IntSoftmax | n:  4
IntGELU    | n:  29
IntSoftmax | n:  4
IntGELU    | n:  29
IntSoftmax | n:  4
IntGELU    | n:  29
IntSoftmax | n:  4
IntGELU    | n:  29
IntSoftmax | n:  4
IntGELU    | n:  29
IntSoftmax | n:  4
IntGELU    | n:  29
IntSoftmax | n:  4
IntGELU    | n:  29
IntSoftmax | n:  4
IntGELU    | n:  29
IntSoftmax | n:  4
IntGELU    | n:  29
.calib done
Test: [  0/391]	Time  3.922 ( 3.922)	Acc@1  12.50 ( 12.50)	Acc@5  31.25 ( 31.25)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 12.500 Prec@5 31.250
Time: 8.82
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=4, intgelu_exp_n=30
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=4, intgelu_exp_n=30, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  4
IntGELU    | n:  30
IntSoftmax | n:  4
IntGELU    | n:  30
IntSoftmax | n:  4
IntGELU    | n:  30
IntSoftmax | n:  4
IntGELU    | n:  30
IntSoftmax | n:  4
IntGELU    | n:  30
IntSoftmax | n:  4
IntGELU    | n:  30
IntSoftmax | n:  4
IntGELU    | n:  30
IntSoftmax | n:  4
IntGELU    | n:  30
IntSoftmax | n:  4
IntGELU    | n:  30
IntSoftmax | n:  4
IntGELU    | n:  30
IntSoftmax | n:  4
IntGELU    | n:  30
IntSoftmax | n:  4
IntGELU    | n:  30
.calib done
Test: [  0/391]	Time  4.051 ( 4.051)	Acc@1  44.53 ( 44.53)	Acc@5  62.50 ( 62.50)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 44.531 Prec@5 62.500
Time: 9.03
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=4, intgelu_exp_n=31
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=4, intgelu_exp_n=31, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  4
IntGELU    | n:  31
IntSoftmax | n:  4
IntGELU    | n:  31
IntSoftmax | n:  4
IntGELU    | n:  31
IntSoftmax | n:  4
IntGELU    | n:  31
IntSoftmax | n:  4
IntGELU    | n:  31
IntSoftmax | n:  4
IntGELU    | n:  31
IntSoftmax | n:  4
IntGELU    | n:  31
IntSoftmax | n:  4
IntGELU    | n:  31
IntSoftmax | n:  4
IntGELU    | n:  31
IntSoftmax | n:  4
IntGELU    | n:  31
IntSoftmax | n:  4
IntGELU    | n:  31
IntSoftmax | n:  4
IntGELU    | n:  31
.calib done
Test: [  0/391]	Time  3.884 ( 3.884)	Acc@1   0.78 (  0.78)	Acc@5   5.47 (  5.47)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.781 Prec@5 5.469
Time: 8.86
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=5, intgelu_exp_n=0
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=5, intgelu_exp_n=0, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  5
IntGELU    | n:  0
IntSoftmax | n:  5
IntGELU    | n:  0
IntSoftmax | n:  5
IntGELU    | n:  0
IntSoftmax | n:  5
IntGELU    | n:  0
IntSoftmax | n:  5
IntGELU    | n:  0
IntSoftmax | n:  5
IntGELU    | n:  0
IntSoftmax | n:  5
IntGELU    | n:  0
IntSoftmax | n:  5
IntGELU    | n:  0
IntSoftmax | n:  5
IntGELU    | n:  0
IntSoftmax | n:  5
IntGELU    | n:  0
IntSoftmax | n:  5
IntGELU    | n:  0
IntSoftmax | n:  5
IntGELU    | n:  0
.calib done
Test: [  0/391]	Time  3.871 ( 3.871)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.81
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=5, intgelu_exp_n=1
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=5, intgelu_exp_n=1, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  5
IntGELU    | n:  1
IntSoftmax | n:  5
IntGELU    | n:  1
IntSoftmax | n:  5
IntGELU    | n:  1
IntSoftmax | n:  5
IntGELU    | n:  1
IntSoftmax | n:  5
IntGELU    | n:  1
IntSoftmax | n:  5
IntGELU    | n:  1
IntSoftmax | n:  5
IntGELU    | n:  1
IntSoftmax | n:  5
IntGELU    | n:  1
IntSoftmax | n:  5
IntGELU    | n:  1
IntSoftmax | n:  5
IntGELU    | n:  1
IntSoftmax | n:  5
IntGELU    | n:  1
IntSoftmax | n:  5
IntGELU    | n:  1
.calib done
Test: [  0/391]	Time  3.723 ( 3.723)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.67
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=5, intgelu_exp_n=2
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=5, intgelu_exp_n=2, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  5
IntGELU    | n:  2
IntSoftmax | n:  5
IntGELU    | n:  2
IntSoftmax | n:  5
IntGELU    | n:  2
IntSoftmax | n:  5
IntGELU    | n:  2
IntSoftmax | n:  5
IntGELU    | n:  2
IntSoftmax | n:  5
IntGELU    | n:  2
IntSoftmax | n:  5
IntGELU    | n:  2
IntSoftmax | n:  5
IntGELU    | n:  2
IntSoftmax | n:  5
IntGELU    | n:  2
IntSoftmax | n:  5
IntGELU    | n:  2
IntSoftmax | n:  5
IntGELU    | n:  2
IntSoftmax | n:  5
IntGELU    | n:  2
.calib done
Test: [  0/391]	Time  3.936 ( 3.936)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.87
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=5, intgelu_exp_n=3
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=5, intgelu_exp_n=3, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  5
IntGELU    | n:  3
IntSoftmax | n:  5
IntGELU    | n:  3
IntSoftmax | n:  5
IntGELU    | n:  3
IntSoftmax | n:  5
IntGELU    | n:  3
IntSoftmax | n:  5
IntGELU    | n:  3
IntSoftmax | n:  5
IntGELU    | n:  3
IntSoftmax | n:  5
IntGELU    | n:  3
IntSoftmax | n:  5
IntGELU    | n:  3
IntSoftmax | n:  5
IntGELU    | n:  3
IntSoftmax | n:  5
IntGELU    | n:  3
IntSoftmax | n:  5
IntGELU    | n:  3
IntSoftmax | n:  5
IntGELU    | n:  3
.calib done
Test: [  0/391]	Time  3.909 ( 3.909)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.81
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=5, intgelu_exp_n=4
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=5, intgelu_exp_n=4, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  5
IntGELU    | n:  4
IntSoftmax | n:  5
IntGELU    | n:  4
IntSoftmax | n:  5
IntGELU    | n:  4
IntSoftmax | n:  5
IntGELU    | n:  4
IntSoftmax | n:  5
IntGELU    | n:  4
IntSoftmax | n:  5
IntGELU    | n:  4
IntSoftmax | n:  5
IntGELU    | n:  4
IntSoftmax | n:  5
IntGELU    | n:  4
IntSoftmax | n:  5
IntGELU    | n:  4
IntSoftmax | n:  5
IntGELU    | n:  4
IntSoftmax | n:  5
IntGELU    | n:  4
IntSoftmax | n:  5
IntGELU    | n:  4
.calib done
Test: [  0/391]	Time  3.636 ( 3.636)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.56
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=5, intgelu_exp_n=5
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=5, intgelu_exp_n=5, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  5
IntGELU    | n:  5
IntSoftmax | n:  5
IntGELU    | n:  5
IntSoftmax | n:  5
IntGELU    | n:  5
IntSoftmax | n:  5
IntGELU    | n:  5
IntSoftmax | n:  5
IntGELU    | n:  5
IntSoftmax | n:  5
IntGELU    | n:  5
IntSoftmax | n:  5
IntGELU    | n:  5
IntSoftmax | n:  5
IntGELU    | n:  5
IntSoftmax | n:  5
IntGELU    | n:  5
IntSoftmax | n:  5
IntGELU    | n:  5
IntSoftmax | n:  5
IntGELU    | n:  5
IntSoftmax | n:  5
IntGELU    | n:  5
.calib done
Test: [  0/391]	Time  3.923 ( 3.923)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.84
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=5, intgelu_exp_n=6
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=5, intgelu_exp_n=6, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  5
IntGELU    | n:  6
IntSoftmax | n:  5
IntGELU    | n:  6
IntSoftmax | n:  5
IntGELU    | n:  6
IntSoftmax | n:  5
IntGELU    | n:  6
IntSoftmax | n:  5
IntGELU    | n:  6
IntSoftmax | n:  5
IntGELU    | n:  6
IntSoftmax | n:  5
IntGELU    | n:  6
IntSoftmax | n:  5
IntGELU    | n:  6
IntSoftmax | n:  5
IntGELU    | n:  6
IntSoftmax | n:  5
IntGELU    | n:  6
IntSoftmax | n:  5
IntGELU    | n:  6
IntSoftmax | n:  5
IntGELU    | n:  6
.calib done
Test: [  0/391]	Time  3.838 ( 3.838)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.79
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=5, intgelu_exp_n=7
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=5, intgelu_exp_n=7, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  5
IntGELU    | n:  7
IntSoftmax | n:  5
IntGELU    | n:  7
IntSoftmax | n:  5
IntGELU    | n:  7
IntSoftmax | n:  5
IntGELU    | n:  7
IntSoftmax | n:  5
IntGELU    | n:  7
IntSoftmax | n:  5
IntGELU    | n:  7
IntSoftmax | n:  5
IntGELU    | n:  7
IntSoftmax | n:  5
IntGELU    | n:  7
IntSoftmax | n:  5
IntGELU    | n:  7
IntSoftmax | n:  5
IntGELU    | n:  7
IntSoftmax | n:  5
IntGELU    | n:  7
IntSoftmax | n:  5
IntGELU    | n:  7
.calib done
Test: [  0/391]	Time  3.868 ( 3.868)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.83
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=5, intgelu_exp_n=8
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=5, intgelu_exp_n=8, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  5
IntGELU    | n:  8
IntSoftmax | n:  5
IntGELU    | n:  8
IntSoftmax | n:  5
IntGELU    | n:  8
IntSoftmax | n:  5
IntGELU    | n:  8
IntSoftmax | n:  5
IntGELU    | n:  8
IntSoftmax | n:  5
IntGELU    | n:  8
IntSoftmax | n:  5
IntGELU    | n:  8
IntSoftmax | n:  5
IntGELU    | n:  8
IntSoftmax | n:  5
IntGELU    | n:  8
IntSoftmax | n:  5
IntGELU    | n:  8
IntSoftmax | n:  5
IntGELU    | n:  8
IntSoftmax | n:  5
IntGELU    | n:  8
.calib done
Test: [  0/391]	Time  3.877 ( 3.877)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.85
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=5, intgelu_exp_n=9
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=5, intgelu_exp_n=9, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  5
IntGELU    | n:  9
IntSoftmax | n:  5
IntGELU    | n:  9
IntSoftmax | n:  5
IntGELU    | n:  9
IntSoftmax | n:  5
IntGELU    | n:  9
IntSoftmax | n:  5
IntGELU    | n:  9
IntSoftmax | n:  5
IntGELU    | n:  9
IntSoftmax | n:  5
IntGELU    | n:  9
IntSoftmax | n:  5
IntGELU    | n:  9
IntSoftmax | n:  5
IntGELU    | n:  9
IntSoftmax | n:  5
IntGELU    | n:  9
IntSoftmax | n:  5
IntGELU    | n:  9
IntSoftmax | n:  5
IntGELU    | n:  9
.calib done
Test: [  0/391]	Time  3.850 ( 3.850)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.76
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=5, intgelu_exp_n=10
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=5, intgelu_exp_n=10, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  5
IntGELU    | n:  10
IntSoftmax | n:  5
IntGELU    | n:  10
IntSoftmax | n:  5
IntGELU    | n:  10
IntSoftmax | n:  5
IntGELU    | n:  10
IntSoftmax | n:  5
IntGELU    | n:  10
IntSoftmax | n:  5
IntGELU    | n:  10
IntSoftmax | n:  5
IntGELU    | n:  10
IntSoftmax | n:  5
IntGELU    | n:  10
IntSoftmax | n:  5
IntGELU    | n:  10
IntSoftmax | n:  5
IntGELU    | n:  10
IntSoftmax | n:  5
IntGELU    | n:  10
IntSoftmax | n:  5
IntGELU    | n:  10
.calib done
Test: [  0/391]	Time  3.885 ( 3.885)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.81
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=5, intgelu_exp_n=11
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=5, intgelu_exp_n=11, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  5
IntGELU    | n:  11
IntSoftmax | n:  5
IntGELU    | n:  11
IntSoftmax | n:  5
IntGELU    | n:  11
IntSoftmax | n:  5
IntGELU    | n:  11
IntSoftmax | n:  5
IntGELU    | n:  11
IntSoftmax | n:  5
IntGELU    | n:  11
IntSoftmax | n:  5
IntGELU    | n:  11
IntSoftmax | n:  5
IntGELU    | n:  11
IntSoftmax | n:  5
IntGELU    | n:  11
IntSoftmax | n:  5
IntGELU    | n:  11
IntSoftmax | n:  5
IntGELU    | n:  11
IntSoftmax | n:  5
IntGELU    | n:  11
.calib done
Test: [  0/391]	Time  3.841 ( 3.841)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.83
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=5, intgelu_exp_n=12
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=5, intgelu_exp_n=12, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  5
IntGELU    | n:  12
IntSoftmax | n:  5
IntGELU    | n:  12
IntSoftmax | n:  5
IntGELU    | n:  12
IntSoftmax | n:  5
IntGELU    | n:  12
IntSoftmax | n:  5
IntGELU    | n:  12
IntSoftmax | n:  5
IntGELU    | n:  12
IntSoftmax | n:  5
IntGELU    | n:  12
IntSoftmax | n:  5
IntGELU    | n:  12
IntSoftmax | n:  5
IntGELU    | n:  12
IntSoftmax | n:  5
IntGELU    | n:  12
IntSoftmax | n:  5
IntGELU    | n:  12
IntSoftmax | n:  5
IntGELU    | n:  12
.calib done
Test: [  0/391]	Time  3.804 ( 3.804)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.76
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=5, intgelu_exp_n=13
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=5, intgelu_exp_n=13, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  5
IntGELU    | n:  13
IntSoftmax | n:  5
IntGELU    | n:  13
IntSoftmax | n:  5
IntGELU    | n:  13
IntSoftmax | n:  5
IntGELU    | n:  13
IntSoftmax | n:  5
IntGELU    | n:  13
IntSoftmax | n:  5
IntGELU    | n:  13
IntSoftmax | n:  5
IntGELU    | n:  13
IntSoftmax | n:  5
IntGELU    | n:  13
IntSoftmax | n:  5
IntGELU    | n:  13
IntSoftmax | n:  5
IntGELU    | n:  13
IntSoftmax | n:  5
IntGELU    | n:  13
IntSoftmax | n:  5
IntGELU    | n:  13
.calib done
Test: [  0/391]	Time  3.988 ( 3.988)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.92
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=5, intgelu_exp_n=14
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=5, intgelu_exp_n=14, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  5
IntGELU    | n:  14
IntSoftmax | n:  5
IntGELU    | n:  14
IntSoftmax | n:  5
IntGELU    | n:  14
IntSoftmax | n:  5
IntGELU    | n:  14
IntSoftmax | n:  5
IntGELU    | n:  14
IntSoftmax | n:  5
IntGELU    | n:  14
IntSoftmax | n:  5
IntGELU    | n:  14
IntSoftmax | n:  5
IntGELU    | n:  14
IntSoftmax | n:  5
IntGELU    | n:  14
IntSoftmax | n:  5
IntGELU    | n:  14
IntSoftmax | n:  5
IntGELU    | n:  14
IntSoftmax | n:  5
IntGELU    | n:  14
.calib done
Test: [  0/391]	Time  3.720 ( 3.720)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.63
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=5, intgelu_exp_n=15
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=5, intgelu_exp_n=15, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  5
IntGELU    | n:  15
IntSoftmax | n:  5
IntGELU    | n:  15
IntSoftmax | n:  5
IntGELU    | n:  15
IntSoftmax | n:  5
IntGELU    | n:  15
IntSoftmax | n:  5
IntGELU    | n:  15
IntSoftmax | n:  5
IntGELU    | n:  15
IntSoftmax | n:  5
IntGELU    | n:  15
IntSoftmax | n:  5
IntGELU    | n:  15
IntSoftmax | n:  5
IntGELU    | n:  15
IntSoftmax | n:  5
IntGELU    | n:  15
IntSoftmax | n:  5
IntGELU    | n:  15
IntSoftmax | n:  5
IntGELU    | n:  15
.calib done
Test: [  0/391]	Time  3.861 ( 3.861)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.82
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=5, intgelu_exp_n=16
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=5, intgelu_exp_n=16, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  5
IntGELU    | n:  16
IntSoftmax | n:  5
IntGELU    | n:  16
IntSoftmax | n:  5
IntGELU    | n:  16
IntSoftmax | n:  5
IntGELU    | n:  16
IntSoftmax | n:  5
IntGELU    | n:  16
IntSoftmax | n:  5
IntGELU    | n:  16
IntSoftmax | n:  5
IntGELU    | n:  16
IntSoftmax | n:  5
IntGELU    | n:  16
IntSoftmax | n:  5
IntGELU    | n:  16
IntSoftmax | n:  5
IntGELU    | n:  16
IntSoftmax | n:  5
IntGELU    | n:  16
IntSoftmax | n:  5
IntGELU    | n:  16
.calib done
Test: [  0/391]	Time  3.878 ( 3.878)	Acc@1   0.00 (  0.00)	Acc@5   0.78 (  0.78)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.781
Time: 8.83
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=5, intgelu_exp_n=17
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=5, intgelu_exp_n=17, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  5
IntGELU    | n:  17
IntSoftmax | n:  5
IntGELU    | n:  17
IntSoftmax | n:  5
IntGELU    | n:  17
IntSoftmax | n:  5
IntGELU    | n:  17
IntSoftmax | n:  5
IntGELU    | n:  17
IntSoftmax | n:  5
IntGELU    | n:  17
IntSoftmax | n:  5
IntGELU    | n:  17
IntSoftmax | n:  5
IntGELU    | n:  17
IntSoftmax | n:  5
IntGELU    | n:  17
IntSoftmax | n:  5
IntGELU    | n:  17
IntSoftmax | n:  5
IntGELU    | n:  17
IntSoftmax | n:  5
IntGELU    | n:  17
.calib done
Test: [  0/391]	Time  3.962 ( 3.962)	Acc@1   1.56 (  1.56)	Acc@5   1.56 (  1.56)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 1.562 Prec@5 1.562
Time: 8.90
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=5, intgelu_exp_n=18
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=5, intgelu_exp_n=18, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  5
IntGELU    | n:  18
IntSoftmax | n:  5
IntGELU    | n:  18
IntSoftmax | n:  5
IntGELU    | n:  18
IntSoftmax | n:  5
IntGELU    | n:  18
IntSoftmax | n:  5
IntGELU    | n:  18
IntSoftmax | n:  5
IntGELU    | n:  18
IntSoftmax | n:  5
IntGELU    | n:  18
IntSoftmax | n:  5
IntGELU    | n:  18
IntSoftmax | n:  5
IntGELU    | n:  18
IntSoftmax | n:  5
IntGELU    | n:  18
IntSoftmax | n:  5
IntGELU    | n:  18
IntSoftmax | n:  5
IntGELU    | n:  18
.calib done
Test: [  0/391]	Time  3.972 ( 3.972)	Acc@1   0.00 (  0.00)	Acc@5   2.34 (  2.34)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 2.344
Time: 8.92
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=5, intgelu_exp_n=19
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=5, intgelu_exp_n=19, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  5
IntGELU    | n:  19
IntSoftmax | n:  5
IntGELU    | n:  19
IntSoftmax | n:  5
IntGELU    | n:  19
IntSoftmax | n:  5
IntGELU    | n:  19
IntSoftmax | n:  5
IntGELU    | n:  19
IntSoftmax | n:  5
IntGELU    | n:  19
IntSoftmax | n:  5
IntGELU    | n:  19
IntSoftmax | n:  5
IntGELU    | n:  19
IntSoftmax | n:  5
IntGELU    | n:  19
IntSoftmax | n:  5
IntGELU    | n:  19
IntSoftmax | n:  5
IntGELU    | n:  19
IntSoftmax | n:  5
IntGELU    | n:  19
.calib done
Test: [  0/391]	Time  3.953 ( 3.953)	Acc@1   0.00 (  0.00)	Acc@5   1.56 (  1.56)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 1.562
Time: 8.94
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=5, intgelu_exp_n=20
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=5, intgelu_exp_n=20, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  5
IntGELU    | n:  20
IntSoftmax | n:  5
IntGELU    | n:  20
IntSoftmax | n:  5
IntGELU    | n:  20
IntSoftmax | n:  5
IntGELU    | n:  20
IntSoftmax | n:  5
IntGELU    | n:  20
IntSoftmax | n:  5
IntGELU    | n:  20
IntSoftmax | n:  5
IntGELU    | n:  20
IntSoftmax | n:  5
IntGELU    | n:  20
IntSoftmax | n:  5
IntGELU    | n:  20
IntSoftmax | n:  5
IntGELU    | n:  20
IntSoftmax | n:  5
IntGELU    | n:  20
IntSoftmax | n:  5
IntGELU    | n:  20
.calib done
Test: [  0/391]	Time  3.884 ( 3.884)	Acc@1   3.91 (  3.91)	Acc@5  10.16 ( 10.16)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 3.906 Prec@5 10.156
Time: 8.88
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=5, intgelu_exp_n=21
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=5, intgelu_exp_n=21, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  5
IntGELU    | n:  21
IntSoftmax | n:  5
IntGELU    | n:  21
IntSoftmax | n:  5
IntGELU    | n:  21
IntSoftmax | n:  5
IntGELU    | n:  21
IntSoftmax | n:  5
IntGELU    | n:  21
IntSoftmax | n:  5
IntGELU    | n:  21
IntSoftmax | n:  5
IntGELU    | n:  21
IntSoftmax | n:  5
IntGELU    | n:  21
IntSoftmax | n:  5
IntGELU    | n:  21
IntSoftmax | n:  5
IntGELU    | n:  21
IntSoftmax | n:  5
IntGELU    | n:  21
IntSoftmax | n:  5
IntGELU    | n:  21
.calib done
Test: [  0/391]	Time  4.026 ( 4.026)	Acc@1   7.03 (  7.03)	Acc@5  14.84 ( 14.84)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 7.031 Prec@5 14.844
Time: 8.95
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=5, intgelu_exp_n=22
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=5, intgelu_exp_n=22, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  5
IntGELU    | n:  22
IntSoftmax | n:  5
IntGELU    | n:  22
IntSoftmax | n:  5
IntGELU    | n:  22
IntSoftmax | n:  5
IntGELU    | n:  22
IntSoftmax | n:  5
IntGELU    | n:  22
IntSoftmax | n:  5
IntGELU    | n:  22
IntSoftmax | n:  5
IntGELU    | n:  22
IntSoftmax | n:  5
IntGELU    | n:  22
IntSoftmax | n:  5
IntGELU    | n:  22
IntSoftmax | n:  5
IntGELU    | n:  22
IntSoftmax | n:  5
IntGELU    | n:  22
IntSoftmax | n:  5
IntGELU    | n:  22
.calib done
Test: [  0/391]	Time  3.890 ( 3.890)	Acc@1   8.59 (  8.59)	Acc@5  17.19 ( 17.19)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 8.594 Prec@5 17.188
Time: 8.88
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=5, intgelu_exp_n=23
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=5, intgelu_exp_n=23, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  5
IntGELU    | n:  23
IntSoftmax | n:  5
IntGELU    | n:  23
IntSoftmax | n:  5
IntGELU    | n:  23
IntSoftmax | n:  5
IntGELU    | n:  23
IntSoftmax | n:  5
IntGELU    | n:  23
IntSoftmax | n:  5
IntGELU    | n:  23
IntSoftmax | n:  5
IntGELU    | n:  23
IntSoftmax | n:  5
IntGELU    | n:  23
IntSoftmax | n:  5
IntGELU    | n:  23
IntSoftmax | n:  5
IntGELU    | n:  23
IntSoftmax | n:  5
IntGELU    | n:  23
IntSoftmax | n:  5
IntGELU    | n:  23
.calib done
Test: [  0/391]	Time  3.925 ( 3.925)	Acc@1  14.84 ( 14.84)	Acc@5  27.34 ( 27.34)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 14.844 Prec@5 27.344
Time: 8.92
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=5, intgelu_exp_n=24
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=5, intgelu_exp_n=24, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  5
IntGELU    | n:  24
IntSoftmax | n:  5
IntGELU    | n:  24
IntSoftmax | n:  5
IntGELU    | n:  24
IntSoftmax | n:  5
IntGELU    | n:  24
IntSoftmax | n:  5
IntGELU    | n:  24
IntSoftmax | n:  5
IntGELU    | n:  24
IntSoftmax | n:  5
IntGELU    | n:  24
IntSoftmax | n:  5
IntGELU    | n:  24
IntSoftmax | n:  5
IntGELU    | n:  24
IntSoftmax | n:  5
IntGELU    | n:  24
IntSoftmax | n:  5
IntGELU    | n:  24
IntSoftmax | n:  5
IntGELU    | n:  24
.calib done
Test: [  0/391]	Time  3.988 ( 3.988)	Acc@1  14.06 ( 14.06)	Acc@5  35.16 ( 35.16)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 14.062 Prec@5 35.156
Time: 8.95
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=5, intgelu_exp_n=25
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=5, intgelu_exp_n=25, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  5
IntGELU    | n:  25
IntSoftmax | n:  5
IntGELU    | n:  25
IntSoftmax | n:  5
IntGELU    | n:  25
IntSoftmax | n:  5
IntGELU    | n:  25
IntSoftmax | n:  5
IntGELU    | n:  25
IntSoftmax | n:  5
IntGELU    | n:  25
IntSoftmax | n:  5
IntGELU    | n:  25
IntSoftmax | n:  5
IntGELU    | n:  25
IntSoftmax | n:  5
IntGELU    | n:  25
IntSoftmax | n:  5
IntGELU    | n:  25
IntSoftmax | n:  5
IntGELU    | n:  25
IntSoftmax | n:  5
IntGELU    | n:  25
.calib done
Test: [  0/391]	Time  3.833 ( 3.833)	Acc@1  16.41 ( 16.41)	Acc@5  40.62 ( 40.62)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 16.406 Prec@5 40.625
Time: 8.77
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=5, intgelu_exp_n=26
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=5, intgelu_exp_n=26, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  5
IntGELU    | n:  26
IntSoftmax | n:  5
IntGELU    | n:  26
IntSoftmax | n:  5
IntGELU    | n:  26
IntSoftmax | n:  5
IntGELU    | n:  26
IntSoftmax | n:  5
IntGELU    | n:  26
IntSoftmax | n:  5
IntGELU    | n:  26
IntSoftmax | n:  5
IntGELU    | n:  26
IntSoftmax | n:  5
IntGELU    | n:  26
IntSoftmax | n:  5
IntGELU    | n:  26
IntSoftmax | n:  5
IntGELU    | n:  26
IntSoftmax | n:  5
IntGELU    | n:  26
IntSoftmax | n:  5
IntGELU    | n:  26
.calib done
Test: [  0/391]	Time  3.853 ( 3.853)	Acc@1  28.12 ( 28.12)	Acc@5  46.09 ( 46.09)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 28.125 Prec@5 46.094
Time: 8.83
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=5, intgelu_exp_n=27
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=5, intgelu_exp_n=27, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  5
IntGELU    | n:  27
IntSoftmax | n:  5
IntGELU    | n:  27
IntSoftmax | n:  5
IntGELU    | n:  27
IntSoftmax | n:  5
IntGELU    | n:  27
IntSoftmax | n:  5
IntGELU    | n:  27
IntSoftmax | n:  5
IntGELU    | n:  27
IntSoftmax | n:  5
IntGELU    | n:  27
IntSoftmax | n:  5
IntGELU    | n:  27
IntSoftmax | n:  5
IntGELU    | n:  27
IntSoftmax | n:  5
IntGELU    | n:  27
IntSoftmax | n:  5
IntGELU    | n:  27
IntSoftmax | n:  5
IntGELU    | n:  27
.calib done
Test: [  0/391]	Time  4.081 ( 4.081)	Acc@1  34.38 ( 34.38)	Acc@5  59.38 ( 59.38)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 34.375 Prec@5 59.375
Time: 9.05
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=5, intgelu_exp_n=28
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=5, intgelu_exp_n=28, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  5
IntGELU    | n:  28
IntSoftmax | n:  5
IntGELU    | n:  28
IntSoftmax | n:  5
IntGELU    | n:  28
IntSoftmax | n:  5
IntGELU    | n:  28
IntSoftmax | n:  5
IntGELU    | n:  28
IntSoftmax | n:  5
IntGELU    | n:  28
IntSoftmax | n:  5
IntGELU    | n:  28
IntSoftmax | n:  5
IntGELU    | n:  28
IntSoftmax | n:  5
IntGELU    | n:  28
IntSoftmax | n:  5
IntGELU    | n:  28
IntSoftmax | n:  5
IntGELU    | n:  28
IntSoftmax | n:  5
IntGELU    | n:  28
.calib done
Test: [  0/391]	Time  3.795 ( 3.795)	Acc@1  36.72 ( 36.72)	Acc@5  59.38 ( 59.38)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 36.719 Prec@5 59.375
Time: 8.78
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=5, intgelu_exp_n=29
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=5, intgelu_exp_n=29, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  5
IntGELU    | n:  29
IntSoftmax | n:  5
IntGELU    | n:  29
IntSoftmax | n:  5
IntGELU    | n:  29
IntSoftmax | n:  5
IntGELU    | n:  29
IntSoftmax | n:  5
IntGELU    | n:  29
IntSoftmax | n:  5
IntGELU    | n:  29
IntSoftmax | n:  5
IntGELU    | n:  29
IntSoftmax | n:  5
IntGELU    | n:  29
IntSoftmax | n:  5
IntGELU    | n:  29
IntSoftmax | n:  5
IntGELU    | n:  29
IntSoftmax | n:  5
IntGELU    | n:  29
IntSoftmax | n:  5
IntGELU    | n:  29
.calib done
Test: [  0/391]	Time  3.965 ( 3.965)	Acc@1  40.62 ( 40.62)	Acc@5  61.72 ( 61.72)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 40.625 Prec@5 61.719
Time: 8.95
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=5, intgelu_exp_n=30
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=5, intgelu_exp_n=30, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  5
IntGELU    | n:  30
IntSoftmax | n:  5
IntGELU    | n:  30
IntSoftmax | n:  5
IntGELU    | n:  30
IntSoftmax | n:  5
IntGELU    | n:  30
IntSoftmax | n:  5
IntGELU    | n:  30
IntSoftmax | n:  5
IntGELU    | n:  30
IntSoftmax | n:  5
IntGELU    | n:  30
IntSoftmax | n:  5
IntGELU    | n:  30
IntSoftmax | n:  5
IntGELU    | n:  30
IntSoftmax | n:  5
IntGELU    | n:  30
IntSoftmax | n:  5
IntGELU    | n:  30
IntSoftmax | n:  5
IntGELU    | n:  30
.calib done
Test: [  0/391]	Time  3.760 ( 3.760)	Acc@1  68.75 ( 68.75)	Acc@5  85.16 ( 85.16)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 68.750 Prec@5 85.156
Time: 8.67
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=5, intgelu_exp_n=31
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=5, intgelu_exp_n=31, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  5
IntGELU    | n:  31
IntSoftmax | n:  5
IntGELU    | n:  31
IntSoftmax | n:  5
IntGELU    | n:  31
IntSoftmax | n:  5
IntGELU    | n:  31
IntSoftmax | n:  5
IntGELU    | n:  31
IntSoftmax | n:  5
IntGELU    | n:  31
IntSoftmax | n:  5
IntGELU    | n:  31
IntSoftmax | n:  5
IntGELU    | n:  31
IntSoftmax | n:  5
IntGELU    | n:  31
IntSoftmax | n:  5
IntGELU    | n:  31
IntSoftmax | n:  5
IntGELU    | n:  31
IntSoftmax | n:  5
IntGELU    | n:  31
.calib done
Test: [  0/391]	Time  3.945 ( 3.945)	Acc@1   7.03 (  7.03)	Acc@5  18.75 ( 18.75)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 7.031 Prec@5 18.750
Time: 8.94
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=6, intgelu_exp_n=0
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=6, intgelu_exp_n=0, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  6
IntGELU    | n:  0
IntSoftmax | n:  6
IntGELU    | n:  0
IntSoftmax | n:  6
IntGELU    | n:  0
IntSoftmax | n:  6
IntGELU    | n:  0
IntSoftmax | n:  6
IntGELU    | n:  0
IntSoftmax | n:  6
IntGELU    | n:  0
IntSoftmax | n:  6
IntGELU    | n:  0
IntSoftmax | n:  6
IntGELU    | n:  0
IntSoftmax | n:  6
IntGELU    | n:  0
IntSoftmax | n:  6
IntGELU    | n:  0
IntSoftmax | n:  6
IntGELU    | n:  0
IntSoftmax | n:  6
IntGELU    | n:  0
.calib done
Test: [  0/391]	Time  3.726 ( 3.726)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.62
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=6, intgelu_exp_n=1
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=6, intgelu_exp_n=1, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  6
IntGELU    | n:  1
IntSoftmax | n:  6
IntGELU    | n:  1
IntSoftmax | n:  6
IntGELU    | n:  1
IntSoftmax | n:  6
IntGELU    | n:  1
IntSoftmax | n:  6
IntGELU    | n:  1
IntSoftmax | n:  6
IntGELU    | n:  1
IntSoftmax | n:  6
IntGELU    | n:  1
IntSoftmax | n:  6
IntGELU    | n:  1
IntSoftmax | n:  6
IntGELU    | n:  1
IntSoftmax | n:  6
IntGELU    | n:  1
IntSoftmax | n:  6
IntGELU    | n:  1
IntSoftmax | n:  6
IntGELU    | n:  1
.calib done
Test: [  0/391]	Time  3.918 ( 3.918)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.85
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=6, intgelu_exp_n=2
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=6, intgelu_exp_n=2, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  6
IntGELU    | n:  2
IntSoftmax | n:  6
IntGELU    | n:  2
IntSoftmax | n:  6
IntGELU    | n:  2
IntSoftmax | n:  6
IntGELU    | n:  2
IntSoftmax | n:  6
IntGELU    | n:  2
IntSoftmax | n:  6
IntGELU    | n:  2
IntSoftmax | n:  6
IntGELU    | n:  2
IntSoftmax | n:  6
IntGELU    | n:  2
IntSoftmax | n:  6
IntGELU    | n:  2
IntSoftmax | n:  6
IntGELU    | n:  2
IntSoftmax | n:  6
IntGELU    | n:  2
IntSoftmax | n:  6
IntGELU    | n:  2
.calib done
Test: [  0/391]	Time  3.933 ( 3.933)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.92
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=6, intgelu_exp_n=3
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=6, intgelu_exp_n=3, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  6
IntGELU    | n:  3
IntSoftmax | n:  6
IntGELU    | n:  3
IntSoftmax | n:  6
IntGELU    | n:  3
IntSoftmax | n:  6
IntGELU    | n:  3
IntSoftmax | n:  6
IntGELU    | n:  3
IntSoftmax | n:  6
IntGELU    | n:  3
IntSoftmax | n:  6
IntGELU    | n:  3
IntSoftmax | n:  6
IntGELU    | n:  3
IntSoftmax | n:  6
IntGELU    | n:  3
IntSoftmax | n:  6
IntGELU    | n:  3
IntSoftmax | n:  6
IntGELU    | n:  3
IntSoftmax | n:  6
IntGELU    | n:  3
.calib done
Test: [  0/391]	Time  3.933 ( 3.933)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.95
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=6, intgelu_exp_n=4
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=6, intgelu_exp_n=4, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  6
IntGELU    | n:  4
IntSoftmax | n:  6
IntGELU    | n:  4
IntSoftmax | n:  6
IntGELU    | n:  4
IntSoftmax | n:  6
IntGELU    | n:  4
IntSoftmax | n:  6
IntGELU    | n:  4
IntSoftmax | n:  6
IntGELU    | n:  4
IntSoftmax | n:  6
IntGELU    | n:  4
IntSoftmax | n:  6
IntGELU    | n:  4
IntSoftmax | n:  6
IntGELU    | n:  4
IntSoftmax | n:  6
IntGELU    | n:  4
IntSoftmax | n:  6
IntGELU    | n:  4
IntSoftmax | n:  6
IntGELU    | n:  4
.calib done
Test: [  0/391]	Time  3.746 ( 3.746)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.71
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=6, intgelu_exp_n=5
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=6, intgelu_exp_n=5, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  6
IntGELU    | n:  5
IntSoftmax | n:  6
IntGELU    | n:  5
IntSoftmax | n:  6
IntGELU    | n:  5
IntSoftmax | n:  6
IntGELU    | n:  5
IntSoftmax | n:  6
IntGELU    | n:  5
IntSoftmax | n:  6
IntGELU    | n:  5
IntSoftmax | n:  6
IntGELU    | n:  5
IntSoftmax | n:  6
IntGELU    | n:  5
IntSoftmax | n:  6
IntGELU    | n:  5
IntSoftmax | n:  6
IntGELU    | n:  5
IntSoftmax | n:  6
IntGELU    | n:  5
IntSoftmax | n:  6
IntGELU    | n:  5
.calib done
Test: [  0/391]	Time  3.869 ( 3.869)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.76
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=6, intgelu_exp_n=6
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=6, intgelu_exp_n=6, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  6
IntGELU    | n:  6
IntSoftmax | n:  6
IntGELU    | n:  6
IntSoftmax | n:  6
IntGELU    | n:  6
IntSoftmax | n:  6
IntGELU    | n:  6
IntSoftmax | n:  6
IntGELU    | n:  6
IntSoftmax | n:  6
IntGELU    | n:  6
IntSoftmax | n:  6
IntGELU    | n:  6
IntSoftmax | n:  6
IntGELU    | n:  6
IntSoftmax | n:  6
IntGELU    | n:  6
IntSoftmax | n:  6
IntGELU    | n:  6
IntSoftmax | n:  6
IntGELU    | n:  6
IntSoftmax | n:  6
IntGELU    | n:  6
.calib done
Test: [  0/391]	Time  3.966 ( 3.966)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.93
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=6, intgelu_exp_n=7
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=6, intgelu_exp_n=7, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  6
IntGELU    | n:  7
IntSoftmax | n:  6
IntGELU    | n:  7
IntSoftmax | n:  6
IntGELU    | n:  7
IntSoftmax | n:  6
IntGELU    | n:  7
IntSoftmax | n:  6
IntGELU    | n:  7
IntSoftmax | n:  6
IntGELU    | n:  7
IntSoftmax | n:  6
IntGELU    | n:  7
IntSoftmax | n:  6
IntGELU    | n:  7
IntSoftmax | n:  6
IntGELU    | n:  7
IntSoftmax | n:  6
IntGELU    | n:  7
IntSoftmax | n:  6
IntGELU    | n:  7
IntSoftmax | n:  6
IntGELU    | n:  7
.calib done
Test: [  0/391]	Time  3.848 ( 3.848)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.81
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=6, intgelu_exp_n=8
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=6, intgelu_exp_n=8, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  6
IntGELU    | n:  8
IntSoftmax | n:  6
IntGELU    | n:  8
IntSoftmax | n:  6
IntGELU    | n:  8
IntSoftmax | n:  6
IntGELU    | n:  8
IntSoftmax | n:  6
IntGELU    | n:  8
IntSoftmax | n:  6
IntGELU    | n:  8
IntSoftmax | n:  6
IntGELU    | n:  8
IntSoftmax | n:  6
IntGELU    | n:  8
IntSoftmax | n:  6
IntGELU    | n:  8
IntSoftmax | n:  6
IntGELU    | n:  8
IntSoftmax | n:  6
IntGELU    | n:  8
IntSoftmax | n:  6
IntGELU    | n:  8
.calib done
Test: [  0/391]	Time  3.931 ( 3.931)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.87
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=6, intgelu_exp_n=9
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=6, intgelu_exp_n=9, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  6
IntGELU    | n:  9
IntSoftmax | n:  6
IntGELU    | n:  9
IntSoftmax | n:  6
IntGELU    | n:  9
IntSoftmax | n:  6
IntGELU    | n:  9
IntSoftmax | n:  6
IntGELU    | n:  9
IntSoftmax | n:  6
IntGELU    | n:  9
IntSoftmax | n:  6
IntGELU    | n:  9
IntSoftmax | n:  6
IntGELU    | n:  9
IntSoftmax | n:  6
IntGELU    | n:  9
IntSoftmax | n:  6
IntGELU    | n:  9
IntSoftmax | n:  6
IntGELU    | n:  9
IntSoftmax | n:  6
IntGELU    | n:  9
.calib done
Test: [  0/391]	Time  3.954 ( 3.954)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.91
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=6, intgelu_exp_n=10
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=6, intgelu_exp_n=10, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  6
IntGELU    | n:  10
IntSoftmax | n:  6
IntGELU    | n:  10
IntSoftmax | n:  6
IntGELU    | n:  10
IntSoftmax | n:  6
IntGELU    | n:  10
IntSoftmax | n:  6
IntGELU    | n:  10
IntSoftmax | n:  6
IntGELU    | n:  10
IntSoftmax | n:  6
IntGELU    | n:  10
IntSoftmax | n:  6
IntGELU    | n:  10
IntSoftmax | n:  6
IntGELU    | n:  10
IntSoftmax | n:  6
IntGELU    | n:  10
IntSoftmax | n:  6
IntGELU    | n:  10
IntSoftmax | n:  6
IntGELU    | n:  10
.calib done
Test: [  0/391]	Time  3.871 ( 3.871)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.83
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=6, intgelu_exp_n=11
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=6, intgelu_exp_n=11, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  6
IntGELU    | n:  11
IntSoftmax | n:  6
IntGELU    | n:  11
IntSoftmax | n:  6
IntGELU    | n:  11
IntSoftmax | n:  6
IntGELU    | n:  11
IntSoftmax | n:  6
IntGELU    | n:  11
IntSoftmax | n:  6
IntGELU    | n:  11
IntSoftmax | n:  6
IntGELU    | n:  11
IntSoftmax | n:  6
IntGELU    | n:  11
IntSoftmax | n:  6
IntGELU    | n:  11
IntSoftmax | n:  6
IntGELU    | n:  11
IntSoftmax | n:  6
IntGELU    | n:  11
IntSoftmax | n:  6
IntGELU    | n:  11
.calib done
Test: [  0/391]	Time  3.863 ( 3.863)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.80
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=6, intgelu_exp_n=12
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=6, intgelu_exp_n=12, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  6
IntGELU    | n:  12
IntSoftmax | n:  6
IntGELU    | n:  12
IntSoftmax | n:  6
IntGELU    | n:  12
IntSoftmax | n:  6
IntGELU    | n:  12
IntSoftmax | n:  6
IntGELU    | n:  12
IntSoftmax | n:  6
IntGELU    | n:  12
IntSoftmax | n:  6
IntGELU    | n:  12
IntSoftmax | n:  6
IntGELU    | n:  12
IntSoftmax | n:  6
IntGELU    | n:  12
IntSoftmax | n:  6
IntGELU    | n:  12
IntSoftmax | n:  6
IntGELU    | n:  12
IntSoftmax | n:  6
IntGELU    | n:  12
.calib done
Test: [  0/391]	Time  3.630 ( 3.630)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.57
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=6, intgelu_exp_n=13
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=6, intgelu_exp_n=13, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  6
IntGELU    | n:  13
IntSoftmax | n:  6
IntGELU    | n:  13
IntSoftmax | n:  6
IntGELU    | n:  13
IntSoftmax | n:  6
IntGELU    | n:  13
IntSoftmax | n:  6
IntGELU    | n:  13
IntSoftmax | n:  6
IntGELU    | n:  13
IntSoftmax | n:  6
IntGELU    | n:  13
IntSoftmax | n:  6
IntGELU    | n:  13
IntSoftmax | n:  6
IntGELU    | n:  13
IntSoftmax | n:  6
IntGELU    | n:  13
IntSoftmax | n:  6
IntGELU    | n:  13
IntSoftmax | n:  6
IntGELU    | n:  13
.calib done
Test: [  0/391]	Time  3.850 ( 3.850)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.80
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=6, intgelu_exp_n=14
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=6, intgelu_exp_n=14, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  6
IntGELU    | n:  14
IntSoftmax | n:  6
IntGELU    | n:  14
IntSoftmax | n:  6
IntGELU    | n:  14
IntSoftmax | n:  6
IntGELU    | n:  14
IntSoftmax | n:  6
IntGELU    | n:  14
IntSoftmax | n:  6
IntGELU    | n:  14
IntSoftmax | n:  6
IntGELU    | n:  14
IntSoftmax | n:  6
IntGELU    | n:  14
IntSoftmax | n:  6
IntGELU    | n:  14
IntSoftmax | n:  6
IntGELU    | n:  14
IntSoftmax | n:  6
IntGELU    | n:  14
IntSoftmax | n:  6
IntGELU    | n:  14
.calib done
Test: [  0/391]	Time  3.660 ( 3.660)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.53
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=6, intgelu_exp_n=15
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=6, intgelu_exp_n=15, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  6
IntGELU    | n:  15
IntSoftmax | n:  6
IntGELU    | n:  15
IntSoftmax | n:  6
IntGELU    | n:  15
IntSoftmax | n:  6
IntGELU    | n:  15
IntSoftmax | n:  6
IntGELU    | n:  15
IntSoftmax | n:  6
IntGELU    | n:  15
IntSoftmax | n:  6
IntGELU    | n:  15
IntSoftmax | n:  6
IntGELU    | n:  15
IntSoftmax | n:  6
IntGELU    | n:  15
IntSoftmax | n:  6
IntGELU    | n:  15
IntSoftmax | n:  6
IntGELU    | n:  15
IntSoftmax | n:  6
IntGELU    | n:  15
.calib done
Test: [  0/391]	Time  3.879 ( 3.879)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.80
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=6, intgelu_exp_n=16
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=6, intgelu_exp_n=16, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  6
IntGELU    | n:  16
IntSoftmax | n:  6
IntGELU    | n:  16
IntSoftmax | n:  6
IntGELU    | n:  16
IntSoftmax | n:  6
IntGELU    | n:  16
IntSoftmax | n:  6
IntGELU    | n:  16
IntSoftmax | n:  6
IntGELU    | n:  16
IntSoftmax | n:  6
IntGELU    | n:  16
IntSoftmax | n:  6
IntGELU    | n:  16
IntSoftmax | n:  6
IntGELU    | n:  16
IntSoftmax | n:  6
IntGELU    | n:  16
IntSoftmax | n:  6
IntGELU    | n:  16
IntSoftmax | n:  6
IntGELU    | n:  16
.calib done
Test: [  0/391]	Time  3.976 ( 3.976)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.98
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=6, intgelu_exp_n=17
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=6, intgelu_exp_n=17, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  6
IntGELU    | n:  17
IntSoftmax | n:  6
IntGELU    | n:  17
IntSoftmax | n:  6
IntGELU    | n:  17
IntSoftmax | n:  6
IntGELU    | n:  17
IntSoftmax | n:  6
IntGELU    | n:  17
IntSoftmax | n:  6
IntGELU    | n:  17
IntSoftmax | n:  6
IntGELU    | n:  17
IntSoftmax | n:  6
IntGELU    | n:  17
IntSoftmax | n:  6
IntGELU    | n:  17
IntSoftmax | n:  6
IntGELU    | n:  17
IntSoftmax | n:  6
IntGELU    | n:  17
IntSoftmax | n:  6
IntGELU    | n:  17
.calib done
Test: [  0/391]	Time  3.916 ( 3.916)	Acc@1   0.00 (  0.00)	Acc@5   1.56 (  1.56)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 1.562
Time: 8.85
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=6, intgelu_exp_n=18
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=6, intgelu_exp_n=18, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  6
IntGELU    | n:  18
IntSoftmax | n:  6
IntGELU    | n:  18
IntSoftmax | n:  6
IntGELU    | n:  18
IntSoftmax | n:  6
IntGELU    | n:  18
IntSoftmax | n:  6
IntGELU    | n:  18
IntSoftmax | n:  6
IntGELU    | n:  18
IntSoftmax | n:  6
IntGELU    | n:  18
IntSoftmax | n:  6
IntGELU    | n:  18
IntSoftmax | n:  6
IntGELU    | n:  18
IntSoftmax | n:  6
IntGELU    | n:  18
IntSoftmax | n:  6
IntGELU    | n:  18
IntSoftmax | n:  6
IntGELU    | n:  18
.calib done
Test: [  0/391]	Time  4.042 ( 4.042)	Acc@1   0.00 (  0.00)	Acc@5   0.78 (  0.78)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.781
Time: 8.96
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=6, intgelu_exp_n=19
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=6, intgelu_exp_n=19, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  6
IntGELU    | n:  19
IntSoftmax | n:  6
IntGELU    | n:  19
IntSoftmax | n:  6
IntGELU    | n:  19
IntSoftmax | n:  6
IntGELU    | n:  19
IntSoftmax | n:  6
IntGELU    | n:  19
IntSoftmax | n:  6
IntGELU    | n:  19
IntSoftmax | n:  6
IntGELU    | n:  19
IntSoftmax | n:  6
IntGELU    | n:  19
IntSoftmax | n:  6
IntGELU    | n:  19
IntSoftmax | n:  6
IntGELU    | n:  19
IntSoftmax | n:  6
IntGELU    | n:  19
IntSoftmax | n:  6
IntGELU    | n:  19
.calib done
Test: [  0/391]	Time  3.797 ( 3.797)	Acc@1   0.78 (  0.78)	Acc@5   4.69 (  4.69)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.781 Prec@5 4.688
Time: 8.76
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=6, intgelu_exp_n=20
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=6, intgelu_exp_n=20, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  6
IntGELU    | n:  20
IntSoftmax | n:  6
IntGELU    | n:  20
IntSoftmax | n:  6
IntGELU    | n:  20
IntSoftmax | n:  6
IntGELU    | n:  20
IntSoftmax | n:  6
IntGELU    | n:  20
IntSoftmax | n:  6
IntGELU    | n:  20
IntSoftmax | n:  6
IntGELU    | n:  20
IntSoftmax | n:  6
IntGELU    | n:  20
IntSoftmax | n:  6
IntGELU    | n:  20
IntSoftmax | n:  6
IntGELU    | n:  20
IntSoftmax | n:  6
IntGELU    | n:  20
IntSoftmax | n:  6
IntGELU    | n:  20
.calib done
Test: [  0/391]	Time  3.953 ( 3.953)	Acc@1   6.25 (  6.25)	Acc@5  15.62 ( 15.62)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 6.250 Prec@5 15.625
Time: 8.87
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=6, intgelu_exp_n=21
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=6, intgelu_exp_n=21, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  6
IntGELU    | n:  21
IntSoftmax | n:  6
IntGELU    | n:  21
IntSoftmax | n:  6
IntGELU    | n:  21
IntSoftmax | n:  6
IntGELU    | n:  21
IntSoftmax | n:  6
IntGELU    | n:  21
IntSoftmax | n:  6
IntGELU    | n:  21
IntSoftmax | n:  6
IntGELU    | n:  21
IntSoftmax | n:  6
IntGELU    | n:  21
IntSoftmax | n:  6
IntGELU    | n:  21
IntSoftmax | n:  6
IntGELU    | n:  21
IntSoftmax | n:  6
IntGELU    | n:  21
IntSoftmax | n:  6
IntGELU    | n:  21
.calib done
Test: [  0/391]	Time  3.954 ( 3.954)	Acc@1   7.81 (  7.81)	Acc@5  25.78 ( 25.78)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 7.812 Prec@5 25.781
Time: 8.87
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=6, intgelu_exp_n=22
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=6, intgelu_exp_n=22, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  6
IntGELU    | n:  22
IntSoftmax | n:  6
IntGELU    | n:  22
IntSoftmax | n:  6
IntGELU    | n:  22
IntSoftmax | n:  6
IntGELU    | n:  22
IntSoftmax | n:  6
IntGELU    | n:  22
IntSoftmax | n:  6
IntGELU    | n:  22
IntSoftmax | n:  6
IntGELU    | n:  22
IntSoftmax | n:  6
IntGELU    | n:  22
IntSoftmax | n:  6
IntGELU    | n:  22
IntSoftmax | n:  6
IntGELU    | n:  22
IntSoftmax | n:  6
IntGELU    | n:  22
IntSoftmax | n:  6
IntGELU    | n:  22
.calib done
Test: [  0/391]	Time  3.953 ( 3.953)	Acc@1   7.03 (  7.03)	Acc@5  23.44 ( 23.44)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 7.031 Prec@5 23.438
Time: 8.95
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=6, intgelu_exp_n=23
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=6, intgelu_exp_n=23, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  6
IntGELU    | n:  23
IntSoftmax | n:  6
IntGELU    | n:  23
IntSoftmax | n:  6
IntGELU    | n:  23
IntSoftmax | n:  6
IntGELU    | n:  23
IntSoftmax | n:  6
IntGELU    | n:  23
IntSoftmax | n:  6
IntGELU    | n:  23
IntSoftmax | n:  6
IntGELU    | n:  23
IntSoftmax | n:  6
IntGELU    | n:  23
IntSoftmax | n:  6
IntGELU    | n:  23
IntSoftmax | n:  6
IntGELU    | n:  23
IntSoftmax | n:  6
IntGELU    | n:  23
IntSoftmax | n:  6
IntGELU    | n:  23
.calib done
Test: [  0/391]	Time  3.951 ( 3.951)	Acc@1  11.72 ( 11.72)	Acc@5  35.16 ( 35.16)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 11.719 Prec@5 35.156
Time: 8.93
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=6, intgelu_exp_n=24
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=6, intgelu_exp_n=24, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  6
IntGELU    | n:  24
IntSoftmax | n:  6
IntGELU    | n:  24
IntSoftmax | n:  6
IntGELU    | n:  24
IntSoftmax | n:  6
IntGELU    | n:  24
IntSoftmax | n:  6
IntGELU    | n:  24
IntSoftmax | n:  6
IntGELU    | n:  24
IntSoftmax | n:  6
IntGELU    | n:  24
IntSoftmax | n:  6
IntGELU    | n:  24
IntSoftmax | n:  6
IntGELU    | n:  24
IntSoftmax | n:  6
IntGELU    | n:  24
IntSoftmax | n:  6
IntGELU    | n:  24
IntSoftmax | n:  6
IntGELU    | n:  24
.calib done
Test: [  0/391]	Time  3.689 ( 3.689)	Acc@1  13.28 ( 13.28)	Acc@5  35.16 ( 35.16)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 13.281 Prec@5 35.156
Time: 8.62
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=6, intgelu_exp_n=25
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=6, intgelu_exp_n=25, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  6
IntGELU    | n:  25
IntSoftmax | n:  6
IntGELU    | n:  25
IntSoftmax | n:  6
IntGELU    | n:  25
IntSoftmax | n:  6
IntGELU    | n:  25
IntSoftmax | n:  6
IntGELU    | n:  25
IntSoftmax | n:  6
IntGELU    | n:  25
IntSoftmax | n:  6
IntGELU    | n:  25
IntSoftmax | n:  6
IntGELU    | n:  25
IntSoftmax | n:  6
IntGELU    | n:  25
IntSoftmax | n:  6
IntGELU    | n:  25
IntSoftmax | n:  6
IntGELU    | n:  25
IntSoftmax | n:  6
IntGELU    | n:  25
.calib done
Test: [  0/391]	Time  3.680 ( 3.680)	Acc@1  14.06 ( 14.06)	Acc@5  39.84 ( 39.84)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 14.062 Prec@5 39.844
Time: 8.62
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=6, intgelu_exp_n=26
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=6, intgelu_exp_n=26, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  6
IntGELU    | n:  26
IntSoftmax | n:  6
IntGELU    | n:  26
IntSoftmax | n:  6
IntGELU    | n:  26
IntSoftmax | n:  6
IntGELU    | n:  26
IntSoftmax | n:  6
IntGELU    | n:  26
IntSoftmax | n:  6
IntGELU    | n:  26
IntSoftmax | n:  6
IntGELU    | n:  26
IntSoftmax | n:  6
IntGELU    | n:  26
IntSoftmax | n:  6
IntGELU    | n:  26
IntSoftmax | n:  6
IntGELU    | n:  26
IntSoftmax | n:  6
IntGELU    | n:  26
IntSoftmax | n:  6
IntGELU    | n:  26
.calib done
Test: [  0/391]	Time  3.640 ( 3.640)	Acc@1  18.75 ( 18.75)	Acc@5  46.09 ( 46.09)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 18.750 Prec@5 46.094
Time: 8.57
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=6, intgelu_exp_n=27
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=6, intgelu_exp_n=27, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  6
IntGELU    | n:  27
IntSoftmax | n:  6
IntGELU    | n:  27
IntSoftmax | n:  6
IntGELU    | n:  27
IntSoftmax | n:  6
IntGELU    | n:  27
IntSoftmax | n:  6
IntGELU    | n:  27
IntSoftmax | n:  6
IntGELU    | n:  27
IntSoftmax | n:  6
IntGELU    | n:  27
IntSoftmax | n:  6
IntGELU    | n:  27
IntSoftmax | n:  6
IntGELU    | n:  27
IntSoftmax | n:  6
IntGELU    | n:  27
IntSoftmax | n:  6
IntGELU    | n:  27
IntSoftmax | n:  6
IntGELU    | n:  27
.calib done
Test: [  0/391]	Time  3.775 ( 3.775)	Acc@1  19.53 ( 19.53)	Acc@5  52.34 ( 52.34)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 19.531 Prec@5 52.344
Time: 8.69
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=6, intgelu_exp_n=28
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=6, intgelu_exp_n=28, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  6
IntGELU    | n:  28
IntSoftmax | n:  6
IntGELU    | n:  28
IntSoftmax | n:  6
IntGELU    | n:  28
IntSoftmax | n:  6
IntGELU    | n:  28
IntSoftmax | n:  6
IntGELU    | n:  28
IntSoftmax | n:  6
IntGELU    | n:  28
IntSoftmax | n:  6
IntGELU    | n:  28
IntSoftmax | n:  6
IntGELU    | n:  28
IntSoftmax | n:  6
IntGELU    | n:  28
IntSoftmax | n:  6
IntGELU    | n:  28
IntSoftmax | n:  6
IntGELU    | n:  28
IntSoftmax | n:  6
IntGELU    | n:  28
.calib done
Test: [  0/391]	Time  3.903 ( 3.903)	Acc@1  25.78 ( 25.78)	Acc@5  53.91 ( 53.91)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 25.781 Prec@5 53.906
Time: 8.90
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=6, intgelu_exp_n=29
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=6, intgelu_exp_n=29, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  6
IntGELU    | n:  29
IntSoftmax | n:  6
IntGELU    | n:  29
IntSoftmax | n:  6
IntGELU    | n:  29
IntSoftmax | n:  6
IntGELU    | n:  29
IntSoftmax | n:  6
IntGELU    | n:  29
IntSoftmax | n:  6
IntGELU    | n:  29
IntSoftmax | n:  6
IntGELU    | n:  29
IntSoftmax | n:  6
IntGELU    | n:  29
IntSoftmax | n:  6
IntGELU    | n:  29
IntSoftmax | n:  6
IntGELU    | n:  29
IntSoftmax | n:  6
IntGELU    | n:  29
IntSoftmax | n:  6
IntGELU    | n:  29
.calib done
Test: [  0/391]	Time  3.946 ( 3.946)	Acc@1  30.47 ( 30.47)	Acc@5  57.03 ( 57.03)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 30.469 Prec@5 57.031
Time: 8.98
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=6, intgelu_exp_n=30
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=6, intgelu_exp_n=30, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  6
IntGELU    | n:  30
IntSoftmax | n:  6
IntGELU    | n:  30
IntSoftmax | n:  6
IntGELU    | n:  30
IntSoftmax | n:  6
IntGELU    | n:  30
IntSoftmax | n:  6
IntGELU    | n:  30
IntSoftmax | n:  6
IntGELU    | n:  30
IntSoftmax | n:  6
IntGELU    | n:  30
IntSoftmax | n:  6
IntGELU    | n:  30
IntSoftmax | n:  6
IntGELU    | n:  30
IntSoftmax | n:  6
IntGELU    | n:  30
IntSoftmax | n:  6
IntGELU    | n:  30
IntSoftmax | n:  6
IntGELU    | n:  30
.calib done
Test: [  0/391]	Time  3.951 ( 3.951)	Acc@1  78.91 ( 78.91)	Acc@5  92.19 ( 92.19)
Test: [  1/391]	Time  1.737 ( 2.844)	Acc@1  62.50 ( 70.70)	Acc@5  93.75 ( 92.97)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 70.703 Prec@5 92.969
Time: 10.70
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=6, intgelu_exp_n=31
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=6, intgelu_exp_n=31, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  6
IntGELU    | n:  31
IntSoftmax | n:  6
IntGELU    | n:  31
IntSoftmax | n:  6
IntGELU    | n:  31
IntSoftmax | n:  6
IntGELU    | n:  31
IntSoftmax | n:  6
IntGELU    | n:  31
IntSoftmax | n:  6
IntGELU    | n:  31
IntSoftmax | n:  6
IntGELU    | n:  31
IntSoftmax | n:  6
IntGELU    | n:  31
IntSoftmax | n:  6
IntGELU    | n:  31
IntSoftmax | n:  6
IntGELU    | n:  31
IntSoftmax | n:  6
IntGELU    | n:  31
IntSoftmax | n:  6
IntGELU    | n:  31
.calib done
Test: [  0/391]	Time  4.008 ( 4.008)	Acc@1   7.81 (  7.81)	Acc@5  19.53 ( 19.53)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 7.812 Prec@5 19.531
Time: 8.94
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=7, intgelu_exp_n=0
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=7, intgelu_exp_n=0, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  7
IntGELU    | n:  0
IntSoftmax | n:  7
IntGELU    | n:  0
IntSoftmax | n:  7
IntGELU    | n:  0
IntSoftmax | n:  7
IntGELU    | n:  0
IntSoftmax | n:  7
IntGELU    | n:  0
IntSoftmax | n:  7
IntGELU    | n:  0
IntSoftmax | n:  7
IntGELU    | n:  0
IntSoftmax | n:  7
IntGELU    | n:  0
IntSoftmax | n:  7
IntGELU    | n:  0
IntSoftmax | n:  7
IntGELU    | n:  0
IntSoftmax | n:  7
IntGELU    | n:  0
IntSoftmax | n:  7
IntGELU    | n:  0
.calib done
Test: [  0/391]	Time  3.974 ( 3.974)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.89
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=7, intgelu_exp_n=1
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=7, intgelu_exp_n=1, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  7
IntGELU    | n:  1
IntSoftmax | n:  7
IntGELU    | n:  1
IntSoftmax | n:  7
IntGELU    | n:  1
IntSoftmax | n:  7
IntGELU    | n:  1
IntSoftmax | n:  7
IntGELU    | n:  1
IntSoftmax | n:  7
IntGELU    | n:  1
IntSoftmax | n:  7
IntGELU    | n:  1
IntSoftmax | n:  7
IntGELU    | n:  1
IntSoftmax | n:  7
IntGELU    | n:  1
IntSoftmax | n:  7
IntGELU    | n:  1
IntSoftmax | n:  7
IntGELU    | n:  1
IntSoftmax | n:  7
IntGELU    | n:  1
.calib done
Test: [  0/391]	Time  3.864 ( 3.864)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.77
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=7, intgelu_exp_n=2
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=7, intgelu_exp_n=2, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  7
IntGELU    | n:  2
IntSoftmax | n:  7
IntGELU    | n:  2
IntSoftmax | n:  7
IntGELU    | n:  2
IntSoftmax | n:  7
IntGELU    | n:  2
IntSoftmax | n:  7
IntGELU    | n:  2
IntSoftmax | n:  7
IntGELU    | n:  2
IntSoftmax | n:  7
IntGELU    | n:  2
IntSoftmax | n:  7
IntGELU    | n:  2
IntSoftmax | n:  7
IntGELU    | n:  2
IntSoftmax | n:  7
IntGELU    | n:  2
IntSoftmax | n:  7
IntGELU    | n:  2
IntSoftmax | n:  7
IntGELU    | n:  2
.calib done
Test: [  0/391]	Time  3.913 ( 3.913)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.89
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=7, intgelu_exp_n=3
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=7, intgelu_exp_n=3, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  7
IntGELU    | n:  3
IntSoftmax | n:  7
IntGELU    | n:  3
IntSoftmax | n:  7
IntGELU    | n:  3
IntSoftmax | n:  7
IntGELU    | n:  3
IntSoftmax | n:  7
IntGELU    | n:  3
IntSoftmax | n:  7
IntGELU    | n:  3
IntSoftmax | n:  7
IntGELU    | n:  3
IntSoftmax | n:  7
IntGELU    | n:  3
IntSoftmax | n:  7
IntGELU    | n:  3
IntSoftmax | n:  7
IntGELU    | n:  3
IntSoftmax | n:  7
IntGELU    | n:  3
IntSoftmax | n:  7
IntGELU    | n:  3
.calib done
Test: [  0/391]	Time  3.634 ( 3.634)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.52
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=7, intgelu_exp_n=4
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=7, intgelu_exp_n=4, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  7
IntGELU    | n:  4
IntSoftmax | n:  7
IntGELU    | n:  4
IntSoftmax | n:  7
IntGELU    | n:  4
IntSoftmax | n:  7
IntGELU    | n:  4
IntSoftmax | n:  7
IntGELU    | n:  4
IntSoftmax | n:  7
IntGELU    | n:  4
IntSoftmax | n:  7
IntGELU    | n:  4
IntSoftmax | n:  7
IntGELU    | n:  4
IntSoftmax | n:  7
IntGELU    | n:  4
IntSoftmax | n:  7
IntGELU    | n:  4
IntSoftmax | n:  7
IntGELU    | n:  4
IntSoftmax | n:  7
IntGELU    | n:  4
.calib done
Test: [  0/391]	Time  3.746 ( 3.746)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.71
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=7, intgelu_exp_n=5
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=7, intgelu_exp_n=5, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  7
IntGELU    | n:  5
IntSoftmax | n:  7
IntGELU    | n:  5
IntSoftmax | n:  7
IntGELU    | n:  5
IntSoftmax | n:  7
IntGELU    | n:  5
IntSoftmax | n:  7
IntGELU    | n:  5
IntSoftmax | n:  7
IntGELU    | n:  5
IntSoftmax | n:  7
IntGELU    | n:  5
IntSoftmax | n:  7
IntGELU    | n:  5
IntSoftmax | n:  7
IntGELU    | n:  5
IntSoftmax | n:  7
IntGELU    | n:  5
IntSoftmax | n:  7
IntGELU    | n:  5
IntSoftmax | n:  7
IntGELU    | n:  5
.calib done
Test: [  0/391]	Time  3.776 ( 3.776)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.70
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=7, intgelu_exp_n=6
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=7, intgelu_exp_n=6, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  7
IntGELU    | n:  6
IntSoftmax | n:  7
IntGELU    | n:  6
IntSoftmax | n:  7
IntGELU    | n:  6
IntSoftmax | n:  7
IntGELU    | n:  6
IntSoftmax | n:  7
IntGELU    | n:  6
IntSoftmax | n:  7
IntGELU    | n:  6
IntSoftmax | n:  7
IntGELU    | n:  6
IntSoftmax | n:  7
IntGELU    | n:  6
IntSoftmax | n:  7
IntGELU    | n:  6
IntSoftmax | n:  7
IntGELU    | n:  6
IntSoftmax | n:  7
IntGELU    | n:  6
IntSoftmax | n:  7
IntGELU    | n:  6
.calib done
Test: [  0/391]	Time  3.813 ( 3.813)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.75
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=7, intgelu_exp_n=7
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=7, intgelu_exp_n=7, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  7
IntGELU    | n:  7
IntSoftmax | n:  7
IntGELU    | n:  7
IntSoftmax | n:  7
IntGELU    | n:  7
IntSoftmax | n:  7
IntGELU    | n:  7
IntSoftmax | n:  7
IntGELU    | n:  7
IntSoftmax | n:  7
IntGELU    | n:  7
IntSoftmax | n:  7
IntGELU    | n:  7
IntSoftmax | n:  7
IntGELU    | n:  7
IntSoftmax | n:  7
IntGELU    | n:  7
IntSoftmax | n:  7
IntGELU    | n:  7
IntSoftmax | n:  7
IntGELU    | n:  7
IntSoftmax | n:  7
IntGELU    | n:  7
.calib done
Test: [  0/391]	Time  3.760 ( 3.760)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.79
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=7, intgelu_exp_n=8
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=7, intgelu_exp_n=8, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  7
IntGELU    | n:  8
IntSoftmax | n:  7
IntGELU    | n:  8
IntSoftmax | n:  7
IntGELU    | n:  8
IntSoftmax | n:  7
IntGELU    | n:  8
IntSoftmax | n:  7
IntGELU    | n:  8
IntSoftmax | n:  7
IntGELU    | n:  8
IntSoftmax | n:  7
IntGELU    | n:  8
IntSoftmax | n:  7
IntGELU    | n:  8
IntSoftmax | n:  7
IntGELU    | n:  8
IntSoftmax | n:  7
IntGELU    | n:  8
IntSoftmax | n:  7
IntGELU    | n:  8
IntSoftmax | n:  7
IntGELU    | n:  8
.calib done
Test: [  0/391]	Time  3.977 ( 3.977)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.92
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=7, intgelu_exp_n=9
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=7, intgelu_exp_n=9, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  7
IntGELU    | n:  9
IntSoftmax | n:  7
IntGELU    | n:  9
IntSoftmax | n:  7
IntGELU    | n:  9
IntSoftmax | n:  7
IntGELU    | n:  9
IntSoftmax | n:  7
IntGELU    | n:  9
IntSoftmax | n:  7
IntGELU    | n:  9
IntSoftmax | n:  7
IntGELU    | n:  9
IntSoftmax | n:  7
IntGELU    | n:  9
IntSoftmax | n:  7
IntGELU    | n:  9
IntSoftmax | n:  7
IntGELU    | n:  9
IntSoftmax | n:  7
IntGELU    | n:  9
IntSoftmax | n:  7
IntGELU    | n:  9
.calib done
Test: [  0/391]	Time  3.959 ( 3.959)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.92
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=7, intgelu_exp_n=10
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=7, intgelu_exp_n=10, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  7
IntGELU    | n:  10
IntSoftmax | n:  7
IntGELU    | n:  10
IntSoftmax | n:  7
IntGELU    | n:  10
IntSoftmax | n:  7
IntGELU    | n:  10
IntSoftmax | n:  7
IntGELU    | n:  10
IntSoftmax | n:  7
IntGELU    | n:  10
IntSoftmax | n:  7
IntGELU    | n:  10
IntSoftmax | n:  7
IntGELU    | n:  10
IntSoftmax | n:  7
IntGELU    | n:  10
IntSoftmax | n:  7
IntGELU    | n:  10
IntSoftmax | n:  7
IntGELU    | n:  10
IntSoftmax | n:  7
IntGELU    | n:  10
.calib done
Test: [  0/391]	Time  3.655 ( 3.655)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.62
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=7, intgelu_exp_n=11
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=7, intgelu_exp_n=11, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  7
IntGELU    | n:  11
IntSoftmax | n:  7
IntGELU    | n:  11
IntSoftmax | n:  7
IntGELU    | n:  11
IntSoftmax | n:  7
IntGELU    | n:  11
IntSoftmax | n:  7
IntGELU    | n:  11
IntSoftmax | n:  7
IntGELU    | n:  11
IntSoftmax | n:  7
IntGELU    | n:  11
IntSoftmax | n:  7
IntGELU    | n:  11
IntSoftmax | n:  7
IntGELU    | n:  11
IntSoftmax | n:  7
IntGELU    | n:  11
IntSoftmax | n:  7
IntGELU    | n:  11
IntSoftmax | n:  7
IntGELU    | n:  11
.calib done
Test: [  0/391]	Time  3.885 ( 3.885)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.76
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=7, intgelu_exp_n=12
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=7, intgelu_exp_n=12, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  7
IntGELU    | n:  12
IntSoftmax | n:  7
IntGELU    | n:  12
IntSoftmax | n:  7
IntGELU    | n:  12
IntSoftmax | n:  7
IntGELU    | n:  12
IntSoftmax | n:  7
IntGELU    | n:  12
IntSoftmax | n:  7
IntGELU    | n:  12
IntSoftmax | n:  7
IntGELU    | n:  12
IntSoftmax | n:  7
IntGELU    | n:  12
IntSoftmax | n:  7
IntGELU    | n:  12
IntSoftmax | n:  7
IntGELU    | n:  12
IntSoftmax | n:  7
IntGELU    | n:  12
IntSoftmax | n:  7
IntGELU    | n:  12
.calib done
Test: [  0/391]	Time  4.023 ( 4.023)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.91
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=7, intgelu_exp_n=13
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=7, intgelu_exp_n=13, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  7
IntGELU    | n:  13
IntSoftmax | n:  7
IntGELU    | n:  13
IntSoftmax | n:  7
IntGELU    | n:  13
IntSoftmax | n:  7
IntGELU    | n:  13
IntSoftmax | n:  7
IntGELU    | n:  13
IntSoftmax | n:  7
IntGELU    | n:  13
IntSoftmax | n:  7
IntGELU    | n:  13
IntSoftmax | n:  7
IntGELU    | n:  13
IntSoftmax | n:  7
IntGELU    | n:  13
IntSoftmax | n:  7
IntGELU    | n:  13
IntSoftmax | n:  7
IntGELU    | n:  13
IntSoftmax | n:  7
IntGELU    | n:  13
.calib done
Test: [  0/391]	Time  3.953 ( 3.953)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.93
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=7, intgelu_exp_n=14
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=7, intgelu_exp_n=14, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  7
IntGELU    | n:  14
IntSoftmax | n:  7
IntGELU    | n:  14
IntSoftmax | n:  7
IntGELU    | n:  14
IntSoftmax | n:  7
IntGELU    | n:  14
IntSoftmax | n:  7
IntGELU    | n:  14
IntSoftmax | n:  7
IntGELU    | n:  14
IntSoftmax | n:  7
IntGELU    | n:  14
IntSoftmax | n:  7
IntGELU    | n:  14
IntSoftmax | n:  7
IntGELU    | n:  14
IntSoftmax | n:  7
IntGELU    | n:  14
IntSoftmax | n:  7
IntGELU    | n:  14
IntSoftmax | n:  7
IntGELU    | n:  14
.calib done
Test: [  0/391]	Time  3.907 ( 3.907)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.82
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=7, intgelu_exp_n=15
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=7, intgelu_exp_n=15, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  7
IntGELU    | n:  15
IntSoftmax | n:  7
IntGELU    | n:  15
IntSoftmax | n:  7
IntGELU    | n:  15
IntSoftmax | n:  7
IntGELU    | n:  15
IntSoftmax | n:  7
IntGELU    | n:  15
IntSoftmax | n:  7
IntGELU    | n:  15
IntSoftmax | n:  7
IntGELU    | n:  15
IntSoftmax | n:  7
IntGELU    | n:  15
IntSoftmax | n:  7
IntGELU    | n:  15
IntSoftmax | n:  7
IntGELU    | n:  15
IntSoftmax | n:  7
IntGELU    | n:  15
IntSoftmax | n:  7
IntGELU    | n:  15
.calib done
Test: [  0/391]	Time  3.961 ( 3.961)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.92
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=7, intgelu_exp_n=16
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=7, intgelu_exp_n=16, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  7
IntGELU    | n:  16
IntSoftmax | n:  7
IntGELU    | n:  16
IntSoftmax | n:  7
IntGELU    | n:  16
IntSoftmax | n:  7
IntGELU    | n:  16
IntSoftmax | n:  7
IntGELU    | n:  16
IntSoftmax | n:  7
IntGELU    | n:  16
IntSoftmax | n:  7
IntGELU    | n:  16
IntSoftmax | n:  7
IntGELU    | n:  16
IntSoftmax | n:  7
IntGELU    | n:  16
IntSoftmax | n:  7
IntGELU    | n:  16
IntSoftmax | n:  7
IntGELU    | n:  16
IntSoftmax | n:  7
IntGELU    | n:  16
.calib done
Test: [  0/391]	Time  3.648 ( 3.648)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.54
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=7, intgelu_exp_n=17
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=7, intgelu_exp_n=17, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  7
IntGELU    | n:  17
IntSoftmax | n:  7
IntGELU    | n:  17
IntSoftmax | n:  7
IntGELU    | n:  17
IntSoftmax | n:  7
IntGELU    | n:  17
IntSoftmax | n:  7
IntGELU    | n:  17
IntSoftmax | n:  7
IntGELU    | n:  17
IntSoftmax | n:  7
IntGELU    | n:  17
IntSoftmax | n:  7
IntGELU    | n:  17
IntSoftmax | n:  7
IntGELU    | n:  17
IntSoftmax | n:  7
IntGELU    | n:  17
IntSoftmax | n:  7
IntGELU    | n:  17
IntSoftmax | n:  7
IntGELU    | n:  17
.calib done
Test: [  0/391]	Time  4.017 ( 4.017)	Acc@1   0.00 (  0.00)	Acc@5   0.78 (  0.78)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.781
Time: 9.05
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=7, intgelu_exp_n=18
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=7, intgelu_exp_n=18, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  7
IntGELU    | n:  18
IntSoftmax | n:  7
IntGELU    | n:  18
IntSoftmax | n:  7
IntGELU    | n:  18
IntSoftmax | n:  7
IntGELU    | n:  18
IntSoftmax | n:  7
IntGELU    | n:  18
IntSoftmax | n:  7
IntGELU    | n:  18
IntSoftmax | n:  7
IntGELU    | n:  18
IntSoftmax | n:  7
IntGELU    | n:  18
IntSoftmax | n:  7
IntGELU    | n:  18
IntSoftmax | n:  7
IntGELU    | n:  18
IntSoftmax | n:  7
IntGELU    | n:  18
IntSoftmax | n:  7
IntGELU    | n:  18
.calib done
Test: [  0/391]	Time  3.988 ( 3.988)	Acc@1   0.78 (  0.78)	Acc@5   4.69 (  4.69)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.781 Prec@5 4.688
Time: 9.00
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=7, intgelu_exp_n=19
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=7, intgelu_exp_n=19, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  7
IntGELU    | n:  19
IntSoftmax | n:  7
IntGELU    | n:  19
IntSoftmax | n:  7
IntGELU    | n:  19
IntSoftmax | n:  7
IntGELU    | n:  19
IntSoftmax | n:  7
IntGELU    | n:  19
IntSoftmax | n:  7
IntGELU    | n:  19
IntSoftmax | n:  7
IntGELU    | n:  19
IntSoftmax | n:  7
IntGELU    | n:  19
IntSoftmax | n:  7
IntGELU    | n:  19
IntSoftmax | n:  7
IntGELU    | n:  19
IntSoftmax | n:  7
IntGELU    | n:  19
IntSoftmax | n:  7
IntGELU    | n:  19
.calib done
Test: [  0/391]	Time  3.998 ( 3.998)	Acc@1   0.00 (  0.00)	Acc@5   0.78 (  0.78)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.781
Time: 8.96
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=7, intgelu_exp_n=20
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=7, intgelu_exp_n=20, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  7
IntGELU    | n:  20
IntSoftmax | n:  7
IntGELU    | n:  20
IntSoftmax | n:  7
IntGELU    | n:  20
IntSoftmax | n:  7
IntGELU    | n:  20
IntSoftmax | n:  7
IntGELU    | n:  20
IntSoftmax | n:  7
IntGELU    | n:  20
IntSoftmax | n:  7
IntGELU    | n:  20
IntSoftmax | n:  7
IntGELU    | n:  20
IntSoftmax | n:  7
IntGELU    | n:  20
IntSoftmax | n:  7
IntGELU    | n:  20
IntSoftmax | n:  7
IntGELU    | n:  20
IntSoftmax | n:  7
IntGELU    | n:  20
.calib done
Test: [  0/391]	Time  3.849 ( 3.849)	Acc@1   3.91 (  3.91)	Acc@5  10.16 ( 10.16)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 3.906 Prec@5 10.156
Time: 8.73
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=7, intgelu_exp_n=21
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=7, intgelu_exp_n=21, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  7
IntGELU    | n:  21
IntSoftmax | n:  7
IntGELU    | n:  21
IntSoftmax | n:  7
IntGELU    | n:  21
IntSoftmax | n:  7
IntGELU    | n:  21
IntSoftmax | n:  7
IntGELU    | n:  21
IntSoftmax | n:  7
IntGELU    | n:  21
IntSoftmax | n:  7
IntGELU    | n:  21
IntSoftmax | n:  7
IntGELU    | n:  21
IntSoftmax | n:  7
IntGELU    | n:  21
IntSoftmax | n:  7
IntGELU    | n:  21
IntSoftmax | n:  7
IntGELU    | n:  21
IntSoftmax | n:  7
IntGELU    | n:  21
.calib done
Test: [  0/391]	Time  3.951 ( 3.951)	Acc@1  10.16 ( 10.16)	Acc@5  24.22 ( 24.22)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 10.156 Prec@5 24.219
Time: 8.91
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=7, intgelu_exp_n=22
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=7, intgelu_exp_n=22, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  7
IntGELU    | n:  22
IntSoftmax | n:  7
IntGELU    | n:  22
IntSoftmax | n:  7
IntGELU    | n:  22
IntSoftmax | n:  7
IntGELU    | n:  22
IntSoftmax | n:  7
IntGELU    | n:  22
IntSoftmax | n:  7
IntGELU    | n:  22
IntSoftmax | n:  7
IntGELU    | n:  22
IntSoftmax | n:  7
IntGELU    | n:  22
IntSoftmax | n:  7
IntGELU    | n:  22
IntSoftmax | n:  7
IntGELU    | n:  22
IntSoftmax | n:  7
IntGELU    | n:  22
IntSoftmax | n:  7
IntGELU    | n:  22
.calib done
Test: [  0/391]	Time  3.790 ( 3.790)	Acc@1  10.16 ( 10.16)	Acc@5  25.78 ( 25.78)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 10.156 Prec@5 25.781
Time: 8.72
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=7, intgelu_exp_n=23
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=7, intgelu_exp_n=23, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  7
IntGELU    | n:  23
IntSoftmax | n:  7
IntGELU    | n:  23
IntSoftmax | n:  7
IntGELU    | n:  23
IntSoftmax | n:  7
IntGELU    | n:  23
IntSoftmax | n:  7
IntGELU    | n:  23
IntSoftmax | n:  7
IntGELU    | n:  23
IntSoftmax | n:  7
IntGELU    | n:  23
IntSoftmax | n:  7
IntGELU    | n:  23
IntSoftmax | n:  7
IntGELU    | n:  23
IntSoftmax | n:  7
IntGELU    | n:  23
IntSoftmax | n:  7
IntGELU    | n:  23
IntSoftmax | n:  7
IntGELU    | n:  23
.calib done
Test: [  0/391]	Time  3.676 ( 3.676)	Acc@1   9.38 (  9.38)	Acc@5  25.78 ( 25.78)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 9.375 Prec@5 25.781
Time: 8.62
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=7, intgelu_exp_n=24
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=7, intgelu_exp_n=24, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  7
IntGELU    | n:  24
IntSoftmax | n:  7
IntGELU    | n:  24
IntSoftmax | n:  7
IntGELU    | n:  24
IntSoftmax | n:  7
IntGELU    | n:  24
IntSoftmax | n:  7
IntGELU    | n:  24
IntSoftmax | n:  7
IntGELU    | n:  24
IntSoftmax | n:  7
IntGELU    | n:  24
IntSoftmax | n:  7
IntGELU    | n:  24
IntSoftmax | n:  7
IntGELU    | n:  24
IntSoftmax | n:  7
IntGELU    | n:  24
IntSoftmax | n:  7
IntGELU    | n:  24
IntSoftmax | n:  7
IntGELU    | n:  24
.calib done
Test: [  0/391]	Time  3.683 ( 3.683)	Acc@1  17.19 ( 17.19)	Acc@5  33.59 ( 33.59)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 17.188 Prec@5 33.594
Time: 8.61
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=7, intgelu_exp_n=25
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=7, intgelu_exp_n=25, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  7
IntGELU    | n:  25
IntSoftmax | n:  7
IntGELU    | n:  25
IntSoftmax | n:  7
IntGELU    | n:  25
IntSoftmax | n:  7
IntGELU    | n:  25
IntSoftmax | n:  7
IntGELU    | n:  25
IntSoftmax | n:  7
IntGELU    | n:  25
IntSoftmax | n:  7
IntGELU    | n:  25
IntSoftmax | n:  7
IntGELU    | n:  25
IntSoftmax | n:  7
IntGELU    | n:  25
IntSoftmax | n:  7
IntGELU    | n:  25
IntSoftmax | n:  7
IntGELU    | n:  25
IntSoftmax | n:  7
IntGELU    | n:  25
.calib done
Test: [  0/391]	Time  3.968 ( 3.968)	Acc@1  14.84 ( 14.84)	Acc@5  39.84 ( 39.84)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 14.844 Prec@5 39.844
Time: 8.98
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=7, intgelu_exp_n=26
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=7, intgelu_exp_n=26, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  7
IntGELU    | n:  26
IntSoftmax | n:  7
IntGELU    | n:  26
IntSoftmax | n:  7
IntGELU    | n:  26
IntSoftmax | n:  7
IntGELU    | n:  26
IntSoftmax | n:  7
IntGELU    | n:  26
IntSoftmax | n:  7
IntGELU    | n:  26
IntSoftmax | n:  7
IntGELU    | n:  26
IntSoftmax | n:  7
IntGELU    | n:  26
IntSoftmax | n:  7
IntGELU    | n:  26
IntSoftmax | n:  7
IntGELU    | n:  26
IntSoftmax | n:  7
IntGELU    | n:  26
IntSoftmax | n:  7
IntGELU    | n:  26
.calib done
Test: [  0/391]	Time  3.899 ( 3.899)	Acc@1  21.09 ( 21.09)	Acc@5  45.31 ( 45.31)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 21.094 Prec@5 45.312
Time: 8.86
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=7, intgelu_exp_n=27
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=7, intgelu_exp_n=27, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  7
IntGELU    | n:  27
IntSoftmax | n:  7
IntGELU    | n:  27
IntSoftmax | n:  7
IntGELU    | n:  27
IntSoftmax | n:  7
IntGELU    | n:  27
IntSoftmax | n:  7
IntGELU    | n:  27
IntSoftmax | n:  7
IntGELU    | n:  27
IntSoftmax | n:  7
IntGELU    | n:  27
IntSoftmax | n:  7
IntGELU    | n:  27
IntSoftmax | n:  7
IntGELU    | n:  27
IntSoftmax | n:  7
IntGELU    | n:  27
IntSoftmax | n:  7
IntGELU    | n:  27
IntSoftmax | n:  7
IntGELU    | n:  27
.calib done
Test: [  0/391]	Time  3.981 ( 3.981)	Acc@1  16.41 ( 16.41)	Acc@5  44.53 ( 44.53)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 16.406 Prec@5 44.531
Time: 8.99
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=7, intgelu_exp_n=28
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=7, intgelu_exp_n=28, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  7
IntGELU    | n:  28
IntSoftmax | n:  7
IntGELU    | n:  28
IntSoftmax | n:  7
IntGELU    | n:  28
IntSoftmax | n:  7
IntGELU    | n:  28
IntSoftmax | n:  7
IntGELU    | n:  28
IntSoftmax | n:  7
IntGELU    | n:  28
IntSoftmax | n:  7
IntGELU    | n:  28
IntSoftmax | n:  7
IntGELU    | n:  28
IntSoftmax | n:  7
IntGELU    | n:  28
IntSoftmax | n:  7
IntGELU    | n:  28
IntSoftmax | n:  7
IntGELU    | n:  28
IntSoftmax | n:  7
IntGELU    | n:  28
.calib done
Test: [  0/391]	Time  3.666 ( 3.666)	Acc@1  22.66 ( 22.66)	Acc@5  51.56 ( 51.56)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 22.656 Prec@5 51.562
Time: 8.61
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=7, intgelu_exp_n=29
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=7, intgelu_exp_n=29, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  7
IntGELU    | n:  29
IntSoftmax | n:  7
IntGELU    | n:  29
IntSoftmax | n:  7
IntGELU    | n:  29
IntSoftmax | n:  7
IntGELU    | n:  29
IntSoftmax | n:  7
IntGELU    | n:  29
IntSoftmax | n:  7
IntGELU    | n:  29
IntSoftmax | n:  7
IntGELU    | n:  29
IntSoftmax | n:  7
IntGELU    | n:  29
IntSoftmax | n:  7
IntGELU    | n:  29
IntSoftmax | n:  7
IntGELU    | n:  29
IntSoftmax | n:  7
IntGELU    | n:  29
IntSoftmax | n:  7
IntGELU    | n:  29
.calib done
Test: [  0/391]	Time  3.856 ( 3.856)	Acc@1  30.47 ( 30.47)	Acc@5  59.38 ( 59.38)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 30.469 Prec@5 59.375
Time: 8.81
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=7, intgelu_exp_n=30
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=7, intgelu_exp_n=30, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  7
IntGELU    | n:  30
IntSoftmax | n:  7
IntGELU    | n:  30
IntSoftmax | n:  7
IntGELU    | n:  30
IntSoftmax | n:  7
IntGELU    | n:  30
IntSoftmax | n:  7
IntGELU    | n:  30
IntSoftmax | n:  7
IntGELU    | n:  30
IntSoftmax | n:  7
IntGELU    | n:  30
IntSoftmax | n:  7
IntGELU    | n:  30
IntSoftmax | n:  7
IntGELU    | n:  30
IntSoftmax | n:  7
IntGELU    | n:  30
IntSoftmax | n:  7
IntGELU    | n:  30
IntSoftmax | n:  7
IntGELU    | n:  30
.calib done
Test: [  0/391]	Time  3.839 ( 3.839)	Acc@1  53.12 ( 53.12)	Acc@5  77.34 ( 77.34)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 53.125 Prec@5 77.344
Time: 8.81
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=7, intgelu_exp_n=31
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=7, intgelu_exp_n=31, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  7
IntGELU    | n:  31
IntSoftmax | n:  7
IntGELU    | n:  31
IntSoftmax | n:  7
IntGELU    | n:  31
IntSoftmax | n:  7
IntGELU    | n:  31
IntSoftmax | n:  7
IntGELU    | n:  31
IntSoftmax | n:  7
IntGELU    | n:  31
IntSoftmax | n:  7
IntGELU    | n:  31
IntSoftmax | n:  7
IntGELU    | n:  31
IntSoftmax | n:  7
IntGELU    | n:  31
IntSoftmax | n:  7
IntGELU    | n:  31
IntSoftmax | n:  7
IntGELU    | n:  31
IntSoftmax | n:  7
IntGELU    | n:  31
.calib done
Test: [  0/391]	Time  3.933 ( 3.933)	Acc@1   5.47 (  5.47)	Acc@5  22.66 ( 22.66)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 5.469 Prec@5 22.656
Time: 8.87
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=8, intgelu_exp_n=0
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=8, intgelu_exp_n=0, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  8
IntGELU    | n:  0
IntSoftmax | n:  8
IntGELU    | n:  0
IntSoftmax | n:  8
IntGELU    | n:  0
IntSoftmax | n:  8
IntGELU    | n:  0
IntSoftmax | n:  8
IntGELU    | n:  0
IntSoftmax | n:  8
IntGELU    | n:  0
IntSoftmax | n:  8
IntGELU    | n:  0
IntSoftmax | n:  8
IntGELU    | n:  0
IntSoftmax | n:  8
IntGELU    | n:  0
IntSoftmax | n:  8
IntGELU    | n:  0
IntSoftmax | n:  8
IntGELU    | n:  0
IntSoftmax | n:  8
IntGELU    | n:  0
.calib done
Test: [  0/391]	Time  4.001 ( 4.001)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.93
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=8, intgelu_exp_n=1
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=8, intgelu_exp_n=1, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  8
IntGELU    | n:  1
IntSoftmax | n:  8
IntGELU    | n:  1
IntSoftmax | n:  8
IntGELU    | n:  1
IntSoftmax | n:  8
IntGELU    | n:  1
IntSoftmax | n:  8
IntGELU    | n:  1
IntSoftmax | n:  8
IntGELU    | n:  1
IntSoftmax | n:  8
IntGELU    | n:  1
IntSoftmax | n:  8
IntGELU    | n:  1
IntSoftmax | n:  8
IntGELU    | n:  1
IntSoftmax | n:  8
IntGELU    | n:  1
IntSoftmax | n:  8
IntGELU    | n:  1
IntSoftmax | n:  8
IntGELU    | n:  1
.calib done
Test: [  0/391]	Time  3.940 ( 3.940)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.92
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=8, intgelu_exp_n=2
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=8, intgelu_exp_n=2, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  8
IntGELU    | n:  2
IntSoftmax | n:  8
IntGELU    | n:  2
IntSoftmax | n:  8
IntGELU    | n:  2
IntSoftmax | n:  8
IntGELU    | n:  2
IntSoftmax | n:  8
IntGELU    | n:  2
IntSoftmax | n:  8
IntGELU    | n:  2
IntSoftmax | n:  8
IntGELU    | n:  2
IntSoftmax | n:  8
IntGELU    | n:  2
IntSoftmax | n:  8
IntGELU    | n:  2
IntSoftmax | n:  8
IntGELU    | n:  2
IntSoftmax | n:  8
IntGELU    | n:  2
IntSoftmax | n:  8
IntGELU    | n:  2
.calib done
Test: [  0/391]	Time  3.863 ( 3.863)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.81
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=8, intgelu_exp_n=3
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=8, intgelu_exp_n=3, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  8
IntGELU    | n:  3
IntSoftmax | n:  8
IntGELU    | n:  3
IntSoftmax | n:  8
IntGELU    | n:  3
IntSoftmax | n:  8
IntGELU    | n:  3
IntSoftmax | n:  8
IntGELU    | n:  3
IntSoftmax | n:  8
IntGELU    | n:  3
IntSoftmax | n:  8
IntGELU    | n:  3
IntSoftmax | n:  8
IntGELU    | n:  3
IntSoftmax | n:  8
IntGELU    | n:  3
IntSoftmax | n:  8
IntGELU    | n:  3
IntSoftmax | n:  8
IntGELU    | n:  3
IntSoftmax | n:  8
IntGELU    | n:  3
.calib done
Test: [  0/391]	Time  3.879 ( 3.879)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.90
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=8, intgelu_exp_n=4
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=8, intgelu_exp_n=4, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  8
IntGELU    | n:  4
IntSoftmax | n:  8
IntGELU    | n:  4
IntSoftmax | n:  8
IntGELU    | n:  4
IntSoftmax | n:  8
IntGELU    | n:  4
IntSoftmax | n:  8
IntGELU    | n:  4
IntSoftmax | n:  8
IntGELU    | n:  4
IntSoftmax | n:  8
IntGELU    | n:  4
IntSoftmax | n:  8
IntGELU    | n:  4
IntSoftmax | n:  8
IntGELU    | n:  4
IntSoftmax | n:  8
IntGELU    | n:  4
IntSoftmax | n:  8
IntGELU    | n:  4
IntSoftmax | n:  8
IntGELU    | n:  4
.calib done
Test: [  0/391]	Time  4.020 ( 4.020)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.92
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=8, intgelu_exp_n=5
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=8, intgelu_exp_n=5, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  8
IntGELU    | n:  5
IntSoftmax | n:  8
IntGELU    | n:  5
IntSoftmax | n:  8
IntGELU    | n:  5
IntSoftmax | n:  8
IntGELU    | n:  5
IntSoftmax | n:  8
IntGELU    | n:  5
IntSoftmax | n:  8
IntGELU    | n:  5
IntSoftmax | n:  8
IntGELU    | n:  5
IntSoftmax | n:  8
IntGELU    | n:  5
IntSoftmax | n:  8
IntGELU    | n:  5
IntSoftmax | n:  8
IntGELU    | n:  5
IntSoftmax | n:  8
IntGELU    | n:  5
IntSoftmax | n:  8
IntGELU    | n:  5
.calib done
Test: [  0/391]	Time  3.769 ( 3.769)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.72
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=8, intgelu_exp_n=6
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=8, intgelu_exp_n=6, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  8
IntGELU    | n:  6
IntSoftmax | n:  8
IntGELU    | n:  6
IntSoftmax | n:  8
IntGELU    | n:  6
IntSoftmax | n:  8
IntGELU    | n:  6
IntSoftmax | n:  8
IntGELU    | n:  6
IntSoftmax | n:  8
IntGELU    | n:  6
IntSoftmax | n:  8
IntGELU    | n:  6
IntSoftmax | n:  8
IntGELU    | n:  6
IntSoftmax | n:  8
IntGELU    | n:  6
IntSoftmax | n:  8
IntGELU    | n:  6
IntSoftmax | n:  8
IntGELU    | n:  6
IntSoftmax | n:  8
IntGELU    | n:  6
.calib done
Test: [  0/391]	Time  3.851 ( 3.851)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.75
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=8, intgelu_exp_n=7
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=8, intgelu_exp_n=7, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  8
IntGELU    | n:  7
IntSoftmax | n:  8
IntGELU    | n:  7
IntSoftmax | n:  8
IntGELU    | n:  7
IntSoftmax | n:  8
IntGELU    | n:  7
IntSoftmax | n:  8
IntGELU    | n:  7
IntSoftmax | n:  8
IntGELU    | n:  7
IntSoftmax | n:  8
IntGELU    | n:  7
IntSoftmax | n:  8
IntGELU    | n:  7
IntSoftmax | n:  8
IntGELU    | n:  7
IntSoftmax | n:  8
IntGELU    | n:  7
IntSoftmax | n:  8
IntGELU    | n:  7
IntSoftmax | n:  8
IntGELU    | n:  7
.calib done
Test: [  0/391]	Time  3.876 ( 3.876)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.82
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=8, intgelu_exp_n=8
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=8, intgelu_exp_n=8, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  8
IntGELU    | n:  8
IntSoftmax | n:  8
IntGELU    | n:  8
IntSoftmax | n:  8
IntGELU    | n:  8
IntSoftmax | n:  8
IntGELU    | n:  8
IntSoftmax | n:  8
IntGELU    | n:  8
IntSoftmax | n:  8
IntGELU    | n:  8
IntSoftmax | n:  8
IntGELU    | n:  8
IntSoftmax | n:  8
IntGELU    | n:  8
IntSoftmax | n:  8
IntGELU    | n:  8
IntSoftmax | n:  8
IntGELU    | n:  8
IntSoftmax | n:  8
IntGELU    | n:  8
IntSoftmax | n:  8
IntGELU    | n:  8
.calib done
Test: [  0/391]	Time  3.951 ( 3.951)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.92
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=8, intgelu_exp_n=9
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=8, intgelu_exp_n=9, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  8
IntGELU    | n:  9
IntSoftmax | n:  8
IntGELU    | n:  9
IntSoftmax | n:  8
IntGELU    | n:  9
IntSoftmax | n:  8
IntGELU    | n:  9
IntSoftmax | n:  8
IntGELU    | n:  9
IntSoftmax | n:  8
IntGELU    | n:  9
IntSoftmax | n:  8
IntGELU    | n:  9
IntSoftmax | n:  8
IntGELU    | n:  9
IntSoftmax | n:  8
IntGELU    | n:  9
IntSoftmax | n:  8
IntGELU    | n:  9
IntSoftmax | n:  8
IntGELU    | n:  9
IntSoftmax | n:  8
IntGELU    | n:  9
.calib done
Test: [  0/391]	Time  3.798 ( 3.798)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.73
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=8, intgelu_exp_n=10
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=8, intgelu_exp_n=10, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  8
IntGELU    | n:  10
IntSoftmax | n:  8
IntGELU    | n:  10
IntSoftmax | n:  8
IntGELU    | n:  10
IntSoftmax | n:  8
IntGELU    | n:  10
IntSoftmax | n:  8
IntGELU    | n:  10
IntSoftmax | n:  8
IntGELU    | n:  10
IntSoftmax | n:  8
IntGELU    | n:  10
IntSoftmax | n:  8
IntGELU    | n:  10
IntSoftmax | n:  8
IntGELU    | n:  10
IntSoftmax | n:  8
IntGELU    | n:  10
IntSoftmax | n:  8
IntGELU    | n:  10
IntSoftmax | n:  8
IntGELU    | n:  10
.calib done
Test: [  0/391]	Time  3.917 ( 3.917)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.88
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=8, intgelu_exp_n=11
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=8, intgelu_exp_n=11, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  8
IntGELU    | n:  11
IntSoftmax | n:  8
IntGELU    | n:  11
IntSoftmax | n:  8
IntGELU    | n:  11
IntSoftmax | n:  8
IntGELU    | n:  11
IntSoftmax | n:  8
IntGELU    | n:  11
IntSoftmax | n:  8
IntGELU    | n:  11
IntSoftmax | n:  8
IntGELU    | n:  11
IntSoftmax | n:  8
IntGELU    | n:  11
IntSoftmax | n:  8
IntGELU    | n:  11
IntSoftmax | n:  8
IntGELU    | n:  11
IntSoftmax | n:  8
IntGELU    | n:  11
IntSoftmax | n:  8
IntGELU    | n:  11
.calib done
Test: [  0/391]	Time  3.904 ( 3.904)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.90
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=8, intgelu_exp_n=12
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=8, intgelu_exp_n=12, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  8
IntGELU    | n:  12
IntSoftmax | n:  8
IntGELU    | n:  12
IntSoftmax | n:  8
IntGELU    | n:  12
IntSoftmax | n:  8
IntGELU    | n:  12
IntSoftmax | n:  8
IntGELU    | n:  12
IntSoftmax | n:  8
IntGELU    | n:  12
IntSoftmax | n:  8
IntGELU    | n:  12
IntSoftmax | n:  8
IntGELU    | n:  12
IntSoftmax | n:  8
IntGELU    | n:  12
IntSoftmax | n:  8
IntGELU    | n:  12
IntSoftmax | n:  8
IntGELU    | n:  12
IntSoftmax | n:  8
IntGELU    | n:  12
.calib done
Test: [  0/391]	Time  3.838 ( 3.838)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.79
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=8, intgelu_exp_n=13
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=8, intgelu_exp_n=13, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  8
IntGELU    | n:  13
IntSoftmax | n:  8
IntGELU    | n:  13
IntSoftmax | n:  8
IntGELU    | n:  13
IntSoftmax | n:  8
IntGELU    | n:  13
IntSoftmax | n:  8
IntGELU    | n:  13
IntSoftmax | n:  8
IntGELU    | n:  13
IntSoftmax | n:  8
IntGELU    | n:  13
IntSoftmax | n:  8
IntGELU    | n:  13
IntSoftmax | n:  8
IntGELU    | n:  13
IntSoftmax | n:  8
IntGELU    | n:  13
IntSoftmax | n:  8
IntGELU    | n:  13
IntSoftmax | n:  8
IntGELU    | n:  13
.calib done
Test: [  0/391]	Time  3.859 ( 3.859)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.76
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=8, intgelu_exp_n=14
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=8, intgelu_exp_n=14, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  8
IntGELU    | n:  14
IntSoftmax | n:  8
IntGELU    | n:  14
IntSoftmax | n:  8
IntGELU    | n:  14
IntSoftmax | n:  8
IntGELU    | n:  14
IntSoftmax | n:  8
IntGELU    | n:  14
IntSoftmax | n:  8
IntGELU    | n:  14
IntSoftmax | n:  8
IntGELU    | n:  14
IntSoftmax | n:  8
IntGELU    | n:  14
IntSoftmax | n:  8
IntGELU    | n:  14
IntSoftmax | n:  8
IntGELU    | n:  14
IntSoftmax | n:  8
IntGELU    | n:  14
IntSoftmax | n:  8
IntGELU    | n:  14
.calib done
Test: [  0/391]	Time  3.850 ( 3.850)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.86
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=8, intgelu_exp_n=15
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=8, intgelu_exp_n=15, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  8
IntGELU    | n:  15
IntSoftmax | n:  8
IntGELU    | n:  15
IntSoftmax | n:  8
IntGELU    | n:  15
IntSoftmax | n:  8
IntGELU    | n:  15
IntSoftmax | n:  8
IntGELU    | n:  15
IntSoftmax | n:  8
IntGELU    | n:  15
IntSoftmax | n:  8
IntGELU    | n:  15
IntSoftmax | n:  8
IntGELU    | n:  15
IntSoftmax | n:  8
IntGELU    | n:  15
IntSoftmax | n:  8
IntGELU    | n:  15
IntSoftmax | n:  8
IntGELU    | n:  15
IntSoftmax | n:  8
IntGELU    | n:  15
.calib done
Test: [  0/391]	Time  3.941 ( 3.941)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.96
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=8, intgelu_exp_n=16
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=8, intgelu_exp_n=16, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  8
IntGELU    | n:  16
IntSoftmax | n:  8
IntGELU    | n:  16
IntSoftmax | n:  8
IntGELU    | n:  16
IntSoftmax | n:  8
IntGELU    | n:  16
IntSoftmax | n:  8
IntGELU    | n:  16
IntSoftmax | n:  8
IntGELU    | n:  16
IntSoftmax | n:  8
IntGELU    | n:  16
IntSoftmax | n:  8
IntGELU    | n:  16
IntSoftmax | n:  8
IntGELU    | n:  16
IntSoftmax | n:  8
IntGELU    | n:  16
IntSoftmax | n:  8
IntGELU    | n:  16
IntSoftmax | n:  8
IntGELU    | n:  16
.calib done
Test: [  0/391]	Time  3.831 ( 3.831)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.78
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=8, intgelu_exp_n=17
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=8, intgelu_exp_n=17, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  8
IntGELU    | n:  17
IntSoftmax | n:  8
IntGELU    | n:  17
IntSoftmax | n:  8
IntGELU    | n:  17
IntSoftmax | n:  8
IntGELU    | n:  17
IntSoftmax | n:  8
IntGELU    | n:  17
IntSoftmax | n:  8
IntGELU    | n:  17
IntSoftmax | n:  8
IntGELU    | n:  17
IntSoftmax | n:  8
IntGELU    | n:  17
IntSoftmax | n:  8
IntGELU    | n:  17
IntSoftmax | n:  8
IntGELU    | n:  17
IntSoftmax | n:  8
IntGELU    | n:  17
IntSoftmax | n:  8
IntGELU    | n:  17
.calib done
Test: [  0/391]	Time  3.714 ( 3.714)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.63
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=8, intgelu_exp_n=18
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=8, intgelu_exp_n=18, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  8
IntGELU    | n:  18
IntSoftmax | n:  8
IntGELU    | n:  18
IntSoftmax | n:  8
IntGELU    | n:  18
IntSoftmax | n:  8
IntGELU    | n:  18
IntSoftmax | n:  8
IntGELU    | n:  18
IntSoftmax | n:  8
IntGELU    | n:  18
IntSoftmax | n:  8
IntGELU    | n:  18
IntSoftmax | n:  8
IntGELU    | n:  18
IntSoftmax | n:  8
IntGELU    | n:  18
IntSoftmax | n:  8
IntGELU    | n:  18
IntSoftmax | n:  8
IntGELU    | n:  18
IntSoftmax | n:  8
IntGELU    | n:  18
.calib done
Test: [  0/391]	Time  3.958 ( 3.958)	Acc@1   0.00 (  0.00)	Acc@5   2.34 (  2.34)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 2.344
Time: 8.91
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=8, intgelu_exp_n=19
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=8, intgelu_exp_n=19, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  8
IntGELU    | n:  19
IntSoftmax | n:  8
IntGELU    | n:  19
IntSoftmax | n:  8
IntGELU    | n:  19
IntSoftmax | n:  8
IntGELU    | n:  19
IntSoftmax | n:  8
IntGELU    | n:  19
IntSoftmax | n:  8
IntGELU    | n:  19
IntSoftmax | n:  8
IntGELU    | n:  19
IntSoftmax | n:  8
IntGELU    | n:  19
IntSoftmax | n:  8
IntGELU    | n:  19
IntSoftmax | n:  8
IntGELU    | n:  19
IntSoftmax | n:  8
IntGELU    | n:  19
IntSoftmax | n:  8
IntGELU    | n:  19
.calib done
Test: [  0/391]	Time  3.796 ( 3.796)	Acc@1   3.12 (  3.12)	Acc@5   7.81 (  7.81)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 3.125 Prec@5 7.812
Time: 8.76
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=8, intgelu_exp_n=20
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=8, intgelu_exp_n=20, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  8
IntGELU    | n:  20
IntSoftmax | n:  8
IntGELU    | n:  20
IntSoftmax | n:  8
IntGELU    | n:  20
IntSoftmax | n:  8
IntGELU    | n:  20
IntSoftmax | n:  8
IntGELU    | n:  20
IntSoftmax | n:  8
IntGELU    | n:  20
IntSoftmax | n:  8
IntGELU    | n:  20
IntSoftmax | n:  8
IntGELU    | n:  20
IntSoftmax | n:  8
IntGELU    | n:  20
IntSoftmax | n:  8
IntGELU    | n:  20
IntSoftmax | n:  8
IntGELU    | n:  20
IntSoftmax | n:  8
IntGELU    | n:  20
.calib done
Test: [  0/391]	Time  3.677 ( 3.677)	Acc@1   2.34 (  2.34)	Acc@5   8.59 (  8.59)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 2.344 Prec@5 8.594
Time: 8.63
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=8, intgelu_exp_n=21
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=8, intgelu_exp_n=21, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  8
IntGELU    | n:  21
IntSoftmax | n:  8
IntGELU    | n:  21
IntSoftmax | n:  8
IntGELU    | n:  21
IntSoftmax | n:  8
IntGELU    | n:  21
IntSoftmax | n:  8
IntGELU    | n:  21
IntSoftmax | n:  8
IntGELU    | n:  21
IntSoftmax | n:  8
IntGELU    | n:  21
IntSoftmax | n:  8
IntGELU    | n:  21
IntSoftmax | n:  8
IntGELU    | n:  21
IntSoftmax | n:  8
IntGELU    | n:  21
IntSoftmax | n:  8
IntGELU    | n:  21
IntSoftmax | n:  8
IntGELU    | n:  21
.calib done
Test: [  0/391]	Time  3.698 ( 3.698)	Acc@1   6.25 (  6.25)	Acc@5  16.41 ( 16.41)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 6.250 Prec@5 16.406
Time: 8.71
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=8, intgelu_exp_n=22
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=8, intgelu_exp_n=22, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  8
IntGELU    | n:  22
IntSoftmax | n:  8
IntGELU    | n:  22
IntSoftmax | n:  8
IntGELU    | n:  22
IntSoftmax | n:  8
IntGELU    | n:  22
IntSoftmax | n:  8
IntGELU    | n:  22
IntSoftmax | n:  8
IntGELU    | n:  22
IntSoftmax | n:  8
IntGELU    | n:  22
IntSoftmax | n:  8
IntGELU    | n:  22
IntSoftmax | n:  8
IntGELU    | n:  22
IntSoftmax | n:  8
IntGELU    | n:  22
IntSoftmax | n:  8
IntGELU    | n:  22
IntSoftmax | n:  8
IntGELU    | n:  22
.calib done
Test: [  0/391]	Time  3.869 ( 3.869)	Acc@1  10.16 ( 10.16)	Acc@5  24.22 ( 24.22)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 10.156 Prec@5 24.219
Time: 8.84
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=8, intgelu_exp_n=23
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=8, intgelu_exp_n=23, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  8
IntGELU    | n:  23
IntSoftmax | n:  8
IntGELU    | n:  23
IntSoftmax | n:  8
IntGELU    | n:  23
IntSoftmax | n:  8
IntGELU    | n:  23
IntSoftmax | n:  8
IntGELU    | n:  23
IntSoftmax | n:  8
IntGELU    | n:  23
IntSoftmax | n:  8
IntGELU    | n:  23
IntSoftmax | n:  8
IntGELU    | n:  23
IntSoftmax | n:  8
IntGELU    | n:  23
IntSoftmax | n:  8
IntGELU    | n:  23
IntSoftmax | n:  8
IntGELU    | n:  23
IntSoftmax | n:  8
IntGELU    | n:  23
.calib done
Test: [  0/391]	Time  3.797 ( 3.797)	Acc@1  14.06 ( 14.06)	Acc@5  32.81 ( 32.81)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 14.062 Prec@5 32.812
Time: 8.78
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=8, intgelu_exp_n=24
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=8, intgelu_exp_n=24, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  8
IntGELU    | n:  24
IntSoftmax | n:  8
IntGELU    | n:  24
IntSoftmax | n:  8
IntGELU    | n:  24
IntSoftmax | n:  8
IntGELU    | n:  24
IntSoftmax | n:  8
IntGELU    | n:  24
IntSoftmax | n:  8
IntGELU    | n:  24
IntSoftmax | n:  8
IntGELU    | n:  24
IntSoftmax | n:  8
IntGELU    | n:  24
IntSoftmax | n:  8
IntGELU    | n:  24
IntSoftmax | n:  8
IntGELU    | n:  24
IntSoftmax | n:  8
IntGELU    | n:  24
IntSoftmax | n:  8
IntGELU    | n:  24
.calib done
Test: [  0/391]	Time  3.905 ( 3.905)	Acc@1  15.62 ( 15.62)	Acc@5  36.72 ( 36.72)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 15.625 Prec@5 36.719
Time: 8.82
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=8, intgelu_exp_n=25
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=8, intgelu_exp_n=25, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  8
IntGELU    | n:  25
IntSoftmax | n:  8
IntGELU    | n:  25
IntSoftmax | n:  8
IntGELU    | n:  25
IntSoftmax | n:  8
IntGELU    | n:  25
IntSoftmax | n:  8
IntGELU    | n:  25
IntSoftmax | n:  8
IntGELU    | n:  25
IntSoftmax | n:  8
IntGELU    | n:  25
IntSoftmax | n:  8
IntGELU    | n:  25
IntSoftmax | n:  8
IntGELU    | n:  25
IntSoftmax | n:  8
IntGELU    | n:  25
IntSoftmax | n:  8
IntGELU    | n:  25
IntSoftmax | n:  8
IntGELU    | n:  25
.calib done
Test: [  0/391]	Time  3.747 ( 3.747)	Acc@1  16.41 ( 16.41)	Acc@5  39.06 ( 39.06)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 16.406 Prec@5 39.062
Time: 8.70
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=8, intgelu_exp_n=26
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=8, intgelu_exp_n=26, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  8
IntGELU    | n:  26
IntSoftmax | n:  8
IntGELU    | n:  26
IntSoftmax | n:  8
IntGELU    | n:  26
IntSoftmax | n:  8
IntGELU    | n:  26
IntSoftmax | n:  8
IntGELU    | n:  26
IntSoftmax | n:  8
IntGELU    | n:  26
IntSoftmax | n:  8
IntGELU    | n:  26
IntSoftmax | n:  8
IntGELU    | n:  26
IntSoftmax | n:  8
IntGELU    | n:  26
IntSoftmax | n:  8
IntGELU    | n:  26
IntSoftmax | n:  8
IntGELU    | n:  26
IntSoftmax | n:  8
IntGELU    | n:  26
.calib done
Test: [  0/391]	Time  3.867 ( 3.867)	Acc@1  18.75 ( 18.75)	Acc@5  42.97 ( 42.97)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 18.750 Prec@5 42.969
Time: 8.77
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=8, intgelu_exp_n=27
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=8, intgelu_exp_n=27, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  8
IntGELU    | n:  27
IntSoftmax | n:  8
IntGELU    | n:  27
IntSoftmax | n:  8
IntGELU    | n:  27
IntSoftmax | n:  8
IntGELU    | n:  27
IntSoftmax | n:  8
IntGELU    | n:  27
IntSoftmax | n:  8
IntGELU    | n:  27
IntSoftmax | n:  8
IntGELU    | n:  27
IntSoftmax | n:  8
IntGELU    | n:  27
IntSoftmax | n:  8
IntGELU    | n:  27
IntSoftmax | n:  8
IntGELU    | n:  27
IntSoftmax | n:  8
IntGELU    | n:  27
IntSoftmax | n:  8
IntGELU    | n:  27
.calib done
Test: [  0/391]	Time  4.039 ( 4.039)	Acc@1  24.22 ( 24.22)	Acc@5  52.34 ( 52.34)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 24.219 Prec@5 52.344
Time: 9.00
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=8, intgelu_exp_n=28
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=8, intgelu_exp_n=28, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  8
IntGELU    | n:  28
IntSoftmax | n:  8
IntGELU    | n:  28
IntSoftmax | n:  8
IntGELU    | n:  28
IntSoftmax | n:  8
IntGELU    | n:  28
IntSoftmax | n:  8
IntGELU    | n:  28
IntSoftmax | n:  8
IntGELU    | n:  28
IntSoftmax | n:  8
IntGELU    | n:  28
IntSoftmax | n:  8
IntGELU    | n:  28
IntSoftmax | n:  8
IntGELU    | n:  28
IntSoftmax | n:  8
IntGELU    | n:  28
IntSoftmax | n:  8
IntGELU    | n:  28
IntSoftmax | n:  8
IntGELU    | n:  28
.calib done
Test: [  0/391]	Time  3.634 ( 3.634)	Acc@1  24.22 ( 24.22)	Acc@5  51.56 ( 51.56)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 24.219 Prec@5 51.562
Time: 8.63
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=8, intgelu_exp_n=29
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=8, intgelu_exp_n=29, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  8
IntGELU    | n:  29
IntSoftmax | n:  8
IntGELU    | n:  29
IntSoftmax | n:  8
IntGELU    | n:  29
IntSoftmax | n:  8
IntGELU    | n:  29
IntSoftmax | n:  8
IntGELU    | n:  29
IntSoftmax | n:  8
IntGELU    | n:  29
IntSoftmax | n:  8
IntGELU    | n:  29
IntSoftmax | n:  8
IntGELU    | n:  29
IntSoftmax | n:  8
IntGELU    | n:  29
IntSoftmax | n:  8
IntGELU    | n:  29
IntSoftmax | n:  8
IntGELU    | n:  29
IntSoftmax | n:  8
IntGELU    | n:  29
.calib done
Test: [  0/391]	Time  3.774 ( 3.774)	Acc@1  27.34 ( 27.34)	Acc@5  59.38 ( 59.38)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 27.344 Prec@5 59.375
Time: 8.76
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=8, intgelu_exp_n=30
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=8, intgelu_exp_n=30, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  8
IntGELU    | n:  30
IntSoftmax | n:  8
IntGELU    | n:  30
IntSoftmax | n:  8
IntGELU    | n:  30
IntSoftmax | n:  8
IntGELU    | n:  30
IntSoftmax | n:  8
IntGELU    | n:  30
IntSoftmax | n:  8
IntGELU    | n:  30
IntSoftmax | n:  8
IntGELU    | n:  30
IntSoftmax | n:  8
IntGELU    | n:  30
IntSoftmax | n:  8
IntGELU    | n:  30
IntSoftmax | n:  8
IntGELU    | n:  30
IntSoftmax | n:  8
IntGELU    | n:  30
IntSoftmax | n:  8
IntGELU    | n:  30
.calib done
Test: [  0/391]	Time  3.805 ( 3.805)	Acc@1  69.53 ( 69.53)	Acc@5  88.28 ( 88.28)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 69.531 Prec@5 88.281
Time: 8.81
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=8, intgelu_exp_n=31
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=8, intgelu_exp_n=31, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  8
IntGELU    | n:  31
IntSoftmax | n:  8
IntGELU    | n:  31
IntSoftmax | n:  8
IntGELU    | n:  31
IntSoftmax | n:  8
IntGELU    | n:  31
IntSoftmax | n:  8
IntGELU    | n:  31
IntSoftmax | n:  8
IntGELU    | n:  31
IntSoftmax | n:  8
IntGELU    | n:  31
IntSoftmax | n:  8
IntGELU    | n:  31
IntSoftmax | n:  8
IntGELU    | n:  31
IntSoftmax | n:  8
IntGELU    | n:  31
IntSoftmax | n:  8
IntGELU    | n:  31
IntSoftmax | n:  8
IntGELU    | n:  31
.calib done
Test: [  0/391]	Time  3.846 ( 3.846)	Acc@1   5.47 (  5.47)	Acc@5  14.06 ( 14.06)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 5.469 Prec@5 14.062
Time: 8.72
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=9, intgelu_exp_n=0
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=9, intgelu_exp_n=0, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  9
IntGELU    | n:  0
IntSoftmax | n:  9
IntGELU    | n:  0
IntSoftmax | n:  9
IntGELU    | n:  0
IntSoftmax | n:  9
IntGELU    | n:  0
IntSoftmax | n:  9
IntGELU    | n:  0
IntSoftmax | n:  9
IntGELU    | n:  0
IntSoftmax | n:  9
IntGELU    | n:  0
IntSoftmax | n:  9
IntGELU    | n:  0
IntSoftmax | n:  9
IntGELU    | n:  0
IntSoftmax | n:  9
IntGELU    | n:  0
IntSoftmax | n:  9
IntGELU    | n:  0
IntSoftmax | n:  9
IntGELU    | n:  0
.calib done
Test: [  0/391]	Time  3.911 ( 3.911)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.87
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=9, intgelu_exp_n=1
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=9, intgelu_exp_n=1, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  9
IntGELU    | n:  1
IntSoftmax | n:  9
IntGELU    | n:  1
IntSoftmax | n:  9
IntGELU    | n:  1
IntSoftmax | n:  9
IntGELU    | n:  1
IntSoftmax | n:  9
IntGELU    | n:  1
IntSoftmax | n:  9
IntGELU    | n:  1
IntSoftmax | n:  9
IntGELU    | n:  1
IntSoftmax | n:  9
IntGELU    | n:  1
IntSoftmax | n:  9
IntGELU    | n:  1
IntSoftmax | n:  9
IntGELU    | n:  1
IntSoftmax | n:  9
IntGELU    | n:  1
IntSoftmax | n:  9
IntGELU    | n:  1
.calib done
Test: [  0/391]	Time  3.951 ( 3.951)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.90
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=9, intgelu_exp_n=2
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=9, intgelu_exp_n=2, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  9
IntGELU    | n:  2
IntSoftmax | n:  9
IntGELU    | n:  2
IntSoftmax | n:  9
IntGELU    | n:  2
IntSoftmax | n:  9
IntGELU    | n:  2
IntSoftmax | n:  9
IntGELU    | n:  2
IntSoftmax | n:  9
IntGELU    | n:  2
IntSoftmax | n:  9
IntGELU    | n:  2
IntSoftmax | n:  9
IntGELU    | n:  2
IntSoftmax | n:  9
IntGELU    | n:  2
IntSoftmax | n:  9
IntGELU    | n:  2
IntSoftmax | n:  9
IntGELU    | n:  2
IntSoftmax | n:  9
IntGELU    | n:  2
.calib done
Test: [  0/391]	Time  3.728 ( 3.728)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.69
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=9, intgelu_exp_n=3
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=9, intgelu_exp_n=3, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  9
IntGELU    | n:  3
IntSoftmax | n:  9
IntGELU    | n:  3
IntSoftmax | n:  9
IntGELU    | n:  3
IntSoftmax | n:  9
IntGELU    | n:  3
IntSoftmax | n:  9
IntGELU    | n:  3
IntSoftmax | n:  9
IntGELU    | n:  3
IntSoftmax | n:  9
IntGELU    | n:  3
IntSoftmax | n:  9
IntGELU    | n:  3
IntSoftmax | n:  9
IntGELU    | n:  3
IntSoftmax | n:  9
IntGELU    | n:  3
IntSoftmax | n:  9
IntGELU    | n:  3
IntSoftmax | n:  9
IntGELU    | n:  3
.calib done
Test: [  0/391]	Time  3.736 ( 3.736)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.72
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=9, intgelu_exp_n=4
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=9, intgelu_exp_n=4, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  9
IntGELU    | n:  4
IntSoftmax | n:  9
IntGELU    | n:  4
IntSoftmax | n:  9
IntGELU    | n:  4
IntSoftmax | n:  9
IntGELU    | n:  4
IntSoftmax | n:  9
IntGELU    | n:  4
IntSoftmax | n:  9
IntGELU    | n:  4
IntSoftmax | n:  9
IntGELU    | n:  4
IntSoftmax | n:  9
IntGELU    | n:  4
IntSoftmax | n:  9
IntGELU    | n:  4
IntSoftmax | n:  9
IntGELU    | n:  4
IntSoftmax | n:  9
IntGELU    | n:  4
IntSoftmax | n:  9
IntGELU    | n:  4
.calib done
Test: [  0/391]	Time  3.811 ( 3.811)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.77
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=9, intgelu_exp_n=5
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=9, intgelu_exp_n=5, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  9
IntGELU    | n:  5
IntSoftmax | n:  9
IntGELU    | n:  5
IntSoftmax | n:  9
IntGELU    | n:  5
IntSoftmax | n:  9
IntGELU    | n:  5
IntSoftmax | n:  9
IntGELU    | n:  5
IntSoftmax | n:  9
IntGELU    | n:  5
IntSoftmax | n:  9
IntGELU    | n:  5
IntSoftmax | n:  9
IntGELU    | n:  5
IntSoftmax | n:  9
IntGELU    | n:  5
IntSoftmax | n:  9
IntGELU    | n:  5
IntSoftmax | n:  9
IntGELU    | n:  5
IntSoftmax | n:  9
IntGELU    | n:  5
.calib done
Test: [  0/391]	Time  3.745 ( 3.745)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.68
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=9, intgelu_exp_n=6
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=9, intgelu_exp_n=6, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  9
IntGELU    | n:  6
IntSoftmax | n:  9
IntGELU    | n:  6
IntSoftmax | n:  9
IntGELU    | n:  6
IntSoftmax | n:  9
IntGELU    | n:  6
IntSoftmax | n:  9
IntGELU    | n:  6
IntSoftmax | n:  9
IntGELU    | n:  6
IntSoftmax | n:  9
IntGELU    | n:  6
IntSoftmax | n:  9
IntGELU    | n:  6
IntSoftmax | n:  9
IntGELU    | n:  6
IntSoftmax | n:  9
IntGELU    | n:  6
IntSoftmax | n:  9
IntGELU    | n:  6
IntSoftmax | n:  9
IntGELU    | n:  6
.calib done
Test: [  0/391]	Time  3.961 ( 3.961)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.91
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=9, intgelu_exp_n=7
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=9, intgelu_exp_n=7, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  9
IntGELU    | n:  7
IntSoftmax | n:  9
IntGELU    | n:  7
IntSoftmax | n:  9
IntGELU    | n:  7
IntSoftmax | n:  9
IntGELU    | n:  7
IntSoftmax | n:  9
IntGELU    | n:  7
IntSoftmax | n:  9
IntGELU    | n:  7
IntSoftmax | n:  9
IntGELU    | n:  7
IntSoftmax | n:  9
IntGELU    | n:  7
IntSoftmax | n:  9
IntGELU    | n:  7
IntSoftmax | n:  9
IntGELU    | n:  7
IntSoftmax | n:  9
IntGELU    | n:  7
IntSoftmax | n:  9
IntGELU    | n:  7
.calib done
Test: [  0/391]	Time  3.947 ( 3.947)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.84
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=9, intgelu_exp_n=8
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=9, intgelu_exp_n=8, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  9
IntGELU    | n:  8
IntSoftmax | n:  9
IntGELU    | n:  8
IntSoftmax | n:  9
IntGELU    | n:  8
IntSoftmax | n:  9
IntGELU    | n:  8
IntSoftmax | n:  9
IntGELU    | n:  8
IntSoftmax | n:  9
IntGELU    | n:  8
IntSoftmax | n:  9
IntGELU    | n:  8
IntSoftmax | n:  9
IntGELU    | n:  8
IntSoftmax | n:  9
IntGELU    | n:  8
IntSoftmax | n:  9
IntGELU    | n:  8
IntSoftmax | n:  9
IntGELU    | n:  8
IntSoftmax | n:  9
IntGELU    | n:  8
.calib done
Test: [  0/391]	Time  3.959 ( 3.959)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.83
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=9, intgelu_exp_n=9
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=9, intgelu_exp_n=9, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  9
IntGELU    | n:  9
IntSoftmax | n:  9
IntGELU    | n:  9
IntSoftmax | n:  9
IntGELU    | n:  9
IntSoftmax | n:  9
IntGELU    | n:  9
IntSoftmax | n:  9
IntGELU    | n:  9
IntSoftmax | n:  9
IntGELU    | n:  9
IntSoftmax | n:  9
IntGELU    | n:  9
IntSoftmax | n:  9
IntGELU    | n:  9
IntSoftmax | n:  9
IntGELU    | n:  9
IntSoftmax | n:  9
IntGELU    | n:  9
IntSoftmax | n:  9
IntGELU    | n:  9
IntSoftmax | n:  9
IntGELU    | n:  9
.calib done
Test: [  0/391]	Time  3.886 ( 3.886)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.87
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=9, intgelu_exp_n=10
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=9, intgelu_exp_n=10, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  9
IntGELU    | n:  10
IntSoftmax | n:  9
IntGELU    | n:  10
IntSoftmax | n:  9
IntGELU    | n:  10
IntSoftmax | n:  9
IntGELU    | n:  10
IntSoftmax | n:  9
IntGELU    | n:  10
IntSoftmax | n:  9
IntGELU    | n:  10
IntSoftmax | n:  9
IntGELU    | n:  10
IntSoftmax | n:  9
IntGELU    | n:  10
IntSoftmax | n:  9
IntGELU    | n:  10
IntSoftmax | n:  9
IntGELU    | n:  10
IntSoftmax | n:  9
IntGELU    | n:  10
IntSoftmax | n:  9
IntGELU    | n:  10
.calib done
Test: [  0/391]	Time  3.948 ( 3.948)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.87
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=9, intgelu_exp_n=11
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=9, intgelu_exp_n=11, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  9
IntGELU    | n:  11
IntSoftmax | n:  9
IntGELU    | n:  11
IntSoftmax | n:  9
IntGELU    | n:  11
IntSoftmax | n:  9
IntGELU    | n:  11
IntSoftmax | n:  9
IntGELU    | n:  11
IntSoftmax | n:  9
IntGELU    | n:  11
IntSoftmax | n:  9
IntGELU    | n:  11
IntSoftmax | n:  9
IntGELU    | n:  11
IntSoftmax | n:  9
IntGELU    | n:  11
IntSoftmax | n:  9
IntGELU    | n:  11
IntSoftmax | n:  9
IntGELU    | n:  11
IntSoftmax | n:  9
IntGELU    | n:  11
.calib done
Test: [  0/391]	Time  3.877 ( 3.877)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.79
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=9, intgelu_exp_n=12
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=9, intgelu_exp_n=12, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  9
IntGELU    | n:  12
IntSoftmax | n:  9
IntGELU    | n:  12
IntSoftmax | n:  9
IntGELU    | n:  12
IntSoftmax | n:  9
IntGELU    | n:  12
IntSoftmax | n:  9
IntGELU    | n:  12
IntSoftmax | n:  9
IntGELU    | n:  12
IntSoftmax | n:  9
IntGELU    | n:  12
IntSoftmax | n:  9
IntGELU    | n:  12
IntSoftmax | n:  9
IntGELU    | n:  12
IntSoftmax | n:  9
IntGELU    | n:  12
IntSoftmax | n:  9
IntGELU    | n:  12
IntSoftmax | n:  9
IntGELU    | n:  12
.calib done
Test: [  0/391]	Time  3.954 ( 3.954)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.92
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=9, intgelu_exp_n=13
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=9, intgelu_exp_n=13, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  9
IntGELU    | n:  13
IntSoftmax | n:  9
IntGELU    | n:  13
IntSoftmax | n:  9
IntGELU    | n:  13
IntSoftmax | n:  9
IntGELU    | n:  13
IntSoftmax | n:  9
IntGELU    | n:  13
IntSoftmax | n:  9
IntGELU    | n:  13
IntSoftmax | n:  9
IntGELU    | n:  13
IntSoftmax | n:  9
IntGELU    | n:  13
IntSoftmax | n:  9
IntGELU    | n:  13
IntSoftmax | n:  9
IntGELU    | n:  13
IntSoftmax | n:  9
IntGELU    | n:  13
IntSoftmax | n:  9
IntGELU    | n:  13
.calib done
Test: [  0/391]	Time  3.653 ( 3.653)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.58
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=9, intgelu_exp_n=14
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=9, intgelu_exp_n=14, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  9
IntGELU    | n:  14
IntSoftmax | n:  9
IntGELU    | n:  14
IntSoftmax | n:  9
IntGELU    | n:  14
IntSoftmax | n:  9
IntGELU    | n:  14
IntSoftmax | n:  9
IntGELU    | n:  14
IntSoftmax | n:  9
IntGELU    | n:  14
IntSoftmax | n:  9
IntGELU    | n:  14
IntSoftmax | n:  9
IntGELU    | n:  14
IntSoftmax | n:  9
IntGELU    | n:  14
IntSoftmax | n:  9
IntGELU    | n:  14
IntSoftmax | n:  9
IntGELU    | n:  14
IntSoftmax | n:  9
IntGELU    | n:  14
.calib done
Test: [  0/391]	Time  3.929 ( 3.929)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.85
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=9, intgelu_exp_n=15
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=9, intgelu_exp_n=15, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  9
IntGELU    | n:  15
IntSoftmax | n:  9
IntGELU    | n:  15
IntSoftmax | n:  9
IntGELU    | n:  15
IntSoftmax | n:  9
IntGELU    | n:  15
IntSoftmax | n:  9
IntGELU    | n:  15
IntSoftmax | n:  9
IntGELU    | n:  15
IntSoftmax | n:  9
IntGELU    | n:  15
IntSoftmax | n:  9
IntGELU    | n:  15
IntSoftmax | n:  9
IntGELU    | n:  15
IntSoftmax | n:  9
IntGELU    | n:  15
IntSoftmax | n:  9
IntGELU    | n:  15
IntSoftmax | n:  9
IntGELU    | n:  15
.calib done
Test: [  0/391]	Time  3.986 ( 3.986)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.89
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=9, intgelu_exp_n=16
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=9, intgelu_exp_n=16, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  9
IntGELU    | n:  16
IntSoftmax | n:  9
IntGELU    | n:  16
IntSoftmax | n:  9
IntGELU    | n:  16
IntSoftmax | n:  9
IntGELU    | n:  16
IntSoftmax | n:  9
IntGELU    | n:  16
IntSoftmax | n:  9
IntGELU    | n:  16
IntSoftmax | n:  9
IntGELU    | n:  16
IntSoftmax | n:  9
IntGELU    | n:  16
IntSoftmax | n:  9
IntGELU    | n:  16
IntSoftmax | n:  9
IntGELU    | n:  16
IntSoftmax | n:  9
IntGELU    | n:  16
IntSoftmax | n:  9
IntGELU    | n:  16
.calib done
Test: [  0/391]	Time  3.827 ( 3.827)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.81
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=9, intgelu_exp_n=17
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=9, intgelu_exp_n=17, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  9
IntGELU    | n:  17
IntSoftmax | n:  9
IntGELU    | n:  17
IntSoftmax | n:  9
IntGELU    | n:  17
IntSoftmax | n:  9
IntGELU    | n:  17
IntSoftmax | n:  9
IntGELU    | n:  17
IntSoftmax | n:  9
IntGELU    | n:  17
IntSoftmax | n:  9
IntGELU    | n:  17
IntSoftmax | n:  9
IntGELU    | n:  17
IntSoftmax | n:  9
IntGELU    | n:  17
IntSoftmax | n:  9
IntGELU    | n:  17
IntSoftmax | n:  9
IntGELU    | n:  17
IntSoftmax | n:  9
IntGELU    | n:  17
.calib done
Test: [  0/391]	Time  3.937 ( 3.937)	Acc@1   0.00 (  0.00)	Acc@5   0.78 (  0.78)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.781
Time: 8.89
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=9, intgelu_exp_n=18
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=9, intgelu_exp_n=18, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  9
IntGELU    | n:  18
IntSoftmax | n:  9
IntGELU    | n:  18
IntSoftmax | n:  9
IntGELU    | n:  18
IntSoftmax | n:  9
IntGELU    | n:  18
IntSoftmax | n:  9
IntGELU    | n:  18
IntSoftmax | n:  9
IntGELU    | n:  18
IntSoftmax | n:  9
IntGELU    | n:  18
IntSoftmax | n:  9
IntGELU    | n:  18
IntSoftmax | n:  9
IntGELU    | n:  18
IntSoftmax | n:  9
IntGELU    | n:  18
IntSoftmax | n:  9
IntGELU    | n:  18
IntSoftmax | n:  9
IntGELU    | n:  18
.calib done
Test: [  0/391]	Time  3.804 ( 3.804)	Acc@1   0.78 (  0.78)	Acc@5   3.12 (  3.12)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.781 Prec@5 3.125
Time: 8.71
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=9, intgelu_exp_n=19
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=9, intgelu_exp_n=19, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  9
IntGELU    | n:  19
IntSoftmax | n:  9
IntGELU    | n:  19
IntSoftmax | n:  9
IntGELU    | n:  19
IntSoftmax | n:  9
IntGELU    | n:  19
IntSoftmax | n:  9
IntGELU    | n:  19
IntSoftmax | n:  9
IntGELU    | n:  19
IntSoftmax | n:  9
IntGELU    | n:  19
IntSoftmax | n:  9
IntGELU    | n:  19
IntSoftmax | n:  9
IntGELU    | n:  19
IntSoftmax | n:  9
IntGELU    | n:  19
IntSoftmax | n:  9
IntGELU    | n:  19
IntSoftmax | n:  9
IntGELU    | n:  19
.calib done
Test: [  0/391]	Time  3.882 ( 3.882)	Acc@1   1.56 (  1.56)	Acc@5   9.38 (  9.38)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 1.562 Prec@5 9.375
Time: 8.86
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=9, intgelu_exp_n=20
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=9, intgelu_exp_n=20, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  9
IntGELU    | n:  20
IntSoftmax | n:  9
IntGELU    | n:  20
IntSoftmax | n:  9
IntGELU    | n:  20
IntSoftmax | n:  9
IntGELU    | n:  20
IntSoftmax | n:  9
IntGELU    | n:  20
IntSoftmax | n:  9
IntGELU    | n:  20
IntSoftmax | n:  9
IntGELU    | n:  20
IntSoftmax | n:  9
IntGELU    | n:  20
IntSoftmax | n:  9
IntGELU    | n:  20
IntSoftmax | n:  9
IntGELU    | n:  20
IntSoftmax | n:  9
IntGELU    | n:  20
IntSoftmax | n:  9
IntGELU    | n:  20
.calib done
Test: [  0/391]	Time  3.955 ( 3.955)	Acc@1   7.03 (  7.03)	Acc@5  16.41 ( 16.41)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 7.031 Prec@5 16.406
Time: 8.97
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=9, intgelu_exp_n=21
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=9, intgelu_exp_n=21, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  9
IntGELU    | n:  21
IntSoftmax | n:  9
IntGELU    | n:  21
IntSoftmax | n:  9
IntGELU    | n:  21
IntSoftmax | n:  9
IntGELU    | n:  21
IntSoftmax | n:  9
IntGELU    | n:  21
IntSoftmax | n:  9
IntGELU    | n:  21
IntSoftmax | n:  9
IntGELU    | n:  21
IntSoftmax | n:  9
IntGELU    | n:  21
IntSoftmax | n:  9
IntGELU    | n:  21
IntSoftmax | n:  9
IntGELU    | n:  21
IntSoftmax | n:  9
IntGELU    | n:  21
IntSoftmax | n:  9
IntGELU    | n:  21
.calib done
Test: [  0/391]	Time  4.020 ( 4.020)	Acc@1   9.38 (  9.38)	Acc@5  17.97 ( 17.97)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 9.375 Prec@5 17.969
Time: 8.92
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=9, intgelu_exp_n=22
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=9, intgelu_exp_n=22, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  9
IntGELU    | n:  22
IntSoftmax | n:  9
IntGELU    | n:  22
IntSoftmax | n:  9
IntGELU    | n:  22
IntSoftmax | n:  9
IntGELU    | n:  22
IntSoftmax | n:  9
IntGELU    | n:  22
IntSoftmax | n:  9
IntGELU    | n:  22
IntSoftmax | n:  9
IntGELU    | n:  22
IntSoftmax | n:  9
IntGELU    | n:  22
IntSoftmax | n:  9
IntGELU    | n:  22
IntSoftmax | n:  9
IntGELU    | n:  22
IntSoftmax | n:  9
IntGELU    | n:  22
IntSoftmax | n:  9
IntGELU    | n:  22
.calib done
Test: [  0/391]	Time  3.856 ( 3.856)	Acc@1   9.38 (  9.38)	Acc@5  21.88 ( 21.88)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 9.375 Prec@5 21.875
Time: 8.76
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=9, intgelu_exp_n=23
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=9, intgelu_exp_n=23, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  9
IntGELU    | n:  23
IntSoftmax | n:  9
IntGELU    | n:  23
IntSoftmax | n:  9
IntGELU    | n:  23
IntSoftmax | n:  9
IntGELU    | n:  23
IntSoftmax | n:  9
IntGELU    | n:  23
IntSoftmax | n:  9
IntGELU    | n:  23
IntSoftmax | n:  9
IntGELU    | n:  23
IntSoftmax | n:  9
IntGELU    | n:  23
IntSoftmax | n:  9
IntGELU    | n:  23
IntSoftmax | n:  9
IntGELU    | n:  23
IntSoftmax | n:  9
IntGELU    | n:  23
IntSoftmax | n:  9
IntGELU    | n:  23
.calib done
Test: [  0/391]	Time  3.969 ( 3.969)	Acc@1  10.94 ( 10.94)	Acc@5  26.56 ( 26.56)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 10.938 Prec@5 26.562
Time: 8.89
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=9, intgelu_exp_n=24
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=9, intgelu_exp_n=24, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  9
IntGELU    | n:  24
IntSoftmax | n:  9
IntGELU    | n:  24
IntSoftmax | n:  9
IntGELU    | n:  24
IntSoftmax | n:  9
IntGELU    | n:  24
IntSoftmax | n:  9
IntGELU    | n:  24
IntSoftmax | n:  9
IntGELU    | n:  24
IntSoftmax | n:  9
IntGELU    | n:  24
IntSoftmax | n:  9
IntGELU    | n:  24
IntSoftmax | n:  9
IntGELU    | n:  24
IntSoftmax | n:  9
IntGELU    | n:  24
IntSoftmax | n:  9
IntGELU    | n:  24
IntSoftmax | n:  9
IntGELU    | n:  24
.calib done
Test: [  0/391]	Time  3.907 ( 3.907)	Acc@1  15.62 ( 15.62)	Acc@5  35.16 ( 35.16)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 15.625 Prec@5 35.156
Time: 8.86
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=9, intgelu_exp_n=25
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=9, intgelu_exp_n=25, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  9
IntGELU    | n:  25
IntSoftmax | n:  9
IntGELU    | n:  25
IntSoftmax | n:  9
IntGELU    | n:  25
IntSoftmax | n:  9
IntGELU    | n:  25
IntSoftmax | n:  9
IntGELU    | n:  25
IntSoftmax | n:  9
IntGELU    | n:  25
IntSoftmax | n:  9
IntGELU    | n:  25
IntSoftmax | n:  9
IntGELU    | n:  25
IntSoftmax | n:  9
IntGELU    | n:  25
IntSoftmax | n:  9
IntGELU    | n:  25
IntSoftmax | n:  9
IntGELU    | n:  25
IntSoftmax | n:  9
IntGELU    | n:  25
.calib done
Test: [  0/391]	Time  3.960 ( 3.960)	Acc@1  20.31 ( 20.31)	Acc@5  39.84 ( 39.84)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 20.312 Prec@5 39.844
Time: 8.92
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=9, intgelu_exp_n=26
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=9, intgelu_exp_n=26, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  9
IntGELU    | n:  26
IntSoftmax | n:  9
IntGELU    | n:  26
IntSoftmax | n:  9
IntGELU    | n:  26
IntSoftmax | n:  9
IntGELU    | n:  26
IntSoftmax | n:  9
IntGELU    | n:  26
IntSoftmax | n:  9
IntGELU    | n:  26
IntSoftmax | n:  9
IntGELU    | n:  26
IntSoftmax | n:  9
IntGELU    | n:  26
IntSoftmax | n:  9
IntGELU    | n:  26
IntSoftmax | n:  9
IntGELU    | n:  26
IntSoftmax | n:  9
IntGELU    | n:  26
IntSoftmax | n:  9
IntGELU    | n:  26
.calib done
Test: [  0/391]	Time  3.909 ( 3.909)	Acc@1  21.09 ( 21.09)	Acc@5  46.09 ( 46.09)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 21.094 Prec@5 46.094
Time: 8.85
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=9, intgelu_exp_n=27
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=9, intgelu_exp_n=27, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  9
IntGELU    | n:  27
IntSoftmax | n:  9
IntGELU    | n:  27
IntSoftmax | n:  9
IntGELU    | n:  27
IntSoftmax | n:  9
IntGELU    | n:  27
IntSoftmax | n:  9
IntGELU    | n:  27
IntSoftmax | n:  9
IntGELU    | n:  27
IntSoftmax | n:  9
IntGELU    | n:  27
IntSoftmax | n:  9
IntGELU    | n:  27
IntSoftmax | n:  9
IntGELU    | n:  27
IntSoftmax | n:  9
IntGELU    | n:  27
IntSoftmax | n:  9
IntGELU    | n:  27
IntSoftmax | n:  9
IntGELU    | n:  27
.calib done
Test: [  0/391]	Time  4.068 ( 4.068)	Acc@1  22.66 ( 22.66)	Acc@5  48.44 ( 48.44)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 22.656 Prec@5 48.438
Time: 9.01
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=9, intgelu_exp_n=28
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=9, intgelu_exp_n=28, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  9
IntGELU    | n:  28
IntSoftmax | n:  9
IntGELU    | n:  28
IntSoftmax | n:  9
IntGELU    | n:  28
IntSoftmax | n:  9
IntGELU    | n:  28
IntSoftmax | n:  9
IntGELU    | n:  28
IntSoftmax | n:  9
IntGELU    | n:  28
IntSoftmax | n:  9
IntGELU    | n:  28
IntSoftmax | n:  9
IntGELU    | n:  28
IntSoftmax | n:  9
IntGELU    | n:  28
IntSoftmax | n:  9
IntGELU    | n:  28
IntSoftmax | n:  9
IntGELU    | n:  28
IntSoftmax | n:  9
IntGELU    | n:  28
.calib done
Test: [  0/391]	Time  3.993 ( 3.993)	Acc@1  26.56 ( 26.56)	Acc@5  52.34 ( 52.34)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 26.562 Prec@5 52.344
Time: 8.91
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=9, intgelu_exp_n=29
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=9, intgelu_exp_n=29, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  9
IntGELU    | n:  29
IntSoftmax | n:  9
IntGELU    | n:  29
IntSoftmax | n:  9
IntGELU    | n:  29
IntSoftmax | n:  9
IntGELU    | n:  29
IntSoftmax | n:  9
IntGELU    | n:  29
IntSoftmax | n:  9
IntGELU    | n:  29
IntSoftmax | n:  9
IntGELU    | n:  29
IntSoftmax | n:  9
IntGELU    | n:  29
IntSoftmax | n:  9
IntGELU    | n:  29
IntSoftmax | n:  9
IntGELU    | n:  29
IntSoftmax | n:  9
IntGELU    | n:  29
IntSoftmax | n:  9
IntGELU    | n:  29
.calib done
Test: [  0/391]	Time  3.915 ( 3.915)	Acc@1  33.59 ( 33.59)	Acc@5  60.16 ( 60.16)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 33.594 Prec@5 60.156
Time: 8.90
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=9, intgelu_exp_n=30
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=9, intgelu_exp_n=30, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  9
IntGELU    | n:  30
IntSoftmax | n:  9
IntGELU    | n:  30
IntSoftmax | n:  9
IntGELU    | n:  30
IntSoftmax | n:  9
IntGELU    | n:  30
IntSoftmax | n:  9
IntGELU    | n:  30
IntSoftmax | n:  9
IntGELU    | n:  30
IntSoftmax | n:  9
IntGELU    | n:  30
IntSoftmax | n:  9
IntGELU    | n:  30
IntSoftmax | n:  9
IntGELU    | n:  30
IntSoftmax | n:  9
IntGELU    | n:  30
IntSoftmax | n:  9
IntGELU    | n:  30
IntSoftmax | n:  9
IntGELU    | n:  30
.calib done
Test: [  0/391]	Time  3.995 ( 3.995)	Acc@1  61.72 ( 61.72)	Acc@5  79.69 ( 79.69)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 61.719 Prec@5 79.688
Time: 8.95
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=9, intgelu_exp_n=31
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=9, intgelu_exp_n=31, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  9
IntGELU    | n:  31
IntSoftmax | n:  9
IntGELU    | n:  31
IntSoftmax | n:  9
IntGELU    | n:  31
IntSoftmax | n:  9
IntGELU    | n:  31
IntSoftmax | n:  9
IntGELU    | n:  31
IntSoftmax | n:  9
IntGELU    | n:  31
IntSoftmax | n:  9
IntGELU    | n:  31
IntSoftmax | n:  9
IntGELU    | n:  31
IntSoftmax | n:  9
IntGELU    | n:  31
IntSoftmax | n:  9
IntGELU    | n:  31
IntSoftmax | n:  9
IntGELU    | n:  31
IntSoftmax | n:  9
IntGELU    | n:  31
.calib done
Test: [  0/391]	Time  3.968 ( 3.968)	Acc@1   7.03 (  7.03)	Acc@5  15.62 ( 15.62)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 7.031 Prec@5 15.625
Time: 8.90
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=10, intgelu_exp_n=0
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=10, intgelu_exp_n=0, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  10
IntGELU    | n:  0
IntSoftmax | n:  10
IntGELU    | n:  0
IntSoftmax | n:  10
IntGELU    | n:  0
IntSoftmax | n:  10
IntGELU    | n:  0
IntSoftmax | n:  10
IntGELU    | n:  0
IntSoftmax | n:  10
IntGELU    | n:  0
IntSoftmax | n:  10
IntGELU    | n:  0
IntSoftmax | n:  10
IntGELU    | n:  0
IntSoftmax | n:  10
IntGELU    | n:  0
IntSoftmax | n:  10
IntGELU    | n:  0
IntSoftmax | n:  10
IntGELU    | n:  0
IntSoftmax | n:  10
IntGELU    | n:  0
.calib done
Test: [  0/391]	Time  3.838 ( 3.838)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.75
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=10, intgelu_exp_n=1
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=10, intgelu_exp_n=1, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  10
IntGELU    | n:  1
IntSoftmax | n:  10
IntGELU    | n:  1
IntSoftmax | n:  10
IntGELU    | n:  1
IntSoftmax | n:  10
IntGELU    | n:  1
IntSoftmax | n:  10
IntGELU    | n:  1
IntSoftmax | n:  10
IntGELU    | n:  1
IntSoftmax | n:  10
IntGELU    | n:  1
IntSoftmax | n:  10
IntGELU    | n:  1
IntSoftmax | n:  10
IntGELU    | n:  1
IntSoftmax | n:  10
IntGELU    | n:  1
IntSoftmax | n:  10
IntGELU    | n:  1
IntSoftmax | n:  10
IntGELU    | n:  1
.calib done
Test: [  0/391]	Time  4.046 ( 4.046)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.96
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=10, intgelu_exp_n=2
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=10, intgelu_exp_n=2, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  10
IntGELU    | n:  2
IntSoftmax | n:  10
IntGELU    | n:  2
IntSoftmax | n:  10
IntGELU    | n:  2
IntSoftmax | n:  10
IntGELU    | n:  2
IntSoftmax | n:  10
IntGELU    | n:  2
IntSoftmax | n:  10
IntGELU    | n:  2
IntSoftmax | n:  10
IntGELU    | n:  2
IntSoftmax | n:  10
IntGELU    | n:  2
IntSoftmax | n:  10
IntGELU    | n:  2
IntSoftmax | n:  10
IntGELU    | n:  2
IntSoftmax | n:  10
IntGELU    | n:  2
IntSoftmax | n:  10
IntGELU    | n:  2
.calib done
Test: [  0/391]	Time  3.832 ( 3.832)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.75
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=10, intgelu_exp_n=3
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=10, intgelu_exp_n=3, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  10
IntGELU    | n:  3
IntSoftmax | n:  10
IntGELU    | n:  3
IntSoftmax | n:  10
IntGELU    | n:  3
IntSoftmax | n:  10
IntGELU    | n:  3
IntSoftmax | n:  10
IntGELU    | n:  3
IntSoftmax | n:  10
IntGELU    | n:  3
IntSoftmax | n:  10
IntGELU    | n:  3
IntSoftmax | n:  10
IntGELU    | n:  3
IntSoftmax | n:  10
IntGELU    | n:  3
IntSoftmax | n:  10
IntGELU    | n:  3
IntSoftmax | n:  10
IntGELU    | n:  3
IntSoftmax | n:  10
IntGELU    | n:  3
.calib done
Test: [  0/391]	Time  3.888 ( 3.888)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.78
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=10, intgelu_exp_n=4
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=10, intgelu_exp_n=4, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  10
IntGELU    | n:  4
IntSoftmax | n:  10
IntGELU    | n:  4
IntSoftmax | n:  10
IntGELU    | n:  4
IntSoftmax | n:  10
IntGELU    | n:  4
IntSoftmax | n:  10
IntGELU    | n:  4
IntSoftmax | n:  10
IntGELU    | n:  4
IntSoftmax | n:  10
IntGELU    | n:  4
IntSoftmax | n:  10
IntGELU    | n:  4
IntSoftmax | n:  10
IntGELU    | n:  4
IntSoftmax | n:  10
IntGELU    | n:  4
IntSoftmax | n:  10
IntGELU    | n:  4
IntSoftmax | n:  10
IntGELU    | n:  4
.calib done
Test: [  0/391]	Time  3.858 ( 3.858)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.78
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=10, intgelu_exp_n=5
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=10, intgelu_exp_n=5, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  10
IntGELU    | n:  5
IntSoftmax | n:  10
IntGELU    | n:  5
IntSoftmax | n:  10
IntGELU    | n:  5
IntSoftmax | n:  10
IntGELU    | n:  5
IntSoftmax | n:  10
IntGELU    | n:  5
IntSoftmax | n:  10
IntGELU    | n:  5
IntSoftmax | n:  10
IntGELU    | n:  5
IntSoftmax | n:  10
IntGELU    | n:  5
IntSoftmax | n:  10
IntGELU    | n:  5
IntSoftmax | n:  10
IntGELU    | n:  5
IntSoftmax | n:  10
IntGELU    | n:  5
IntSoftmax | n:  10
IntGELU    | n:  5
.calib done
Test: [  0/391]	Time  3.697 ( 3.697)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.66
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=10, intgelu_exp_n=6
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=10, intgelu_exp_n=6, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  10
IntGELU    | n:  6
IntSoftmax | n:  10
IntGELU    | n:  6
IntSoftmax | n:  10
IntGELU    | n:  6
IntSoftmax | n:  10
IntGELU    | n:  6
IntSoftmax | n:  10
IntGELU    | n:  6
IntSoftmax | n:  10
IntGELU    | n:  6
IntSoftmax | n:  10
IntGELU    | n:  6
IntSoftmax | n:  10
IntGELU    | n:  6
IntSoftmax | n:  10
IntGELU    | n:  6
IntSoftmax | n:  10
IntGELU    | n:  6
IntSoftmax | n:  10
IntGELU    | n:  6
IntSoftmax | n:  10
IntGELU    | n:  6
.calib done
Test: [  0/391]	Time  3.781 ( 3.781)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.62
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=10, intgelu_exp_n=7
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=10, intgelu_exp_n=7, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  10
IntGELU    | n:  7
IntSoftmax | n:  10
IntGELU    | n:  7
IntSoftmax | n:  10
IntGELU    | n:  7
IntSoftmax | n:  10
IntGELU    | n:  7
IntSoftmax | n:  10
IntGELU    | n:  7
IntSoftmax | n:  10
IntGELU    | n:  7
IntSoftmax | n:  10
IntGELU    | n:  7
IntSoftmax | n:  10
IntGELU    | n:  7
IntSoftmax | n:  10
IntGELU    | n:  7
IntSoftmax | n:  10
IntGELU    | n:  7
IntSoftmax | n:  10
IntGELU    | n:  7
IntSoftmax | n:  10
IntGELU    | n:  7
.calib done
Test: [  0/391]	Time  3.888 ( 3.888)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.81
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=10, intgelu_exp_n=8
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=10, intgelu_exp_n=8, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  10
IntGELU    | n:  8
IntSoftmax | n:  10
IntGELU    | n:  8
IntSoftmax | n:  10
IntGELU    | n:  8
IntSoftmax | n:  10
IntGELU    | n:  8
IntSoftmax | n:  10
IntGELU    | n:  8
IntSoftmax | n:  10
IntGELU    | n:  8
IntSoftmax | n:  10
IntGELU    | n:  8
IntSoftmax | n:  10
IntGELU    | n:  8
IntSoftmax | n:  10
IntGELU    | n:  8
IntSoftmax | n:  10
IntGELU    | n:  8
IntSoftmax | n:  10
IntGELU    | n:  8
IntSoftmax | n:  10
IntGELU    | n:  8
.calib done
Test: [  0/391]	Time  3.887 ( 3.887)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.75
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=10, intgelu_exp_n=9
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=10, intgelu_exp_n=9, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  10
IntGELU    | n:  9
IntSoftmax | n:  10
IntGELU    | n:  9
IntSoftmax | n:  10
IntGELU    | n:  9
IntSoftmax | n:  10
IntGELU    | n:  9
IntSoftmax | n:  10
IntGELU    | n:  9
IntSoftmax | n:  10
IntGELU    | n:  9
IntSoftmax | n:  10
IntGELU    | n:  9
IntSoftmax | n:  10
IntGELU    | n:  9
IntSoftmax | n:  10
IntGELU    | n:  9
IntSoftmax | n:  10
IntGELU    | n:  9
IntSoftmax | n:  10
IntGELU    | n:  9
IntSoftmax | n:  10
IntGELU    | n:  9
.calib done
Test: [  0/391]	Time  3.919 ( 3.919)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.83
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=10, intgelu_exp_n=10
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=10, intgelu_exp_n=10, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  10
IntGELU    | n:  10
IntSoftmax | n:  10
IntGELU    | n:  10
IntSoftmax | n:  10
IntGELU    | n:  10
IntSoftmax | n:  10
IntGELU    | n:  10
IntSoftmax | n:  10
IntGELU    | n:  10
IntSoftmax | n:  10
IntGELU    | n:  10
IntSoftmax | n:  10
IntGELU    | n:  10
IntSoftmax | n:  10
IntGELU    | n:  10
IntSoftmax | n:  10
IntGELU    | n:  10
IntSoftmax | n:  10
IntGELU    | n:  10
IntSoftmax | n:  10
IntGELU    | n:  10
IntSoftmax | n:  10
IntGELU    | n:  10
.calib done
Test: [  0/391]	Time  3.711 ( 3.711)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.63
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=10, intgelu_exp_n=11
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=10, intgelu_exp_n=11, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  10
IntGELU    | n:  11
IntSoftmax | n:  10
IntGELU    | n:  11
IntSoftmax | n:  10
IntGELU    | n:  11
IntSoftmax | n:  10
IntGELU    | n:  11
IntSoftmax | n:  10
IntGELU    | n:  11
IntSoftmax | n:  10
IntGELU    | n:  11
IntSoftmax | n:  10
IntGELU    | n:  11
IntSoftmax | n:  10
IntGELU    | n:  11
IntSoftmax | n:  10
IntGELU    | n:  11
IntSoftmax | n:  10
IntGELU    | n:  11
IntSoftmax | n:  10
IntGELU    | n:  11
IntSoftmax | n:  10
IntGELU    | n:  11
.calib done
Test: [  0/391]	Time  3.705 ( 3.705)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.67
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=10, intgelu_exp_n=12
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=10, intgelu_exp_n=12, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  10
IntGELU    | n:  12
IntSoftmax | n:  10
IntGELU    | n:  12
IntSoftmax | n:  10
IntGELU    | n:  12
IntSoftmax | n:  10
IntGELU    | n:  12
IntSoftmax | n:  10
IntGELU    | n:  12
IntSoftmax | n:  10
IntGELU    | n:  12
IntSoftmax | n:  10
IntGELU    | n:  12
IntSoftmax | n:  10
IntGELU    | n:  12
IntSoftmax | n:  10
IntGELU    | n:  12
IntSoftmax | n:  10
IntGELU    | n:  12
IntSoftmax | n:  10
IntGELU    | n:  12
IntSoftmax | n:  10
IntGELU    | n:  12
.calib done
Test: [  0/391]	Time  3.899 ( 3.899)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.88
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=10, intgelu_exp_n=13
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=10, intgelu_exp_n=13, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  10
IntGELU    | n:  13
IntSoftmax | n:  10
IntGELU    | n:  13
IntSoftmax | n:  10
IntGELU    | n:  13
IntSoftmax | n:  10
IntGELU    | n:  13
IntSoftmax | n:  10
IntGELU    | n:  13
IntSoftmax | n:  10
IntGELU    | n:  13
IntSoftmax | n:  10
IntGELU    | n:  13
IntSoftmax | n:  10
IntGELU    | n:  13
IntSoftmax | n:  10
IntGELU    | n:  13
IntSoftmax | n:  10
IntGELU    | n:  13
IntSoftmax | n:  10
IntGELU    | n:  13
IntSoftmax | n:  10
IntGELU    | n:  13
.calib done
Test: [  0/391]	Time  3.865 ( 3.865)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.89
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=10, intgelu_exp_n=14
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=10, intgelu_exp_n=14, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  10
IntGELU    | n:  14
IntSoftmax | n:  10
IntGELU    | n:  14
IntSoftmax | n:  10
IntGELU    | n:  14
IntSoftmax | n:  10
IntGELU    | n:  14
IntSoftmax | n:  10
IntGELU    | n:  14
IntSoftmax | n:  10
IntGELU    | n:  14
IntSoftmax | n:  10
IntGELU    | n:  14
IntSoftmax | n:  10
IntGELU    | n:  14
IntSoftmax | n:  10
IntGELU    | n:  14
IntSoftmax | n:  10
IntGELU    | n:  14
IntSoftmax | n:  10
IntGELU    | n:  14
IntSoftmax | n:  10
IntGELU    | n:  14
.calib done
Test: [  0/391]	Time  3.679 ( 3.679)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.63
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=10, intgelu_exp_n=15
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=10, intgelu_exp_n=15, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  10
IntGELU    | n:  15
IntSoftmax | n:  10
IntGELU    | n:  15
IntSoftmax | n:  10
IntGELU    | n:  15
IntSoftmax | n:  10
IntGELU    | n:  15
IntSoftmax | n:  10
IntGELU    | n:  15
IntSoftmax | n:  10
IntGELU    | n:  15
IntSoftmax | n:  10
IntGELU    | n:  15
IntSoftmax | n:  10
IntGELU    | n:  15
IntSoftmax | n:  10
IntGELU    | n:  15
IntSoftmax | n:  10
IntGELU    | n:  15
IntSoftmax | n:  10
IntGELU    | n:  15
IntSoftmax | n:  10
IntGELU    | n:  15
.calib done
Test: [  0/391]	Time  3.934 ( 3.934)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.86
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=10, intgelu_exp_n=16
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=10, intgelu_exp_n=16, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  10
IntGELU    | n:  16
IntSoftmax | n:  10
IntGELU    | n:  16
IntSoftmax | n:  10
IntGELU    | n:  16
IntSoftmax | n:  10
IntGELU    | n:  16
IntSoftmax | n:  10
IntGELU    | n:  16
IntSoftmax | n:  10
IntGELU    | n:  16
IntSoftmax | n:  10
IntGELU    | n:  16
IntSoftmax | n:  10
IntGELU    | n:  16
IntSoftmax | n:  10
IntGELU    | n:  16
IntSoftmax | n:  10
IntGELU    | n:  16
IntSoftmax | n:  10
IntGELU    | n:  16
IntSoftmax | n:  10
IntGELU    | n:  16
.calib done
Test: [  0/391]	Time  3.791 ( 3.791)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.75
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=10, intgelu_exp_n=17
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=10, intgelu_exp_n=17, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  10
IntGELU    | n:  17
IntSoftmax | n:  10
IntGELU    | n:  17
IntSoftmax | n:  10
IntGELU    | n:  17
IntSoftmax | n:  10
IntGELU    | n:  17
IntSoftmax | n:  10
IntGELU    | n:  17
IntSoftmax | n:  10
IntGELU    | n:  17
IntSoftmax | n:  10
IntGELU    | n:  17
IntSoftmax | n:  10
IntGELU    | n:  17
IntSoftmax | n:  10
IntGELU    | n:  17
IntSoftmax | n:  10
IntGELU    | n:  17
IntSoftmax | n:  10
IntGELU    | n:  17
IntSoftmax | n:  10
IntGELU    | n:  17
.calib done
Test: [  0/391]	Time  3.836 ( 3.836)	Acc@1   0.78 (  0.78)	Acc@5   4.69 (  4.69)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.781 Prec@5 4.688
Time: 8.80
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=10, intgelu_exp_n=18
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=10, intgelu_exp_n=18, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  10
IntGELU    | n:  18
IntSoftmax | n:  10
IntGELU    | n:  18
IntSoftmax | n:  10
IntGELU    | n:  18
IntSoftmax | n:  10
IntGELU    | n:  18
IntSoftmax | n:  10
IntGELU    | n:  18
IntSoftmax | n:  10
IntGELU    | n:  18
IntSoftmax | n:  10
IntGELU    | n:  18
IntSoftmax | n:  10
IntGELU    | n:  18
IntSoftmax | n:  10
IntGELU    | n:  18
IntSoftmax | n:  10
IntGELU    | n:  18
IntSoftmax | n:  10
IntGELU    | n:  18
IntSoftmax | n:  10
IntGELU    | n:  18
.calib done
Test: [  0/391]	Time  3.739 ( 3.739)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.64
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=10, intgelu_exp_n=19
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=10, intgelu_exp_n=19, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  10
IntGELU    | n:  19
IntSoftmax | n:  10
IntGELU    | n:  19
IntSoftmax | n:  10
IntGELU    | n:  19
IntSoftmax | n:  10
IntGELU    | n:  19
IntSoftmax | n:  10
IntGELU    | n:  19
IntSoftmax | n:  10
IntGELU    | n:  19
IntSoftmax | n:  10
IntGELU    | n:  19
IntSoftmax | n:  10
IntGELU    | n:  19
IntSoftmax | n:  10
IntGELU    | n:  19
IntSoftmax | n:  10
IntGELU    | n:  19
IntSoftmax | n:  10
IntGELU    | n:  19
IntSoftmax | n:  10
IntGELU    | n:  19
.calib done
Test: [  0/391]	Time  3.897 ( 3.897)	Acc@1   0.78 (  0.78)	Acc@5   1.56 (  1.56)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.781 Prec@5 1.562
Time: 8.85
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=10, intgelu_exp_n=20
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=10, intgelu_exp_n=20, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  10
IntGELU    | n:  20
IntSoftmax | n:  10
IntGELU    | n:  20
IntSoftmax | n:  10
IntGELU    | n:  20
IntSoftmax | n:  10
IntGELU    | n:  20
IntSoftmax | n:  10
IntGELU    | n:  20
IntSoftmax | n:  10
IntGELU    | n:  20
IntSoftmax | n:  10
IntGELU    | n:  20
IntSoftmax | n:  10
IntGELU    | n:  20
IntSoftmax | n:  10
IntGELU    | n:  20
IntSoftmax | n:  10
IntGELU    | n:  20
IntSoftmax | n:  10
IntGELU    | n:  20
IntSoftmax | n:  10
IntGELU    | n:  20
.calib done
Test: [  0/391]	Time  3.902 ( 3.902)	Acc@1   3.12 (  3.12)	Acc@5   8.59 (  8.59)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 3.125 Prec@5 8.594
Time: 8.81
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=10, intgelu_exp_n=21
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=10, intgelu_exp_n=21, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  10
IntGELU    | n:  21
IntSoftmax | n:  10
IntGELU    | n:  21
IntSoftmax | n:  10
IntGELU    | n:  21
IntSoftmax | n:  10
IntGELU    | n:  21
IntSoftmax | n:  10
IntGELU    | n:  21
IntSoftmax | n:  10
IntGELU    | n:  21
IntSoftmax | n:  10
IntGELU    | n:  21
IntSoftmax | n:  10
IntGELU    | n:  21
IntSoftmax | n:  10
IntGELU    | n:  21
IntSoftmax | n:  10
IntGELU    | n:  21
IntSoftmax | n:  10
IntGELU    | n:  21
IntSoftmax | n:  10
IntGELU    | n:  21
.calib done
Test: [  0/391]	Time  3.673 ( 3.673)	Acc@1   8.59 (  8.59)	Acc@5  16.41 ( 16.41)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 8.594 Prec@5 16.406
Time: 8.64
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=10, intgelu_exp_n=22
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=10, intgelu_exp_n=22, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  10
IntGELU    | n:  22
IntSoftmax | n:  10
IntGELU    | n:  22
IntSoftmax | n:  10
IntGELU    | n:  22
IntSoftmax | n:  10
IntGELU    | n:  22
IntSoftmax | n:  10
IntGELU    | n:  22
IntSoftmax | n:  10
IntGELU    | n:  22
IntSoftmax | n:  10
IntGELU    | n:  22
IntSoftmax | n:  10
IntGELU    | n:  22
IntSoftmax | n:  10
IntGELU    | n:  22
IntSoftmax | n:  10
IntGELU    | n:  22
IntSoftmax | n:  10
IntGELU    | n:  22
IntSoftmax | n:  10
IntGELU    | n:  22
.calib done
Test: [  0/391]	Time  3.970 ( 3.970)	Acc@1  10.94 ( 10.94)	Acc@5  21.09 ( 21.09)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 10.938 Prec@5 21.094
Time: 8.91
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=10, intgelu_exp_n=23
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=10, intgelu_exp_n=23, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  10
IntGELU    | n:  23
IntSoftmax | n:  10
IntGELU    | n:  23
IntSoftmax | n:  10
IntGELU    | n:  23
IntSoftmax | n:  10
IntGELU    | n:  23
IntSoftmax | n:  10
IntGELU    | n:  23
IntSoftmax | n:  10
IntGELU    | n:  23
IntSoftmax | n:  10
IntGELU    | n:  23
IntSoftmax | n:  10
IntGELU    | n:  23
IntSoftmax | n:  10
IntGELU    | n:  23
IntSoftmax | n:  10
IntGELU    | n:  23
IntSoftmax | n:  10
IntGELU    | n:  23
IntSoftmax | n:  10
IntGELU    | n:  23
.calib done
Test: [  0/391]	Time  3.897 ( 3.897)	Acc@1   8.59 (  8.59)	Acc@5  25.00 ( 25.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 8.594 Prec@5 25.000
Time: 8.80
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=10, intgelu_exp_n=24
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=10, intgelu_exp_n=24, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  10
IntGELU    | n:  24
IntSoftmax | n:  10
IntGELU    | n:  24
IntSoftmax | n:  10
IntGELU    | n:  24
IntSoftmax | n:  10
IntGELU    | n:  24
IntSoftmax | n:  10
IntGELU    | n:  24
IntSoftmax | n:  10
IntGELU    | n:  24
IntSoftmax | n:  10
IntGELU    | n:  24
IntSoftmax | n:  10
IntGELU    | n:  24
IntSoftmax | n:  10
IntGELU    | n:  24
IntSoftmax | n:  10
IntGELU    | n:  24
IntSoftmax | n:  10
IntGELU    | n:  24
IntSoftmax | n:  10
IntGELU    | n:  24
.calib done
Test: [  0/391]	Time  3.973 ( 3.973)	Acc@1  19.53 ( 19.53)	Acc@5  37.50 ( 37.50)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 19.531 Prec@5 37.500
Time: 8.98
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=10, intgelu_exp_n=25
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=10, intgelu_exp_n=25, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  10
IntGELU    | n:  25
IntSoftmax | n:  10
IntGELU    | n:  25
IntSoftmax | n:  10
IntGELU    | n:  25
IntSoftmax | n:  10
IntGELU    | n:  25
IntSoftmax | n:  10
IntGELU    | n:  25
IntSoftmax | n:  10
IntGELU    | n:  25
IntSoftmax | n:  10
IntGELU    | n:  25
IntSoftmax | n:  10
IntGELU    | n:  25
IntSoftmax | n:  10
IntGELU    | n:  25
IntSoftmax | n:  10
IntGELU    | n:  25
IntSoftmax | n:  10
IntGELU    | n:  25
IntSoftmax | n:  10
IntGELU    | n:  25
.calib done
Test: [  0/391]	Time  3.765 ( 3.765)	Acc@1  18.75 ( 18.75)	Acc@5  39.84 ( 39.84)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 18.750 Prec@5 39.844
Time: 8.70
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=10, intgelu_exp_n=26
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=10, intgelu_exp_n=26, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  10
IntGELU    | n:  26
IntSoftmax | n:  10
IntGELU    | n:  26
IntSoftmax | n:  10
IntGELU    | n:  26
IntSoftmax | n:  10
IntGELU    | n:  26
IntSoftmax | n:  10
IntGELU    | n:  26
IntSoftmax | n:  10
IntGELU    | n:  26
IntSoftmax | n:  10
IntGELU    | n:  26
IntSoftmax | n:  10
IntGELU    | n:  26
IntSoftmax | n:  10
IntGELU    | n:  26
IntSoftmax | n:  10
IntGELU    | n:  26
IntSoftmax | n:  10
IntGELU    | n:  26
IntSoftmax | n:  10
IntGELU    | n:  26
.calib done
Test: [  0/391]	Time  3.676 ( 3.676)	Acc@1  22.66 ( 22.66)	Acc@5  44.53 ( 44.53)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 22.656 Prec@5 44.531
Time: 8.64
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=10, intgelu_exp_n=27
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=10, intgelu_exp_n=27, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  10
IntGELU    | n:  27
IntSoftmax | n:  10
IntGELU    | n:  27
IntSoftmax | n:  10
IntGELU    | n:  27
IntSoftmax | n:  10
IntGELU    | n:  27
IntSoftmax | n:  10
IntGELU    | n:  27
IntSoftmax | n:  10
IntGELU    | n:  27
IntSoftmax | n:  10
IntGELU    | n:  27
IntSoftmax | n:  10
IntGELU    | n:  27
IntSoftmax | n:  10
IntGELU    | n:  27
IntSoftmax | n:  10
IntGELU    | n:  27
IntSoftmax | n:  10
IntGELU    | n:  27
IntSoftmax | n:  10
IntGELU    | n:  27
.calib done
Test: [  0/391]	Time  3.843 ( 3.843)	Acc@1  25.78 ( 25.78)	Acc@5  49.22 ( 49.22)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 25.781 Prec@5 49.219
Time: 8.82
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=10, intgelu_exp_n=28
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=10, intgelu_exp_n=28, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  10
IntGELU    | n:  28
IntSoftmax | n:  10
IntGELU    | n:  28
IntSoftmax | n:  10
IntGELU    | n:  28
IntSoftmax | n:  10
IntGELU    | n:  28
IntSoftmax | n:  10
IntGELU    | n:  28
IntSoftmax | n:  10
IntGELU    | n:  28
IntSoftmax | n:  10
IntGELU    | n:  28
IntSoftmax | n:  10
IntGELU    | n:  28
IntSoftmax | n:  10
IntGELU    | n:  28
IntSoftmax | n:  10
IntGELU    | n:  28
IntSoftmax | n:  10
IntGELU    | n:  28
IntSoftmax | n:  10
IntGELU    | n:  28
.calib done
Test: [  0/391]	Time  4.003 ( 4.003)	Acc@1  27.34 ( 27.34)	Acc@5  53.12 ( 53.12)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 27.344 Prec@5 53.125
Time: 8.93
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=10, intgelu_exp_n=29
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=10, intgelu_exp_n=29, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  10
IntGELU    | n:  29
IntSoftmax | n:  10
IntGELU    | n:  29
IntSoftmax | n:  10
IntGELU    | n:  29
IntSoftmax | n:  10
IntGELU    | n:  29
IntSoftmax | n:  10
IntGELU    | n:  29
IntSoftmax | n:  10
IntGELU    | n:  29
IntSoftmax | n:  10
IntGELU    | n:  29
IntSoftmax | n:  10
IntGELU    | n:  29
IntSoftmax | n:  10
IntGELU    | n:  29
IntSoftmax | n:  10
IntGELU    | n:  29
IntSoftmax | n:  10
IntGELU    | n:  29
IntSoftmax | n:  10
IntGELU    | n:  29
.calib done
Test: [  0/391]	Time  4.088 ( 4.088)	Acc@1  31.25 ( 31.25)	Acc@5  53.91 ( 53.91)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 31.250 Prec@5 53.906
Time: 8.99
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=10, intgelu_exp_n=30
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=10, intgelu_exp_n=30, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  10
IntGELU    | n:  30
IntSoftmax | n:  10
IntGELU    | n:  30
IntSoftmax | n:  10
IntGELU    | n:  30
IntSoftmax | n:  10
IntGELU    | n:  30
IntSoftmax | n:  10
IntGELU    | n:  30
IntSoftmax | n:  10
IntGELU    | n:  30
IntSoftmax | n:  10
IntGELU    | n:  30
IntSoftmax | n:  10
IntGELU    | n:  30
IntSoftmax | n:  10
IntGELU    | n:  30
IntSoftmax | n:  10
IntGELU    | n:  30
IntSoftmax | n:  10
IntGELU    | n:  30
IntSoftmax | n:  10
IntGELU    | n:  30
.calib done
Test: [  0/391]	Time  3.947 ( 3.947)	Acc@1  57.03 ( 57.03)	Acc@5  79.69 ( 79.69)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 57.031 Prec@5 79.688
Time: 8.93
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=10, intgelu_exp_n=31
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=10, intgelu_exp_n=31, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  10
IntGELU    | n:  31
IntSoftmax | n:  10
IntGELU    | n:  31
IntSoftmax | n:  10
IntGELU    | n:  31
IntSoftmax | n:  10
IntGELU    | n:  31
IntSoftmax | n:  10
IntGELU    | n:  31
IntSoftmax | n:  10
IntGELU    | n:  31
IntSoftmax | n:  10
IntGELU    | n:  31
IntSoftmax | n:  10
IntGELU    | n:  31
IntSoftmax | n:  10
IntGELU    | n:  31
IntSoftmax | n:  10
IntGELU    | n:  31
IntSoftmax | n:  10
IntGELU    | n:  31
IntSoftmax | n:  10
IntGELU    | n:  31
.calib done
Test: [  0/391]	Time  3.911 ( 3.911)	Acc@1   6.25 (  6.25)	Acc@5  14.06 ( 14.06)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 6.250 Prec@5 14.062
Time: 8.80
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=11, intgelu_exp_n=0
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=11, intgelu_exp_n=0, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  11
IntGELU    | n:  0
IntSoftmax | n:  11
IntGELU    | n:  0
IntSoftmax | n:  11
IntGELU    | n:  0
IntSoftmax | n:  11
IntGELU    | n:  0
IntSoftmax | n:  11
IntGELU    | n:  0
IntSoftmax | n:  11
IntGELU    | n:  0
IntSoftmax | n:  11
IntGELU    | n:  0
IntSoftmax | n:  11
IntGELU    | n:  0
IntSoftmax | n:  11
IntGELU    | n:  0
IntSoftmax | n:  11
IntGELU    | n:  0
IntSoftmax | n:  11
IntGELU    | n:  0
IntSoftmax | n:  11
IntGELU    | n:  0
.calib done
Test: [  0/391]	Time  3.746 ( 3.746)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.71
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=11, intgelu_exp_n=1
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=11, intgelu_exp_n=1, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  11
IntGELU    | n:  1
IntSoftmax | n:  11
IntGELU    | n:  1
IntSoftmax | n:  11
IntGELU    | n:  1
IntSoftmax | n:  11
IntGELU    | n:  1
IntSoftmax | n:  11
IntGELU    | n:  1
IntSoftmax | n:  11
IntGELU    | n:  1
IntSoftmax | n:  11
IntGELU    | n:  1
IntSoftmax | n:  11
IntGELU    | n:  1
IntSoftmax | n:  11
IntGELU    | n:  1
IntSoftmax | n:  11
IntGELU    | n:  1
IntSoftmax | n:  11
IntGELU    | n:  1
IntSoftmax | n:  11
IntGELU    | n:  1
.calib done
Test: [  0/391]	Time  3.691 ( 3.691)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.65
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=11, intgelu_exp_n=2
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=11, intgelu_exp_n=2, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  11
IntGELU    | n:  2
IntSoftmax | n:  11
IntGELU    | n:  2
IntSoftmax | n:  11
IntGELU    | n:  2
IntSoftmax | n:  11
IntGELU    | n:  2
IntSoftmax | n:  11
IntGELU    | n:  2
IntSoftmax | n:  11
IntGELU    | n:  2
IntSoftmax | n:  11
IntGELU    | n:  2
IntSoftmax | n:  11
IntGELU    | n:  2
IntSoftmax | n:  11
IntGELU    | n:  2
IntSoftmax | n:  11
IntGELU    | n:  2
IntSoftmax | n:  11
IntGELU    | n:  2
IntSoftmax | n:  11
IntGELU    | n:  2
.calib done
Test: [  0/391]	Time  3.863 ( 3.863)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.83
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=11, intgelu_exp_n=3
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=11, intgelu_exp_n=3, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  11
IntGELU    | n:  3
IntSoftmax | n:  11
IntGELU    | n:  3
IntSoftmax | n:  11
IntGELU    | n:  3
IntSoftmax | n:  11
IntGELU    | n:  3
IntSoftmax | n:  11
IntGELU    | n:  3
IntSoftmax | n:  11
IntGELU    | n:  3
IntSoftmax | n:  11
IntGELU    | n:  3
IntSoftmax | n:  11
IntGELU    | n:  3
IntSoftmax | n:  11
IntGELU    | n:  3
IntSoftmax | n:  11
IntGELU    | n:  3
IntSoftmax | n:  11
IntGELU    | n:  3
IntSoftmax | n:  11
IntGELU    | n:  3
.calib done
Test: [  0/391]	Time  3.897 ( 3.897)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.94
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=11, intgelu_exp_n=4
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=11, intgelu_exp_n=4, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  11
IntGELU    | n:  4
IntSoftmax | n:  11
IntGELU    | n:  4
IntSoftmax | n:  11
IntGELU    | n:  4
IntSoftmax | n:  11
IntGELU    | n:  4
IntSoftmax | n:  11
IntGELU    | n:  4
IntSoftmax | n:  11
IntGELU    | n:  4
IntSoftmax | n:  11
IntGELU    | n:  4
IntSoftmax | n:  11
IntGELU    | n:  4
IntSoftmax | n:  11
IntGELU    | n:  4
IntSoftmax | n:  11
IntGELU    | n:  4
IntSoftmax | n:  11
IntGELU    | n:  4
IntSoftmax | n:  11
IntGELU    | n:  4
.calib done
Test: [  0/391]	Time  3.952 ( 3.952)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.89
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=11, intgelu_exp_n=5
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=11, intgelu_exp_n=5, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  11
IntGELU    | n:  5
IntSoftmax | n:  11
IntGELU    | n:  5
IntSoftmax | n:  11
IntGELU    | n:  5
IntSoftmax | n:  11
IntGELU    | n:  5
IntSoftmax | n:  11
IntGELU    | n:  5
IntSoftmax | n:  11
IntGELU    | n:  5
IntSoftmax | n:  11
IntGELU    | n:  5
IntSoftmax | n:  11
IntGELU    | n:  5
IntSoftmax | n:  11
IntGELU    | n:  5
IntSoftmax | n:  11
IntGELU    | n:  5
IntSoftmax | n:  11
IntGELU    | n:  5
IntSoftmax | n:  11
IntGELU    | n:  5
.calib done
Test: [  0/391]	Time  3.808 ( 3.808)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.75
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=11, intgelu_exp_n=6
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=11, intgelu_exp_n=6, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  11
IntGELU    | n:  6
IntSoftmax | n:  11
IntGELU    | n:  6
IntSoftmax | n:  11
IntGELU    | n:  6
IntSoftmax | n:  11
IntGELU    | n:  6
IntSoftmax | n:  11
IntGELU    | n:  6
IntSoftmax | n:  11
IntGELU    | n:  6
IntSoftmax | n:  11
IntGELU    | n:  6
IntSoftmax | n:  11
IntGELU    | n:  6
IntSoftmax | n:  11
IntGELU    | n:  6
IntSoftmax | n:  11
IntGELU    | n:  6
IntSoftmax | n:  11
IntGELU    | n:  6
IntSoftmax | n:  11
IntGELU    | n:  6
.calib done
Test: [  0/391]	Time  3.818 ( 3.818)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.76
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=11, intgelu_exp_n=7
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=11, intgelu_exp_n=7, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  11
IntGELU    | n:  7
IntSoftmax | n:  11
IntGELU    | n:  7
IntSoftmax | n:  11
IntGELU    | n:  7
IntSoftmax | n:  11
IntGELU    | n:  7
IntSoftmax | n:  11
IntGELU    | n:  7
IntSoftmax | n:  11
IntGELU    | n:  7
IntSoftmax | n:  11
IntGELU    | n:  7
IntSoftmax | n:  11
IntGELU    | n:  7
IntSoftmax | n:  11
IntGELU    | n:  7
IntSoftmax | n:  11
IntGELU    | n:  7
IntSoftmax | n:  11
IntGELU    | n:  7
IntSoftmax | n:  11
IntGELU    | n:  7
.calib done
Test: [  0/391]	Time  3.805 ( 3.805)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.76
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=11, intgelu_exp_n=8
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=11, intgelu_exp_n=8, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  11
IntGELU    | n:  8
IntSoftmax | n:  11
IntGELU    | n:  8
IntSoftmax | n:  11
IntGELU    | n:  8
IntSoftmax | n:  11
IntGELU    | n:  8
IntSoftmax | n:  11
IntGELU    | n:  8
IntSoftmax | n:  11
IntGELU    | n:  8
IntSoftmax | n:  11
IntGELU    | n:  8
IntSoftmax | n:  11
IntGELU    | n:  8
IntSoftmax | n:  11
IntGELU    | n:  8
IntSoftmax | n:  11
IntGELU    | n:  8
IntSoftmax | n:  11
IntGELU    | n:  8
IntSoftmax | n:  11
IntGELU    | n:  8
.calib done
Test: [  0/391]	Time  3.671 ( 3.671)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.65
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=11, intgelu_exp_n=9
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=11, intgelu_exp_n=9, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  11
IntGELU    | n:  9
IntSoftmax | n:  11
IntGELU    | n:  9
IntSoftmax | n:  11
IntGELU    | n:  9
IntSoftmax | n:  11
IntGELU    | n:  9
IntSoftmax | n:  11
IntGELU    | n:  9
IntSoftmax | n:  11
IntGELU    | n:  9
IntSoftmax | n:  11
IntGELU    | n:  9
IntSoftmax | n:  11
IntGELU    | n:  9
IntSoftmax | n:  11
IntGELU    | n:  9
IntSoftmax | n:  11
IntGELU    | n:  9
IntSoftmax | n:  11
IntGELU    | n:  9
IntSoftmax | n:  11
IntGELU    | n:  9
.calib done
Test: [  0/391]	Time  3.802 ( 3.802)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.73
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=11, intgelu_exp_n=10
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=11, intgelu_exp_n=10, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  11
IntGELU    | n:  10
IntSoftmax | n:  11
IntGELU    | n:  10
IntSoftmax | n:  11
IntGELU    | n:  10
IntSoftmax | n:  11
IntGELU    | n:  10
IntSoftmax | n:  11
IntGELU    | n:  10
IntSoftmax | n:  11
IntGELU    | n:  10
IntSoftmax | n:  11
IntGELU    | n:  10
IntSoftmax | n:  11
IntGELU    | n:  10
IntSoftmax | n:  11
IntGELU    | n:  10
IntSoftmax | n:  11
IntGELU    | n:  10
IntSoftmax | n:  11
IntGELU    | n:  10
IntSoftmax | n:  11
IntGELU    | n:  10
.calib done
Test: [  0/391]	Time  3.675 ( 3.675)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.62
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=11, intgelu_exp_n=11
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=11, intgelu_exp_n=11, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  11
IntGELU    | n:  11
IntSoftmax | n:  11
IntGELU    | n:  11
IntSoftmax | n:  11
IntGELU    | n:  11
IntSoftmax | n:  11
IntGELU    | n:  11
IntSoftmax | n:  11
IntGELU    | n:  11
IntSoftmax | n:  11
IntGELU    | n:  11
IntSoftmax | n:  11
IntGELU    | n:  11
IntSoftmax | n:  11
IntGELU    | n:  11
IntSoftmax | n:  11
IntGELU    | n:  11
IntSoftmax | n:  11
IntGELU    | n:  11
IntSoftmax | n:  11
IntGELU    | n:  11
IntSoftmax | n:  11
IntGELU    | n:  11
.calib done
Test: [  0/391]	Time  3.801 ( 3.801)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.70
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=11, intgelu_exp_n=12
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=11, intgelu_exp_n=12, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  11
IntGELU    | n:  12
IntSoftmax | n:  11
IntGELU    | n:  12
IntSoftmax | n:  11
IntGELU    | n:  12
IntSoftmax | n:  11
IntGELU    | n:  12
IntSoftmax | n:  11
IntGELU    | n:  12
IntSoftmax | n:  11
IntGELU    | n:  12
IntSoftmax | n:  11
IntGELU    | n:  12
IntSoftmax | n:  11
IntGELU    | n:  12
IntSoftmax | n:  11
IntGELU    | n:  12
IntSoftmax | n:  11
IntGELU    | n:  12
IntSoftmax | n:  11
IntGELU    | n:  12
IntSoftmax | n:  11
IntGELU    | n:  12
.calib done
Test: [  0/391]	Time  3.884 ( 3.884)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.82
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=11, intgelu_exp_n=13
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=11, intgelu_exp_n=13, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  11
IntGELU    | n:  13
IntSoftmax | n:  11
IntGELU    | n:  13
IntSoftmax | n:  11
IntGELU    | n:  13
IntSoftmax | n:  11
IntGELU    | n:  13
IntSoftmax | n:  11
IntGELU    | n:  13
IntSoftmax | n:  11
IntGELU    | n:  13
IntSoftmax | n:  11
IntGELU    | n:  13
IntSoftmax | n:  11
IntGELU    | n:  13
IntSoftmax | n:  11
IntGELU    | n:  13
IntSoftmax | n:  11
IntGELU    | n:  13
IntSoftmax | n:  11
IntGELU    | n:  13
IntSoftmax | n:  11
IntGELU    | n:  13
.calib done
Test: [  0/391]	Time  3.924 ( 3.924)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.82
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=11, intgelu_exp_n=14
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=11, intgelu_exp_n=14, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  11
IntGELU    | n:  14
IntSoftmax | n:  11
IntGELU    | n:  14
IntSoftmax | n:  11
IntGELU    | n:  14
IntSoftmax | n:  11
IntGELU    | n:  14
IntSoftmax | n:  11
IntGELU    | n:  14
IntSoftmax | n:  11
IntGELU    | n:  14
IntSoftmax | n:  11
IntGELU    | n:  14
IntSoftmax | n:  11
IntGELU    | n:  14
IntSoftmax | n:  11
IntGELU    | n:  14
IntSoftmax | n:  11
IntGELU    | n:  14
IntSoftmax | n:  11
IntGELU    | n:  14
IntSoftmax | n:  11
IntGELU    | n:  14
.calib done
Test: [  0/391]	Time  3.864 ( 3.864)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.80
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=11, intgelu_exp_n=15
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=11, intgelu_exp_n=15, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  11
IntGELU    | n:  15
IntSoftmax | n:  11
IntGELU    | n:  15
IntSoftmax | n:  11
IntGELU    | n:  15
IntSoftmax | n:  11
IntGELU    | n:  15
IntSoftmax | n:  11
IntGELU    | n:  15
IntSoftmax | n:  11
IntGELU    | n:  15
IntSoftmax | n:  11
IntGELU    | n:  15
IntSoftmax | n:  11
IntGELU    | n:  15
IntSoftmax | n:  11
IntGELU    | n:  15
IntSoftmax | n:  11
IntGELU    | n:  15
IntSoftmax | n:  11
IntGELU    | n:  15
IntSoftmax | n:  11
IntGELU    | n:  15
.calib done
Test: [  0/391]	Time  3.864 ( 3.864)	Acc@1   0.00 (  0.00)	Acc@5   0.78 (  0.78)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.781
Time: 8.88
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=11, intgelu_exp_n=16
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=11, intgelu_exp_n=16, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  11
IntGELU    | n:  16
IntSoftmax | n:  11
IntGELU    | n:  16
IntSoftmax | n:  11
IntGELU    | n:  16
IntSoftmax | n:  11
IntGELU    | n:  16
IntSoftmax | n:  11
IntGELU    | n:  16
IntSoftmax | n:  11
IntGELU    | n:  16
IntSoftmax | n:  11
IntGELU    | n:  16
IntSoftmax | n:  11
IntGELU    | n:  16
IntSoftmax | n:  11
IntGELU    | n:  16
IntSoftmax | n:  11
IntGELU    | n:  16
IntSoftmax | n:  11
IntGELU    | n:  16
IntSoftmax | n:  11
IntGELU    | n:  16
.calib done
Test: [  0/391]	Time  3.825 ( 3.825)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.76
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=11, intgelu_exp_n=17
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=11, intgelu_exp_n=17, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  11
IntGELU    | n:  17
IntSoftmax | n:  11
IntGELU    | n:  17
IntSoftmax | n:  11
IntGELU    | n:  17
IntSoftmax | n:  11
IntGELU    | n:  17
IntSoftmax | n:  11
IntGELU    | n:  17
IntSoftmax | n:  11
IntGELU    | n:  17
IntSoftmax | n:  11
IntGELU    | n:  17
IntSoftmax | n:  11
IntGELU    | n:  17
IntSoftmax | n:  11
IntGELU    | n:  17
IntSoftmax | n:  11
IntGELU    | n:  17
IntSoftmax | n:  11
IntGELU    | n:  17
IntSoftmax | n:  11
IntGELU    | n:  17
.calib done
Test: [  0/391]	Time  3.787 ( 3.787)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.73
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=11, intgelu_exp_n=18
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=11, intgelu_exp_n=18, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  11
IntGELU    | n:  18
IntSoftmax | n:  11
IntGELU    | n:  18
IntSoftmax | n:  11
IntGELU    | n:  18
IntSoftmax | n:  11
IntGELU    | n:  18
IntSoftmax | n:  11
IntGELU    | n:  18
IntSoftmax | n:  11
IntGELU    | n:  18
IntSoftmax | n:  11
IntGELU    | n:  18
IntSoftmax | n:  11
IntGELU    | n:  18
IntSoftmax | n:  11
IntGELU    | n:  18
IntSoftmax | n:  11
IntGELU    | n:  18
IntSoftmax | n:  11
IntGELU    | n:  18
IntSoftmax | n:  11
IntGELU    | n:  18
.calib done
Test: [  0/391]	Time  3.807 ( 3.807)	Acc@1   0.00 (  0.00)	Acc@5   2.34 (  2.34)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 2.344
Time: 8.71
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=11, intgelu_exp_n=19
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=11, intgelu_exp_n=19, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  11
IntGELU    | n:  19
IntSoftmax | n:  11
IntGELU    | n:  19
IntSoftmax | n:  11
IntGELU    | n:  19
IntSoftmax | n:  11
IntGELU    | n:  19
IntSoftmax | n:  11
IntGELU    | n:  19
IntSoftmax | n:  11
IntGELU    | n:  19
IntSoftmax | n:  11
IntGELU    | n:  19
IntSoftmax | n:  11
IntGELU    | n:  19
IntSoftmax | n:  11
IntGELU    | n:  19
IntSoftmax | n:  11
IntGELU    | n:  19
IntSoftmax | n:  11
IntGELU    | n:  19
IntSoftmax | n:  11
IntGELU    | n:  19
.calib done
Test: [  0/391]	Time  4.009 ( 4.009)	Acc@1   1.56 (  1.56)	Acc@5   5.47 (  5.47)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 1.562 Prec@5 5.469
Time: 8.96
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=11, intgelu_exp_n=20
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=11, intgelu_exp_n=20, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  11
IntGELU    | n:  20
IntSoftmax | n:  11
IntGELU    | n:  20
IntSoftmax | n:  11
IntGELU    | n:  20
IntSoftmax | n:  11
IntGELU    | n:  20
IntSoftmax | n:  11
IntGELU    | n:  20
IntSoftmax | n:  11
IntGELU    | n:  20
IntSoftmax | n:  11
IntGELU    | n:  20
IntSoftmax | n:  11
IntGELU    | n:  20
IntSoftmax | n:  11
IntGELU    | n:  20
IntSoftmax | n:  11
IntGELU    | n:  20
IntSoftmax | n:  11
IntGELU    | n:  20
IntSoftmax | n:  11
IntGELU    | n:  20
.calib done
Test: [  0/391]	Time  3.672 ( 3.672)	Acc@1   2.34 (  2.34)	Acc@5   7.03 (  7.03)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 2.344 Prec@5 7.031
Time: 8.59
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=11, intgelu_exp_n=21
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=11, intgelu_exp_n=21, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  11
IntGELU    | n:  21
IntSoftmax | n:  11
IntGELU    | n:  21
IntSoftmax | n:  11
IntGELU    | n:  21
IntSoftmax | n:  11
IntGELU    | n:  21
IntSoftmax | n:  11
IntGELU    | n:  21
IntSoftmax | n:  11
IntGELU    | n:  21
IntSoftmax | n:  11
IntGELU    | n:  21
IntSoftmax | n:  11
IntGELU    | n:  21
IntSoftmax | n:  11
IntGELU    | n:  21
IntSoftmax | n:  11
IntGELU    | n:  21
IntSoftmax | n:  11
IntGELU    | n:  21
IntSoftmax | n:  11
IntGELU    | n:  21
.calib done
Test: [  0/391]	Time  3.717 ( 3.717)	Acc@1   6.25 (  6.25)	Acc@5  14.06 ( 14.06)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 6.250 Prec@5 14.062
Time: 8.72
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=11, intgelu_exp_n=22
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=11, intgelu_exp_n=22, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  11
IntGELU    | n:  22
IntSoftmax | n:  11
IntGELU    | n:  22
IntSoftmax | n:  11
IntGELU    | n:  22
IntSoftmax | n:  11
IntGELU    | n:  22
IntSoftmax | n:  11
IntGELU    | n:  22
IntSoftmax | n:  11
IntGELU    | n:  22
IntSoftmax | n:  11
IntGELU    | n:  22
IntSoftmax | n:  11
IntGELU    | n:  22
IntSoftmax | n:  11
IntGELU    | n:  22
IntSoftmax | n:  11
IntGELU    | n:  22
IntSoftmax | n:  11
IntGELU    | n:  22
IntSoftmax | n:  11
IntGELU    | n:  22
.calib done
Test: [  0/391]	Time  3.836 ( 3.836)	Acc@1  13.28 ( 13.28)	Acc@5  23.44 ( 23.44)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 13.281 Prec@5 23.438
Time: 8.75
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=11, intgelu_exp_n=23
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=11, intgelu_exp_n=23, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  11
IntGELU    | n:  23
IntSoftmax | n:  11
IntGELU    | n:  23
IntSoftmax | n:  11
IntGELU    | n:  23
IntSoftmax | n:  11
IntGELU    | n:  23
IntSoftmax | n:  11
IntGELU    | n:  23
IntSoftmax | n:  11
IntGELU    | n:  23
IntSoftmax | n:  11
IntGELU    | n:  23
IntSoftmax | n:  11
IntGELU    | n:  23
IntSoftmax | n:  11
IntGELU    | n:  23
IntSoftmax | n:  11
IntGELU    | n:  23
IntSoftmax | n:  11
IntGELU    | n:  23
IntSoftmax | n:  11
IntGELU    | n:  23
.calib done
Test: [  0/391]	Time  3.824 ( 3.824)	Acc@1   1.56 (  1.56)	Acc@5  12.50 ( 12.50)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 1.562 Prec@5 12.500
Time: 8.76
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=11, intgelu_exp_n=24
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=11, intgelu_exp_n=24, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  11
IntGELU    | n:  24
IntSoftmax | n:  11
IntGELU    | n:  24
IntSoftmax | n:  11
IntGELU    | n:  24
IntSoftmax | n:  11
IntGELU    | n:  24
IntSoftmax | n:  11
IntGELU    | n:  24
IntSoftmax | n:  11
IntGELU    | n:  24
IntSoftmax | n:  11
IntGELU    | n:  24
IntSoftmax | n:  11
IntGELU    | n:  24
IntSoftmax | n:  11
IntGELU    | n:  24
IntSoftmax | n:  11
IntGELU    | n:  24
IntSoftmax | n:  11
IntGELU    | n:  24
IntSoftmax | n:  11
IntGELU    | n:  24
.calib done
Test: [  0/391]	Time  3.890 ( 3.890)	Acc@1  15.62 ( 15.62)	Acc@5  35.16 ( 35.16)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 15.625 Prec@5 35.156
Time: 8.85
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=11, intgelu_exp_n=25
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=11, intgelu_exp_n=25, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  11
IntGELU    | n:  25
IntSoftmax | n:  11
IntGELU    | n:  25
IntSoftmax | n:  11
IntGELU    | n:  25
IntSoftmax | n:  11
IntGELU    | n:  25
IntSoftmax | n:  11
IntGELU    | n:  25
IntSoftmax | n:  11
IntGELU    | n:  25
IntSoftmax | n:  11
IntGELU    | n:  25
IntSoftmax | n:  11
IntGELU    | n:  25
IntSoftmax | n:  11
IntGELU    | n:  25
IntSoftmax | n:  11
IntGELU    | n:  25
IntSoftmax | n:  11
IntGELU    | n:  25
IntSoftmax | n:  11
IntGELU    | n:  25
.calib done
Test: [  0/391]	Time  3.924 ( 3.924)	Acc@1  17.97 ( 17.97)	Acc@5  41.41 ( 41.41)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 17.969 Prec@5 41.406
Time: 8.88
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=11, intgelu_exp_n=26
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=11, intgelu_exp_n=26, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  11
IntGELU    | n:  26
IntSoftmax | n:  11
IntGELU    | n:  26
IntSoftmax | n:  11
IntGELU    | n:  26
IntSoftmax | n:  11
IntGELU    | n:  26
IntSoftmax | n:  11
IntGELU    | n:  26
IntSoftmax | n:  11
IntGELU    | n:  26
IntSoftmax | n:  11
IntGELU    | n:  26
IntSoftmax | n:  11
IntGELU    | n:  26
IntSoftmax | n:  11
IntGELU    | n:  26
IntSoftmax | n:  11
IntGELU    | n:  26
IntSoftmax | n:  11
IntGELU    | n:  26
IntSoftmax | n:  11
IntGELU    | n:  26
.calib done
Test: [  0/391]	Time  3.908 ( 3.908)	Acc@1  17.97 ( 17.97)	Acc@5  39.06 ( 39.06)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 17.969 Prec@5 39.062
Time: 8.83
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=11, intgelu_exp_n=27
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=11, intgelu_exp_n=27, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  11
IntGELU    | n:  27
IntSoftmax | n:  11
IntGELU    | n:  27
IntSoftmax | n:  11
IntGELU    | n:  27
IntSoftmax | n:  11
IntGELU    | n:  27
IntSoftmax | n:  11
IntGELU    | n:  27
IntSoftmax | n:  11
IntGELU    | n:  27
IntSoftmax | n:  11
IntGELU    | n:  27
IntSoftmax | n:  11
IntGELU    | n:  27
IntSoftmax | n:  11
IntGELU    | n:  27
IntSoftmax | n:  11
IntGELU    | n:  27
IntSoftmax | n:  11
IntGELU    | n:  27
IntSoftmax | n:  11
IntGELU    | n:  27
.calib done
Test: [  0/391]	Time  3.909 ( 3.909)	Acc@1  23.44 ( 23.44)	Acc@5  45.31 ( 45.31)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 23.438 Prec@5 45.312
Time: 8.89
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=11, intgelu_exp_n=28
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=11, intgelu_exp_n=28, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  11
IntGELU    | n:  28
IntSoftmax | n:  11
IntGELU    | n:  28
IntSoftmax | n:  11
IntGELU    | n:  28
IntSoftmax | n:  11
IntGELU    | n:  28
IntSoftmax | n:  11
IntGELU    | n:  28
IntSoftmax | n:  11
IntGELU    | n:  28
IntSoftmax | n:  11
IntGELU    | n:  28
IntSoftmax | n:  11
IntGELU    | n:  28
IntSoftmax | n:  11
IntGELU    | n:  28
IntSoftmax | n:  11
IntGELU    | n:  28
IntSoftmax | n:  11
IntGELU    | n:  28
IntSoftmax | n:  11
IntGELU    | n:  28
.calib done
Test: [  0/391]	Time  3.894 ( 3.894)	Acc@1  28.12 ( 28.12)	Acc@5  51.56 ( 51.56)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 28.125 Prec@5 51.562
Time: 8.82
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=11, intgelu_exp_n=29
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=11, intgelu_exp_n=29, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  11
IntGELU    | n:  29
IntSoftmax | n:  11
IntGELU    | n:  29
IntSoftmax | n:  11
IntGELU    | n:  29
IntSoftmax | n:  11
IntGELU    | n:  29
IntSoftmax | n:  11
IntGELU    | n:  29
IntSoftmax | n:  11
IntGELU    | n:  29
IntSoftmax | n:  11
IntGELU    | n:  29
IntSoftmax | n:  11
IntGELU    | n:  29
IntSoftmax | n:  11
IntGELU    | n:  29
IntSoftmax | n:  11
IntGELU    | n:  29
IntSoftmax | n:  11
IntGELU    | n:  29
IntSoftmax | n:  11
IntGELU    | n:  29
.calib done
Test: [  0/391]	Time  3.867 ( 3.867)	Acc@1  32.03 ( 32.03)	Acc@5  55.47 ( 55.47)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 32.031 Prec@5 55.469
Time: 8.80
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=11, intgelu_exp_n=30
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=11, intgelu_exp_n=30, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  11
IntGELU    | n:  30
IntSoftmax | n:  11
IntGELU    | n:  30
IntSoftmax | n:  11
IntGELU    | n:  30
IntSoftmax | n:  11
IntGELU    | n:  30
IntSoftmax | n:  11
IntGELU    | n:  30
IntSoftmax | n:  11
IntGELU    | n:  30
IntSoftmax | n:  11
IntGELU    | n:  30
IntSoftmax | n:  11
IntGELU    | n:  30
IntSoftmax | n:  11
IntGELU    | n:  30
IntSoftmax | n:  11
IntGELU    | n:  30
IntSoftmax | n:  11
IntGELU    | n:  30
IntSoftmax | n:  11
IntGELU    | n:  30
.calib done
Test: [  0/391]	Time  3.900 ( 3.900)	Acc@1  89.84 ( 89.84)	Acc@5  96.88 ( 96.88)
Test: [ 10/391]	Time  1.737 ( 1.933)	Acc@1  64.06 ( 81.89)	Acc@5  85.94 ( 94.39)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 81.889 Prec@5 94.389
Time: 26.19
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=11, intgelu_exp_n=31
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=11, intgelu_exp_n=31, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  11
IntGELU    | n:  31
IntSoftmax | n:  11
IntGELU    | n:  31
IntSoftmax | n:  11
IntGELU    | n:  31
IntSoftmax | n:  11
IntGELU    | n:  31
IntSoftmax | n:  11
IntGELU    | n:  31
IntSoftmax | n:  11
IntGELU    | n:  31
IntSoftmax | n:  11
IntGELU    | n:  31
IntSoftmax | n:  11
IntGELU    | n:  31
IntSoftmax | n:  11
IntGELU    | n:  31
IntSoftmax | n:  11
IntGELU    | n:  31
IntSoftmax | n:  11
IntGELU    | n:  31
IntSoftmax | n:  11
IntGELU    | n:  31
.calib done
Test: [  0/391]	Time  3.922 ( 3.922)	Acc@1  11.72 ( 11.72)	Acc@5  19.53 ( 19.53)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 11.719 Prec@5 19.531
Time: 8.99
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=12, intgelu_exp_n=0
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=12, intgelu_exp_n=0, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  12
IntGELU    | n:  0
IntSoftmax | n:  12
IntGELU    | n:  0
IntSoftmax | n:  12
IntGELU    | n:  0
IntSoftmax | n:  12
IntGELU    | n:  0
IntSoftmax | n:  12
IntGELU    | n:  0
IntSoftmax | n:  12
IntGELU    | n:  0
IntSoftmax | n:  12
IntGELU    | n:  0
IntSoftmax | n:  12
IntGELU    | n:  0
IntSoftmax | n:  12
IntGELU    | n:  0
IntSoftmax | n:  12
IntGELU    | n:  0
IntSoftmax | n:  12
IntGELU    | n:  0
IntSoftmax | n:  12
IntGELU    | n:  0
.calib done
Test: [  0/391]	Time  3.992 ( 3.992)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.92
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=12, intgelu_exp_n=1
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=12, intgelu_exp_n=1, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  12
IntGELU    | n:  1
IntSoftmax | n:  12
IntGELU    | n:  1
IntSoftmax | n:  12
IntGELU    | n:  1
IntSoftmax | n:  12
IntGELU    | n:  1
IntSoftmax | n:  12
IntGELU    | n:  1
IntSoftmax | n:  12
IntGELU    | n:  1
IntSoftmax | n:  12
IntGELU    | n:  1
IntSoftmax | n:  12
IntGELU    | n:  1
IntSoftmax | n:  12
IntGELU    | n:  1
IntSoftmax | n:  12
IntGELU    | n:  1
IntSoftmax | n:  12
IntGELU    | n:  1
IntSoftmax | n:  12
IntGELU    | n:  1
.calib done
Test: [  0/391]	Time  3.833 ( 3.833)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.83
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=12, intgelu_exp_n=2
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=12, intgelu_exp_n=2, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  12
IntGELU    | n:  2
IntSoftmax | n:  12
IntGELU    | n:  2
IntSoftmax | n:  12
IntGELU    | n:  2
IntSoftmax | n:  12
IntGELU    | n:  2
IntSoftmax | n:  12
IntGELU    | n:  2
IntSoftmax | n:  12
IntGELU    | n:  2
IntSoftmax | n:  12
IntGELU    | n:  2
IntSoftmax | n:  12
IntGELU    | n:  2
IntSoftmax | n:  12
IntGELU    | n:  2
IntSoftmax | n:  12
IntGELU    | n:  2
IntSoftmax | n:  12
IntGELU    | n:  2
IntSoftmax | n:  12
IntGELU    | n:  2
.calib done
Test: [  0/391]	Time  3.813 ( 3.813)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.68
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=12, intgelu_exp_n=3
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=12, intgelu_exp_n=3, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  12
IntGELU    | n:  3
IntSoftmax | n:  12
IntGELU    | n:  3
IntSoftmax | n:  12
IntGELU    | n:  3
IntSoftmax | n:  12
IntGELU    | n:  3
IntSoftmax | n:  12
IntGELU    | n:  3
IntSoftmax | n:  12
IntGELU    | n:  3
IntSoftmax | n:  12
IntGELU    | n:  3
IntSoftmax | n:  12
IntGELU    | n:  3
IntSoftmax | n:  12
IntGELU    | n:  3
IntSoftmax | n:  12
IntGELU    | n:  3
IntSoftmax | n:  12
IntGELU    | n:  3
IntSoftmax | n:  12
IntGELU    | n:  3
.calib done
Test: [  0/391]	Time  3.707 ( 3.707)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.68
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=12, intgelu_exp_n=4
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=12, intgelu_exp_n=4, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  12
IntGELU    | n:  4
IntSoftmax | n:  12
IntGELU    | n:  4
IntSoftmax | n:  12
IntGELU    | n:  4
IntSoftmax | n:  12
IntGELU    | n:  4
IntSoftmax | n:  12
IntGELU    | n:  4
IntSoftmax | n:  12
IntGELU    | n:  4
IntSoftmax | n:  12
IntGELU    | n:  4
IntSoftmax | n:  12
IntGELU    | n:  4
IntSoftmax | n:  12
IntGELU    | n:  4
IntSoftmax | n:  12
IntGELU    | n:  4
IntSoftmax | n:  12
IntGELU    | n:  4
IntSoftmax | n:  12
IntGELU    | n:  4
.calib done
Test: [  0/391]	Time  3.896 ( 3.896)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.93
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=12, intgelu_exp_n=5
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=12, intgelu_exp_n=5, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  12
IntGELU    | n:  5
IntSoftmax | n:  12
IntGELU    | n:  5
IntSoftmax | n:  12
IntGELU    | n:  5
IntSoftmax | n:  12
IntGELU    | n:  5
IntSoftmax | n:  12
IntGELU    | n:  5
IntSoftmax | n:  12
IntGELU    | n:  5
IntSoftmax | n:  12
IntGELU    | n:  5
IntSoftmax | n:  12
IntGELU    | n:  5
IntSoftmax | n:  12
IntGELU    | n:  5
IntSoftmax | n:  12
IntGELU    | n:  5
IntSoftmax | n:  12
IntGELU    | n:  5
IntSoftmax | n:  12
IntGELU    | n:  5
.calib done
Test: [  0/391]	Time  3.949 ( 3.949)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.91
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=12, intgelu_exp_n=6
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=12, intgelu_exp_n=6, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  12
IntGELU    | n:  6
IntSoftmax | n:  12
IntGELU    | n:  6
IntSoftmax | n:  12
IntGELU    | n:  6
IntSoftmax | n:  12
IntGELU    | n:  6
IntSoftmax | n:  12
IntGELU    | n:  6
IntSoftmax | n:  12
IntGELU    | n:  6
IntSoftmax | n:  12
IntGELU    | n:  6
IntSoftmax | n:  12
IntGELU    | n:  6
IntSoftmax | n:  12
IntGELU    | n:  6
IntSoftmax | n:  12
IntGELU    | n:  6
IntSoftmax | n:  12
IntGELU    | n:  6
IntSoftmax | n:  12
IntGELU    | n:  6
.calib done
Test: [  0/391]	Time  3.713 ( 3.713)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.65
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=12, intgelu_exp_n=7
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=12, intgelu_exp_n=7, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  12
IntGELU    | n:  7
IntSoftmax | n:  12
IntGELU    | n:  7
IntSoftmax | n:  12
IntGELU    | n:  7
IntSoftmax | n:  12
IntGELU    | n:  7
IntSoftmax | n:  12
IntGELU    | n:  7
IntSoftmax | n:  12
IntGELU    | n:  7
IntSoftmax | n:  12
IntGELU    | n:  7
IntSoftmax | n:  12
IntGELU    | n:  7
IntSoftmax | n:  12
IntGELU    | n:  7
IntSoftmax | n:  12
IntGELU    | n:  7
IntSoftmax | n:  12
IntGELU    | n:  7
IntSoftmax | n:  12
IntGELU    | n:  7
.calib done
Test: [  0/391]	Time  3.965 ( 3.965)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.90
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=12, intgelu_exp_n=8
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=12, intgelu_exp_n=8, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  12
IntGELU    | n:  8
IntSoftmax | n:  12
IntGELU    | n:  8
IntSoftmax | n:  12
IntGELU    | n:  8
IntSoftmax | n:  12
IntGELU    | n:  8
IntSoftmax | n:  12
IntGELU    | n:  8
IntSoftmax | n:  12
IntGELU    | n:  8
IntSoftmax | n:  12
IntGELU    | n:  8
IntSoftmax | n:  12
IntGELU    | n:  8
IntSoftmax | n:  12
IntGELU    | n:  8
IntSoftmax | n:  12
IntGELU    | n:  8
IntSoftmax | n:  12
IntGELU    | n:  8
IntSoftmax | n:  12
IntGELU    | n:  8
.calib done
Test: [  0/391]	Time  3.829 ( 3.829)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.76
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=12, intgelu_exp_n=9
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=12, intgelu_exp_n=9, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  12
IntGELU    | n:  9
IntSoftmax | n:  12
IntGELU    | n:  9
IntSoftmax | n:  12
IntGELU    | n:  9
IntSoftmax | n:  12
IntGELU    | n:  9
IntSoftmax | n:  12
IntGELU    | n:  9
IntSoftmax | n:  12
IntGELU    | n:  9
IntSoftmax | n:  12
IntGELU    | n:  9
IntSoftmax | n:  12
IntGELU    | n:  9
IntSoftmax | n:  12
IntGELU    | n:  9
IntSoftmax | n:  12
IntGELU    | n:  9
IntSoftmax | n:  12
IntGELU    | n:  9
IntSoftmax | n:  12
IntGELU    | n:  9
.calib done
Test: [  0/391]	Time  3.804 ( 3.804)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.81
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=12, intgelu_exp_n=10
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=12, intgelu_exp_n=10, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  12
IntGELU    | n:  10
IntSoftmax | n:  12
IntGELU    | n:  10
IntSoftmax | n:  12
IntGELU    | n:  10
IntSoftmax | n:  12
IntGELU    | n:  10
IntSoftmax | n:  12
IntGELU    | n:  10
IntSoftmax | n:  12
IntGELU    | n:  10
IntSoftmax | n:  12
IntGELU    | n:  10
IntSoftmax | n:  12
IntGELU    | n:  10
IntSoftmax | n:  12
IntGELU    | n:  10
IntSoftmax | n:  12
IntGELU    | n:  10
IntSoftmax | n:  12
IntGELU    | n:  10
IntSoftmax | n:  12
IntGELU    | n:  10
.calib done
Test: [  0/391]	Time  3.852 ( 3.852)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.83
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=12, intgelu_exp_n=11
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=12, intgelu_exp_n=11, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  12
IntGELU    | n:  11
IntSoftmax | n:  12
IntGELU    | n:  11
IntSoftmax | n:  12
IntGELU    | n:  11
IntSoftmax | n:  12
IntGELU    | n:  11
IntSoftmax | n:  12
IntGELU    | n:  11
IntSoftmax | n:  12
IntGELU    | n:  11
IntSoftmax | n:  12
IntGELU    | n:  11
IntSoftmax | n:  12
IntGELU    | n:  11
IntSoftmax | n:  12
IntGELU    | n:  11
IntSoftmax | n:  12
IntGELU    | n:  11
IntSoftmax | n:  12
IntGELU    | n:  11
IntSoftmax | n:  12
IntGELU    | n:  11
.calib done
Test: [  0/391]	Time  3.794 ( 3.794)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.70
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=12, intgelu_exp_n=12
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=12, intgelu_exp_n=12, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  12
IntGELU    | n:  12
IntSoftmax | n:  12
IntGELU    | n:  12
IntSoftmax | n:  12
IntGELU    | n:  12
IntSoftmax | n:  12
IntGELU    | n:  12
IntSoftmax | n:  12
IntGELU    | n:  12
IntSoftmax | n:  12
IntGELU    | n:  12
IntSoftmax | n:  12
IntGELU    | n:  12
IntSoftmax | n:  12
IntGELU    | n:  12
IntSoftmax | n:  12
IntGELU    | n:  12
IntSoftmax | n:  12
IntGELU    | n:  12
IntSoftmax | n:  12
IntGELU    | n:  12
IntSoftmax | n:  12
IntGELU    | n:  12
.calib done
Test: [  0/391]	Time  3.768 ( 3.768)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.74
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=12, intgelu_exp_n=13
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=12, intgelu_exp_n=13, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  12
IntGELU    | n:  13
IntSoftmax | n:  12
IntGELU    | n:  13
IntSoftmax | n:  12
IntGELU    | n:  13
IntSoftmax | n:  12
IntGELU    | n:  13
IntSoftmax | n:  12
IntGELU    | n:  13
IntSoftmax | n:  12
IntGELU    | n:  13
IntSoftmax | n:  12
IntGELU    | n:  13
IntSoftmax | n:  12
IntGELU    | n:  13
IntSoftmax | n:  12
IntGELU    | n:  13
IntSoftmax | n:  12
IntGELU    | n:  13
IntSoftmax | n:  12
IntGELU    | n:  13
IntSoftmax | n:  12
IntGELU    | n:  13
.calib done
Test: [  0/391]	Time  3.684 ( 3.684)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.63
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=12, intgelu_exp_n=14
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=12, intgelu_exp_n=14, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  12
IntGELU    | n:  14
IntSoftmax | n:  12
IntGELU    | n:  14
IntSoftmax | n:  12
IntGELU    | n:  14
IntSoftmax | n:  12
IntGELU    | n:  14
IntSoftmax | n:  12
IntGELU    | n:  14
IntSoftmax | n:  12
IntGELU    | n:  14
IntSoftmax | n:  12
IntGELU    | n:  14
IntSoftmax | n:  12
IntGELU    | n:  14
IntSoftmax | n:  12
IntGELU    | n:  14
IntSoftmax | n:  12
IntGELU    | n:  14
IntSoftmax | n:  12
IntGELU    | n:  14
IntSoftmax | n:  12
IntGELU    | n:  14
.calib done
Test: [  0/391]	Time  3.817 ( 3.817)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.85
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=12, intgelu_exp_n=15
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=12, intgelu_exp_n=15, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  12
IntGELU    | n:  15
IntSoftmax | n:  12
IntGELU    | n:  15
IntSoftmax | n:  12
IntGELU    | n:  15
IntSoftmax | n:  12
IntGELU    | n:  15
IntSoftmax | n:  12
IntGELU    | n:  15
IntSoftmax | n:  12
IntGELU    | n:  15
IntSoftmax | n:  12
IntGELU    | n:  15
IntSoftmax | n:  12
IntGELU    | n:  15
IntSoftmax | n:  12
IntGELU    | n:  15
IntSoftmax | n:  12
IntGELU    | n:  15
IntSoftmax | n:  12
IntGELU    | n:  15
IntSoftmax | n:  12
IntGELU    | n:  15
.calib done
Test: [  0/391]	Time  3.876 ( 3.876)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.81
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=12, intgelu_exp_n=16
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=12, intgelu_exp_n=16, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  12
IntGELU    | n:  16
IntSoftmax | n:  12
IntGELU    | n:  16
IntSoftmax | n:  12
IntGELU    | n:  16
IntSoftmax | n:  12
IntGELU    | n:  16
IntSoftmax | n:  12
IntGELU    | n:  16
IntSoftmax | n:  12
IntGELU    | n:  16
IntSoftmax | n:  12
IntGELU    | n:  16
IntSoftmax | n:  12
IntGELU    | n:  16
IntSoftmax | n:  12
IntGELU    | n:  16
IntSoftmax | n:  12
IntGELU    | n:  16
IntSoftmax | n:  12
IntGELU    | n:  16
IntSoftmax | n:  12
IntGELU    | n:  16
.calib done
Test: [  0/391]	Time  3.906 ( 3.906)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.86
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=12, intgelu_exp_n=17
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=12, intgelu_exp_n=17, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  12
IntGELU    | n:  17
IntSoftmax | n:  12
IntGELU    | n:  17
IntSoftmax | n:  12
IntGELU    | n:  17
IntSoftmax | n:  12
IntGELU    | n:  17
IntSoftmax | n:  12
IntGELU    | n:  17
IntSoftmax | n:  12
IntGELU    | n:  17
IntSoftmax | n:  12
IntGELU    | n:  17
IntSoftmax | n:  12
IntGELU    | n:  17
IntSoftmax | n:  12
IntGELU    | n:  17
IntSoftmax | n:  12
IntGELU    | n:  17
IntSoftmax | n:  12
IntGELU    | n:  17
IntSoftmax | n:  12
IntGELU    | n:  17
.calib done
Test: [  0/391]	Time  3.897 ( 3.897)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.86
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=12, intgelu_exp_n=18
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=12, intgelu_exp_n=18, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  12
IntGELU    | n:  18
IntSoftmax | n:  12
IntGELU    | n:  18
IntSoftmax | n:  12
IntGELU    | n:  18
IntSoftmax | n:  12
IntGELU    | n:  18
IntSoftmax | n:  12
IntGELU    | n:  18
IntSoftmax | n:  12
IntGELU    | n:  18
IntSoftmax | n:  12
IntGELU    | n:  18
IntSoftmax | n:  12
IntGELU    | n:  18
IntSoftmax | n:  12
IntGELU    | n:  18
IntSoftmax | n:  12
IntGELU    | n:  18
IntSoftmax | n:  12
IntGELU    | n:  18
IntSoftmax | n:  12
IntGELU    | n:  18
.calib done
Test: [  0/391]	Time  4.002 ( 4.002)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.99
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=12, intgelu_exp_n=19
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=12, intgelu_exp_n=19, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  12
IntGELU    | n:  19
IntSoftmax | n:  12
IntGELU    | n:  19
IntSoftmax | n:  12
IntGELU    | n:  19
IntSoftmax | n:  12
IntGELU    | n:  19
IntSoftmax | n:  12
IntGELU    | n:  19
IntSoftmax | n:  12
IntGELU    | n:  19
IntSoftmax | n:  12
IntGELU    | n:  19
IntSoftmax | n:  12
IntGELU    | n:  19
IntSoftmax | n:  12
IntGELU    | n:  19
IntSoftmax | n:  12
IntGELU    | n:  19
IntSoftmax | n:  12
IntGELU    | n:  19
IntSoftmax | n:  12
IntGELU    | n:  19
.calib done
Test: [  0/391]	Time  4.009 ( 4.009)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 9.06
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=12, intgelu_exp_n=20
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=12, intgelu_exp_n=20, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  12
IntGELU    | n:  20
IntSoftmax | n:  12
IntGELU    | n:  20
IntSoftmax | n:  12
IntGELU    | n:  20
IntSoftmax | n:  12
IntGELU    | n:  20
IntSoftmax | n:  12
IntGELU    | n:  20
IntSoftmax | n:  12
IntGELU    | n:  20
IntSoftmax | n:  12
IntGELU    | n:  20
IntSoftmax | n:  12
IntGELU    | n:  20
IntSoftmax | n:  12
IntGELU    | n:  20
IntSoftmax | n:  12
IntGELU    | n:  20
IntSoftmax | n:  12
IntGELU    | n:  20
IntSoftmax | n:  12
IntGELU    | n:  20
.calib done
Test: [  0/391]	Time  3.910 ( 3.910)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.91
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=12, intgelu_exp_n=21
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=12, intgelu_exp_n=21, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  12
IntGELU    | n:  21
IntSoftmax | n:  12
IntGELU    | n:  21
IntSoftmax | n:  12
IntGELU    | n:  21
IntSoftmax | n:  12
IntGELU    | n:  21
IntSoftmax | n:  12
IntGELU    | n:  21
IntSoftmax | n:  12
IntGELU    | n:  21
IntSoftmax | n:  12
IntGELU    | n:  21
IntSoftmax | n:  12
IntGELU    | n:  21
IntSoftmax | n:  12
IntGELU    | n:  21
IntSoftmax | n:  12
IntGELU    | n:  21
IntSoftmax | n:  12
IntGELU    | n:  21
IntSoftmax | n:  12
IntGELU    | n:  21
.calib done
Test: [  0/391]	Time  3.970 ( 3.970)	Acc@1  10.16 ( 10.16)	Acc@5  22.66 ( 22.66)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 10.156 Prec@5 22.656
Time: 8.90
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=12, intgelu_exp_n=22
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=12, intgelu_exp_n=22, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  12
IntGELU    | n:  22
IntSoftmax | n:  12
IntGELU    | n:  22
IntSoftmax | n:  12
IntGELU    | n:  22
IntSoftmax | n:  12
IntGELU    | n:  22
IntSoftmax | n:  12
IntGELU    | n:  22
IntSoftmax | n:  12
IntGELU    | n:  22
IntSoftmax | n:  12
IntGELU    | n:  22
IntSoftmax | n:  12
IntGELU    | n:  22
IntSoftmax | n:  12
IntGELU    | n:  22
IntSoftmax | n:  12
IntGELU    | n:  22
IntSoftmax | n:  12
IntGELU    | n:  22
IntSoftmax | n:  12
IntGELU    | n:  22
.calib done
Test: [  0/391]	Time  3.999 ( 3.999)	Acc@1   9.38 (  9.38)	Acc@5  21.88 ( 21.88)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 9.375 Prec@5 21.875
Time: 8.95
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=12, intgelu_exp_n=23
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=12, intgelu_exp_n=23, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  12
IntGELU    | n:  23
IntSoftmax | n:  12
IntGELU    | n:  23
IntSoftmax | n:  12
IntGELU    | n:  23
IntSoftmax | n:  12
IntGELU    | n:  23
IntSoftmax | n:  12
IntGELU    | n:  23
IntSoftmax | n:  12
IntGELU    | n:  23
IntSoftmax | n:  12
IntGELU    | n:  23
IntSoftmax | n:  12
IntGELU    | n:  23
IntSoftmax | n:  12
IntGELU    | n:  23
IntSoftmax | n:  12
IntGELU    | n:  23
IntSoftmax | n:  12
IntGELU    | n:  23
IntSoftmax | n:  12
IntGELU    | n:  23
.calib done
Test: [  0/391]	Time  3.831 ( 3.831)	Acc@1  13.28 ( 13.28)	Acc@5  30.47 ( 30.47)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 13.281 Prec@5 30.469
Time: 8.79
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=12, intgelu_exp_n=24
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=12, intgelu_exp_n=24, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  12
IntGELU    | n:  24
IntSoftmax | n:  12
IntGELU    | n:  24
IntSoftmax | n:  12
IntGELU    | n:  24
IntSoftmax | n:  12
IntGELU    | n:  24
IntSoftmax | n:  12
IntGELU    | n:  24
IntSoftmax | n:  12
IntGELU    | n:  24
IntSoftmax | n:  12
IntGELU    | n:  24
IntSoftmax | n:  12
IntGELU    | n:  24
IntSoftmax | n:  12
IntGELU    | n:  24
IntSoftmax | n:  12
IntGELU    | n:  24
IntSoftmax | n:  12
IntGELU    | n:  24
IntSoftmax | n:  12
IntGELU    | n:  24
.calib done
Test: [  0/391]	Time  4.077 ( 4.077)	Acc@1  11.72 ( 11.72)	Acc@5  29.69 ( 29.69)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 11.719 Prec@5 29.688
Time: 9.05
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=12, intgelu_exp_n=25
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=12, intgelu_exp_n=25, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  12
IntGELU    | n:  25
IntSoftmax | n:  12
IntGELU    | n:  25
IntSoftmax | n:  12
IntGELU    | n:  25
IntSoftmax | n:  12
IntGELU    | n:  25
IntSoftmax | n:  12
IntGELU    | n:  25
IntSoftmax | n:  12
IntGELU    | n:  25
IntSoftmax | n:  12
IntGELU    | n:  25
IntSoftmax | n:  12
IntGELU    | n:  25
IntSoftmax | n:  12
IntGELU    | n:  25
IntSoftmax | n:  12
IntGELU    | n:  25
IntSoftmax | n:  12
IntGELU    | n:  25
IntSoftmax | n:  12
IntGELU    | n:  25
.calib done
Test: [  0/391]	Time  3.705 ( 3.705)	Acc@1  17.19 ( 17.19)	Acc@5  35.94 ( 35.94)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 17.188 Prec@5 35.938
Time: 8.66
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=12, intgelu_exp_n=26
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=12, intgelu_exp_n=26, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  12
IntGELU    | n:  26
IntSoftmax | n:  12
IntGELU    | n:  26
IntSoftmax | n:  12
IntGELU    | n:  26
IntSoftmax | n:  12
IntGELU    | n:  26
IntSoftmax | n:  12
IntGELU    | n:  26
IntSoftmax | n:  12
IntGELU    | n:  26
IntSoftmax | n:  12
IntGELU    | n:  26
IntSoftmax | n:  12
IntGELU    | n:  26
IntSoftmax | n:  12
IntGELU    | n:  26
IntSoftmax | n:  12
IntGELU    | n:  26
IntSoftmax | n:  12
IntGELU    | n:  26
IntSoftmax | n:  12
IntGELU    | n:  26
.calib done
Test: [  0/391]	Time  3.954 ( 3.954)	Acc@1  23.44 ( 23.44)	Acc@5  43.75 ( 43.75)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 23.438 Prec@5 43.750
Time: 8.95
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=12, intgelu_exp_n=27
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=12, intgelu_exp_n=27, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  12
IntGELU    | n:  27
IntSoftmax | n:  12
IntGELU    | n:  27
IntSoftmax | n:  12
IntGELU    | n:  27
IntSoftmax | n:  12
IntGELU    | n:  27
IntSoftmax | n:  12
IntGELU    | n:  27
IntSoftmax | n:  12
IntGELU    | n:  27
IntSoftmax | n:  12
IntGELU    | n:  27
IntSoftmax | n:  12
IntGELU    | n:  27
IntSoftmax | n:  12
IntGELU    | n:  27
IntSoftmax | n:  12
IntGELU    | n:  27
IntSoftmax | n:  12
IntGELU    | n:  27
IntSoftmax | n:  12
IntGELU    | n:  27
.calib done
Test: [  0/391]	Time  3.941 ( 3.941)	Acc@1  28.12 ( 28.12)	Acc@5  50.78 ( 50.78)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 28.125 Prec@5 50.781
Time: 8.92
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=12, intgelu_exp_n=28
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=12, intgelu_exp_n=28, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  12
IntGELU    | n:  28
IntSoftmax | n:  12
IntGELU    | n:  28
IntSoftmax | n:  12
IntGELU    | n:  28
IntSoftmax | n:  12
IntGELU    | n:  28
IntSoftmax | n:  12
IntGELU    | n:  28
IntSoftmax | n:  12
IntGELU    | n:  28
IntSoftmax | n:  12
IntGELU    | n:  28
IntSoftmax | n:  12
IntGELU    | n:  28
IntSoftmax | n:  12
IntGELU    | n:  28
IntSoftmax | n:  12
IntGELU    | n:  28
IntSoftmax | n:  12
IntGELU    | n:  28
IntSoftmax | n:  12
IntGELU    | n:  28
.calib done
Test: [  0/391]	Time  3.942 ( 3.942)	Acc@1  25.78 ( 25.78)	Acc@5  53.91 ( 53.91)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 25.781 Prec@5 53.906
Time: 8.87
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=12, intgelu_exp_n=29
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=12, intgelu_exp_n=29, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  12
IntGELU    | n:  29
IntSoftmax | n:  12
IntGELU    | n:  29
IntSoftmax | n:  12
IntGELU    | n:  29
IntSoftmax | n:  12
IntGELU    | n:  29
IntSoftmax | n:  12
IntGELU    | n:  29
IntSoftmax | n:  12
IntGELU    | n:  29
IntSoftmax | n:  12
IntGELU    | n:  29
IntSoftmax | n:  12
IntGELU    | n:  29
IntSoftmax | n:  12
IntGELU    | n:  29
IntSoftmax | n:  12
IntGELU    | n:  29
IntSoftmax | n:  12
IntGELU    | n:  29
IntSoftmax | n:  12
IntGELU    | n:  29
.calib done
Test: [  0/391]	Time  3.946 ( 3.946)	Acc@1  29.69 ( 29.69)	Acc@5  56.25 ( 56.25)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 29.688 Prec@5 56.250
Time: 8.86
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=12, intgelu_exp_n=30
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=12, intgelu_exp_n=30, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  12
IntGELU    | n:  30
IntSoftmax | n:  12
IntGELU    | n:  30
IntSoftmax | n:  12
IntGELU    | n:  30
IntSoftmax | n:  12
IntGELU    | n:  30
IntSoftmax | n:  12
IntGELU    | n:  30
IntSoftmax | n:  12
IntGELU    | n:  30
IntSoftmax | n:  12
IntGELU    | n:  30
IntSoftmax | n:  12
IntGELU    | n:  30
IntSoftmax | n:  12
IntGELU    | n:  30
IntSoftmax | n:  12
IntGELU    | n:  30
IntSoftmax | n:  12
IntGELU    | n:  30
IntSoftmax | n:  12
IntGELU    | n:  30
.calib done
Test: [  0/391]	Time  3.937 ( 3.937)	Acc@1  63.28 ( 63.28)	Acc@5  89.06 ( 89.06)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 63.281 Prec@5 89.062
Time: 8.93
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=12, intgelu_exp_n=31
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=12, intgelu_exp_n=31, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  12
IntGELU    | n:  31
IntSoftmax | n:  12
IntGELU    | n:  31
IntSoftmax | n:  12
IntGELU    | n:  31
IntSoftmax | n:  12
IntGELU    | n:  31
IntSoftmax | n:  12
IntGELU    | n:  31
IntSoftmax | n:  12
IntGELU    | n:  31
IntSoftmax | n:  12
IntGELU    | n:  31
IntSoftmax | n:  12
IntGELU    | n:  31
IntSoftmax | n:  12
IntGELU    | n:  31
IntSoftmax | n:  12
IntGELU    | n:  31
IntSoftmax | n:  12
IntGELU    | n:  31
IntSoftmax | n:  12
IntGELU    | n:  31
.calib done
Test: [  0/391]	Time  3.900 ( 3.900)	Acc@1  10.16 ( 10.16)	Acc@5  18.75 ( 18.75)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 10.156 Prec@5 18.750
Time: 8.80
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=13, intgelu_exp_n=0
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=13, intgelu_exp_n=0, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  13
IntGELU    | n:  0
IntSoftmax | n:  13
IntGELU    | n:  0
IntSoftmax | n:  13
IntGELU    | n:  0
IntSoftmax | n:  13
IntGELU    | n:  0
IntSoftmax | n:  13
IntGELU    | n:  0
IntSoftmax | n:  13
IntGELU    | n:  0
IntSoftmax | n:  13
IntGELU    | n:  0
IntSoftmax | n:  13
IntGELU    | n:  0
IntSoftmax | n:  13
IntGELU    | n:  0
IntSoftmax | n:  13
IntGELU    | n:  0
IntSoftmax | n:  13
IntGELU    | n:  0
IntSoftmax | n:  13
IntGELU    | n:  0
.calib done
Test: [  0/391]	Time  3.743 ( 3.743)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.74
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=13, intgelu_exp_n=1
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=13, intgelu_exp_n=1, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  13
IntGELU    | n:  1
IntSoftmax | n:  13
IntGELU    | n:  1
IntSoftmax | n:  13
IntGELU    | n:  1
IntSoftmax | n:  13
IntGELU    | n:  1
IntSoftmax | n:  13
IntGELU    | n:  1
IntSoftmax | n:  13
IntGELU    | n:  1
IntSoftmax | n:  13
IntGELU    | n:  1
IntSoftmax | n:  13
IntGELU    | n:  1
IntSoftmax | n:  13
IntGELU    | n:  1
IntSoftmax | n:  13
IntGELU    | n:  1
IntSoftmax | n:  13
IntGELU    | n:  1
IntSoftmax | n:  13
IntGELU    | n:  1
.calib done
Test: [  0/391]	Time  3.934 ( 3.934)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.90
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=13, intgelu_exp_n=2
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=13, intgelu_exp_n=2, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  13
IntGELU    | n:  2
IntSoftmax | n:  13
IntGELU    | n:  2
IntSoftmax | n:  13
IntGELU    | n:  2
IntSoftmax | n:  13
IntGELU    | n:  2
IntSoftmax | n:  13
IntGELU    | n:  2
IntSoftmax | n:  13
IntGELU    | n:  2
IntSoftmax | n:  13
IntGELU    | n:  2
IntSoftmax | n:  13
IntGELU    | n:  2
IntSoftmax | n:  13
IntGELU    | n:  2
IntSoftmax | n:  13
IntGELU    | n:  2
IntSoftmax | n:  13
IntGELU    | n:  2
IntSoftmax | n:  13
IntGELU    | n:  2
.calib done
Test: [  0/391]	Time  3.895 ( 3.895)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.81
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=13, intgelu_exp_n=3
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=13, intgelu_exp_n=3, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  13
IntGELU    | n:  3
IntSoftmax | n:  13
IntGELU    | n:  3
IntSoftmax | n:  13
IntGELU    | n:  3
IntSoftmax | n:  13
IntGELU    | n:  3
IntSoftmax | n:  13
IntGELU    | n:  3
IntSoftmax | n:  13
IntGELU    | n:  3
IntSoftmax | n:  13
IntGELU    | n:  3
IntSoftmax | n:  13
IntGELU    | n:  3
IntSoftmax | n:  13
IntGELU    | n:  3
IntSoftmax | n:  13
IntGELU    | n:  3
IntSoftmax | n:  13
IntGELU    | n:  3
IntSoftmax | n:  13
IntGELU    | n:  3
.calib done
Test: [  0/391]	Time  3.952 ( 3.952)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.88
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=13, intgelu_exp_n=4
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=13, intgelu_exp_n=4, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  13
IntGELU    | n:  4
IntSoftmax | n:  13
IntGELU    | n:  4
IntSoftmax | n:  13
IntGELU    | n:  4
IntSoftmax | n:  13
IntGELU    | n:  4
IntSoftmax | n:  13
IntGELU    | n:  4
IntSoftmax | n:  13
IntGELU    | n:  4
IntSoftmax | n:  13
IntGELU    | n:  4
IntSoftmax | n:  13
IntGELU    | n:  4
IntSoftmax | n:  13
IntGELU    | n:  4
IntSoftmax | n:  13
IntGELU    | n:  4
IntSoftmax | n:  13
IntGELU    | n:  4
IntSoftmax | n:  13
IntGELU    | n:  4
.calib done
Test: [  0/391]	Time  3.832 ( 3.832)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.80
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=13, intgelu_exp_n=5
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=13, intgelu_exp_n=5, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  13
IntGELU    | n:  5
IntSoftmax | n:  13
IntGELU    | n:  5
IntSoftmax | n:  13
IntGELU    | n:  5
IntSoftmax | n:  13
IntGELU    | n:  5
IntSoftmax | n:  13
IntGELU    | n:  5
IntSoftmax | n:  13
IntGELU    | n:  5
IntSoftmax | n:  13
IntGELU    | n:  5
IntSoftmax | n:  13
IntGELU    | n:  5
IntSoftmax | n:  13
IntGELU    | n:  5
IntSoftmax | n:  13
IntGELU    | n:  5
IntSoftmax | n:  13
IntGELU    | n:  5
IntSoftmax | n:  13
IntGELU    | n:  5
.calib done
Test: [  0/391]	Time  3.734 ( 3.734)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.72
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=13, intgelu_exp_n=6
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=13, intgelu_exp_n=6, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  13
IntGELU    | n:  6
IntSoftmax | n:  13
IntGELU    | n:  6
IntSoftmax | n:  13
IntGELU    | n:  6
IntSoftmax | n:  13
IntGELU    | n:  6
IntSoftmax | n:  13
IntGELU    | n:  6
IntSoftmax | n:  13
IntGELU    | n:  6
IntSoftmax | n:  13
IntGELU    | n:  6
IntSoftmax | n:  13
IntGELU    | n:  6
IntSoftmax | n:  13
IntGELU    | n:  6
IntSoftmax | n:  13
IntGELU    | n:  6
IntSoftmax | n:  13
IntGELU    | n:  6
IntSoftmax | n:  13
IntGELU    | n:  6
.calib done
Test: [  0/391]	Time  3.912 ( 3.912)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.83
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=13, intgelu_exp_n=7
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=13, intgelu_exp_n=7, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  13
IntGELU    | n:  7
IntSoftmax | n:  13
IntGELU    | n:  7
IntSoftmax | n:  13
IntGELU    | n:  7
IntSoftmax | n:  13
IntGELU    | n:  7
IntSoftmax | n:  13
IntGELU    | n:  7
IntSoftmax | n:  13
IntGELU    | n:  7
IntSoftmax | n:  13
IntGELU    | n:  7
IntSoftmax | n:  13
IntGELU    | n:  7
IntSoftmax | n:  13
IntGELU    | n:  7
IntSoftmax | n:  13
IntGELU    | n:  7
IntSoftmax | n:  13
IntGELU    | n:  7
IntSoftmax | n:  13
IntGELU    | n:  7
.calib done
Test: [  0/391]	Time  3.705 ( 3.705)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.74
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=13, intgelu_exp_n=8
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=13, intgelu_exp_n=8, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  13
IntGELU    | n:  8
IntSoftmax | n:  13
IntGELU    | n:  8
IntSoftmax | n:  13
IntGELU    | n:  8
IntSoftmax | n:  13
IntGELU    | n:  8
IntSoftmax | n:  13
IntGELU    | n:  8
IntSoftmax | n:  13
IntGELU    | n:  8
IntSoftmax | n:  13
IntGELU    | n:  8
IntSoftmax | n:  13
IntGELU    | n:  8
IntSoftmax | n:  13
IntGELU    | n:  8
IntSoftmax | n:  13
IntGELU    | n:  8
IntSoftmax | n:  13
IntGELU    | n:  8
IntSoftmax | n:  13
IntGELU    | n:  8
.calib done
Test: [  0/391]	Time  3.891 ( 3.891)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.80
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=13, intgelu_exp_n=9
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=13, intgelu_exp_n=9, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  13
IntGELU    | n:  9
IntSoftmax | n:  13
IntGELU    | n:  9
IntSoftmax | n:  13
IntGELU    | n:  9
IntSoftmax | n:  13
IntGELU    | n:  9
IntSoftmax | n:  13
IntGELU    | n:  9
IntSoftmax | n:  13
IntGELU    | n:  9
IntSoftmax | n:  13
IntGELU    | n:  9
IntSoftmax | n:  13
IntGELU    | n:  9
IntSoftmax | n:  13
IntGELU    | n:  9
IntSoftmax | n:  13
IntGELU    | n:  9
IntSoftmax | n:  13
IntGELU    | n:  9
IntSoftmax | n:  13
IntGELU    | n:  9
.calib done
Test: [  0/391]	Time  3.760 ( 3.760)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.74
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=13, intgelu_exp_n=10
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=13, intgelu_exp_n=10, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  13
IntGELU    | n:  10
IntSoftmax | n:  13
IntGELU    | n:  10
IntSoftmax | n:  13
IntGELU    | n:  10
IntSoftmax | n:  13
IntGELU    | n:  10
IntSoftmax | n:  13
IntGELU    | n:  10
IntSoftmax | n:  13
IntGELU    | n:  10
IntSoftmax | n:  13
IntGELU    | n:  10
IntSoftmax | n:  13
IntGELU    | n:  10
IntSoftmax | n:  13
IntGELU    | n:  10
IntSoftmax | n:  13
IntGELU    | n:  10
IntSoftmax | n:  13
IntGELU    | n:  10
IntSoftmax | n:  13
IntGELU    | n:  10
.calib done
Test: [  0/391]	Time  3.930 ( 3.930)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.95
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=13, intgelu_exp_n=11
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=13, intgelu_exp_n=11, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  13
IntGELU    | n:  11
IntSoftmax | n:  13
IntGELU    | n:  11
IntSoftmax | n:  13
IntGELU    | n:  11
IntSoftmax | n:  13
IntGELU    | n:  11
IntSoftmax | n:  13
IntGELU    | n:  11
IntSoftmax | n:  13
IntGELU    | n:  11
IntSoftmax | n:  13
IntGELU    | n:  11
IntSoftmax | n:  13
IntGELU    | n:  11
IntSoftmax | n:  13
IntGELU    | n:  11
IntSoftmax | n:  13
IntGELU    | n:  11
IntSoftmax | n:  13
IntGELU    | n:  11
IntSoftmax | n:  13
IntGELU    | n:  11
.calib done
Test: [  0/391]	Time  3.984 ( 3.984)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.94
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=13, intgelu_exp_n=12
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=13, intgelu_exp_n=12, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  13
IntGELU    | n:  12
IntSoftmax | n:  13
IntGELU    | n:  12
IntSoftmax | n:  13
IntGELU    | n:  12
IntSoftmax | n:  13
IntGELU    | n:  12
IntSoftmax | n:  13
IntGELU    | n:  12
IntSoftmax | n:  13
IntGELU    | n:  12
IntSoftmax | n:  13
IntGELU    | n:  12
IntSoftmax | n:  13
IntGELU    | n:  12
IntSoftmax | n:  13
IntGELU    | n:  12
IntSoftmax | n:  13
IntGELU    | n:  12
IntSoftmax | n:  13
IntGELU    | n:  12
IntSoftmax | n:  13
IntGELU    | n:  12
.calib done
Test: [  0/391]	Time  3.884 ( 3.884)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.81
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=13, intgelu_exp_n=13
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=13, intgelu_exp_n=13, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  13
IntGELU    | n:  13
IntSoftmax | n:  13
IntGELU    | n:  13
IntSoftmax | n:  13
IntGELU    | n:  13
IntSoftmax | n:  13
IntGELU    | n:  13
IntSoftmax | n:  13
IntGELU    | n:  13
IntSoftmax | n:  13
IntGELU    | n:  13
IntSoftmax | n:  13
IntGELU    | n:  13
IntSoftmax | n:  13
IntGELU    | n:  13
IntSoftmax | n:  13
IntGELU    | n:  13
IntSoftmax | n:  13
IntGELU    | n:  13
IntSoftmax | n:  13
IntGELU    | n:  13
IntSoftmax | n:  13
IntGELU    | n:  13
.calib done
Test: [  0/391]	Time  3.924 ( 3.924)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.89
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=13, intgelu_exp_n=14
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=13, intgelu_exp_n=14, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  13
IntGELU    | n:  14
IntSoftmax | n:  13
IntGELU    | n:  14
IntSoftmax | n:  13
IntGELU    | n:  14
IntSoftmax | n:  13
IntGELU    | n:  14
IntSoftmax | n:  13
IntGELU    | n:  14
IntSoftmax | n:  13
IntGELU    | n:  14
IntSoftmax | n:  13
IntGELU    | n:  14
IntSoftmax | n:  13
IntGELU    | n:  14
IntSoftmax | n:  13
IntGELU    | n:  14
IntSoftmax | n:  13
IntGELU    | n:  14
IntSoftmax | n:  13
IntGELU    | n:  14
IntSoftmax | n:  13
IntGELU    | n:  14
.calib done
Test: [  0/391]	Time  3.872 ( 3.872)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.83
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=13, intgelu_exp_n=15
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=13, intgelu_exp_n=15, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  13
IntGELU    | n:  15
IntSoftmax | n:  13
IntGELU    | n:  15
IntSoftmax | n:  13
IntGELU    | n:  15
IntSoftmax | n:  13
IntGELU    | n:  15
IntSoftmax | n:  13
IntGELU    | n:  15
IntSoftmax | n:  13
IntGELU    | n:  15
IntSoftmax | n:  13
IntGELU    | n:  15
IntSoftmax | n:  13
IntGELU    | n:  15
IntSoftmax | n:  13
IntGELU    | n:  15
IntSoftmax | n:  13
IntGELU    | n:  15
IntSoftmax | n:  13
IntGELU    | n:  15
IntSoftmax | n:  13
IntGELU    | n:  15
.calib done
Test: [  0/391]	Time  3.979 ( 3.979)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.94
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=13, intgelu_exp_n=16
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=13, intgelu_exp_n=16, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  13
IntGELU    | n:  16
IntSoftmax | n:  13
IntGELU    | n:  16
IntSoftmax | n:  13
IntGELU    | n:  16
IntSoftmax | n:  13
IntGELU    | n:  16
IntSoftmax | n:  13
IntGELU    | n:  16
IntSoftmax | n:  13
IntGELU    | n:  16
IntSoftmax | n:  13
IntGELU    | n:  16
IntSoftmax | n:  13
IntGELU    | n:  16
IntSoftmax | n:  13
IntGELU    | n:  16
IntSoftmax | n:  13
IntGELU    | n:  16
IntSoftmax | n:  13
IntGELU    | n:  16
IntSoftmax | n:  13
IntGELU    | n:  16
.calib done
Test: [  0/391]	Time  3.932 ( 3.932)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.84
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=13, intgelu_exp_n=17
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=13, intgelu_exp_n=17, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  13
IntGELU    | n:  17
IntSoftmax | n:  13
IntGELU    | n:  17
IntSoftmax | n:  13
IntGELU    | n:  17
IntSoftmax | n:  13
IntGELU    | n:  17
IntSoftmax | n:  13
IntGELU    | n:  17
IntSoftmax | n:  13
IntGELU    | n:  17
IntSoftmax | n:  13
IntGELU    | n:  17
IntSoftmax | n:  13
IntGELU    | n:  17
IntSoftmax | n:  13
IntGELU    | n:  17
IntSoftmax | n:  13
IntGELU    | n:  17
IntSoftmax | n:  13
IntGELU    | n:  17
IntSoftmax | n:  13
IntGELU    | n:  17
.calib done
Test: [  0/391]	Time  3.935 ( 3.935)	Acc@1   0.00 (  0.00)	Acc@5   3.91 (  3.91)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 3.906
Time: 8.89
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=13, intgelu_exp_n=18
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=13, intgelu_exp_n=18, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  13
IntGELU    | n:  18
IntSoftmax | n:  13
IntGELU    | n:  18
IntSoftmax | n:  13
IntGELU    | n:  18
IntSoftmax | n:  13
IntGELU    | n:  18
IntSoftmax | n:  13
IntGELU    | n:  18
IntSoftmax | n:  13
IntGELU    | n:  18
IntSoftmax | n:  13
IntGELU    | n:  18
IntSoftmax | n:  13
IntGELU    | n:  18
IntSoftmax | n:  13
IntGELU    | n:  18
IntSoftmax | n:  13
IntGELU    | n:  18
IntSoftmax | n:  13
IntGELU    | n:  18
IntSoftmax | n:  13
IntGELU    | n:  18
.calib done
Test: [  0/391]	Time  3.857 ( 3.857)	Acc@1   1.56 (  1.56)	Acc@5   3.12 (  3.12)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 1.562 Prec@5 3.125
Time: 8.85
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=13, intgelu_exp_n=19
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=13, intgelu_exp_n=19, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  13
IntGELU    | n:  19
IntSoftmax | n:  13
IntGELU    | n:  19
IntSoftmax | n:  13
IntGELU    | n:  19
IntSoftmax | n:  13
IntGELU    | n:  19
IntSoftmax | n:  13
IntGELU    | n:  19
IntSoftmax | n:  13
IntGELU    | n:  19
IntSoftmax | n:  13
IntGELU    | n:  19
IntSoftmax | n:  13
IntGELU    | n:  19
IntSoftmax | n:  13
IntGELU    | n:  19
IntSoftmax | n:  13
IntGELU    | n:  19
IntSoftmax | n:  13
IntGELU    | n:  19
IntSoftmax | n:  13
IntGELU    | n:  19
.calib done
Test: [  0/391]	Time  3.987 ( 3.987)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.93
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=13, intgelu_exp_n=20
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=13, intgelu_exp_n=20, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  13
IntGELU    | n:  20
IntSoftmax | n:  13
IntGELU    | n:  20
IntSoftmax | n:  13
IntGELU    | n:  20
IntSoftmax | n:  13
IntGELU    | n:  20
IntSoftmax | n:  13
IntGELU    | n:  20
IntSoftmax | n:  13
IntGELU    | n:  20
IntSoftmax | n:  13
IntGELU    | n:  20
IntSoftmax | n:  13
IntGELU    | n:  20
IntSoftmax | n:  13
IntGELU    | n:  20
IntSoftmax | n:  13
IntGELU    | n:  20
IntSoftmax | n:  13
IntGELU    | n:  20
IntSoftmax | n:  13
IntGELU    | n:  20
.calib done
Test: [  0/391]	Time  3.638 ( 3.638)	Acc@1   0.00 (  0.00)	Acc@5   0.78 (  0.78)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.781
Time: 8.61
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=13, intgelu_exp_n=21
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=13, intgelu_exp_n=21, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  13
IntGELU    | n:  21
IntSoftmax | n:  13
IntGELU    | n:  21
IntSoftmax | n:  13
IntGELU    | n:  21
IntSoftmax | n:  13
IntGELU    | n:  21
IntSoftmax | n:  13
IntGELU    | n:  21
IntSoftmax | n:  13
IntGELU    | n:  21
IntSoftmax | n:  13
IntGELU    | n:  21
IntSoftmax | n:  13
IntGELU    | n:  21
IntSoftmax | n:  13
IntGELU    | n:  21
IntSoftmax | n:  13
IntGELU    | n:  21
IntSoftmax | n:  13
IntGELU    | n:  21
IntSoftmax | n:  13
IntGELU    | n:  21
.calib done
Test: [  0/391]	Time  3.895 ( 3.895)	Acc@1   0.78 (  0.78)	Acc@5   6.25 (  6.25)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.781 Prec@5 6.250
Time: 8.87
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=13, intgelu_exp_n=22
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=13, intgelu_exp_n=22, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  13
IntGELU    | n:  22
IntSoftmax | n:  13
IntGELU    | n:  22
IntSoftmax | n:  13
IntGELU    | n:  22
IntSoftmax | n:  13
IntGELU    | n:  22
IntSoftmax | n:  13
IntGELU    | n:  22
IntSoftmax | n:  13
IntGELU    | n:  22
IntSoftmax | n:  13
IntGELU    | n:  22
IntSoftmax | n:  13
IntGELU    | n:  22
IntSoftmax | n:  13
IntGELU    | n:  22
IntSoftmax | n:  13
IntGELU    | n:  22
IntSoftmax | n:  13
IntGELU    | n:  22
IntSoftmax | n:  13
IntGELU    | n:  22
.calib done
Test: [  0/391]	Time  3.909 ( 3.909)	Acc@1  10.16 ( 10.16)	Acc@5  22.66 ( 22.66)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 10.156 Prec@5 22.656
Time: 8.84
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=13, intgelu_exp_n=23
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=13, intgelu_exp_n=23, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  13
IntGELU    | n:  23
IntSoftmax | n:  13
IntGELU    | n:  23
IntSoftmax | n:  13
IntGELU    | n:  23
IntSoftmax | n:  13
IntGELU    | n:  23
IntSoftmax | n:  13
IntGELU    | n:  23
IntSoftmax | n:  13
IntGELU    | n:  23
IntSoftmax | n:  13
IntGELU    | n:  23
IntSoftmax | n:  13
IntGELU    | n:  23
IntSoftmax | n:  13
IntGELU    | n:  23
IntSoftmax | n:  13
IntGELU    | n:  23
IntSoftmax | n:  13
IntGELU    | n:  23
IntSoftmax | n:  13
IntGELU    | n:  23
.calib done
Test: [  0/391]	Time  3.694 ( 3.694)	Acc@1   2.34 (  2.34)	Acc@5  10.16 ( 10.16)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 2.344 Prec@5 10.156
Time: 8.63
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=13, intgelu_exp_n=24
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=13, intgelu_exp_n=24, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  13
IntGELU    | n:  24
IntSoftmax | n:  13
IntGELU    | n:  24
IntSoftmax | n:  13
IntGELU    | n:  24
IntSoftmax | n:  13
IntGELU    | n:  24
IntSoftmax | n:  13
IntGELU    | n:  24
IntSoftmax | n:  13
IntGELU    | n:  24
IntSoftmax | n:  13
IntGELU    | n:  24
IntSoftmax | n:  13
IntGELU    | n:  24
IntSoftmax | n:  13
IntGELU    | n:  24
IntSoftmax | n:  13
IntGELU    | n:  24
IntSoftmax | n:  13
IntGELU    | n:  24
IntSoftmax | n:  13
IntGELU    | n:  24
.calib done
Test: [  0/391]	Time  3.921 ( 3.921)	Acc@1  17.19 ( 17.19)	Acc@5  33.59 ( 33.59)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 17.188 Prec@5 33.594
Time: 8.83
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=13, intgelu_exp_n=25
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=13, intgelu_exp_n=25, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  13
IntGELU    | n:  25
IntSoftmax | n:  13
IntGELU    | n:  25
IntSoftmax | n:  13
IntGELU    | n:  25
IntSoftmax | n:  13
IntGELU    | n:  25
IntSoftmax | n:  13
IntGELU    | n:  25
IntSoftmax | n:  13
IntGELU    | n:  25
IntSoftmax | n:  13
IntGELU    | n:  25
IntSoftmax | n:  13
IntGELU    | n:  25
IntSoftmax | n:  13
IntGELU    | n:  25
IntSoftmax | n:  13
IntGELU    | n:  25
IntSoftmax | n:  13
IntGELU    | n:  25
IntSoftmax | n:  13
IntGELU    | n:  25
.calib done
Test: [  0/391]	Time  3.833 ( 3.833)	Acc@1  22.66 ( 22.66)	Acc@5  42.97 ( 42.97)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 22.656 Prec@5 42.969
Time: 8.79
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=13, intgelu_exp_n=26
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=13, intgelu_exp_n=26, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  13
IntGELU    | n:  26
IntSoftmax | n:  13
IntGELU    | n:  26
IntSoftmax | n:  13
IntGELU    | n:  26
IntSoftmax | n:  13
IntGELU    | n:  26
IntSoftmax | n:  13
IntGELU    | n:  26
IntSoftmax | n:  13
IntGELU    | n:  26
IntSoftmax | n:  13
IntGELU    | n:  26
IntSoftmax | n:  13
IntGELU    | n:  26
IntSoftmax | n:  13
IntGELU    | n:  26
IntSoftmax | n:  13
IntGELU    | n:  26
IntSoftmax | n:  13
IntGELU    | n:  26
IntSoftmax | n:  13
IntGELU    | n:  26
.calib done
Test: [  0/391]	Time  3.914 ( 3.914)	Acc@1  22.66 ( 22.66)	Acc@5  42.19 ( 42.19)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 22.656 Prec@5 42.188
Time: 8.83
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=13, intgelu_exp_n=27
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=13, intgelu_exp_n=27, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  13
IntGELU    | n:  27
IntSoftmax | n:  13
IntGELU    | n:  27
IntSoftmax | n:  13
IntGELU    | n:  27
IntSoftmax | n:  13
IntGELU    | n:  27
IntSoftmax | n:  13
IntGELU    | n:  27
IntSoftmax | n:  13
IntGELU    | n:  27
IntSoftmax | n:  13
IntGELU    | n:  27
IntSoftmax | n:  13
IntGELU    | n:  27
IntSoftmax | n:  13
IntGELU    | n:  27
IntSoftmax | n:  13
IntGELU    | n:  27
IntSoftmax | n:  13
IntGELU    | n:  27
IntSoftmax | n:  13
IntGELU    | n:  27
.calib done
Test: [  0/391]	Time  3.871 ( 3.871)	Acc@1  23.44 ( 23.44)	Acc@5  44.53 ( 44.53)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 23.438 Prec@5 44.531
Time: 8.83
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=13, intgelu_exp_n=28
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=13, intgelu_exp_n=28, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  13
IntGELU    | n:  28
IntSoftmax | n:  13
IntGELU    | n:  28
IntSoftmax | n:  13
IntGELU    | n:  28
IntSoftmax | n:  13
IntGELU    | n:  28
IntSoftmax | n:  13
IntGELU    | n:  28
IntSoftmax | n:  13
IntGELU    | n:  28
IntSoftmax | n:  13
IntGELU    | n:  28
IntSoftmax | n:  13
IntGELU    | n:  28
IntSoftmax | n:  13
IntGELU    | n:  28
IntSoftmax | n:  13
IntGELU    | n:  28
IntSoftmax | n:  13
IntGELU    | n:  28
IntSoftmax | n:  13
IntGELU    | n:  28
.calib done
Test: [  0/391]	Time  3.894 ( 3.894)	Acc@1  25.78 ( 25.78)	Acc@5  52.34 ( 52.34)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 25.781 Prec@5 52.344
Time: 8.78
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=13, intgelu_exp_n=29
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=13, intgelu_exp_n=29, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  13
IntGELU    | n:  29
IntSoftmax | n:  13
IntGELU    | n:  29
IntSoftmax | n:  13
IntGELU    | n:  29
IntSoftmax | n:  13
IntGELU    | n:  29
IntSoftmax | n:  13
IntGELU    | n:  29
IntSoftmax | n:  13
IntGELU    | n:  29
IntSoftmax | n:  13
IntGELU    | n:  29
IntSoftmax | n:  13
IntGELU    | n:  29
IntSoftmax | n:  13
IntGELU    | n:  29
IntSoftmax | n:  13
IntGELU    | n:  29
IntSoftmax | n:  13
IntGELU    | n:  29
IntSoftmax | n:  13
IntGELU    | n:  29
.calib done
Test: [  0/391]	Time  3.932 ( 3.932)	Acc@1  34.38 ( 34.38)	Acc@5  58.59 ( 58.59)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 34.375 Prec@5 58.594
Time: 8.91
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=13, intgelu_exp_n=30
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=13, intgelu_exp_n=30, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  13
IntGELU    | n:  30
IntSoftmax | n:  13
IntGELU    | n:  30
IntSoftmax | n:  13
IntGELU    | n:  30
IntSoftmax | n:  13
IntGELU    | n:  30
IntSoftmax | n:  13
IntGELU    | n:  30
IntSoftmax | n:  13
IntGELU    | n:  30
IntSoftmax | n:  13
IntGELU    | n:  30
IntSoftmax | n:  13
IntGELU    | n:  30
IntSoftmax | n:  13
IntGELU    | n:  30
IntSoftmax | n:  13
IntGELU    | n:  30
IntSoftmax | n:  13
IntGELU    | n:  30
IntSoftmax | n:  13
IntGELU    | n:  30
.calib done
Test: [  0/391]	Time  4.109 ( 4.109)	Acc@1  91.41 ( 91.41)	Acc@5  96.88 ( 96.88)
Test: [ 10/391]	Time  1.734 ( 1.949)	Acc@1  65.62 ( 81.75)	Acc@5  88.28 ( 94.03)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 81.747 Prec@5 94.034
Time: 26.39
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=13, intgelu_exp_n=31
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=13, intgelu_exp_n=31, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  13
IntGELU    | n:  31
IntSoftmax | n:  13
IntGELU    | n:  31
IntSoftmax | n:  13
IntGELU    | n:  31
IntSoftmax | n:  13
IntGELU    | n:  31
IntSoftmax | n:  13
IntGELU    | n:  31
IntSoftmax | n:  13
IntGELU    | n:  31
IntSoftmax | n:  13
IntGELU    | n:  31
IntSoftmax | n:  13
IntGELU    | n:  31
IntSoftmax | n:  13
IntGELU    | n:  31
IntSoftmax | n:  13
IntGELU    | n:  31
IntSoftmax | n:  13
IntGELU    | n:  31
IntSoftmax | n:  13
IntGELU    | n:  31
.calib done
Test: [  0/391]	Time  3.928 ( 3.928)	Acc@1   8.59 (  8.59)	Acc@5  21.88 ( 21.88)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 8.594 Prec@5 21.875
Time: 8.92
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=14, intgelu_exp_n=0
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=14, intgelu_exp_n=0, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  14
IntGELU    | n:  0
IntSoftmax | n:  14
IntGELU    | n:  0
IntSoftmax | n:  14
IntGELU    | n:  0
IntSoftmax | n:  14
IntGELU    | n:  0
IntSoftmax | n:  14
IntGELU    | n:  0
IntSoftmax | n:  14
IntGELU    | n:  0
IntSoftmax | n:  14
IntGELU    | n:  0
IntSoftmax | n:  14
IntGELU    | n:  0
IntSoftmax | n:  14
IntGELU    | n:  0
IntSoftmax | n:  14
IntGELU    | n:  0
IntSoftmax | n:  14
IntGELU    | n:  0
IntSoftmax | n:  14
IntGELU    | n:  0
.calib done
Test: [  0/391]	Time  3.942 ( 3.942)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.81
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=14, intgelu_exp_n=1
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=14, intgelu_exp_n=1, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  14
IntGELU    | n:  1
IntSoftmax | n:  14
IntGELU    | n:  1
IntSoftmax | n:  14
IntGELU    | n:  1
IntSoftmax | n:  14
IntGELU    | n:  1
IntSoftmax | n:  14
IntGELU    | n:  1
IntSoftmax | n:  14
IntGELU    | n:  1
IntSoftmax | n:  14
IntGELU    | n:  1
IntSoftmax | n:  14
IntGELU    | n:  1
IntSoftmax | n:  14
IntGELU    | n:  1
IntSoftmax | n:  14
IntGELU    | n:  1
IntSoftmax | n:  14
IntGELU    | n:  1
IntSoftmax | n:  14
IntGELU    | n:  1
.calib done
Test: [  0/391]	Time  3.966 ( 3.966)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.87
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=14, intgelu_exp_n=2
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=14, intgelu_exp_n=2, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  14
IntGELU    | n:  2
IntSoftmax | n:  14
IntGELU    | n:  2
IntSoftmax | n:  14
IntGELU    | n:  2
IntSoftmax | n:  14
IntGELU    | n:  2
IntSoftmax | n:  14
IntGELU    | n:  2
IntSoftmax | n:  14
IntGELU    | n:  2
IntSoftmax | n:  14
IntGELU    | n:  2
IntSoftmax | n:  14
IntGELU    | n:  2
IntSoftmax | n:  14
IntGELU    | n:  2
IntSoftmax | n:  14
IntGELU    | n:  2
IntSoftmax | n:  14
IntGELU    | n:  2
IntSoftmax | n:  14
IntGELU    | n:  2
.calib done
Test: [  0/391]	Time  3.799 ( 3.799)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.73
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=14, intgelu_exp_n=3
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=14, intgelu_exp_n=3, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  14
IntGELU    | n:  3
IntSoftmax | n:  14
IntGELU    | n:  3
IntSoftmax | n:  14
IntGELU    | n:  3
IntSoftmax | n:  14
IntGELU    | n:  3
IntSoftmax | n:  14
IntGELU    | n:  3
IntSoftmax | n:  14
IntGELU    | n:  3
IntSoftmax | n:  14
IntGELU    | n:  3
IntSoftmax | n:  14
IntGELU    | n:  3
IntSoftmax | n:  14
IntGELU    | n:  3
IntSoftmax | n:  14
IntGELU    | n:  3
IntSoftmax | n:  14
IntGELU    | n:  3
IntSoftmax | n:  14
IntGELU    | n:  3
.calib done
Test: [  0/391]	Time  3.642 ( 3.642)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.57
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=14, intgelu_exp_n=4
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=14, intgelu_exp_n=4, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  14
IntGELU    | n:  4
IntSoftmax | n:  14
IntGELU    | n:  4
IntSoftmax | n:  14
IntGELU    | n:  4
IntSoftmax | n:  14
IntGELU    | n:  4
IntSoftmax | n:  14
IntGELU    | n:  4
IntSoftmax | n:  14
IntGELU    | n:  4
IntSoftmax | n:  14
IntGELU    | n:  4
IntSoftmax | n:  14
IntGELU    | n:  4
IntSoftmax | n:  14
IntGELU    | n:  4
IntSoftmax | n:  14
IntGELU    | n:  4
IntSoftmax | n:  14
IntGELU    | n:  4
IntSoftmax | n:  14
IntGELU    | n:  4
.calib done
Test: [  0/391]	Time  3.707 ( 3.707)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.61
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=14, intgelu_exp_n=5
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=14, intgelu_exp_n=5, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  14
IntGELU    | n:  5
IntSoftmax | n:  14
IntGELU    | n:  5
IntSoftmax | n:  14
IntGELU    | n:  5
IntSoftmax | n:  14
IntGELU    | n:  5
IntSoftmax | n:  14
IntGELU    | n:  5
IntSoftmax | n:  14
IntGELU    | n:  5
IntSoftmax | n:  14
IntGELU    | n:  5
IntSoftmax | n:  14
IntGELU    | n:  5
IntSoftmax | n:  14
IntGELU    | n:  5
IntSoftmax | n:  14
IntGELU    | n:  5
IntSoftmax | n:  14
IntGELU    | n:  5
IntSoftmax | n:  14
IntGELU    | n:  5
.calib done
Test: [  0/391]	Time  3.991 ( 3.991)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.88
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=14, intgelu_exp_n=6
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=14, intgelu_exp_n=6, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  14
IntGELU    | n:  6
IntSoftmax | n:  14
IntGELU    | n:  6
IntSoftmax | n:  14
IntGELU    | n:  6
IntSoftmax | n:  14
IntGELU    | n:  6
IntSoftmax | n:  14
IntGELU    | n:  6
IntSoftmax | n:  14
IntGELU    | n:  6
IntSoftmax | n:  14
IntGELU    | n:  6
IntSoftmax | n:  14
IntGELU    | n:  6
IntSoftmax | n:  14
IntGELU    | n:  6
IntSoftmax | n:  14
IntGELU    | n:  6
IntSoftmax | n:  14
IntGELU    | n:  6
IntSoftmax | n:  14
IntGELU    | n:  6
.calib done
Test: [  0/391]	Time  3.805 ( 3.805)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.82
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=14, intgelu_exp_n=7
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=14, intgelu_exp_n=7, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  14
IntGELU    | n:  7
IntSoftmax | n:  14
IntGELU    | n:  7
IntSoftmax | n:  14
IntGELU    | n:  7
IntSoftmax | n:  14
IntGELU    | n:  7
IntSoftmax | n:  14
IntGELU    | n:  7
IntSoftmax | n:  14
IntGELU    | n:  7
IntSoftmax | n:  14
IntGELU    | n:  7
IntSoftmax | n:  14
IntGELU    | n:  7
IntSoftmax | n:  14
IntGELU    | n:  7
IntSoftmax | n:  14
IntGELU    | n:  7
IntSoftmax | n:  14
IntGELU    | n:  7
IntSoftmax | n:  14
IntGELU    | n:  7
.calib done
Test: [  0/391]	Time  3.902 ( 3.902)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.85
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=14, intgelu_exp_n=8
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=14, intgelu_exp_n=8, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  14
IntGELU    | n:  8
IntSoftmax | n:  14
IntGELU    | n:  8
IntSoftmax | n:  14
IntGELU    | n:  8
IntSoftmax | n:  14
IntGELU    | n:  8
IntSoftmax | n:  14
IntGELU    | n:  8
IntSoftmax | n:  14
IntGELU    | n:  8
IntSoftmax | n:  14
IntGELU    | n:  8
IntSoftmax | n:  14
IntGELU    | n:  8
IntSoftmax | n:  14
IntGELU    | n:  8
IntSoftmax | n:  14
IntGELU    | n:  8
IntSoftmax | n:  14
IntGELU    | n:  8
IntSoftmax | n:  14
IntGELU    | n:  8
.calib done
Test: [  0/391]	Time  3.881 ( 3.881)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.81
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=14, intgelu_exp_n=9
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=14, intgelu_exp_n=9, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  14
IntGELU    | n:  9
IntSoftmax | n:  14
IntGELU    | n:  9
IntSoftmax | n:  14
IntGELU    | n:  9
IntSoftmax | n:  14
IntGELU    | n:  9
IntSoftmax | n:  14
IntGELU    | n:  9
IntSoftmax | n:  14
IntGELU    | n:  9
IntSoftmax | n:  14
IntGELU    | n:  9
IntSoftmax | n:  14
IntGELU    | n:  9
IntSoftmax | n:  14
IntGELU    | n:  9
IntSoftmax | n:  14
IntGELU    | n:  9
IntSoftmax | n:  14
IntGELU    | n:  9
IntSoftmax | n:  14
IntGELU    | n:  9
.calib done
Test: [  0/391]	Time  3.895 ( 3.895)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.76
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=14, intgelu_exp_n=10
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=14, intgelu_exp_n=10, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  14
IntGELU    | n:  10
IntSoftmax | n:  14
IntGELU    | n:  10
IntSoftmax | n:  14
IntGELU    | n:  10
IntSoftmax | n:  14
IntGELU    | n:  10
IntSoftmax | n:  14
IntGELU    | n:  10
IntSoftmax | n:  14
IntGELU    | n:  10
IntSoftmax | n:  14
IntGELU    | n:  10
IntSoftmax | n:  14
IntGELU    | n:  10
IntSoftmax | n:  14
IntGELU    | n:  10
IntSoftmax | n:  14
IntGELU    | n:  10
IntSoftmax | n:  14
IntGELU    | n:  10
IntSoftmax | n:  14
IntGELU    | n:  10
.calib done
Test: [  0/391]	Time  3.708 ( 3.708)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.64
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=14, intgelu_exp_n=11
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=14, intgelu_exp_n=11, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  14
IntGELU    | n:  11
IntSoftmax | n:  14
IntGELU    | n:  11
IntSoftmax | n:  14
IntGELU    | n:  11
IntSoftmax | n:  14
IntGELU    | n:  11
IntSoftmax | n:  14
IntGELU    | n:  11
IntSoftmax | n:  14
IntGELU    | n:  11
IntSoftmax | n:  14
IntGELU    | n:  11
IntSoftmax | n:  14
IntGELU    | n:  11
IntSoftmax | n:  14
IntGELU    | n:  11
IntSoftmax | n:  14
IntGELU    | n:  11
IntSoftmax | n:  14
IntGELU    | n:  11
IntSoftmax | n:  14
IntGELU    | n:  11
.calib done
Test: [  0/391]	Time  3.716 ( 3.716)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.66
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=14, intgelu_exp_n=12
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=14, intgelu_exp_n=12, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  14
IntGELU    | n:  12
IntSoftmax | n:  14
IntGELU    | n:  12
IntSoftmax | n:  14
IntGELU    | n:  12
IntSoftmax | n:  14
IntGELU    | n:  12
IntSoftmax | n:  14
IntGELU    | n:  12
IntSoftmax | n:  14
IntGELU    | n:  12
IntSoftmax | n:  14
IntGELU    | n:  12
IntSoftmax | n:  14
IntGELU    | n:  12
IntSoftmax | n:  14
IntGELU    | n:  12
IntSoftmax | n:  14
IntGELU    | n:  12
IntSoftmax | n:  14
IntGELU    | n:  12
IntSoftmax | n:  14
IntGELU    | n:  12
.calib done
Test: [  0/391]	Time  3.946 ( 3.946)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.89
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=14, intgelu_exp_n=13
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=14, intgelu_exp_n=13, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  14
IntGELU    | n:  13
IntSoftmax | n:  14
IntGELU    | n:  13
IntSoftmax | n:  14
IntGELU    | n:  13
IntSoftmax | n:  14
IntGELU    | n:  13
IntSoftmax | n:  14
IntGELU    | n:  13
IntSoftmax | n:  14
IntGELU    | n:  13
IntSoftmax | n:  14
IntGELU    | n:  13
IntSoftmax | n:  14
IntGELU    | n:  13
IntSoftmax | n:  14
IntGELU    | n:  13
IntSoftmax | n:  14
IntGELU    | n:  13
IntSoftmax | n:  14
IntGELU    | n:  13
IntSoftmax | n:  14
IntGELU    | n:  13
.calib done
Test: [  0/391]	Time  3.848 ( 3.848)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.91
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=14, intgelu_exp_n=14
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=14, intgelu_exp_n=14, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  14
IntGELU    | n:  14
IntSoftmax | n:  14
IntGELU    | n:  14
IntSoftmax | n:  14
IntGELU    | n:  14
IntSoftmax | n:  14
IntGELU    | n:  14
IntSoftmax | n:  14
IntGELU    | n:  14
IntSoftmax | n:  14
IntGELU    | n:  14
IntSoftmax | n:  14
IntGELU    | n:  14
IntSoftmax | n:  14
IntGELU    | n:  14
IntSoftmax | n:  14
IntGELU    | n:  14
IntSoftmax | n:  14
IntGELU    | n:  14
IntSoftmax | n:  14
IntGELU    | n:  14
IntSoftmax | n:  14
IntGELU    | n:  14
.calib done
Test: [  0/391]	Time  3.700 ( 3.700)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.70
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=14, intgelu_exp_n=15
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=14, intgelu_exp_n=15, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  14
IntGELU    | n:  15
IntSoftmax | n:  14
IntGELU    | n:  15
IntSoftmax | n:  14
IntGELU    | n:  15
IntSoftmax | n:  14
IntGELU    | n:  15
IntSoftmax | n:  14
IntGELU    | n:  15
IntSoftmax | n:  14
IntGELU    | n:  15
IntSoftmax | n:  14
IntGELU    | n:  15
IntSoftmax | n:  14
IntGELU    | n:  15
IntSoftmax | n:  14
IntGELU    | n:  15
IntSoftmax | n:  14
IntGELU    | n:  15
IntSoftmax | n:  14
IntGELU    | n:  15
IntSoftmax | n:  14
IntGELU    | n:  15
.calib done
Test: [  0/391]	Time  3.709 ( 3.709)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.64
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=14, intgelu_exp_n=16
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=14, intgelu_exp_n=16, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  14
IntGELU    | n:  16
IntSoftmax | n:  14
IntGELU    | n:  16
IntSoftmax | n:  14
IntGELU    | n:  16
IntSoftmax | n:  14
IntGELU    | n:  16
IntSoftmax | n:  14
IntGELU    | n:  16
IntSoftmax | n:  14
IntGELU    | n:  16
IntSoftmax | n:  14
IntGELU    | n:  16
IntSoftmax | n:  14
IntGELU    | n:  16
IntSoftmax | n:  14
IntGELU    | n:  16
IntSoftmax | n:  14
IntGELU    | n:  16
IntSoftmax | n:  14
IntGELU    | n:  16
IntSoftmax | n:  14
IntGELU    | n:  16
.calib done
Test: [  0/391]	Time  3.907 ( 3.907)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.85
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=14, intgelu_exp_n=17
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=14, intgelu_exp_n=17, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  14
IntGELU    | n:  17
IntSoftmax | n:  14
IntGELU    | n:  17
IntSoftmax | n:  14
IntGELU    | n:  17
IntSoftmax | n:  14
IntGELU    | n:  17
IntSoftmax | n:  14
IntGELU    | n:  17
IntSoftmax | n:  14
IntGELU    | n:  17
IntSoftmax | n:  14
IntGELU    | n:  17
IntSoftmax | n:  14
IntGELU    | n:  17
IntSoftmax | n:  14
IntGELU    | n:  17
IntSoftmax | n:  14
IntGELU    | n:  17
IntSoftmax | n:  14
IntGELU    | n:  17
IntSoftmax | n:  14
IntGELU    | n:  17
.calib done
Test: [  0/391]	Time  4.058 ( 4.058)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 9.00
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=14, intgelu_exp_n=18
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=14, intgelu_exp_n=18, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  14
IntGELU    | n:  18
IntSoftmax | n:  14
IntGELU    | n:  18
IntSoftmax | n:  14
IntGELU    | n:  18
IntSoftmax | n:  14
IntGELU    | n:  18
IntSoftmax | n:  14
IntGELU    | n:  18
IntSoftmax | n:  14
IntGELU    | n:  18
IntSoftmax | n:  14
IntGELU    | n:  18
IntSoftmax | n:  14
IntGELU    | n:  18
IntSoftmax | n:  14
IntGELU    | n:  18
IntSoftmax | n:  14
IntGELU    | n:  18
IntSoftmax | n:  14
IntGELU    | n:  18
IntSoftmax | n:  14
IntGELU    | n:  18
.calib done
Test: [  0/391]	Time  3.764 ( 3.764)	Acc@1   0.78 (  0.78)	Acc@5   3.12 (  3.12)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.781 Prec@5 3.125
Time: 8.74
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=14, intgelu_exp_n=19
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=14, intgelu_exp_n=19, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  14
IntGELU    | n:  19
IntSoftmax | n:  14
IntGELU    | n:  19
IntSoftmax | n:  14
IntGELU    | n:  19
IntSoftmax | n:  14
IntGELU    | n:  19
IntSoftmax | n:  14
IntGELU    | n:  19
IntSoftmax | n:  14
IntGELU    | n:  19
IntSoftmax | n:  14
IntGELU    | n:  19
IntSoftmax | n:  14
IntGELU    | n:  19
IntSoftmax | n:  14
IntGELU    | n:  19
IntSoftmax | n:  14
IntGELU    | n:  19
IntSoftmax | n:  14
IntGELU    | n:  19
IntSoftmax | n:  14
IntGELU    | n:  19
.calib done
Test: [  0/391]	Time  3.677 ( 3.677)	Acc@1   0.00 (  0.00)	Acc@5   0.78 (  0.78)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.781
Time: 8.56
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=14, intgelu_exp_n=20
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=14, intgelu_exp_n=20, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  14
IntGELU    | n:  20
IntSoftmax | n:  14
IntGELU    | n:  20
IntSoftmax | n:  14
IntGELU    | n:  20
IntSoftmax | n:  14
IntGELU    | n:  20
IntSoftmax | n:  14
IntGELU    | n:  20
IntSoftmax | n:  14
IntGELU    | n:  20
IntSoftmax | n:  14
IntGELU    | n:  20
IntSoftmax | n:  14
IntGELU    | n:  20
IntSoftmax | n:  14
IntGELU    | n:  20
IntSoftmax | n:  14
IntGELU    | n:  20
IntSoftmax | n:  14
IntGELU    | n:  20
IntSoftmax | n:  14
IntGELU    | n:  20
.calib done
Test: [  0/391]	Time  3.769 ( 3.769)	Acc@1   3.12 (  3.12)	Acc@5   7.03 (  7.03)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 3.125 Prec@5 7.031
Time: 8.65
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=14, intgelu_exp_n=21
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=14, intgelu_exp_n=21, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  14
IntGELU    | n:  21
IntSoftmax | n:  14
IntGELU    | n:  21
IntSoftmax | n:  14
IntGELU    | n:  21
IntSoftmax | n:  14
IntGELU    | n:  21
IntSoftmax | n:  14
IntGELU    | n:  21
IntSoftmax | n:  14
IntGELU    | n:  21
IntSoftmax | n:  14
IntGELU    | n:  21
IntSoftmax | n:  14
IntGELU    | n:  21
IntSoftmax | n:  14
IntGELU    | n:  21
IntSoftmax | n:  14
IntGELU    | n:  21
IntSoftmax | n:  14
IntGELU    | n:  21
IntSoftmax | n:  14
IntGELU    | n:  21
.calib done
Test: [  0/391]	Time  3.889 ( 3.889)	Acc@1   4.69 (  4.69)	Acc@5  14.84 ( 14.84)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 4.688 Prec@5 14.844
Time: 8.77
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=14, intgelu_exp_n=22
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=14, intgelu_exp_n=22, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  14
IntGELU    | n:  22
IntSoftmax | n:  14
IntGELU    | n:  22
IntSoftmax | n:  14
IntGELU    | n:  22
IntSoftmax | n:  14
IntGELU    | n:  22
IntSoftmax | n:  14
IntGELU    | n:  22
IntSoftmax | n:  14
IntGELU    | n:  22
IntSoftmax | n:  14
IntGELU    | n:  22
IntSoftmax | n:  14
IntGELU    | n:  22
IntSoftmax | n:  14
IntGELU    | n:  22
IntSoftmax | n:  14
IntGELU    | n:  22
IntSoftmax | n:  14
IntGELU    | n:  22
IntSoftmax | n:  14
IntGELU    | n:  22
.calib done
Test: [  0/391]	Time  3.941 ( 3.941)	Acc@1   5.47 (  5.47)	Acc@5  20.31 ( 20.31)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 5.469 Prec@5 20.312
Time: 8.91
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=14, intgelu_exp_n=23
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=14, intgelu_exp_n=23, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  14
IntGELU    | n:  23
IntSoftmax | n:  14
IntGELU    | n:  23
IntSoftmax | n:  14
IntGELU    | n:  23
IntSoftmax | n:  14
IntGELU    | n:  23
IntSoftmax | n:  14
IntGELU    | n:  23
IntSoftmax | n:  14
IntGELU    | n:  23
IntSoftmax | n:  14
IntGELU    | n:  23
IntSoftmax | n:  14
IntGELU    | n:  23
IntSoftmax | n:  14
IntGELU    | n:  23
IntSoftmax | n:  14
IntGELU    | n:  23
IntSoftmax | n:  14
IntGELU    | n:  23
IntSoftmax | n:  14
IntGELU    | n:  23
.calib done
Test: [  0/391]	Time  3.685 ( 3.685)	Acc@1  14.84 ( 14.84)	Acc@5  28.91 ( 28.91)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 14.844 Prec@5 28.906
Time: 8.79
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=14, intgelu_exp_n=24
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=14, intgelu_exp_n=24, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  14
IntGELU    | n:  24
IntSoftmax | n:  14
IntGELU    | n:  24
IntSoftmax | n:  14
IntGELU    | n:  24
IntSoftmax | n:  14
IntGELU    | n:  24
IntSoftmax | n:  14
IntGELU    | n:  24
IntSoftmax | n:  14
IntGELU    | n:  24
IntSoftmax | n:  14
IntGELU    | n:  24
IntSoftmax | n:  14
IntGELU    | n:  24
IntSoftmax | n:  14
IntGELU    | n:  24
IntSoftmax | n:  14
IntGELU    | n:  24
IntSoftmax | n:  14
IntGELU    | n:  24
IntSoftmax | n:  14
IntGELU    | n:  24
.calib done
Test: [  0/391]	Time  3.945 ( 3.945)	Acc@1  17.19 ( 17.19)	Acc@5  30.47 ( 30.47)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 17.188 Prec@5 30.469
Time: 8.93
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=14, intgelu_exp_n=25
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=14, intgelu_exp_n=25, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  14
IntGELU    | n:  25
IntSoftmax | n:  14
IntGELU    | n:  25
IntSoftmax | n:  14
IntGELU    | n:  25
IntSoftmax | n:  14
IntGELU    | n:  25
IntSoftmax | n:  14
IntGELU    | n:  25
IntSoftmax | n:  14
IntGELU    | n:  25
IntSoftmax | n:  14
IntGELU    | n:  25
IntSoftmax | n:  14
IntGELU    | n:  25
IntSoftmax | n:  14
IntGELU    | n:  25
IntSoftmax | n:  14
IntGELU    | n:  25
IntSoftmax | n:  14
IntGELU    | n:  25
IntSoftmax | n:  14
IntGELU    | n:  25
.calib done
Test: [  0/391]	Time  4.022 ( 4.022)	Acc@1  19.53 ( 19.53)	Acc@5  39.84 ( 39.84)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 19.531 Prec@5 39.844
Time: 8.96
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=14, intgelu_exp_n=26
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=14, intgelu_exp_n=26, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  14
IntGELU    | n:  26
IntSoftmax | n:  14
IntGELU    | n:  26
IntSoftmax | n:  14
IntGELU    | n:  26
IntSoftmax | n:  14
IntGELU    | n:  26
IntSoftmax | n:  14
IntGELU    | n:  26
IntSoftmax | n:  14
IntGELU    | n:  26
IntSoftmax | n:  14
IntGELU    | n:  26
IntSoftmax | n:  14
IntGELU    | n:  26
IntSoftmax | n:  14
IntGELU    | n:  26
IntSoftmax | n:  14
IntGELU    | n:  26
IntSoftmax | n:  14
IntGELU    | n:  26
IntSoftmax | n:  14
IntGELU    | n:  26
.calib done
Test: [  0/391]	Time  3.923 ( 3.923)	Acc@1  25.00 ( 25.00)	Acc@5  45.31 ( 45.31)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 25.000 Prec@5 45.312
Time: 8.88
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=14, intgelu_exp_n=27
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=14, intgelu_exp_n=27, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  14
IntGELU    | n:  27
IntSoftmax | n:  14
IntGELU    | n:  27
IntSoftmax | n:  14
IntGELU    | n:  27
IntSoftmax | n:  14
IntGELU    | n:  27
IntSoftmax | n:  14
IntGELU    | n:  27
IntSoftmax | n:  14
IntGELU    | n:  27
IntSoftmax | n:  14
IntGELU    | n:  27
IntSoftmax | n:  14
IntGELU    | n:  27
IntSoftmax | n:  14
IntGELU    | n:  27
IntSoftmax | n:  14
IntGELU    | n:  27
IntSoftmax | n:  14
IntGELU    | n:  27
IntSoftmax | n:  14
IntGELU    | n:  27
.calib done
Test: [  0/391]	Time  3.938 ( 3.938)	Acc@1  30.47 ( 30.47)	Acc@5  48.44 ( 48.44)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 30.469 Prec@5 48.438
Time: 8.89
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=14, intgelu_exp_n=28
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=14, intgelu_exp_n=28, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  14
IntGELU    | n:  28
IntSoftmax | n:  14
IntGELU    | n:  28
IntSoftmax | n:  14
IntGELU    | n:  28
IntSoftmax | n:  14
IntGELU    | n:  28
IntSoftmax | n:  14
IntGELU    | n:  28
IntSoftmax | n:  14
IntGELU    | n:  28
IntSoftmax | n:  14
IntGELU    | n:  28
IntSoftmax | n:  14
IntGELU    | n:  28
IntSoftmax | n:  14
IntGELU    | n:  28
IntSoftmax | n:  14
IntGELU    | n:  28
IntSoftmax | n:  14
IntGELU    | n:  28
IntSoftmax | n:  14
IntGELU    | n:  28
.calib done
Test: [  0/391]	Time  3.966 ( 3.966)	Acc@1  29.69 ( 29.69)	Acc@5  53.91 ( 53.91)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 29.688 Prec@5 53.906
Time: 8.90
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=14, intgelu_exp_n=29
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=14, intgelu_exp_n=29, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  14
IntGELU    | n:  29
IntSoftmax | n:  14
IntGELU    | n:  29
IntSoftmax | n:  14
IntGELU    | n:  29
IntSoftmax | n:  14
IntGELU    | n:  29
IntSoftmax | n:  14
IntGELU    | n:  29
IntSoftmax | n:  14
IntGELU    | n:  29
IntSoftmax | n:  14
IntGELU    | n:  29
IntSoftmax | n:  14
IntGELU    | n:  29
IntSoftmax | n:  14
IntGELU    | n:  29
IntSoftmax | n:  14
IntGELU    | n:  29
IntSoftmax | n:  14
IntGELU    | n:  29
IntSoftmax | n:  14
IntGELU    | n:  29
.calib done
Test: [  0/391]	Time  3.958 ( 3.958)	Acc@1  32.81 ( 32.81)	Acc@5  57.03 ( 57.03)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 32.812 Prec@5 57.031
Time: 8.90
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=14, intgelu_exp_n=30
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=14, intgelu_exp_n=30, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  14
IntGELU    | n:  30
IntSoftmax | n:  14
IntGELU    | n:  30
IntSoftmax | n:  14
IntGELU    | n:  30
IntSoftmax | n:  14
IntGELU    | n:  30
IntSoftmax | n:  14
IntGELU    | n:  30
IntSoftmax | n:  14
IntGELU    | n:  30
IntSoftmax | n:  14
IntGELU    | n:  30
IntSoftmax | n:  14
IntGELU    | n:  30
IntSoftmax | n:  14
IntGELU    | n:  30
IntSoftmax | n:  14
IntGELU    | n:  30
IntSoftmax | n:  14
IntGELU    | n:  30
IntSoftmax | n:  14
IntGELU    | n:  30
.calib done
Test: [  0/391]	Time  4.026 ( 4.026)	Acc@1  60.16 ( 60.16)	Acc@5  79.69 ( 79.69)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 60.156 Prec@5 79.688
Time: 8.95
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=14, intgelu_exp_n=31
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=14, intgelu_exp_n=31, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  14
IntGELU    | n:  31
IntSoftmax | n:  14
IntGELU    | n:  31
IntSoftmax | n:  14
IntGELU    | n:  31
IntSoftmax | n:  14
IntGELU    | n:  31
IntSoftmax | n:  14
IntGELU    | n:  31
IntSoftmax | n:  14
IntGELU    | n:  31
IntSoftmax | n:  14
IntGELU    | n:  31
IntSoftmax | n:  14
IntGELU    | n:  31
IntSoftmax | n:  14
IntGELU    | n:  31
IntSoftmax | n:  14
IntGELU    | n:  31
IntSoftmax | n:  14
IntGELU    | n:  31
IntSoftmax | n:  14
IntGELU    | n:  31
.calib done
Test: [  0/391]	Time  4.015 ( 4.015)	Acc@1   8.59 (  8.59)	Acc@5  19.53 ( 19.53)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 8.594 Prec@5 19.531
Time: 8.98
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=15, intgelu_exp_n=0
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=15, intgelu_exp_n=0, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  15
IntGELU    | n:  0
IntSoftmax | n:  15
IntGELU    | n:  0
IntSoftmax | n:  15
IntGELU    | n:  0
IntSoftmax | n:  15
IntGELU    | n:  0
IntSoftmax | n:  15
IntGELU    | n:  0
IntSoftmax | n:  15
IntGELU    | n:  0
IntSoftmax | n:  15
IntGELU    | n:  0
IntSoftmax | n:  15
IntGELU    | n:  0
IntSoftmax | n:  15
IntGELU    | n:  0
IntSoftmax | n:  15
IntGELU    | n:  0
IntSoftmax | n:  15
IntGELU    | n:  0
IntSoftmax | n:  15
IntGELU    | n:  0
.calib done
Test: [  0/391]	Time  3.702 ( 3.702)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.65
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=15, intgelu_exp_n=1
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=15, intgelu_exp_n=1, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  15
IntGELU    | n:  1
IntSoftmax | n:  15
IntGELU    | n:  1
IntSoftmax | n:  15
IntGELU    | n:  1
IntSoftmax | n:  15
IntGELU    | n:  1
IntSoftmax | n:  15
IntGELU    | n:  1
IntSoftmax | n:  15
IntGELU    | n:  1
IntSoftmax | n:  15
IntGELU    | n:  1
IntSoftmax | n:  15
IntGELU    | n:  1
IntSoftmax | n:  15
IntGELU    | n:  1
IntSoftmax | n:  15
IntGELU    | n:  1
IntSoftmax | n:  15
IntGELU    | n:  1
IntSoftmax | n:  15
IntGELU    | n:  1
.calib done
Test: [  0/391]	Time  4.089 ( 4.089)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 9.05
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=15, intgelu_exp_n=2
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=15, intgelu_exp_n=2, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  15
IntGELU    | n:  2
IntSoftmax | n:  15
IntGELU    | n:  2
IntSoftmax | n:  15
IntGELU    | n:  2
IntSoftmax | n:  15
IntGELU    | n:  2
IntSoftmax | n:  15
IntGELU    | n:  2
IntSoftmax | n:  15
IntGELU    | n:  2
IntSoftmax | n:  15
IntGELU    | n:  2
IntSoftmax | n:  15
IntGELU    | n:  2
IntSoftmax | n:  15
IntGELU    | n:  2
IntSoftmax | n:  15
IntGELU    | n:  2
IntSoftmax | n:  15
IntGELU    | n:  2
IntSoftmax | n:  15
IntGELU    | n:  2
.calib done
Test: [  0/391]	Time  3.809 ( 3.809)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.75
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=15, intgelu_exp_n=3
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=15, intgelu_exp_n=3, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  15
IntGELU    | n:  3
IntSoftmax | n:  15
IntGELU    | n:  3
IntSoftmax | n:  15
IntGELU    | n:  3
IntSoftmax | n:  15
IntGELU    | n:  3
IntSoftmax | n:  15
IntGELU    | n:  3
IntSoftmax | n:  15
IntGELU    | n:  3
IntSoftmax | n:  15
IntGELU    | n:  3
IntSoftmax | n:  15
IntGELU    | n:  3
IntSoftmax | n:  15
IntGELU    | n:  3
IntSoftmax | n:  15
IntGELU    | n:  3
IntSoftmax | n:  15
IntGELU    | n:  3
IntSoftmax | n:  15
IntGELU    | n:  3
.calib done
Test: [  0/391]	Time  3.955 ( 3.955)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.96
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=15, intgelu_exp_n=4
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=15, intgelu_exp_n=4, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  15
IntGELU    | n:  4
IntSoftmax | n:  15
IntGELU    | n:  4
IntSoftmax | n:  15
IntGELU    | n:  4
IntSoftmax | n:  15
IntGELU    | n:  4
IntSoftmax | n:  15
IntGELU    | n:  4
IntSoftmax | n:  15
IntGELU    | n:  4
IntSoftmax | n:  15
IntGELU    | n:  4
IntSoftmax | n:  15
IntGELU    | n:  4
IntSoftmax | n:  15
IntGELU    | n:  4
IntSoftmax | n:  15
IntGELU    | n:  4
IntSoftmax | n:  15
IntGELU    | n:  4
IntSoftmax | n:  15
IntGELU    | n:  4
.calib done
Test: [  0/391]	Time  3.795 ( 3.795)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.74
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=15, intgelu_exp_n=5
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=15, intgelu_exp_n=5, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  15
IntGELU    | n:  5
IntSoftmax | n:  15
IntGELU    | n:  5
IntSoftmax | n:  15
IntGELU    | n:  5
IntSoftmax | n:  15
IntGELU    | n:  5
IntSoftmax | n:  15
IntGELU    | n:  5
IntSoftmax | n:  15
IntGELU    | n:  5
IntSoftmax | n:  15
IntGELU    | n:  5
IntSoftmax | n:  15
IntGELU    | n:  5
IntSoftmax | n:  15
IntGELU    | n:  5
IntSoftmax | n:  15
IntGELU    | n:  5
IntSoftmax | n:  15
IntGELU    | n:  5
IntSoftmax | n:  15
IntGELU    | n:  5
.calib done
Test: [  0/391]	Time  3.880 ( 3.880)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.79
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=15, intgelu_exp_n=6
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=15, intgelu_exp_n=6, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  15
IntGELU    | n:  6
IntSoftmax | n:  15
IntGELU    | n:  6
IntSoftmax | n:  15
IntGELU    | n:  6
IntSoftmax | n:  15
IntGELU    | n:  6
IntSoftmax | n:  15
IntGELU    | n:  6
IntSoftmax | n:  15
IntGELU    | n:  6
IntSoftmax | n:  15
IntGELU    | n:  6
IntSoftmax | n:  15
IntGELU    | n:  6
IntSoftmax | n:  15
IntGELU    | n:  6
IntSoftmax | n:  15
IntGELU    | n:  6
IntSoftmax | n:  15
IntGELU    | n:  6
IntSoftmax | n:  15
IntGELU    | n:  6
.calib done
Test: [  0/391]	Time  3.780 ( 3.780)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.72
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=15, intgelu_exp_n=7
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=15, intgelu_exp_n=7, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  15
IntGELU    | n:  7
IntSoftmax | n:  15
IntGELU    | n:  7
IntSoftmax | n:  15
IntGELU    | n:  7
IntSoftmax | n:  15
IntGELU    | n:  7
IntSoftmax | n:  15
IntGELU    | n:  7
IntSoftmax | n:  15
IntGELU    | n:  7
IntSoftmax | n:  15
IntGELU    | n:  7
IntSoftmax | n:  15
IntGELU    | n:  7
IntSoftmax | n:  15
IntGELU    | n:  7
IntSoftmax | n:  15
IntGELU    | n:  7
IntSoftmax | n:  15
IntGELU    | n:  7
IntSoftmax | n:  15
IntGELU    | n:  7
.calib done
Test: [  0/391]	Time  3.884 ( 3.884)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.86
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=15, intgelu_exp_n=8
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=15, intgelu_exp_n=8, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  15
IntGELU    | n:  8
IntSoftmax | n:  15
IntGELU    | n:  8
IntSoftmax | n:  15
IntGELU    | n:  8
IntSoftmax | n:  15
IntGELU    | n:  8
IntSoftmax | n:  15
IntGELU    | n:  8
IntSoftmax | n:  15
IntGELU    | n:  8
IntSoftmax | n:  15
IntGELU    | n:  8
IntSoftmax | n:  15
IntGELU    | n:  8
IntSoftmax | n:  15
IntGELU    | n:  8
IntSoftmax | n:  15
IntGELU    | n:  8
IntSoftmax | n:  15
IntGELU    | n:  8
IntSoftmax | n:  15
IntGELU    | n:  8
.calib done
Test: [  0/391]	Time  4.035 ( 4.035)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.98
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=15, intgelu_exp_n=9
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=15, intgelu_exp_n=9, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  15
IntGELU    | n:  9
IntSoftmax | n:  15
IntGELU    | n:  9
IntSoftmax | n:  15
IntGELU    | n:  9
IntSoftmax | n:  15
IntGELU    | n:  9
IntSoftmax | n:  15
IntGELU    | n:  9
IntSoftmax | n:  15
IntGELU    | n:  9
IntSoftmax | n:  15
IntGELU    | n:  9
IntSoftmax | n:  15
IntGELU    | n:  9
IntSoftmax | n:  15
IntGELU    | n:  9
IntSoftmax | n:  15
IntGELU    | n:  9
IntSoftmax | n:  15
IntGELU    | n:  9
IntSoftmax | n:  15
IntGELU    | n:  9
.calib done
Test: [  0/391]	Time  3.664 ( 3.664)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.61
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=15, intgelu_exp_n=10
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=15, intgelu_exp_n=10, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  15
IntGELU    | n:  10
IntSoftmax | n:  15
IntGELU    | n:  10
IntSoftmax | n:  15
IntGELU    | n:  10
IntSoftmax | n:  15
IntGELU    | n:  10
IntSoftmax | n:  15
IntGELU    | n:  10
IntSoftmax | n:  15
IntGELU    | n:  10
IntSoftmax | n:  15
IntGELU    | n:  10
IntSoftmax | n:  15
IntGELU    | n:  10
IntSoftmax | n:  15
IntGELU    | n:  10
IntSoftmax | n:  15
IntGELU    | n:  10
IntSoftmax | n:  15
IntGELU    | n:  10
IntSoftmax | n:  15
IntGELU    | n:  10
.calib done
Test: [  0/391]	Time  3.986 ( 3.986)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.87
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=15, intgelu_exp_n=11
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=15, intgelu_exp_n=11, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  15
IntGELU    | n:  11
IntSoftmax | n:  15
IntGELU    | n:  11
IntSoftmax | n:  15
IntGELU    | n:  11
IntSoftmax | n:  15
IntGELU    | n:  11
IntSoftmax | n:  15
IntGELU    | n:  11
IntSoftmax | n:  15
IntGELU    | n:  11
IntSoftmax | n:  15
IntGELU    | n:  11
IntSoftmax | n:  15
IntGELU    | n:  11
IntSoftmax | n:  15
IntGELU    | n:  11
IntSoftmax | n:  15
IntGELU    | n:  11
IntSoftmax | n:  15
IntGELU    | n:  11
IntSoftmax | n:  15
IntGELU    | n:  11
.calib done
Test: [  0/391]	Time  3.688 ( 3.688)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.68
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=15, intgelu_exp_n=12
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=15, intgelu_exp_n=12, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  15
IntGELU    | n:  12
IntSoftmax | n:  15
IntGELU    | n:  12
IntSoftmax | n:  15
IntGELU    | n:  12
IntSoftmax | n:  15
IntGELU    | n:  12
IntSoftmax | n:  15
IntGELU    | n:  12
IntSoftmax | n:  15
IntGELU    | n:  12
IntSoftmax | n:  15
IntGELU    | n:  12
IntSoftmax | n:  15
IntGELU    | n:  12
IntSoftmax | n:  15
IntGELU    | n:  12
IntSoftmax | n:  15
IntGELU    | n:  12
IntSoftmax | n:  15
IntGELU    | n:  12
IntSoftmax | n:  15
IntGELU    | n:  12
.calib done
Test: [  0/391]	Time  3.793 ( 3.793)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.73
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=15, intgelu_exp_n=13
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=15, intgelu_exp_n=13, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  15
IntGELU    | n:  13
IntSoftmax | n:  15
IntGELU    | n:  13
IntSoftmax | n:  15
IntGELU    | n:  13
IntSoftmax | n:  15
IntGELU    | n:  13
IntSoftmax | n:  15
IntGELU    | n:  13
IntSoftmax | n:  15
IntGELU    | n:  13
IntSoftmax | n:  15
IntGELU    | n:  13
IntSoftmax | n:  15
IntGELU    | n:  13
IntSoftmax | n:  15
IntGELU    | n:  13
IntSoftmax | n:  15
IntGELU    | n:  13
IntSoftmax | n:  15
IntGELU    | n:  13
IntSoftmax | n:  15
IntGELU    | n:  13
.calib done
Test: [  0/391]	Time  3.824 ( 3.824)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.73
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=15, intgelu_exp_n=14
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=15, intgelu_exp_n=14, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  15
IntGELU    | n:  14
IntSoftmax | n:  15
IntGELU    | n:  14
IntSoftmax | n:  15
IntGELU    | n:  14
IntSoftmax | n:  15
IntGELU    | n:  14
IntSoftmax | n:  15
IntGELU    | n:  14
IntSoftmax | n:  15
IntGELU    | n:  14
IntSoftmax | n:  15
IntGELU    | n:  14
IntSoftmax | n:  15
IntGELU    | n:  14
IntSoftmax | n:  15
IntGELU    | n:  14
IntSoftmax | n:  15
IntGELU    | n:  14
IntSoftmax | n:  15
IntGELU    | n:  14
IntSoftmax | n:  15
IntGELU    | n:  14
.calib done
Test: [  0/391]	Time  3.980 ( 3.980)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.92
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=15, intgelu_exp_n=15
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=15, intgelu_exp_n=15, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  15
IntGELU    | n:  15
IntSoftmax | n:  15
IntGELU    | n:  15
IntSoftmax | n:  15
IntGELU    | n:  15
IntSoftmax | n:  15
IntGELU    | n:  15
IntSoftmax | n:  15
IntGELU    | n:  15
IntSoftmax | n:  15
IntGELU    | n:  15
IntSoftmax | n:  15
IntGELU    | n:  15
IntSoftmax | n:  15
IntGELU    | n:  15
IntSoftmax | n:  15
IntGELU    | n:  15
IntSoftmax | n:  15
IntGELU    | n:  15
IntSoftmax | n:  15
IntGELU    | n:  15
IntSoftmax | n:  15
IntGELU    | n:  15
.calib done
Test: [  0/391]	Time  3.943 ( 3.943)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.86
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=15, intgelu_exp_n=16
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=15, intgelu_exp_n=16, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  15
IntGELU    | n:  16
IntSoftmax | n:  15
IntGELU    | n:  16
IntSoftmax | n:  15
IntGELU    | n:  16
IntSoftmax | n:  15
IntGELU    | n:  16
IntSoftmax | n:  15
IntGELU    | n:  16
IntSoftmax | n:  15
IntGELU    | n:  16
IntSoftmax | n:  15
IntGELU    | n:  16
IntSoftmax | n:  15
IntGELU    | n:  16
IntSoftmax | n:  15
IntGELU    | n:  16
IntSoftmax | n:  15
IntGELU    | n:  16
IntSoftmax | n:  15
IntGELU    | n:  16
IntSoftmax | n:  15
IntGELU    | n:  16
.calib done
Test: [  0/391]	Time  3.985 ( 3.985)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.97
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=15, intgelu_exp_n=17
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=15, intgelu_exp_n=17, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  15
IntGELU    | n:  17
IntSoftmax | n:  15
IntGELU    | n:  17
IntSoftmax | n:  15
IntGELU    | n:  17
IntSoftmax | n:  15
IntGELU    | n:  17
IntSoftmax | n:  15
IntGELU    | n:  17
IntSoftmax | n:  15
IntGELU    | n:  17
IntSoftmax | n:  15
IntGELU    | n:  17
IntSoftmax | n:  15
IntGELU    | n:  17
IntSoftmax | n:  15
IntGELU    | n:  17
IntSoftmax | n:  15
IntGELU    | n:  17
IntSoftmax | n:  15
IntGELU    | n:  17
IntSoftmax | n:  15
IntGELU    | n:  17
.calib done
Test: [  0/391]	Time  3.840 ( 3.840)	Acc@1   0.00 (  0.00)	Acc@5   3.12 (  3.12)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 3.125
Time: 8.80
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=15, intgelu_exp_n=18
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=15, intgelu_exp_n=18, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  15
IntGELU    | n:  18
IntSoftmax | n:  15
IntGELU    | n:  18
IntSoftmax | n:  15
IntGELU    | n:  18
IntSoftmax | n:  15
IntGELU    | n:  18
IntSoftmax | n:  15
IntGELU    | n:  18
IntSoftmax | n:  15
IntGELU    | n:  18
IntSoftmax | n:  15
IntGELU    | n:  18
IntSoftmax | n:  15
IntGELU    | n:  18
IntSoftmax | n:  15
IntGELU    | n:  18
IntSoftmax | n:  15
IntGELU    | n:  18
IntSoftmax | n:  15
IntGELU    | n:  18
IntSoftmax | n:  15
IntGELU    | n:  18
.calib done
Test: [  0/391]	Time  3.809 ( 3.809)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.78
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=15, intgelu_exp_n=19
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=15, intgelu_exp_n=19, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  15
IntGELU    | n:  19
IntSoftmax | n:  15
IntGELU    | n:  19
IntSoftmax | n:  15
IntGELU    | n:  19
IntSoftmax | n:  15
IntGELU    | n:  19
IntSoftmax | n:  15
IntGELU    | n:  19
IntSoftmax | n:  15
IntGELU    | n:  19
IntSoftmax | n:  15
IntGELU    | n:  19
IntSoftmax | n:  15
IntGELU    | n:  19
IntSoftmax | n:  15
IntGELU    | n:  19
IntSoftmax | n:  15
IntGELU    | n:  19
IntSoftmax | n:  15
IntGELU    | n:  19
IntSoftmax | n:  15
IntGELU    | n:  19
.calib done
Test: [  0/391]	Time  3.827 ( 3.827)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.82
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=15, intgelu_exp_n=20
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=15, intgelu_exp_n=20, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  15
IntGELU    | n:  20
IntSoftmax | n:  15
IntGELU    | n:  20
IntSoftmax | n:  15
IntGELU    | n:  20
IntSoftmax | n:  15
IntGELU    | n:  20
IntSoftmax | n:  15
IntGELU    | n:  20
IntSoftmax | n:  15
IntGELU    | n:  20
IntSoftmax | n:  15
IntGELU    | n:  20
IntSoftmax | n:  15
IntGELU    | n:  20
IntSoftmax | n:  15
IntGELU    | n:  20
IntSoftmax | n:  15
IntGELU    | n:  20
IntSoftmax | n:  15
IntGELU    | n:  20
IntSoftmax | n:  15
IntGELU    | n:  20
.calib done
Test: [  0/391]	Time  3.858 ( 3.858)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.83
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=15, intgelu_exp_n=21
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=15, intgelu_exp_n=21, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  15
IntGELU    | n:  21
IntSoftmax | n:  15
IntGELU    | n:  21
IntSoftmax | n:  15
IntGELU    | n:  21
IntSoftmax | n:  15
IntGELU    | n:  21
IntSoftmax | n:  15
IntGELU    | n:  21
IntSoftmax | n:  15
IntGELU    | n:  21
IntSoftmax | n:  15
IntGELU    | n:  21
IntSoftmax | n:  15
IntGELU    | n:  21
IntSoftmax | n:  15
IntGELU    | n:  21
IntSoftmax | n:  15
IntGELU    | n:  21
IntSoftmax | n:  15
IntGELU    | n:  21
IntSoftmax | n:  15
IntGELU    | n:  21
.calib done
Test: [  0/391]	Time  3.707 ( 3.707)	Acc@1   0.00 (  0.00)	Acc@5   2.34 (  2.34)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 2.344
Time: 8.64
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=15, intgelu_exp_n=22
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=15, intgelu_exp_n=22, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  15
IntGELU    | n:  22
IntSoftmax | n:  15
IntGELU    | n:  22
IntSoftmax | n:  15
IntGELU    | n:  22
IntSoftmax | n:  15
IntGELU    | n:  22
IntSoftmax | n:  15
IntGELU    | n:  22
IntSoftmax | n:  15
IntGELU    | n:  22
IntSoftmax | n:  15
IntGELU    | n:  22
IntSoftmax | n:  15
IntGELU    | n:  22
IntSoftmax | n:  15
IntGELU    | n:  22
IntSoftmax | n:  15
IntGELU    | n:  22
IntSoftmax | n:  15
IntGELU    | n:  22
IntSoftmax | n:  15
IntGELU    | n:  22
.calib done
Test: [  0/391]	Time  3.960 ( 3.960)	Acc@1   6.25 (  6.25)	Acc@5  19.53 ( 19.53)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 6.250 Prec@5 19.531
Time: 8.96
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=15, intgelu_exp_n=23
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=15, intgelu_exp_n=23, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
.calib done
Test: [  0/391]	Time  3.922 ( 3.922)	Acc@1   7.81 (  7.81)	Acc@5  27.34 ( 27.34)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 7.812 Prec@5 27.344
Time: 8.90
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=15, intgelu_exp_n=24
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=15, intgelu_exp_n=24, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  15
IntGELU    | n:  24
IntSoftmax | n:  15
IntGELU    | n:  24
IntSoftmax | n:  15
IntGELU    | n:  24
IntSoftmax | n:  15
IntGELU    | n:  24
IntSoftmax | n:  15
IntGELU    | n:  24
IntSoftmax | n:  15
IntGELU    | n:  24
IntSoftmax | n:  15
IntGELU    | n:  24
IntSoftmax | n:  15
IntGELU    | n:  24
IntSoftmax | n:  15
IntGELU    | n:  24
IntSoftmax | n:  15
IntGELU    | n:  24
IntSoftmax | n:  15
IntGELU    | n:  24
IntSoftmax | n:  15
IntGELU    | n:  24
.calib done
Test: [  0/391]	Time  3.852 ( 3.852)	Acc@1  14.06 ( 14.06)	Acc@5  30.47 ( 30.47)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 14.062 Prec@5 30.469
Time: 8.84
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=15, intgelu_exp_n=25
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=15, intgelu_exp_n=25, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  15
IntGELU    | n:  25
IntSoftmax | n:  15
IntGELU    | n:  25
IntSoftmax | n:  15
IntGELU    | n:  25
IntSoftmax | n:  15
IntGELU    | n:  25
IntSoftmax | n:  15
IntGELU    | n:  25
IntSoftmax | n:  15
IntGELU    | n:  25
IntSoftmax | n:  15
IntGELU    | n:  25
IntSoftmax | n:  15
IntGELU    | n:  25
IntSoftmax | n:  15
IntGELU    | n:  25
IntSoftmax | n:  15
IntGELU    | n:  25
IntSoftmax | n:  15
IntGELU    | n:  25
IntSoftmax | n:  15
IntGELU    | n:  25
.calib done
Test: [  0/391]	Time  3.986 ( 3.986)	Acc@1  19.53 ( 19.53)	Acc@5  42.19 ( 42.19)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 19.531 Prec@5 42.188
Time: 8.94
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=15, intgelu_exp_n=26
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=15, intgelu_exp_n=26, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  15
IntGELU    | n:  26
IntSoftmax | n:  15
IntGELU    | n:  26
IntSoftmax | n:  15
IntGELU    | n:  26
IntSoftmax | n:  15
IntGELU    | n:  26
IntSoftmax | n:  15
IntGELU    | n:  26
IntSoftmax | n:  15
IntGELU    | n:  26
IntSoftmax | n:  15
IntGELU    | n:  26
IntSoftmax | n:  15
IntGELU    | n:  26
IntSoftmax | n:  15
IntGELU    | n:  26
IntSoftmax | n:  15
IntGELU    | n:  26
IntSoftmax | n:  15
IntGELU    | n:  26
IntSoftmax | n:  15
IntGELU    | n:  26
.calib done
Test: [  0/391]	Time  3.963 ( 3.963)	Acc@1  22.66 ( 22.66)	Acc@5  45.31 ( 45.31)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 22.656 Prec@5 45.312
Time: 8.88
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=15, intgelu_exp_n=27
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=15, intgelu_exp_n=27, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  15
IntGELU    | n:  27
IntSoftmax | n:  15
IntGELU    | n:  27
IntSoftmax | n:  15
IntGELU    | n:  27
IntSoftmax | n:  15
IntGELU    | n:  27
IntSoftmax | n:  15
IntGELU    | n:  27
IntSoftmax | n:  15
IntGELU    | n:  27
IntSoftmax | n:  15
IntGELU    | n:  27
IntSoftmax | n:  15
IntGELU    | n:  27
IntSoftmax | n:  15
IntGELU    | n:  27
IntSoftmax | n:  15
IntGELU    | n:  27
IntSoftmax | n:  15
IntGELU    | n:  27
IntSoftmax | n:  15
IntGELU    | n:  27
.calib done
Test: [  0/391]	Time  3.942 ( 3.942)	Acc@1  28.12 ( 28.12)	Acc@5  46.88 ( 46.88)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 28.125 Prec@5 46.875
Time: 8.96
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=15, intgelu_exp_n=28
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=15, intgelu_exp_n=28, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  15
IntGELU    | n:  28
IntSoftmax | n:  15
IntGELU    | n:  28
IntSoftmax | n:  15
IntGELU    | n:  28
IntSoftmax | n:  15
IntGELU    | n:  28
IntSoftmax | n:  15
IntGELU    | n:  28
IntSoftmax | n:  15
IntGELU    | n:  28
IntSoftmax | n:  15
IntGELU    | n:  28
IntSoftmax | n:  15
IntGELU    | n:  28
IntSoftmax | n:  15
IntGELU    | n:  28
IntSoftmax | n:  15
IntGELU    | n:  28
IntSoftmax | n:  15
IntGELU    | n:  28
IntSoftmax | n:  15
IntGELU    | n:  28
.calib done
Test: [  0/391]	Time  3.892 ( 3.892)	Acc@1  24.22 ( 24.22)	Acc@5  54.69 ( 54.69)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 24.219 Prec@5 54.688
Time: 8.88
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=15, intgelu_exp_n=29
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=15, intgelu_exp_n=29, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  15
IntGELU    | n:  29
IntSoftmax | n:  15
IntGELU    | n:  29
IntSoftmax | n:  15
IntGELU    | n:  29
IntSoftmax | n:  15
IntGELU    | n:  29
IntSoftmax | n:  15
IntGELU    | n:  29
IntSoftmax | n:  15
IntGELU    | n:  29
IntSoftmax | n:  15
IntGELU    | n:  29
IntSoftmax | n:  15
IntGELU    | n:  29
IntSoftmax | n:  15
IntGELU    | n:  29
IntSoftmax | n:  15
IntGELU    | n:  29
IntSoftmax | n:  15
IntGELU    | n:  29
IntSoftmax | n:  15
IntGELU    | n:  29
.calib done
Test: [  0/391]	Time  3.775 ( 3.775)	Acc@1  31.25 ( 31.25)	Acc@5  55.47 ( 55.47)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 31.250 Prec@5 55.469
Time: 8.73
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=15, intgelu_exp_n=30
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=15, intgelu_exp_n=30, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  15
IntGELU    | n:  30
IntSoftmax | n:  15
IntGELU    | n:  30
IntSoftmax | n:  15
IntGELU    | n:  30
IntSoftmax | n:  15
IntGELU    | n:  30
IntSoftmax | n:  15
IntGELU    | n:  30
IntSoftmax | n:  15
IntGELU    | n:  30
IntSoftmax | n:  15
IntGELU    | n:  30
IntSoftmax | n:  15
IntGELU    | n:  30
IntSoftmax | n:  15
IntGELU    | n:  30
IntSoftmax | n:  15
IntGELU    | n:  30
IntSoftmax | n:  15
IntGELU    | n:  30
IntSoftmax | n:  15
IntGELU    | n:  30
.calib done
Test: [  0/391]	Time  3.867 ( 3.867)	Acc@1  62.50 ( 62.50)	Acc@5  79.69 ( 79.69)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 62.500 Prec@5 79.688
Time: 8.82
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=15, intgelu_exp_n=31
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=15, intgelu_exp_n=31, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  15
IntGELU    | n:  31
IntSoftmax | n:  15
IntGELU    | n:  31
IntSoftmax | n:  15
IntGELU    | n:  31
IntSoftmax | n:  15
IntGELU    | n:  31
IntSoftmax | n:  15
IntGELU    | n:  31
IntSoftmax | n:  15
IntGELU    | n:  31
IntSoftmax | n:  15
IntGELU    | n:  31
IntSoftmax | n:  15
IntGELU    | n:  31
IntSoftmax | n:  15
IntGELU    | n:  31
IntSoftmax | n:  15
IntGELU    | n:  31
IntSoftmax | n:  15
IntGELU    | n:  31
IntSoftmax | n:  15
IntGELU    | n:  31
.calib done
Test: [  0/391]	Time  3.800 ( 3.800)	Acc@1   7.81 (  7.81)	Acc@5  21.88 ( 21.88)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 7.812 Prec@5 21.875
Time: 8.74
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=16, intgelu_exp_n=0
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=16, intgelu_exp_n=0, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  16
IntGELU    | n:  0
IntSoftmax | n:  16
IntGELU    | n:  0
IntSoftmax | n:  16
IntGELU    | n:  0
IntSoftmax | n:  16
IntGELU    | n:  0
IntSoftmax | n:  16
IntGELU    | n:  0
IntSoftmax | n:  16
IntGELU    | n:  0
IntSoftmax | n:  16
IntGELU    | n:  0
IntSoftmax | n:  16
IntGELU    | n:  0
IntSoftmax | n:  16
IntGELU    | n:  0
IntSoftmax | n:  16
IntGELU    | n:  0
IntSoftmax | n:  16
IntGELU    | n:  0
IntSoftmax | n:  16
IntGELU    | n:  0
.calib done
Test: [  0/391]	Time  3.954 ( 3.954)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.94
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=16, intgelu_exp_n=1
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=16, intgelu_exp_n=1, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  16
IntGELU    | n:  1
IntSoftmax | n:  16
IntGELU    | n:  1
IntSoftmax | n:  16
IntGELU    | n:  1
IntSoftmax | n:  16
IntGELU    | n:  1
IntSoftmax | n:  16
IntGELU    | n:  1
IntSoftmax | n:  16
IntGELU    | n:  1
IntSoftmax | n:  16
IntGELU    | n:  1
IntSoftmax | n:  16
IntGELU    | n:  1
IntSoftmax | n:  16
IntGELU    | n:  1
IntSoftmax | n:  16
IntGELU    | n:  1
IntSoftmax | n:  16
IntGELU    | n:  1
IntSoftmax | n:  16
IntGELU    | n:  1
.calib done
Test: [  0/391]	Time  3.663 ( 3.663)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.59
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=16, intgelu_exp_n=2
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=16, intgelu_exp_n=2, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  16
IntGELU    | n:  2
IntSoftmax | n:  16
IntGELU    | n:  2
IntSoftmax | n:  16
IntGELU    | n:  2
IntSoftmax | n:  16
IntGELU    | n:  2
IntSoftmax | n:  16
IntGELU    | n:  2
IntSoftmax | n:  16
IntGELU    | n:  2
IntSoftmax | n:  16
IntGELU    | n:  2
IntSoftmax | n:  16
IntGELU    | n:  2
IntSoftmax | n:  16
IntGELU    | n:  2
IntSoftmax | n:  16
IntGELU    | n:  2
IntSoftmax | n:  16
IntGELU    | n:  2
IntSoftmax | n:  16
IntGELU    | n:  2
.calib done
Test: [  0/391]	Time  3.785 ( 3.785)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.74
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=16, intgelu_exp_n=3
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=16, intgelu_exp_n=3, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  16
IntGELU    | n:  3
IntSoftmax | n:  16
IntGELU    | n:  3
IntSoftmax | n:  16
IntGELU    | n:  3
IntSoftmax | n:  16
IntGELU    | n:  3
IntSoftmax | n:  16
IntGELU    | n:  3
IntSoftmax | n:  16
IntGELU    | n:  3
IntSoftmax | n:  16
IntGELU    | n:  3
IntSoftmax | n:  16
IntGELU    | n:  3
IntSoftmax | n:  16
IntGELU    | n:  3
IntSoftmax | n:  16
IntGELU    | n:  3
IntSoftmax | n:  16
IntGELU    | n:  3
IntSoftmax | n:  16
IntGELU    | n:  3
.calib done
Test: [  0/391]	Time  3.934 ( 3.934)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.86
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=16, intgelu_exp_n=4
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=16, intgelu_exp_n=4, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  16
IntGELU    | n:  4
IntSoftmax | n:  16
IntGELU    | n:  4
IntSoftmax | n:  16
IntGELU    | n:  4
IntSoftmax | n:  16
IntGELU    | n:  4
IntSoftmax | n:  16
IntGELU    | n:  4
IntSoftmax | n:  16
IntGELU    | n:  4
IntSoftmax | n:  16
IntGELU    | n:  4
IntSoftmax | n:  16
IntGELU    | n:  4
IntSoftmax | n:  16
IntGELU    | n:  4
IntSoftmax | n:  16
IntGELU    | n:  4
IntSoftmax | n:  16
IntGELU    | n:  4
IntSoftmax | n:  16
IntGELU    | n:  4
.calib done
Test: [  0/391]	Time  3.944 ( 3.944)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.87
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=16, intgelu_exp_n=5
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=16, intgelu_exp_n=5, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  16
IntGELU    | n:  5
IntSoftmax | n:  16
IntGELU    | n:  5
IntSoftmax | n:  16
IntGELU    | n:  5
IntSoftmax | n:  16
IntGELU    | n:  5
IntSoftmax | n:  16
IntGELU    | n:  5
IntSoftmax | n:  16
IntGELU    | n:  5
IntSoftmax | n:  16
IntGELU    | n:  5
IntSoftmax | n:  16
IntGELU    | n:  5
IntSoftmax | n:  16
IntGELU    | n:  5
IntSoftmax | n:  16
IntGELU    | n:  5
IntSoftmax | n:  16
IntGELU    | n:  5
IntSoftmax | n:  16
IntGELU    | n:  5
.calib done
Test: [  0/391]	Time  3.875 ( 3.875)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.79
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=16, intgelu_exp_n=6
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=16, intgelu_exp_n=6, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  16
IntGELU    | n:  6
IntSoftmax | n:  16
IntGELU    | n:  6
IntSoftmax | n:  16
IntGELU    | n:  6
IntSoftmax | n:  16
IntGELU    | n:  6
IntSoftmax | n:  16
IntGELU    | n:  6
IntSoftmax | n:  16
IntGELU    | n:  6
IntSoftmax | n:  16
IntGELU    | n:  6
IntSoftmax | n:  16
IntGELU    | n:  6
IntSoftmax | n:  16
IntGELU    | n:  6
IntSoftmax | n:  16
IntGELU    | n:  6
IntSoftmax | n:  16
IntGELU    | n:  6
IntSoftmax | n:  16
IntGELU    | n:  6
.calib done
Test: [  0/391]	Time  3.766 ( 3.766)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.67
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=16, intgelu_exp_n=7
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=16, intgelu_exp_n=7, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  16
IntGELU    | n:  7
IntSoftmax | n:  16
IntGELU    | n:  7
IntSoftmax | n:  16
IntGELU    | n:  7
IntSoftmax | n:  16
IntGELU    | n:  7
IntSoftmax | n:  16
IntGELU    | n:  7
IntSoftmax | n:  16
IntGELU    | n:  7
IntSoftmax | n:  16
IntGELU    | n:  7
IntSoftmax | n:  16
IntGELU    | n:  7
IntSoftmax | n:  16
IntGELU    | n:  7
IntSoftmax | n:  16
IntGELU    | n:  7
IntSoftmax | n:  16
IntGELU    | n:  7
IntSoftmax | n:  16
IntGELU    | n:  7
.calib done
Test: [  0/391]	Time  3.856 ( 3.856)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.81
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=16, intgelu_exp_n=8
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=16, intgelu_exp_n=8, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  16
IntGELU    | n:  8
IntSoftmax | n:  16
IntGELU    | n:  8
IntSoftmax | n:  16
IntGELU    | n:  8
IntSoftmax | n:  16
IntGELU    | n:  8
IntSoftmax | n:  16
IntGELU    | n:  8
IntSoftmax | n:  16
IntGELU    | n:  8
IntSoftmax | n:  16
IntGELU    | n:  8
IntSoftmax | n:  16
IntGELU    | n:  8
IntSoftmax | n:  16
IntGELU    | n:  8
IntSoftmax | n:  16
IntGELU    | n:  8
IntSoftmax | n:  16
IntGELU    | n:  8
IntSoftmax | n:  16
IntGELU    | n:  8
.calib done
Test: [  0/391]	Time  3.929 ( 3.929)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.93
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=16, intgelu_exp_n=9
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=16, intgelu_exp_n=9, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  16
IntGELU    | n:  9
IntSoftmax | n:  16
IntGELU    | n:  9
IntSoftmax | n:  16
IntGELU    | n:  9
IntSoftmax | n:  16
IntGELU    | n:  9
IntSoftmax | n:  16
IntGELU    | n:  9
IntSoftmax | n:  16
IntGELU    | n:  9
IntSoftmax | n:  16
IntGELU    | n:  9
IntSoftmax | n:  16
IntGELU    | n:  9
IntSoftmax | n:  16
IntGELU    | n:  9
IntSoftmax | n:  16
IntGELU    | n:  9
IntSoftmax | n:  16
IntGELU    | n:  9
IntSoftmax | n:  16
IntGELU    | n:  9
.calib done
Test: [  0/391]	Time  3.868 ( 3.868)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.83
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=16, intgelu_exp_n=10
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=16, intgelu_exp_n=10, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  16
IntGELU    | n:  10
IntSoftmax | n:  16
IntGELU    | n:  10
IntSoftmax | n:  16
IntGELU    | n:  10
IntSoftmax | n:  16
IntGELU    | n:  10
IntSoftmax | n:  16
IntGELU    | n:  10
IntSoftmax | n:  16
IntGELU    | n:  10
IntSoftmax | n:  16
IntGELU    | n:  10
IntSoftmax | n:  16
IntGELU    | n:  10
IntSoftmax | n:  16
IntGELU    | n:  10
IntSoftmax | n:  16
IntGELU    | n:  10
IntSoftmax | n:  16
IntGELU    | n:  10
IntSoftmax | n:  16
IntGELU    | n:  10
.calib done
Test: [  0/391]	Time  3.983 ( 3.983)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.90
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=16, intgelu_exp_n=11
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=16, intgelu_exp_n=11, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  16
IntGELU    | n:  11
IntSoftmax | n:  16
IntGELU    | n:  11
IntSoftmax | n:  16
IntGELU    | n:  11
IntSoftmax | n:  16
IntGELU    | n:  11
IntSoftmax | n:  16
IntGELU    | n:  11
IntSoftmax | n:  16
IntGELU    | n:  11
IntSoftmax | n:  16
IntGELU    | n:  11
IntSoftmax | n:  16
IntGELU    | n:  11
IntSoftmax | n:  16
IntGELU    | n:  11
IntSoftmax | n:  16
IntGELU    | n:  11
IntSoftmax | n:  16
IntGELU    | n:  11
IntSoftmax | n:  16
IntGELU    | n:  11
.calib done
Test: [  0/391]	Time  3.902 ( 3.902)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.83
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=16, intgelu_exp_n=12
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=16, intgelu_exp_n=12, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  16
IntGELU    | n:  12
IntSoftmax | n:  16
IntGELU    | n:  12
IntSoftmax | n:  16
IntGELU    | n:  12
IntSoftmax | n:  16
IntGELU    | n:  12
IntSoftmax | n:  16
IntGELU    | n:  12
IntSoftmax | n:  16
IntGELU    | n:  12
IntSoftmax | n:  16
IntGELU    | n:  12
IntSoftmax | n:  16
IntGELU    | n:  12
IntSoftmax | n:  16
IntGELU    | n:  12
IntSoftmax | n:  16
IntGELU    | n:  12
IntSoftmax | n:  16
IntGELU    | n:  12
IntSoftmax | n:  16
IntGELU    | n:  12
.calib done
Test: [  0/391]	Time  3.882 ( 3.882)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.80
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=16, intgelu_exp_n=13
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=16, intgelu_exp_n=13, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  16
IntGELU    | n:  13
IntSoftmax | n:  16
IntGELU    | n:  13
IntSoftmax | n:  16
IntGELU    | n:  13
IntSoftmax | n:  16
IntGELU    | n:  13
IntSoftmax | n:  16
IntGELU    | n:  13
IntSoftmax | n:  16
IntGELU    | n:  13
IntSoftmax | n:  16
IntGELU    | n:  13
IntSoftmax | n:  16
IntGELU    | n:  13
IntSoftmax | n:  16
IntGELU    | n:  13
IntSoftmax | n:  16
IntGELU    | n:  13
IntSoftmax | n:  16
IntGELU    | n:  13
IntSoftmax | n:  16
IntGELU    | n:  13
.calib done
Test: [  0/391]	Time  3.786 ( 3.786)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.71
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=16, intgelu_exp_n=14
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=16, intgelu_exp_n=14, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  16
IntGELU    | n:  14
IntSoftmax | n:  16
IntGELU    | n:  14
IntSoftmax | n:  16
IntGELU    | n:  14
IntSoftmax | n:  16
IntGELU    | n:  14
IntSoftmax | n:  16
IntGELU    | n:  14
IntSoftmax | n:  16
IntGELU    | n:  14
IntSoftmax | n:  16
IntGELU    | n:  14
IntSoftmax | n:  16
IntGELU    | n:  14
IntSoftmax | n:  16
IntGELU    | n:  14
IntSoftmax | n:  16
IntGELU    | n:  14
IntSoftmax | n:  16
IntGELU    | n:  14
IntSoftmax | n:  16
IntGELU    | n:  14
.calib done
Test: [  0/391]	Time  3.660 ( 3.660)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.65
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=16, intgelu_exp_n=15
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=16, intgelu_exp_n=15, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  16
IntGELU    | n:  15
IntSoftmax | n:  16
IntGELU    | n:  15
IntSoftmax | n:  16
IntGELU    | n:  15
IntSoftmax | n:  16
IntGELU    | n:  15
IntSoftmax | n:  16
IntGELU    | n:  15
IntSoftmax | n:  16
IntGELU    | n:  15
IntSoftmax | n:  16
IntGELU    | n:  15
IntSoftmax | n:  16
IntGELU    | n:  15
IntSoftmax | n:  16
IntGELU    | n:  15
IntSoftmax | n:  16
IntGELU    | n:  15
IntSoftmax | n:  16
IntGELU    | n:  15
IntSoftmax | n:  16
IntGELU    | n:  15
.calib done
Test: [  0/391]	Time  4.044 ( 4.044)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.97
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=16, intgelu_exp_n=16
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=16, intgelu_exp_n=16, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  16
IntGELU    | n:  16
IntSoftmax | n:  16
IntGELU    | n:  16
IntSoftmax | n:  16
IntGELU    | n:  16
IntSoftmax | n:  16
IntGELU    | n:  16
IntSoftmax | n:  16
IntGELU    | n:  16
IntSoftmax | n:  16
IntGELU    | n:  16
IntSoftmax | n:  16
IntGELU    | n:  16
IntSoftmax | n:  16
IntGELU    | n:  16
IntSoftmax | n:  16
IntGELU    | n:  16
IntSoftmax | n:  16
IntGELU    | n:  16
IntSoftmax | n:  16
IntGELU    | n:  16
IntSoftmax | n:  16
IntGELU    | n:  16
.calib done
Test: [  0/391]	Time  3.866 ( 3.866)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.84
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=16, intgelu_exp_n=17
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=16, intgelu_exp_n=17, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  16
IntGELU    | n:  17
IntSoftmax | n:  16
IntGELU    | n:  17
IntSoftmax | n:  16
IntGELU    | n:  17
IntSoftmax | n:  16
IntGELU    | n:  17
IntSoftmax | n:  16
IntGELU    | n:  17
IntSoftmax | n:  16
IntGELU    | n:  17
IntSoftmax | n:  16
IntGELU    | n:  17
IntSoftmax | n:  16
IntGELU    | n:  17
IntSoftmax | n:  16
IntGELU    | n:  17
IntSoftmax | n:  16
IntGELU    | n:  17
IntSoftmax | n:  16
IntGELU    | n:  17
IntSoftmax | n:  16
IntGELU    | n:  17
.calib done
Test: [  0/391]	Time  3.748 ( 3.748)	Acc@1   0.00 (  0.00)	Acc@5   2.34 (  2.34)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 2.344
Time: 8.69
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=16, intgelu_exp_n=18
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=16, intgelu_exp_n=18, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  16
IntGELU    | n:  18
IntSoftmax | n:  16
IntGELU    | n:  18
IntSoftmax | n:  16
IntGELU    | n:  18
IntSoftmax | n:  16
IntGELU    | n:  18
IntSoftmax | n:  16
IntGELU    | n:  18
IntSoftmax | n:  16
IntGELU    | n:  18
IntSoftmax | n:  16
IntGELU    | n:  18
IntSoftmax | n:  16
IntGELU    | n:  18
IntSoftmax | n:  16
IntGELU    | n:  18
IntSoftmax | n:  16
IntGELU    | n:  18
IntSoftmax | n:  16
IntGELU    | n:  18
IntSoftmax | n:  16
IntGELU    | n:  18
.calib done
Test: [  0/391]	Time  3.839 ( 3.839)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.77
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=16, intgelu_exp_n=19
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=16, intgelu_exp_n=19, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  16
IntGELU    | n:  19
IntSoftmax | n:  16
IntGELU    | n:  19
IntSoftmax | n:  16
IntGELU    | n:  19
IntSoftmax | n:  16
IntGELU    | n:  19
IntSoftmax | n:  16
IntGELU    | n:  19
IntSoftmax | n:  16
IntGELU    | n:  19
IntSoftmax | n:  16
IntGELU    | n:  19
IntSoftmax | n:  16
IntGELU    | n:  19
IntSoftmax | n:  16
IntGELU    | n:  19
IntSoftmax | n:  16
IntGELU    | n:  19
IntSoftmax | n:  16
IntGELU    | n:  19
IntSoftmax | n:  16
IntGELU    | n:  19
.calib done
Test: [  0/391]	Time  4.058 ( 4.058)	Acc@1   1.56 (  1.56)	Acc@5   6.25 (  6.25)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 1.562 Prec@5 6.250
Time: 9.05
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=16, intgelu_exp_n=20
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=16, intgelu_exp_n=20, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  16
IntGELU    | n:  20
IntSoftmax | n:  16
IntGELU    | n:  20
IntSoftmax | n:  16
IntGELU    | n:  20
IntSoftmax | n:  16
IntGELU    | n:  20
IntSoftmax | n:  16
IntGELU    | n:  20
IntSoftmax | n:  16
IntGELU    | n:  20
IntSoftmax | n:  16
IntGELU    | n:  20
IntSoftmax | n:  16
IntGELU    | n:  20
IntSoftmax | n:  16
IntGELU    | n:  20
IntSoftmax | n:  16
IntGELU    | n:  20
IntSoftmax | n:  16
IntGELU    | n:  20
IntSoftmax | n:  16
IntGELU    | n:  20
.calib done
Test: [  0/391]	Time  3.932 ( 3.932)	Acc@1   7.03 (  7.03)	Acc@5  11.72 ( 11.72)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 7.031 Prec@5 11.719
Time: 8.87
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=16, intgelu_exp_n=21
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=16, intgelu_exp_n=21, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  16
IntGELU    | n:  21
IntSoftmax | n:  16
IntGELU    | n:  21
IntSoftmax | n:  16
IntGELU    | n:  21
IntSoftmax | n:  16
IntGELU    | n:  21
IntSoftmax | n:  16
IntGELU    | n:  21
IntSoftmax | n:  16
IntGELU    | n:  21
IntSoftmax | n:  16
IntGELU    | n:  21
IntSoftmax | n:  16
IntGELU    | n:  21
IntSoftmax | n:  16
IntGELU    | n:  21
IntSoftmax | n:  16
IntGELU    | n:  21
IntSoftmax | n:  16
IntGELU    | n:  21
IntSoftmax | n:  16
IntGELU    | n:  21
.calib done
Test: [  0/391]	Time  3.662 ( 3.662)	Acc@1   5.47 (  5.47)	Acc@5  10.94 ( 10.94)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 5.469 Prec@5 10.938
Time: 8.66
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=16, intgelu_exp_n=22
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=16, intgelu_exp_n=22, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  16
IntGELU    | n:  22
IntSoftmax | n:  16
IntGELU    | n:  22
IntSoftmax | n:  16
IntGELU    | n:  22
IntSoftmax | n:  16
IntGELU    | n:  22
IntSoftmax | n:  16
IntGELU    | n:  22
IntSoftmax | n:  16
IntGELU    | n:  22
IntSoftmax | n:  16
IntGELU    | n:  22
IntSoftmax | n:  16
IntGELU    | n:  22
IntSoftmax | n:  16
IntGELU    | n:  22
IntSoftmax | n:  16
IntGELU    | n:  22
IntSoftmax | n:  16
IntGELU    | n:  22
IntSoftmax | n:  16
IntGELU    | n:  22
.calib done
Test: [  0/391]	Time  3.990 ( 3.990)	Acc@1   4.69 (  4.69)	Acc@5  17.97 ( 17.97)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 4.688 Prec@5 17.969
Time: 8.94
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=16, intgelu_exp_n=23
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=16, intgelu_exp_n=23, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  16
IntGELU    | n:  23
IntSoftmax | n:  16
IntGELU    | n:  23
IntSoftmax | n:  16
IntGELU    | n:  23
IntSoftmax | n:  16
IntGELU    | n:  23
IntSoftmax | n:  16
IntGELU    | n:  23
IntSoftmax | n:  16
IntGELU    | n:  23
IntSoftmax | n:  16
IntGELU    | n:  23
IntSoftmax | n:  16
IntGELU    | n:  23
IntSoftmax | n:  16
IntGELU    | n:  23
IntSoftmax | n:  16
IntGELU    | n:  23
IntSoftmax | n:  16
IntGELU    | n:  23
IntSoftmax | n:  16
IntGELU    | n:  23
.calib done
Test: [  0/391]	Time  3.816 ( 3.816)	Acc@1   7.03 (  7.03)	Acc@5  24.22 ( 24.22)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 7.031 Prec@5 24.219
Time: 8.80
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=16, intgelu_exp_n=24
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=16, intgelu_exp_n=24, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  16
IntGELU    | n:  24
IntSoftmax | n:  16
IntGELU    | n:  24
IntSoftmax | n:  16
IntGELU    | n:  24
IntSoftmax | n:  16
IntGELU    | n:  24
IntSoftmax | n:  16
IntGELU    | n:  24
IntSoftmax | n:  16
IntGELU    | n:  24
IntSoftmax | n:  16
IntGELU    | n:  24
IntSoftmax | n:  16
IntGELU    | n:  24
IntSoftmax | n:  16
IntGELU    | n:  24
IntSoftmax | n:  16
IntGELU    | n:  24
IntSoftmax | n:  16
IntGELU    | n:  24
IntSoftmax | n:  16
IntGELU    | n:  24
.calib done
Test: [  0/391]	Time  3.929 ( 3.929)	Acc@1  10.94 ( 10.94)	Acc@5  34.38 ( 34.38)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 10.938 Prec@5 34.375
Time: 8.89
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=16, intgelu_exp_n=25
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=16, intgelu_exp_n=25, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  16
IntGELU    | n:  25
IntSoftmax | n:  16
IntGELU    | n:  25
IntSoftmax | n:  16
IntGELU    | n:  25
IntSoftmax | n:  16
IntGELU    | n:  25
IntSoftmax | n:  16
IntGELU    | n:  25
IntSoftmax | n:  16
IntGELU    | n:  25
IntSoftmax | n:  16
IntGELU    | n:  25
IntSoftmax | n:  16
IntGELU    | n:  25
IntSoftmax | n:  16
IntGELU    | n:  25
IntSoftmax | n:  16
IntGELU    | n:  25
IntSoftmax | n:  16
IntGELU    | n:  25
IntSoftmax | n:  16
IntGELU    | n:  25
.calib done
Test: [  0/391]	Time  3.875 ( 3.875)	Acc@1  19.53 ( 19.53)	Acc@5  38.28 ( 38.28)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 19.531 Prec@5 38.281
Time: 8.81
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=16, intgelu_exp_n=26
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=16, intgelu_exp_n=26, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  16
IntGELU    | n:  26
IntSoftmax | n:  16
IntGELU    | n:  26
IntSoftmax | n:  16
IntGELU    | n:  26
IntSoftmax | n:  16
IntGELU    | n:  26
IntSoftmax | n:  16
IntGELU    | n:  26
IntSoftmax | n:  16
IntGELU    | n:  26
IntSoftmax | n:  16
IntGELU    | n:  26
IntSoftmax | n:  16
IntGELU    | n:  26
IntSoftmax | n:  16
IntGELU    | n:  26
IntSoftmax | n:  16
IntGELU    | n:  26
IntSoftmax | n:  16
IntGELU    | n:  26
IntSoftmax | n:  16
IntGELU    | n:  26
.calib done
Test: [  0/391]	Time  3.933 ( 3.933)	Acc@1  21.88 ( 21.88)	Acc@5  42.19 ( 42.19)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 21.875 Prec@5 42.188
Time: 8.88
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=16, intgelu_exp_n=27
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=16, intgelu_exp_n=27, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  16
IntGELU    | n:  27
IntSoftmax | n:  16
IntGELU    | n:  27
IntSoftmax | n:  16
IntGELU    | n:  27
IntSoftmax | n:  16
IntGELU    | n:  27
IntSoftmax | n:  16
IntGELU    | n:  27
IntSoftmax | n:  16
IntGELU    | n:  27
IntSoftmax | n:  16
IntGELU    | n:  27
IntSoftmax | n:  16
IntGELU    | n:  27
IntSoftmax | n:  16
IntGELU    | n:  27
IntSoftmax | n:  16
IntGELU    | n:  27
IntSoftmax | n:  16
IntGELU    | n:  27
IntSoftmax | n:  16
IntGELU    | n:  27
.calib done
Test: [  0/391]	Time  3.993 ( 3.993)	Acc@1  32.03 ( 32.03)	Acc@5  49.22 ( 49.22)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 32.031 Prec@5 49.219
Time: 8.97
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=16, intgelu_exp_n=28
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=16, intgelu_exp_n=28, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  16
IntGELU    | n:  28
IntSoftmax | n:  16
IntGELU    | n:  28
IntSoftmax | n:  16
IntGELU    | n:  28
IntSoftmax | n:  16
IntGELU    | n:  28
IntSoftmax | n:  16
IntGELU    | n:  28
IntSoftmax | n:  16
IntGELU    | n:  28
IntSoftmax | n:  16
IntGELU    | n:  28
IntSoftmax | n:  16
IntGELU    | n:  28
IntSoftmax | n:  16
IntGELU    | n:  28
IntSoftmax | n:  16
IntGELU    | n:  28
IntSoftmax | n:  16
IntGELU    | n:  28
IntSoftmax | n:  16
IntGELU    | n:  28
.calib done
Test: [  0/391]	Time  3.698 ( 3.698)	Acc@1   5.47 (  5.47)	Acc@5  26.56 ( 26.56)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 5.469 Prec@5 26.562
Time: 8.61
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=16, intgelu_exp_n=29
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=16, intgelu_exp_n=29, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  16
IntGELU    | n:  29
IntSoftmax | n:  16
IntGELU    | n:  29
IntSoftmax | n:  16
IntGELU    | n:  29
IntSoftmax | n:  16
IntGELU    | n:  29
IntSoftmax | n:  16
IntGELU    | n:  29
IntSoftmax | n:  16
IntGELU    | n:  29
IntSoftmax | n:  16
IntGELU    | n:  29
IntSoftmax | n:  16
IntGELU    | n:  29
IntSoftmax | n:  16
IntGELU    | n:  29
IntSoftmax | n:  16
IntGELU    | n:  29
IntSoftmax | n:  16
IntGELU    | n:  29
IntSoftmax | n:  16
IntGELU    | n:  29
.calib done
Test: [  0/391]	Time  4.016 ( 4.016)	Acc@1  32.81 ( 32.81)	Acc@5  58.59 ( 58.59)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 32.812 Prec@5 58.594
Time: 8.96
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=16, intgelu_exp_n=30
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=16, intgelu_exp_n=30, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  16
IntGELU    | n:  30
IntSoftmax | n:  16
IntGELU    | n:  30
IntSoftmax | n:  16
IntGELU    | n:  30
IntSoftmax | n:  16
IntGELU    | n:  30
IntSoftmax | n:  16
IntGELU    | n:  30
IntSoftmax | n:  16
IntGELU    | n:  30
IntSoftmax | n:  16
IntGELU    | n:  30
IntSoftmax | n:  16
IntGELU    | n:  30
IntSoftmax | n:  16
IntGELU    | n:  30
IntSoftmax | n:  16
IntGELU    | n:  30
IntSoftmax | n:  16
IntGELU    | n:  30
IntSoftmax | n:  16
IntGELU    | n:  30
.calib done
Test: [  0/391]	Time  3.935 ( 3.935)	Acc@1  66.41 ( 66.41)	Acc@5  85.16 ( 85.16)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 66.406 Prec@5 85.156
Time: 8.93
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=16, intgelu_exp_n=31
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=16, intgelu_exp_n=31, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  16
IntGELU    | n:  31
IntSoftmax | n:  16
IntGELU    | n:  31
IntSoftmax | n:  16
IntGELU    | n:  31
IntSoftmax | n:  16
IntGELU    | n:  31
IntSoftmax | n:  16
IntGELU    | n:  31
IntSoftmax | n:  16
IntGELU    | n:  31
IntSoftmax | n:  16
IntGELU    | n:  31
IntSoftmax | n:  16
IntGELU    | n:  31
IntSoftmax | n:  16
IntGELU    | n:  31
IntSoftmax | n:  16
IntGELU    | n:  31
IntSoftmax | n:  16
IntGELU    | n:  31
IntSoftmax | n:  16
IntGELU    | n:  31
.calib done
Test: [  0/391]	Time  3.961 ( 3.961)	Acc@1  10.94 ( 10.94)	Acc@5  19.53 ( 19.53)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 10.938 Prec@5 19.531
Time: 8.92
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=17, intgelu_exp_n=0
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=17, intgelu_exp_n=0, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  17
IntGELU    | n:  0
IntSoftmax | n:  17
IntGELU    | n:  0
IntSoftmax | n:  17
IntGELU    | n:  0
IntSoftmax | n:  17
IntGELU    | n:  0
IntSoftmax | n:  17
IntGELU    | n:  0
IntSoftmax | n:  17
IntGELU    | n:  0
IntSoftmax | n:  17
IntGELU    | n:  0
IntSoftmax | n:  17
IntGELU    | n:  0
IntSoftmax | n:  17
IntGELU    | n:  0
IntSoftmax | n:  17
IntGELU    | n:  0
IntSoftmax | n:  17
IntGELU    | n:  0
IntSoftmax | n:  17
IntGELU    | n:  0
.calib done
Test: [  0/391]	Time  3.959 ( 3.959)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.91
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=17, intgelu_exp_n=1
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=17, intgelu_exp_n=1, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  17
IntGELU    | n:  1
IntSoftmax | n:  17
IntGELU    | n:  1
IntSoftmax | n:  17
IntGELU    | n:  1
IntSoftmax | n:  17
IntGELU    | n:  1
IntSoftmax | n:  17
IntGELU    | n:  1
IntSoftmax | n:  17
IntGELU    | n:  1
IntSoftmax | n:  17
IntGELU    | n:  1
IntSoftmax | n:  17
IntGELU    | n:  1
IntSoftmax | n:  17
IntGELU    | n:  1
IntSoftmax | n:  17
IntGELU    | n:  1
IntSoftmax | n:  17
IntGELU    | n:  1
IntSoftmax | n:  17
IntGELU    | n:  1
.calib done
Test: [  0/391]	Time  3.916 ( 3.916)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.83
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=17, intgelu_exp_n=2
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=17, intgelu_exp_n=2, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  17
IntGELU    | n:  2
IntSoftmax | n:  17
IntGELU    | n:  2
IntSoftmax | n:  17
IntGELU    | n:  2
IntSoftmax | n:  17
IntGELU    | n:  2
IntSoftmax | n:  17
IntGELU    | n:  2
IntSoftmax | n:  17
IntGELU    | n:  2
IntSoftmax | n:  17
IntGELU    | n:  2
IntSoftmax | n:  17
IntGELU    | n:  2
IntSoftmax | n:  17
IntGELU    | n:  2
IntSoftmax | n:  17
IntGELU    | n:  2
IntSoftmax | n:  17
IntGELU    | n:  2
IntSoftmax | n:  17
IntGELU    | n:  2
.calib done
Test: [  0/391]	Time  3.891 ( 3.891)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.82
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=17, intgelu_exp_n=3
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=17, intgelu_exp_n=3, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  17
IntGELU    | n:  3
IntSoftmax | n:  17
IntGELU    | n:  3
IntSoftmax | n:  17
IntGELU    | n:  3
IntSoftmax | n:  17
IntGELU    | n:  3
IntSoftmax | n:  17
IntGELU    | n:  3
IntSoftmax | n:  17
IntGELU    | n:  3
IntSoftmax | n:  17
IntGELU    | n:  3
IntSoftmax | n:  17
IntGELU    | n:  3
IntSoftmax | n:  17
IntGELU    | n:  3
IntSoftmax | n:  17
IntGELU    | n:  3
IntSoftmax | n:  17
IntGELU    | n:  3
IntSoftmax | n:  17
IntGELU    | n:  3
.calib done
Test: [  0/391]	Time  3.875 ( 3.875)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.83
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=17, intgelu_exp_n=4
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=17, intgelu_exp_n=4, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  17
IntGELU    | n:  4
IntSoftmax | n:  17
IntGELU    | n:  4
IntSoftmax | n:  17
IntGELU    | n:  4
IntSoftmax | n:  17
IntGELU    | n:  4
IntSoftmax | n:  17
IntGELU    | n:  4
IntSoftmax | n:  17
IntGELU    | n:  4
IntSoftmax | n:  17
IntGELU    | n:  4
IntSoftmax | n:  17
IntGELU    | n:  4
IntSoftmax | n:  17
IntGELU    | n:  4
IntSoftmax | n:  17
IntGELU    | n:  4
IntSoftmax | n:  17
IntGELU    | n:  4
IntSoftmax | n:  17
IntGELU    | n:  4
.calib done
Test: [  0/391]	Time  3.867 ( 3.867)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.78
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=17, intgelu_exp_n=5
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=17, intgelu_exp_n=5, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  17
IntGELU    | n:  5
IntSoftmax | n:  17
IntGELU    | n:  5
IntSoftmax | n:  17
IntGELU    | n:  5
IntSoftmax | n:  17
IntGELU    | n:  5
IntSoftmax | n:  17
IntGELU    | n:  5
IntSoftmax | n:  17
IntGELU    | n:  5
IntSoftmax | n:  17
IntGELU    | n:  5
IntSoftmax | n:  17
IntGELU    | n:  5
IntSoftmax | n:  17
IntGELU    | n:  5
IntSoftmax | n:  17
IntGELU    | n:  5
IntSoftmax | n:  17
IntGELU    | n:  5
IntSoftmax | n:  17
IntGELU    | n:  5
.calib done
Test: [  0/391]	Time  3.707 ( 3.707)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.72
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=17, intgelu_exp_n=6
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=17, intgelu_exp_n=6, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  17
IntGELU    | n:  6
IntSoftmax | n:  17
IntGELU    | n:  6
IntSoftmax | n:  17
IntGELU    | n:  6
IntSoftmax | n:  17
IntGELU    | n:  6
IntSoftmax | n:  17
IntGELU    | n:  6
IntSoftmax | n:  17
IntGELU    | n:  6
IntSoftmax | n:  17
IntGELU    | n:  6
IntSoftmax | n:  17
IntGELU    | n:  6
IntSoftmax | n:  17
IntGELU    | n:  6
IntSoftmax | n:  17
IntGELU    | n:  6
IntSoftmax | n:  17
IntGELU    | n:  6
IntSoftmax | n:  17
IntGELU    | n:  6
.calib done
Test: [  0/391]	Time  3.952 ( 3.952)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.92
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=17, intgelu_exp_n=7
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=17, intgelu_exp_n=7, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  17
IntGELU    | n:  7
IntSoftmax | n:  17
IntGELU    | n:  7
IntSoftmax | n:  17
IntGELU    | n:  7
IntSoftmax | n:  17
IntGELU    | n:  7
IntSoftmax | n:  17
IntGELU    | n:  7
IntSoftmax | n:  17
IntGELU    | n:  7
IntSoftmax | n:  17
IntGELU    | n:  7
IntSoftmax | n:  17
IntGELU    | n:  7
IntSoftmax | n:  17
IntGELU    | n:  7
IntSoftmax | n:  17
IntGELU    | n:  7
IntSoftmax | n:  17
IntGELU    | n:  7
IntSoftmax | n:  17
IntGELU    | n:  7
.calib done
Test: [  0/391]	Time  3.949 ( 3.949)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.96
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=17, intgelu_exp_n=8
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=17, intgelu_exp_n=8, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  17
IntGELU    | n:  8
IntSoftmax | n:  17
IntGELU    | n:  8
IntSoftmax | n:  17
IntGELU    | n:  8
IntSoftmax | n:  17
IntGELU    | n:  8
IntSoftmax | n:  17
IntGELU    | n:  8
IntSoftmax | n:  17
IntGELU    | n:  8
IntSoftmax | n:  17
IntGELU    | n:  8
IntSoftmax | n:  17
IntGELU    | n:  8
IntSoftmax | n:  17
IntGELU    | n:  8
IntSoftmax | n:  17
IntGELU    | n:  8
IntSoftmax | n:  17
IntGELU    | n:  8
IntSoftmax | n:  17
IntGELU    | n:  8
.calib done
Test: [  0/391]	Time  4.055 ( 4.055)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 9.02
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=17, intgelu_exp_n=9
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=17, intgelu_exp_n=9, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  17
IntGELU    | n:  9
IntSoftmax | n:  17
IntGELU    | n:  9
IntSoftmax | n:  17
IntGELU    | n:  9
IntSoftmax | n:  17
IntGELU    | n:  9
IntSoftmax | n:  17
IntGELU    | n:  9
IntSoftmax | n:  17
IntGELU    | n:  9
IntSoftmax | n:  17
IntGELU    | n:  9
IntSoftmax | n:  17
IntGELU    | n:  9
IntSoftmax | n:  17
IntGELU    | n:  9
IntSoftmax | n:  17
IntGELU    | n:  9
IntSoftmax | n:  17
IntGELU    | n:  9
IntSoftmax | n:  17
IntGELU    | n:  9
.calib done
Test: [  0/391]	Time  3.828 ( 3.828)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.75
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=17, intgelu_exp_n=10
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=17, intgelu_exp_n=10, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  17
IntGELU    | n:  10
IntSoftmax | n:  17
IntGELU    | n:  10
IntSoftmax | n:  17
IntGELU    | n:  10
IntSoftmax | n:  17
IntGELU    | n:  10
IntSoftmax | n:  17
IntGELU    | n:  10
IntSoftmax | n:  17
IntGELU    | n:  10
IntSoftmax | n:  17
IntGELU    | n:  10
IntSoftmax | n:  17
IntGELU    | n:  10
IntSoftmax | n:  17
IntGELU    | n:  10
IntSoftmax | n:  17
IntGELU    | n:  10
IntSoftmax | n:  17
IntGELU    | n:  10
IntSoftmax | n:  17
IntGELU    | n:  10
.calib done
Test: [  0/391]	Time  3.864 ( 3.864)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.89
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=17, intgelu_exp_n=11
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=17, intgelu_exp_n=11, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  17
IntGELU    | n:  11
IntSoftmax | n:  17
IntGELU    | n:  11
IntSoftmax | n:  17
IntGELU    | n:  11
IntSoftmax | n:  17
IntGELU    | n:  11
IntSoftmax | n:  17
IntGELU    | n:  11
IntSoftmax | n:  17
IntGELU    | n:  11
IntSoftmax | n:  17
IntGELU    | n:  11
IntSoftmax | n:  17
IntGELU    | n:  11
IntSoftmax | n:  17
IntGELU    | n:  11
IntSoftmax | n:  17
IntGELU    | n:  11
IntSoftmax | n:  17
IntGELU    | n:  11
IntSoftmax | n:  17
IntGELU    | n:  11
.calib done
Test: [  0/391]	Time  3.703 ( 3.703)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.61
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=17, intgelu_exp_n=12
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=17, intgelu_exp_n=12, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  17
IntGELU    | n:  12
IntSoftmax | n:  17
IntGELU    | n:  12
IntSoftmax | n:  17
IntGELU    | n:  12
IntSoftmax | n:  17
IntGELU    | n:  12
IntSoftmax | n:  17
IntGELU    | n:  12
IntSoftmax | n:  17
IntGELU    | n:  12
IntSoftmax | n:  17
IntGELU    | n:  12
IntSoftmax | n:  17
IntGELU    | n:  12
IntSoftmax | n:  17
IntGELU    | n:  12
IntSoftmax | n:  17
IntGELU    | n:  12
IntSoftmax | n:  17
IntGELU    | n:  12
IntSoftmax | n:  17
IntGELU    | n:  12
.calib done
Test: [  0/391]	Time  3.831 ( 3.831)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.76
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=17, intgelu_exp_n=13
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=17, intgelu_exp_n=13, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  17
IntGELU    | n:  13
IntSoftmax | n:  17
IntGELU    | n:  13
IntSoftmax | n:  17
IntGELU    | n:  13
IntSoftmax | n:  17
IntGELU    | n:  13
IntSoftmax | n:  17
IntGELU    | n:  13
IntSoftmax | n:  17
IntGELU    | n:  13
IntSoftmax | n:  17
IntGELU    | n:  13
IntSoftmax | n:  17
IntGELU    | n:  13
IntSoftmax | n:  17
IntGELU    | n:  13
IntSoftmax | n:  17
IntGELU    | n:  13
IntSoftmax | n:  17
IntGELU    | n:  13
IntSoftmax | n:  17
IntGELU    | n:  13
.calib done
Test: [  0/391]	Time  3.759 ( 3.759)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.63
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=17, intgelu_exp_n=14
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=17, intgelu_exp_n=14, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  17
IntGELU    | n:  14
IntSoftmax | n:  17
IntGELU    | n:  14
IntSoftmax | n:  17
IntGELU    | n:  14
IntSoftmax | n:  17
IntGELU    | n:  14
IntSoftmax | n:  17
IntGELU    | n:  14
IntSoftmax | n:  17
IntGELU    | n:  14
IntSoftmax | n:  17
IntGELU    | n:  14
IntSoftmax | n:  17
IntGELU    | n:  14
IntSoftmax | n:  17
IntGELU    | n:  14
IntSoftmax | n:  17
IntGELU    | n:  14
IntSoftmax | n:  17
IntGELU    | n:  14
IntSoftmax | n:  17
IntGELU    | n:  14
.calib done
Test: [  0/391]	Time  3.805 ( 3.805)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.78
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=17, intgelu_exp_n=15
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=17, intgelu_exp_n=15, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  17
IntGELU    | n:  15
IntSoftmax | n:  17
IntGELU    | n:  15
IntSoftmax | n:  17
IntGELU    | n:  15
IntSoftmax | n:  17
IntGELU    | n:  15
IntSoftmax | n:  17
IntGELU    | n:  15
IntSoftmax | n:  17
IntGELU    | n:  15
IntSoftmax | n:  17
IntGELU    | n:  15
IntSoftmax | n:  17
IntGELU    | n:  15
IntSoftmax | n:  17
IntGELU    | n:  15
IntSoftmax | n:  17
IntGELU    | n:  15
IntSoftmax | n:  17
IntGELU    | n:  15
IntSoftmax | n:  17
IntGELU    | n:  15
.calib done
Test: [  0/391]	Time  3.939 ( 3.939)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.90
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=17, intgelu_exp_n=16
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=17, intgelu_exp_n=16, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  17
IntGELU    | n:  16
IntSoftmax | n:  17
IntGELU    | n:  16
IntSoftmax | n:  17
IntGELU    | n:  16
IntSoftmax | n:  17
IntGELU    | n:  16
IntSoftmax | n:  17
IntGELU    | n:  16
IntSoftmax | n:  17
IntGELU    | n:  16
IntSoftmax | n:  17
IntGELU    | n:  16
IntSoftmax | n:  17
IntGELU    | n:  16
IntSoftmax | n:  17
IntGELU    | n:  16
IntSoftmax | n:  17
IntGELU    | n:  16
IntSoftmax | n:  17
IntGELU    | n:  16
IntSoftmax | n:  17
IntGELU    | n:  16
.calib done
Test: [  0/391]	Time  4.044 ( 4.044)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 9.02
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=17, intgelu_exp_n=17
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=17, intgelu_exp_n=17, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  17
IntGELU    | n:  17
IntSoftmax | n:  17
IntGELU    | n:  17
IntSoftmax | n:  17
IntGELU    | n:  17
IntSoftmax | n:  17
IntGELU    | n:  17
IntSoftmax | n:  17
IntGELU    | n:  17
IntSoftmax | n:  17
IntGELU    | n:  17
IntSoftmax | n:  17
IntGELU    | n:  17
IntSoftmax | n:  17
IntGELU    | n:  17
IntSoftmax | n:  17
IntGELU    | n:  17
IntSoftmax | n:  17
IntGELU    | n:  17
IntSoftmax | n:  17
IntGELU    | n:  17
IntSoftmax | n:  17
IntGELU    | n:  17
.calib done
Test: [  0/391]	Time  4.010 ( 4.010)	Acc@1   0.00 (  0.00)	Acc@5   0.78 (  0.78)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.781
Time: 8.94
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=17, intgelu_exp_n=18
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=17, intgelu_exp_n=18, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  17
IntGELU    | n:  18
IntSoftmax | n:  17
IntGELU    | n:  18
IntSoftmax | n:  17
IntGELU    | n:  18
IntSoftmax | n:  17
IntGELU    | n:  18
IntSoftmax | n:  17
IntGELU    | n:  18
IntSoftmax | n:  17
IntGELU    | n:  18
IntSoftmax | n:  17
IntGELU    | n:  18
IntSoftmax | n:  17
IntGELU    | n:  18
IntSoftmax | n:  17
IntGELU    | n:  18
IntSoftmax | n:  17
IntGELU    | n:  18
IntSoftmax | n:  17
IntGELU    | n:  18
IntSoftmax | n:  17
IntGELU    | n:  18
.calib done
Test: [  0/391]	Time  3.653 ( 3.653)	Acc@1   0.00 (  0.00)	Acc@5   0.78 (  0.78)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.781
Time: 8.61
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=17, intgelu_exp_n=19
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=17, intgelu_exp_n=19, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  17
IntGELU    | n:  19
IntSoftmax | n:  17
IntGELU    | n:  19
IntSoftmax | n:  17
IntGELU    | n:  19
IntSoftmax | n:  17
IntGELU    | n:  19
IntSoftmax | n:  17
IntGELU    | n:  19
IntSoftmax | n:  17
IntGELU    | n:  19
IntSoftmax | n:  17
IntGELU    | n:  19
IntSoftmax | n:  17
IntGELU    | n:  19
IntSoftmax | n:  17
IntGELU    | n:  19
IntSoftmax | n:  17
IntGELU    | n:  19
IntSoftmax | n:  17
IntGELU    | n:  19
IntSoftmax | n:  17
IntGELU    | n:  19
.calib done
Test: [  0/391]	Time  3.966 ( 3.966)	Acc@1   3.91 (  3.91)	Acc@5   8.59 (  8.59)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 3.906 Prec@5 8.594
Time: 8.99
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=17, intgelu_exp_n=20
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=17, intgelu_exp_n=20, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  17
IntGELU    | n:  20
IntSoftmax | n:  17
IntGELU    | n:  20
IntSoftmax | n:  17
IntGELU    | n:  20
IntSoftmax | n:  17
IntGELU    | n:  20
IntSoftmax | n:  17
IntGELU    | n:  20
IntSoftmax | n:  17
IntGELU    | n:  20
IntSoftmax | n:  17
IntGELU    | n:  20
IntSoftmax | n:  17
IntGELU    | n:  20
IntSoftmax | n:  17
IntGELU    | n:  20
IntSoftmax | n:  17
IntGELU    | n:  20
IntSoftmax | n:  17
IntGELU    | n:  20
IntSoftmax | n:  17
IntGELU    | n:  20
.calib done
Test: [  0/391]	Time  3.872 ( 3.872)	Acc@1   3.12 (  3.12)	Acc@5   7.81 (  7.81)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 3.125 Prec@5 7.812
Time: 8.79
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=17, intgelu_exp_n=21
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=17, intgelu_exp_n=21, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  17
IntGELU    | n:  21
IntSoftmax | n:  17
IntGELU    | n:  21
IntSoftmax | n:  17
IntGELU    | n:  21
IntSoftmax | n:  17
IntGELU    | n:  21
IntSoftmax | n:  17
IntGELU    | n:  21
IntSoftmax | n:  17
IntGELU    | n:  21
IntSoftmax | n:  17
IntGELU    | n:  21
IntSoftmax | n:  17
IntGELU    | n:  21
IntSoftmax | n:  17
IntGELU    | n:  21
IntSoftmax | n:  17
IntGELU    | n:  21
IntSoftmax | n:  17
IntGELU    | n:  21
IntSoftmax | n:  17
IntGELU    | n:  21
.calib done
Test: [  0/391]	Time  3.886 ( 3.886)	Acc@1   4.69 (  4.69)	Acc@5  16.41 ( 16.41)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 4.688 Prec@5 16.406
Time: 8.83
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=17, intgelu_exp_n=22
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=17, intgelu_exp_n=22, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  17
IntGELU    | n:  22
IntSoftmax | n:  17
IntGELU    | n:  22
IntSoftmax | n:  17
IntGELU    | n:  22
IntSoftmax | n:  17
IntGELU    | n:  22
IntSoftmax | n:  17
IntGELU    | n:  22
IntSoftmax | n:  17
IntGELU    | n:  22
IntSoftmax | n:  17
IntGELU    | n:  22
IntSoftmax | n:  17
IntGELU    | n:  22
IntSoftmax | n:  17
IntGELU    | n:  22
IntSoftmax | n:  17
IntGELU    | n:  22
IntSoftmax | n:  17
IntGELU    | n:  22
IntSoftmax | n:  17
IntGELU    | n:  22
.calib done
Test: [  0/391]	Time  4.000 ( 4.000)	Acc@1   7.03 (  7.03)	Acc@5  22.66 ( 22.66)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 7.031 Prec@5 22.656
Time: 8.99
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=17, intgelu_exp_n=23
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=17, intgelu_exp_n=23, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  17
IntGELU    | n:  23
IntSoftmax | n:  17
IntGELU    | n:  23
IntSoftmax | n:  17
IntGELU    | n:  23
IntSoftmax | n:  17
IntGELU    | n:  23
IntSoftmax | n:  17
IntGELU    | n:  23
IntSoftmax | n:  17
IntGELU    | n:  23
IntSoftmax | n:  17
IntGELU    | n:  23
IntSoftmax | n:  17
IntGELU    | n:  23
IntSoftmax | n:  17
IntGELU    | n:  23
IntSoftmax | n:  17
IntGELU    | n:  23
IntSoftmax | n:  17
IntGELU    | n:  23
IntSoftmax | n:  17
IntGELU    | n:  23
.calib done
Test: [  0/391]	Time  3.952 ( 3.952)	Acc@1   8.59 (  8.59)	Acc@5  23.44 ( 23.44)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 8.594 Prec@5 23.438
Time: 8.86
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=17, intgelu_exp_n=24
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=17, intgelu_exp_n=24, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  17
IntGELU    | n:  24
IntSoftmax | n:  17
IntGELU    | n:  24
IntSoftmax | n:  17
IntGELU    | n:  24
IntSoftmax | n:  17
IntGELU    | n:  24
IntSoftmax | n:  17
IntGELU    | n:  24
IntSoftmax | n:  17
IntGELU    | n:  24
IntSoftmax | n:  17
IntGELU    | n:  24
IntSoftmax | n:  17
IntGELU    | n:  24
IntSoftmax | n:  17
IntGELU    | n:  24
IntSoftmax | n:  17
IntGELU    | n:  24
IntSoftmax | n:  17
IntGELU    | n:  24
IntSoftmax | n:  17
IntGELU    | n:  24
.calib done
Test: [  0/391]	Time  3.676 ( 3.676)	Acc@1  16.41 ( 16.41)	Acc@5  35.16 ( 35.16)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 16.406 Prec@5 35.156
Time: 8.69
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=17, intgelu_exp_n=25
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=17, intgelu_exp_n=25, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  17
IntGELU    | n:  25
IntSoftmax | n:  17
IntGELU    | n:  25
IntSoftmax | n:  17
IntGELU    | n:  25
IntSoftmax | n:  17
IntGELU    | n:  25
IntSoftmax | n:  17
IntGELU    | n:  25
IntSoftmax | n:  17
IntGELU    | n:  25
IntSoftmax | n:  17
IntGELU    | n:  25
IntSoftmax | n:  17
IntGELU    | n:  25
IntSoftmax | n:  17
IntGELU    | n:  25
IntSoftmax | n:  17
IntGELU    | n:  25
IntSoftmax | n:  17
IntGELU    | n:  25
IntSoftmax | n:  17
IntGELU    | n:  25
.calib done
Test: [  0/391]	Time  3.761 ( 3.761)	Acc@1  14.06 ( 14.06)	Acc@5  35.16 ( 35.16)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 14.062 Prec@5 35.156
Time: 8.71
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=17, intgelu_exp_n=26
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=17, intgelu_exp_n=26, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  17
IntGELU    | n:  26
IntSoftmax | n:  17
IntGELU    | n:  26
IntSoftmax | n:  17
IntGELU    | n:  26
IntSoftmax | n:  17
IntGELU    | n:  26
IntSoftmax | n:  17
IntGELU    | n:  26
IntSoftmax | n:  17
IntGELU    | n:  26
IntSoftmax | n:  17
IntGELU    | n:  26
IntSoftmax | n:  17
IntGELU    | n:  26
IntSoftmax | n:  17
IntGELU    | n:  26
IntSoftmax | n:  17
IntGELU    | n:  26
IntSoftmax | n:  17
IntGELU    | n:  26
IntSoftmax | n:  17
IntGELU    | n:  26
.calib done
Test: [  0/391]	Time  3.781 ( 3.781)	Acc@1  20.31 ( 20.31)	Acc@5  41.41 ( 41.41)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 20.312 Prec@5 41.406
Time: 8.80
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=17, intgelu_exp_n=27
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=17, intgelu_exp_n=27, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  17
IntGELU    | n:  27
IntSoftmax | n:  17
IntGELU    | n:  27
IntSoftmax | n:  17
IntGELU    | n:  27
IntSoftmax | n:  17
IntGELU    | n:  27
IntSoftmax | n:  17
IntGELU    | n:  27
IntSoftmax | n:  17
IntGELU    | n:  27
IntSoftmax | n:  17
IntGELU    | n:  27
IntSoftmax | n:  17
IntGELU    | n:  27
IntSoftmax | n:  17
IntGELU    | n:  27
IntSoftmax | n:  17
IntGELU    | n:  27
IntSoftmax | n:  17
IntGELU    | n:  27
IntSoftmax | n:  17
IntGELU    | n:  27
.calib done
Test: [  0/391]	Time  4.011 ( 4.011)	Acc@1  28.91 ( 28.91)	Acc@5  50.00 ( 50.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 28.906 Prec@5 50.000
Time: 9.04
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=17, intgelu_exp_n=28
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=17, intgelu_exp_n=28, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  17
IntGELU    | n:  28
IntSoftmax | n:  17
IntGELU    | n:  28
IntSoftmax | n:  17
IntGELU    | n:  28
IntSoftmax | n:  17
IntGELU    | n:  28
IntSoftmax | n:  17
IntGELU    | n:  28
IntSoftmax | n:  17
IntGELU    | n:  28
IntSoftmax | n:  17
IntGELU    | n:  28
IntSoftmax | n:  17
IntGELU    | n:  28
IntSoftmax | n:  17
IntGELU    | n:  28
IntSoftmax | n:  17
IntGELU    | n:  28
IntSoftmax | n:  17
IntGELU    | n:  28
IntSoftmax | n:  17
IntGELU    | n:  28
.calib done
Test: [  0/391]	Time  3.681 ( 3.681)	Acc@1  25.00 ( 25.00)	Acc@5  53.12 ( 53.12)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 25.000 Prec@5 53.125
Time: 8.62
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=17, intgelu_exp_n=29
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=17, intgelu_exp_n=29, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  17
IntGELU    | n:  29
IntSoftmax | n:  17
IntGELU    | n:  29
IntSoftmax | n:  17
IntGELU    | n:  29
IntSoftmax | n:  17
IntGELU    | n:  29
IntSoftmax | n:  17
IntGELU    | n:  29
IntSoftmax | n:  17
IntGELU    | n:  29
IntSoftmax | n:  17
IntGELU    | n:  29
IntSoftmax | n:  17
IntGELU    | n:  29
IntSoftmax | n:  17
IntGELU    | n:  29
IntSoftmax | n:  17
IntGELU    | n:  29
IntSoftmax | n:  17
IntGELU    | n:  29
IntSoftmax | n:  17
IntGELU    | n:  29
.calib done
Test: [  0/391]	Time  3.793 ( 3.793)	Acc@1  32.81 ( 32.81)	Acc@5  57.81 ( 57.81)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 32.812 Prec@5 57.812
Time: 8.76
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=17, intgelu_exp_n=30
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=17, intgelu_exp_n=30, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  17
IntGELU    | n:  30
IntSoftmax | n:  17
IntGELU    | n:  30
IntSoftmax | n:  17
IntGELU    | n:  30
IntSoftmax | n:  17
IntGELU    | n:  30
IntSoftmax | n:  17
IntGELU    | n:  30
IntSoftmax | n:  17
IntGELU    | n:  30
IntSoftmax | n:  17
IntGELU    | n:  30
IntSoftmax | n:  17
IntGELU    | n:  30
IntSoftmax | n:  17
IntGELU    | n:  30
IntSoftmax | n:  17
IntGELU    | n:  30
IntSoftmax | n:  17
IntGELU    | n:  30
IntSoftmax | n:  17
IntGELU    | n:  30
.calib done
Test: [  0/391]	Time  3.699 ( 3.699)	Acc@1  91.41 ( 91.41)	Acc@5  96.09 ( 96.09)
Test: [ 10/391]	Time  1.747 ( 1.924)	Acc@1  61.72 ( 79.97)	Acc@5  84.38 ( 93.25)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 79.972 Prec@5 93.253
Time: 26.17
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=17, intgelu_exp_n=31
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=17, intgelu_exp_n=31, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  17
IntGELU    | n:  31
IntSoftmax | n:  17
IntGELU    | n:  31
IntSoftmax | n:  17
IntGELU    | n:  31
IntSoftmax | n:  17
IntGELU    | n:  31
IntSoftmax | n:  17
IntGELU    | n:  31
IntSoftmax | n:  17
IntGELU    | n:  31
IntSoftmax | n:  17
IntGELU    | n:  31
IntSoftmax | n:  17
IntGELU    | n:  31
IntSoftmax | n:  17
IntGELU    | n:  31
IntSoftmax | n:  17
IntGELU    | n:  31
IntSoftmax | n:  17
IntGELU    | n:  31
IntSoftmax | n:  17
IntGELU    | n:  31
.calib done
Test: [  0/391]	Time  3.824 ( 3.824)	Acc@1   7.03 (  7.03)	Acc@5  17.19 ( 17.19)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 7.031 Prec@5 17.188
Time: 8.77
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=18, intgelu_exp_n=0
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=18, intgelu_exp_n=0, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  18
IntGELU    | n:  0
IntSoftmax | n:  18
IntGELU    | n:  0
IntSoftmax | n:  18
IntGELU    | n:  0
IntSoftmax | n:  18
IntGELU    | n:  0
IntSoftmax | n:  18
IntGELU    | n:  0
IntSoftmax | n:  18
IntGELU    | n:  0
IntSoftmax | n:  18
IntGELU    | n:  0
IntSoftmax | n:  18
IntGELU    | n:  0
IntSoftmax | n:  18
IntGELU    | n:  0
IntSoftmax | n:  18
IntGELU    | n:  0
IntSoftmax | n:  18
IntGELU    | n:  0
IntSoftmax | n:  18
IntGELU    | n:  0
.calib done
Test: [  0/391]	Time  3.681 ( 3.681)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.61
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=18, intgelu_exp_n=1
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=18, intgelu_exp_n=1, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  18
IntGELU    | n:  1
IntSoftmax | n:  18
IntGELU    | n:  1
IntSoftmax | n:  18
IntGELU    | n:  1
IntSoftmax | n:  18
IntGELU    | n:  1
IntSoftmax | n:  18
IntGELU    | n:  1
IntSoftmax | n:  18
IntGELU    | n:  1
IntSoftmax | n:  18
IntGELU    | n:  1
IntSoftmax | n:  18
IntGELU    | n:  1
IntSoftmax | n:  18
IntGELU    | n:  1
IntSoftmax | n:  18
IntGELU    | n:  1
IntSoftmax | n:  18
IntGELU    | n:  1
IntSoftmax | n:  18
IntGELU    | n:  1
.calib done
Test: [  0/391]	Time  3.933 ( 3.933)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.86
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=18, intgelu_exp_n=2
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=18, intgelu_exp_n=2, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  18
IntGELU    | n:  2
IntSoftmax | n:  18
IntGELU    | n:  2
IntSoftmax | n:  18
IntGELU    | n:  2
IntSoftmax | n:  18
IntGELU    | n:  2
IntSoftmax | n:  18
IntGELU    | n:  2
IntSoftmax | n:  18
IntGELU    | n:  2
IntSoftmax | n:  18
IntGELU    | n:  2
IntSoftmax | n:  18
IntGELU    | n:  2
IntSoftmax | n:  18
IntGELU    | n:  2
IntSoftmax | n:  18
IntGELU    | n:  2
IntSoftmax | n:  18
IntGELU    | n:  2
IntSoftmax | n:  18
IntGELU    | n:  2
.calib done
Test: [  0/391]	Time  3.848 ( 3.848)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.82
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=18, intgelu_exp_n=3
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=18, intgelu_exp_n=3, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  18
IntGELU    | n:  3
IntSoftmax | n:  18
IntGELU    | n:  3
IntSoftmax | n:  18
IntGELU    | n:  3
IntSoftmax | n:  18
IntGELU    | n:  3
IntSoftmax | n:  18
IntGELU    | n:  3
IntSoftmax | n:  18
IntGELU    | n:  3
IntSoftmax | n:  18
IntGELU    | n:  3
IntSoftmax | n:  18
IntGELU    | n:  3
IntSoftmax | n:  18
IntGELU    | n:  3
IntSoftmax | n:  18
IntGELU    | n:  3
IntSoftmax | n:  18
IntGELU    | n:  3
IntSoftmax | n:  18
IntGELU    | n:  3
.calib done
Test: [  0/391]	Time  3.649 ( 3.649)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.52
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=18, intgelu_exp_n=4
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=18, intgelu_exp_n=4, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  18
IntGELU    | n:  4
IntSoftmax | n:  18
IntGELU    | n:  4
IntSoftmax | n:  18
IntGELU    | n:  4
IntSoftmax | n:  18
IntGELU    | n:  4
IntSoftmax | n:  18
IntGELU    | n:  4
IntSoftmax | n:  18
IntGELU    | n:  4
IntSoftmax | n:  18
IntGELU    | n:  4
IntSoftmax | n:  18
IntGELU    | n:  4
IntSoftmax | n:  18
IntGELU    | n:  4
IntSoftmax | n:  18
IntGELU    | n:  4
IntSoftmax | n:  18
IntGELU    | n:  4
IntSoftmax | n:  18
IntGELU    | n:  4
.calib done
Test: [  0/391]	Time  3.850 ( 3.850)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.85
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=18, intgelu_exp_n=5
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=18, intgelu_exp_n=5, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  18
IntGELU    | n:  5
IntSoftmax | n:  18
IntGELU    | n:  5
IntSoftmax | n:  18
IntGELU    | n:  5
IntSoftmax | n:  18
IntGELU    | n:  5
IntSoftmax | n:  18
IntGELU    | n:  5
IntSoftmax | n:  18
IntGELU    | n:  5
IntSoftmax | n:  18
IntGELU    | n:  5
IntSoftmax | n:  18
IntGELU    | n:  5
IntSoftmax | n:  18
IntGELU    | n:  5
IntSoftmax | n:  18
IntGELU    | n:  5
IntSoftmax | n:  18
IntGELU    | n:  5
IntSoftmax | n:  18
IntGELU    | n:  5
.calib done
Test: [  0/391]	Time  3.891 ( 3.891)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.81
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=18, intgelu_exp_n=6
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=18, intgelu_exp_n=6, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  18
IntGELU    | n:  6
IntSoftmax | n:  18
IntGELU    | n:  6
IntSoftmax | n:  18
IntGELU    | n:  6
IntSoftmax | n:  18
IntGELU    | n:  6
IntSoftmax | n:  18
IntGELU    | n:  6
IntSoftmax | n:  18
IntGELU    | n:  6
IntSoftmax | n:  18
IntGELU    | n:  6
IntSoftmax | n:  18
IntGELU    | n:  6
IntSoftmax | n:  18
IntGELU    | n:  6
IntSoftmax | n:  18
IntGELU    | n:  6
IntSoftmax | n:  18
IntGELU    | n:  6
IntSoftmax | n:  18
IntGELU    | n:  6
.calib done
Test: [  0/391]	Time  3.833 ( 3.833)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.81
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=18, intgelu_exp_n=7
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=18, intgelu_exp_n=7, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  18
IntGELU    | n:  7
IntSoftmax | n:  18
IntGELU    | n:  7
IntSoftmax | n:  18
IntGELU    | n:  7
IntSoftmax | n:  18
IntGELU    | n:  7
IntSoftmax | n:  18
IntGELU    | n:  7
IntSoftmax | n:  18
IntGELU    | n:  7
IntSoftmax | n:  18
IntGELU    | n:  7
IntSoftmax | n:  18
IntGELU    | n:  7
IntSoftmax | n:  18
IntGELU    | n:  7
IntSoftmax | n:  18
IntGELU    | n:  7
IntSoftmax | n:  18
IntGELU    | n:  7
IntSoftmax | n:  18
IntGELU    | n:  7
.calib done
Test: [  0/391]	Time  4.025 ( 4.025)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.94
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=18, intgelu_exp_n=8
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=18, intgelu_exp_n=8, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  18
IntGELU    | n:  8
IntSoftmax | n:  18
IntGELU    | n:  8
IntSoftmax | n:  18
IntGELU    | n:  8
IntSoftmax | n:  18
IntGELU    | n:  8
IntSoftmax | n:  18
IntGELU    | n:  8
IntSoftmax | n:  18
IntGELU    | n:  8
IntSoftmax | n:  18
IntGELU    | n:  8
IntSoftmax | n:  18
IntGELU    | n:  8
IntSoftmax | n:  18
IntGELU    | n:  8
IntSoftmax | n:  18
IntGELU    | n:  8
IntSoftmax | n:  18
IntGELU    | n:  8
IntSoftmax | n:  18
IntGELU    | n:  8
.calib done
Test: [  0/391]	Time  3.605 ( 3.605)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.55
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=18, intgelu_exp_n=9
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=18, intgelu_exp_n=9, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  18
IntGELU    | n:  9
IntSoftmax | n:  18
IntGELU    | n:  9
IntSoftmax | n:  18
IntGELU    | n:  9
IntSoftmax | n:  18
IntGELU    | n:  9
IntSoftmax | n:  18
IntGELU    | n:  9
IntSoftmax | n:  18
IntGELU    | n:  9
IntSoftmax | n:  18
IntGELU    | n:  9
IntSoftmax | n:  18
IntGELU    | n:  9
IntSoftmax | n:  18
IntGELU    | n:  9
IntSoftmax | n:  18
IntGELU    | n:  9
IntSoftmax | n:  18
IntGELU    | n:  9
IntSoftmax | n:  18
IntGELU    | n:  9
.calib done
Test: [  0/391]	Time  3.755 ( 3.755)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.73
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=18, intgelu_exp_n=10
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=18, intgelu_exp_n=10, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  18
IntGELU    | n:  10
IntSoftmax | n:  18
IntGELU    | n:  10
IntSoftmax | n:  18
IntGELU    | n:  10
IntSoftmax | n:  18
IntGELU    | n:  10
IntSoftmax | n:  18
IntGELU    | n:  10
IntSoftmax | n:  18
IntGELU    | n:  10
IntSoftmax | n:  18
IntGELU    | n:  10
IntSoftmax | n:  18
IntGELU    | n:  10
IntSoftmax | n:  18
IntGELU    | n:  10
IntSoftmax | n:  18
IntGELU    | n:  10
IntSoftmax | n:  18
IntGELU    | n:  10
IntSoftmax | n:  18
IntGELU    | n:  10
.calib done
Test: [  0/391]	Time  3.882 ( 3.882)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.88
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=18, intgelu_exp_n=11
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=18, intgelu_exp_n=11, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  18
IntGELU    | n:  11
IntSoftmax | n:  18
IntGELU    | n:  11
IntSoftmax | n:  18
IntGELU    | n:  11
IntSoftmax | n:  18
IntGELU    | n:  11
IntSoftmax | n:  18
IntGELU    | n:  11
IntSoftmax | n:  18
IntGELU    | n:  11
IntSoftmax | n:  18
IntGELU    | n:  11
IntSoftmax | n:  18
IntGELU    | n:  11
IntSoftmax | n:  18
IntGELU    | n:  11
IntSoftmax | n:  18
IntGELU    | n:  11
IntSoftmax | n:  18
IntGELU    | n:  11
IntSoftmax | n:  18
IntGELU    | n:  11
.calib done
Test: [  0/391]	Time  3.818 ( 3.818)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.74
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=18, intgelu_exp_n=12
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=18, intgelu_exp_n=12, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  18
IntGELU    | n:  12
IntSoftmax | n:  18
IntGELU    | n:  12
IntSoftmax | n:  18
IntGELU    | n:  12
IntSoftmax | n:  18
IntGELU    | n:  12
IntSoftmax | n:  18
IntGELU    | n:  12
IntSoftmax | n:  18
IntGELU    | n:  12
IntSoftmax | n:  18
IntGELU    | n:  12
IntSoftmax | n:  18
IntGELU    | n:  12
IntSoftmax | n:  18
IntGELU    | n:  12
IntSoftmax | n:  18
IntGELU    | n:  12
IntSoftmax | n:  18
IntGELU    | n:  12
IntSoftmax | n:  18
IntGELU    | n:  12
.calib done
Test: [  0/391]	Time  3.947 ( 3.947)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.88
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=18, intgelu_exp_n=13
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=18, intgelu_exp_n=13, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  18
IntGELU    | n:  13
IntSoftmax | n:  18
IntGELU    | n:  13
IntSoftmax | n:  18
IntGELU    | n:  13
IntSoftmax | n:  18
IntGELU    | n:  13
IntSoftmax | n:  18
IntGELU    | n:  13
IntSoftmax | n:  18
IntGELU    | n:  13
IntSoftmax | n:  18
IntGELU    | n:  13
IntSoftmax | n:  18
IntGELU    | n:  13
IntSoftmax | n:  18
IntGELU    | n:  13
IntSoftmax | n:  18
IntGELU    | n:  13
IntSoftmax | n:  18
IntGELU    | n:  13
IntSoftmax | n:  18
IntGELU    | n:  13
.calib done
Test: [  0/391]	Time  3.828 ( 3.828)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.79
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=18, intgelu_exp_n=14
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=18, intgelu_exp_n=14, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  18
IntGELU    | n:  14
IntSoftmax | n:  18
IntGELU    | n:  14
IntSoftmax | n:  18
IntGELU    | n:  14
IntSoftmax | n:  18
IntGELU    | n:  14
IntSoftmax | n:  18
IntGELU    | n:  14
IntSoftmax | n:  18
IntGELU    | n:  14
IntSoftmax | n:  18
IntGELU    | n:  14
IntSoftmax | n:  18
IntGELU    | n:  14
IntSoftmax | n:  18
IntGELU    | n:  14
IntSoftmax | n:  18
IntGELU    | n:  14
IntSoftmax | n:  18
IntGELU    | n:  14
IntSoftmax | n:  18
IntGELU    | n:  14
.calib done
Test: [  0/391]	Time  3.948 ( 3.948)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.92
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=18, intgelu_exp_n=15
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=18, intgelu_exp_n=15, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  18
IntGELU    | n:  15
IntSoftmax | n:  18
IntGELU    | n:  15
IntSoftmax | n:  18
IntGELU    | n:  15
IntSoftmax | n:  18
IntGELU    | n:  15
IntSoftmax | n:  18
IntGELU    | n:  15
IntSoftmax | n:  18
IntGELU    | n:  15
IntSoftmax | n:  18
IntGELU    | n:  15
IntSoftmax | n:  18
IntGELU    | n:  15
IntSoftmax | n:  18
IntGELU    | n:  15
IntSoftmax | n:  18
IntGELU    | n:  15
IntSoftmax | n:  18
IntGELU    | n:  15
IntSoftmax | n:  18
IntGELU    | n:  15
.calib done
Test: [  0/391]	Time  3.850 ( 3.850)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.83
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=18, intgelu_exp_n=16
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=18, intgelu_exp_n=16, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  18
IntGELU    | n:  16
IntSoftmax | n:  18
IntGELU    | n:  16
IntSoftmax | n:  18
IntGELU    | n:  16
IntSoftmax | n:  18
IntGELU    | n:  16
IntSoftmax | n:  18
IntGELU    | n:  16
IntSoftmax | n:  18
IntGELU    | n:  16
IntSoftmax | n:  18
IntGELU    | n:  16
IntSoftmax | n:  18
IntGELU    | n:  16
IntSoftmax | n:  18
IntGELU    | n:  16
IntSoftmax | n:  18
IntGELU    | n:  16
IntSoftmax | n:  18
IntGELU    | n:  16
IntSoftmax | n:  18
IntGELU    | n:  16
.calib done
Test: [  0/391]	Time  3.967 ( 3.967)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.98
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=18, intgelu_exp_n=17
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=18, intgelu_exp_n=17, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  18
IntGELU    | n:  17
IntSoftmax | n:  18
IntGELU    | n:  17
IntSoftmax | n:  18
IntGELU    | n:  17
IntSoftmax | n:  18
IntGELU    | n:  17
IntSoftmax | n:  18
IntGELU    | n:  17
IntSoftmax | n:  18
IntGELU    | n:  17
IntSoftmax | n:  18
IntGELU    | n:  17
IntSoftmax | n:  18
IntGELU    | n:  17
IntSoftmax | n:  18
IntGELU    | n:  17
IntSoftmax | n:  18
IntGELU    | n:  17
IntSoftmax | n:  18
IntGELU    | n:  17
IntSoftmax | n:  18
IntGELU    | n:  17
.calib done
Test: [  0/391]	Time  3.891 ( 3.891)	Acc@1   0.78 (  0.78)	Acc@5   1.56 (  1.56)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.781 Prec@5 1.562
Time: 8.84
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=18, intgelu_exp_n=18
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=18, intgelu_exp_n=18, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  18
IntGELU    | n:  18
IntSoftmax | n:  18
IntGELU    | n:  18
IntSoftmax | n:  18
IntGELU    | n:  18
IntSoftmax | n:  18
IntGELU    | n:  18
IntSoftmax | n:  18
IntGELU    | n:  18
IntSoftmax | n:  18
IntGELU    | n:  18
IntSoftmax | n:  18
IntGELU    | n:  18
IntSoftmax | n:  18
IntGELU    | n:  18
IntSoftmax | n:  18
IntGELU    | n:  18
IntSoftmax | n:  18
IntGELU    | n:  18
IntSoftmax | n:  18
IntGELU    | n:  18
IntSoftmax | n:  18
IntGELU    | n:  18
.calib done
Test: [  0/391]	Time  3.955 ( 3.955)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.96
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=18, intgelu_exp_n=19
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=18, intgelu_exp_n=19, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  18
IntGELU    | n:  19
IntSoftmax | n:  18
IntGELU    | n:  19
IntSoftmax | n:  18
IntGELU    | n:  19
IntSoftmax | n:  18
IntGELU    | n:  19
IntSoftmax | n:  18
IntGELU    | n:  19
IntSoftmax | n:  18
IntGELU    | n:  19
IntSoftmax | n:  18
IntGELU    | n:  19
IntSoftmax | n:  18
IntGELU    | n:  19
IntSoftmax | n:  18
IntGELU    | n:  19
IntSoftmax | n:  18
IntGELU    | n:  19
IntSoftmax | n:  18
IntGELU    | n:  19
IntSoftmax | n:  18
IntGELU    | n:  19
.calib done
Test: [  0/391]	Time  3.778 ( 3.778)	Acc@1   3.91 (  3.91)	Acc@5   7.81 (  7.81)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 3.906 Prec@5 7.812
Time: 8.69
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=18, intgelu_exp_n=20
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=18, intgelu_exp_n=20, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  18
IntGELU    | n:  20
IntSoftmax | n:  18
IntGELU    | n:  20
IntSoftmax | n:  18
IntGELU    | n:  20
IntSoftmax | n:  18
IntGELU    | n:  20
IntSoftmax | n:  18
IntGELU    | n:  20
IntSoftmax | n:  18
IntGELU    | n:  20
IntSoftmax | n:  18
IntGELU    | n:  20
IntSoftmax | n:  18
IntGELU    | n:  20
IntSoftmax | n:  18
IntGELU    | n:  20
IntSoftmax | n:  18
IntGELU    | n:  20
IntSoftmax | n:  18
IntGELU    | n:  20
IntSoftmax | n:  18
IntGELU    | n:  20
.calib done
Test: [  0/391]	Time  3.987 ( 3.987)	Acc@1   1.56 (  1.56)	Acc@5   6.25 (  6.25)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 1.562 Prec@5 6.250
Time: 8.99
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=18, intgelu_exp_n=21
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=18, intgelu_exp_n=21, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  18
IntGELU    | n:  21
IntSoftmax | n:  18
IntGELU    | n:  21
IntSoftmax | n:  18
IntGELU    | n:  21
IntSoftmax | n:  18
IntGELU    | n:  21
IntSoftmax | n:  18
IntGELU    | n:  21
IntSoftmax | n:  18
IntGELU    | n:  21
IntSoftmax | n:  18
IntGELU    | n:  21
IntSoftmax | n:  18
IntGELU    | n:  21
IntSoftmax | n:  18
IntGELU    | n:  21
IntSoftmax | n:  18
IntGELU    | n:  21
IntSoftmax | n:  18
IntGELU    | n:  21
IntSoftmax | n:  18
IntGELU    | n:  21
.calib done
Test: [  0/391]	Time  3.943 ( 3.943)	Acc@1   7.81 (  7.81)	Acc@5  15.62 ( 15.62)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 7.812 Prec@5 15.625
Time: 8.89
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=18, intgelu_exp_n=22
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=18, intgelu_exp_n=22, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  18
IntGELU    | n:  22
IntSoftmax | n:  18
IntGELU    | n:  22
IntSoftmax | n:  18
IntGELU    | n:  22
IntSoftmax | n:  18
IntGELU    | n:  22
IntSoftmax | n:  18
IntGELU    | n:  22
IntSoftmax | n:  18
IntGELU    | n:  22
IntSoftmax | n:  18
IntGELU    | n:  22
IntSoftmax | n:  18
IntGELU    | n:  22
IntSoftmax | n:  18
IntGELU    | n:  22
IntSoftmax | n:  18
IntGELU    | n:  22
IntSoftmax | n:  18
IntGELU    | n:  22
IntSoftmax | n:  18
IntGELU    | n:  22
.calib done
Test: [  0/391]	Time  3.666 ( 3.666)	Acc@1  11.72 ( 11.72)	Acc@5  22.66 ( 22.66)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 11.719 Prec@5 22.656
Time: 8.70
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=18, intgelu_exp_n=23
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=18, intgelu_exp_n=23, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  18
IntGELU    | n:  23
IntSoftmax | n:  18
IntGELU    | n:  23
IntSoftmax | n:  18
IntGELU    | n:  23
IntSoftmax | n:  18
IntGELU    | n:  23
IntSoftmax | n:  18
IntGELU    | n:  23
IntSoftmax | n:  18
IntGELU    | n:  23
IntSoftmax | n:  18
IntGELU    | n:  23
IntSoftmax | n:  18
IntGELU    | n:  23
IntSoftmax | n:  18
IntGELU    | n:  23
IntSoftmax | n:  18
IntGELU    | n:  23
IntSoftmax | n:  18
IntGELU    | n:  23
IntSoftmax | n:  18
IntGELU    | n:  23
.calib done
Test: [  0/391]	Time  3.905 ( 3.905)	Acc@1   7.03 (  7.03)	Acc@5  25.00 ( 25.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 7.031 Prec@5 25.000
Time: 8.90
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=18, intgelu_exp_n=24
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=18, intgelu_exp_n=24, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  18
IntGELU    | n:  24
IntSoftmax | n:  18
IntGELU    | n:  24
IntSoftmax | n:  18
IntGELU    | n:  24
IntSoftmax | n:  18
IntGELU    | n:  24
IntSoftmax | n:  18
IntGELU    | n:  24
IntSoftmax | n:  18
IntGELU    | n:  24
IntSoftmax | n:  18
IntGELU    | n:  24
IntSoftmax | n:  18
IntGELU    | n:  24
IntSoftmax | n:  18
IntGELU    | n:  24
IntSoftmax | n:  18
IntGELU    | n:  24
IntSoftmax | n:  18
IntGELU    | n:  24
IntSoftmax | n:  18
IntGELU    | n:  24
.calib done
Test: [  0/391]	Time  3.717 ( 3.717)	Acc@1  13.28 ( 13.28)	Acc@5  31.25 ( 31.25)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 13.281 Prec@5 31.250
Time: 8.64
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=18, intgelu_exp_n=25
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=18, intgelu_exp_n=25, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  18
IntGELU    | n:  25
IntSoftmax | n:  18
IntGELU    | n:  25
IntSoftmax | n:  18
IntGELU    | n:  25
IntSoftmax | n:  18
IntGELU    | n:  25
IntSoftmax | n:  18
IntGELU    | n:  25
IntSoftmax | n:  18
IntGELU    | n:  25
IntSoftmax | n:  18
IntGELU    | n:  25
IntSoftmax | n:  18
IntGELU    | n:  25
IntSoftmax | n:  18
IntGELU    | n:  25
IntSoftmax | n:  18
IntGELU    | n:  25
IntSoftmax | n:  18
IntGELU    | n:  25
IntSoftmax | n:  18
IntGELU    | n:  25
.calib done
Test: [  0/391]	Time  3.990 ( 3.990)	Acc@1  20.31 ( 20.31)	Acc@5  40.62 ( 40.62)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 20.312 Prec@5 40.625
Time: 8.94
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=18, intgelu_exp_n=26
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=18, intgelu_exp_n=26, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  18
IntGELU    | n:  26
IntSoftmax | n:  18
IntGELU    | n:  26
IntSoftmax | n:  18
IntGELU    | n:  26
IntSoftmax | n:  18
IntGELU    | n:  26
IntSoftmax | n:  18
IntGELU    | n:  26
IntSoftmax | n:  18
IntGELU    | n:  26
IntSoftmax | n:  18
IntGELU    | n:  26
IntSoftmax | n:  18
IntGELU    | n:  26
IntSoftmax | n:  18
IntGELU    | n:  26
IntSoftmax | n:  18
IntGELU    | n:  26
IntSoftmax | n:  18
IntGELU    | n:  26
IntSoftmax | n:  18
IntGELU    | n:  26
.calib done
Test: [  0/391]	Time  3.935 ( 3.935)	Acc@1  21.88 ( 21.88)	Acc@5  43.75 ( 43.75)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 21.875 Prec@5 43.750
Time: 8.88
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=18, intgelu_exp_n=27
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=18, intgelu_exp_n=27, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  18
IntGELU    | n:  27
IntSoftmax | n:  18
IntGELU    | n:  27
IntSoftmax | n:  18
IntGELU    | n:  27
IntSoftmax | n:  18
IntGELU    | n:  27
IntSoftmax | n:  18
IntGELU    | n:  27
IntSoftmax | n:  18
IntGELU    | n:  27
IntSoftmax | n:  18
IntGELU    | n:  27
IntSoftmax | n:  18
IntGELU    | n:  27
IntSoftmax | n:  18
IntGELU    | n:  27
IntSoftmax | n:  18
IntGELU    | n:  27
IntSoftmax | n:  18
IntGELU    | n:  27
IntSoftmax | n:  18
IntGELU    | n:  27
.calib done
Test: [  0/391]	Time  3.905 ( 3.905)	Acc@1  23.44 ( 23.44)	Acc@5  49.22 ( 49.22)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 23.438 Prec@5 49.219
Time: 8.87
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=18, intgelu_exp_n=28
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=18, intgelu_exp_n=28, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  18
IntGELU    | n:  28
IntSoftmax | n:  18
IntGELU    | n:  28
IntSoftmax | n:  18
IntGELU    | n:  28
IntSoftmax | n:  18
IntGELU    | n:  28
IntSoftmax | n:  18
IntGELU    | n:  28
IntSoftmax | n:  18
IntGELU    | n:  28
IntSoftmax | n:  18
IntGELU    | n:  28
IntSoftmax | n:  18
IntGELU    | n:  28
IntSoftmax | n:  18
IntGELU    | n:  28
IntSoftmax | n:  18
IntGELU    | n:  28
IntSoftmax | n:  18
IntGELU    | n:  28
IntSoftmax | n:  18
IntGELU    | n:  28
.calib done
Test: [  0/391]	Time  3.755 ( 3.755)	Acc@1  20.31 ( 20.31)	Acc@5  49.22 ( 49.22)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 20.312 Prec@5 49.219
Time: 8.73
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=18, intgelu_exp_n=29
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=18, intgelu_exp_n=29, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  18
IntGELU    | n:  29
IntSoftmax | n:  18
IntGELU    | n:  29
IntSoftmax | n:  18
IntGELU    | n:  29
IntSoftmax | n:  18
IntGELU    | n:  29
IntSoftmax | n:  18
IntGELU    | n:  29
IntSoftmax | n:  18
IntGELU    | n:  29
IntSoftmax | n:  18
IntGELU    | n:  29
IntSoftmax | n:  18
IntGELU    | n:  29
IntSoftmax | n:  18
IntGELU    | n:  29
IntSoftmax | n:  18
IntGELU    | n:  29
IntSoftmax | n:  18
IntGELU    | n:  29
IntSoftmax | n:  18
IntGELU    | n:  29
.calib done
Test: [  0/391]	Time  3.847 ( 3.847)	Acc@1  32.03 ( 32.03)	Acc@5  58.59 ( 58.59)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 32.031 Prec@5 58.594
Time: 8.79
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=18, intgelu_exp_n=30
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=18, intgelu_exp_n=30, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  18
IntGELU    | n:  30
IntSoftmax | n:  18
IntGELU    | n:  30
IntSoftmax | n:  18
IntGELU    | n:  30
IntSoftmax | n:  18
IntGELU    | n:  30
IntSoftmax | n:  18
IntGELU    | n:  30
IntSoftmax | n:  18
IntGELU    | n:  30
IntSoftmax | n:  18
IntGELU    | n:  30
IntSoftmax | n:  18
IntGELU    | n:  30
IntSoftmax | n:  18
IntGELU    | n:  30
IntSoftmax | n:  18
IntGELU    | n:  30
IntSoftmax | n:  18
IntGELU    | n:  30
IntSoftmax | n:  18
IntGELU    | n:  30
.calib done
Test: [  0/391]	Time  3.848 ( 3.848)	Acc@1  65.62 ( 65.62)	Acc@5  85.16 ( 85.16)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 65.625 Prec@5 85.156
Time: 8.85
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=18, intgelu_exp_n=31
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=18, intgelu_exp_n=31, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  18
IntGELU    | n:  31
IntSoftmax | n:  18
IntGELU    | n:  31
IntSoftmax | n:  18
IntGELU    | n:  31
IntSoftmax | n:  18
IntGELU    | n:  31
IntSoftmax | n:  18
IntGELU    | n:  31
IntSoftmax | n:  18
IntGELU    | n:  31
IntSoftmax | n:  18
IntGELU    | n:  31
IntSoftmax | n:  18
IntGELU    | n:  31
IntSoftmax | n:  18
IntGELU    | n:  31
IntSoftmax | n:  18
IntGELU    | n:  31
IntSoftmax | n:  18
IntGELU    | n:  31
IntSoftmax | n:  18
IntGELU    | n:  31
.calib done
Test: [  0/391]	Time  3.692 ( 3.692)	Acc@1   7.03 (  7.03)	Acc@5  22.66 ( 22.66)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 7.031 Prec@5 22.656
Time: 8.64
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=19, intgelu_exp_n=0
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=19, intgelu_exp_n=0, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  19
IntGELU    | n:  0
IntSoftmax | n:  19
IntGELU    | n:  0
IntSoftmax | n:  19
IntGELU    | n:  0
IntSoftmax | n:  19
IntGELU    | n:  0
IntSoftmax | n:  19
IntGELU    | n:  0
IntSoftmax | n:  19
IntGELU    | n:  0
IntSoftmax | n:  19
IntGELU    | n:  0
IntSoftmax | n:  19
IntGELU    | n:  0
IntSoftmax | n:  19
IntGELU    | n:  0
IntSoftmax | n:  19
IntGELU    | n:  0
IntSoftmax | n:  19
IntGELU    | n:  0
IntSoftmax | n:  19
IntGELU    | n:  0
.calib done
Test: [  0/391]	Time  3.739 ( 3.739)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.66
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=19, intgelu_exp_n=1
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=19, intgelu_exp_n=1, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  19
IntGELU    | n:  1
IntSoftmax | n:  19
IntGELU    | n:  1
IntSoftmax | n:  19
IntGELU    | n:  1
IntSoftmax | n:  19
IntGELU    | n:  1
IntSoftmax | n:  19
IntGELU    | n:  1
IntSoftmax | n:  19
IntGELU    | n:  1
IntSoftmax | n:  19
IntGELU    | n:  1
IntSoftmax | n:  19
IntGELU    | n:  1
IntSoftmax | n:  19
IntGELU    | n:  1
IntSoftmax | n:  19
IntGELU    | n:  1
IntSoftmax | n:  19
IntGELU    | n:  1
IntSoftmax | n:  19
IntGELU    | n:  1
.calib done
Test: [  0/391]	Time  3.714 ( 3.714)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.68
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=19, intgelu_exp_n=2
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=19, intgelu_exp_n=2, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  19
IntGELU    | n:  2
IntSoftmax | n:  19
IntGELU    | n:  2
IntSoftmax | n:  19
IntGELU    | n:  2
IntSoftmax | n:  19
IntGELU    | n:  2
IntSoftmax | n:  19
IntGELU    | n:  2
IntSoftmax | n:  19
IntGELU    | n:  2
IntSoftmax | n:  19
IntGELU    | n:  2
IntSoftmax | n:  19
IntGELU    | n:  2
IntSoftmax | n:  19
IntGELU    | n:  2
IntSoftmax | n:  19
IntGELU    | n:  2
IntSoftmax | n:  19
IntGELU    | n:  2
IntSoftmax | n:  19
IntGELU    | n:  2
.calib done
Test: [  0/391]	Time  3.782 ( 3.782)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.75
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=19, intgelu_exp_n=3
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=19, intgelu_exp_n=3, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  19
IntGELU    | n:  3
IntSoftmax | n:  19
IntGELU    | n:  3
IntSoftmax | n:  19
IntGELU    | n:  3
IntSoftmax | n:  19
IntGELU    | n:  3
IntSoftmax | n:  19
IntGELU    | n:  3
IntSoftmax | n:  19
IntGELU    | n:  3
IntSoftmax | n:  19
IntGELU    | n:  3
IntSoftmax | n:  19
IntGELU    | n:  3
IntSoftmax | n:  19
IntGELU    | n:  3
IntSoftmax | n:  19
IntGELU    | n:  3
IntSoftmax | n:  19
IntGELU    | n:  3
IntSoftmax | n:  19
IntGELU    | n:  3
.calib done
Test: [  0/391]	Time  3.691 ( 3.691)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.72
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=19, intgelu_exp_n=4
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=19, intgelu_exp_n=4, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  19
IntGELU    | n:  4
IntSoftmax | n:  19
IntGELU    | n:  4
IntSoftmax | n:  19
IntGELU    | n:  4
IntSoftmax | n:  19
IntGELU    | n:  4
IntSoftmax | n:  19
IntGELU    | n:  4
IntSoftmax | n:  19
IntGELU    | n:  4
IntSoftmax | n:  19
IntGELU    | n:  4
IntSoftmax | n:  19
IntGELU    | n:  4
IntSoftmax | n:  19
IntGELU    | n:  4
IntSoftmax | n:  19
IntGELU    | n:  4
IntSoftmax | n:  19
IntGELU    | n:  4
IntSoftmax | n:  19
IntGELU    | n:  4
.calib done
Test: [  0/391]	Time  3.921 ( 3.921)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.86
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=19, intgelu_exp_n=5
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=19, intgelu_exp_n=5, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  19
IntGELU    | n:  5
IntSoftmax | n:  19
IntGELU    | n:  5
IntSoftmax | n:  19
IntGELU    | n:  5
IntSoftmax | n:  19
IntGELU    | n:  5
IntSoftmax | n:  19
IntGELU    | n:  5
IntSoftmax | n:  19
IntGELU    | n:  5
IntSoftmax | n:  19
IntGELU    | n:  5
IntSoftmax | n:  19
IntGELU    | n:  5
IntSoftmax | n:  19
IntGELU    | n:  5
IntSoftmax | n:  19
IntGELU    | n:  5
IntSoftmax | n:  19
IntGELU    | n:  5
IntSoftmax | n:  19
IntGELU    | n:  5
.calib done
Test: [  0/391]	Time  3.976 ( 3.976)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.97
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=19, intgelu_exp_n=6
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=19, intgelu_exp_n=6, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  19
IntGELU    | n:  6
IntSoftmax | n:  19
IntGELU    | n:  6
IntSoftmax | n:  19
IntGELU    | n:  6
IntSoftmax | n:  19
IntGELU    | n:  6
IntSoftmax | n:  19
IntGELU    | n:  6
IntSoftmax | n:  19
IntGELU    | n:  6
IntSoftmax | n:  19
IntGELU    | n:  6
IntSoftmax | n:  19
IntGELU    | n:  6
IntSoftmax | n:  19
IntGELU    | n:  6
IntSoftmax | n:  19
IntGELU    | n:  6
IntSoftmax | n:  19
IntGELU    | n:  6
IntSoftmax | n:  19
IntGELU    | n:  6
.calib done
Test: [  0/391]	Time  3.642 ( 3.642)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.55
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=19, intgelu_exp_n=7
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=19, intgelu_exp_n=7, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  19
IntGELU    | n:  7
IntSoftmax | n:  19
IntGELU    | n:  7
IntSoftmax | n:  19
IntGELU    | n:  7
IntSoftmax | n:  19
IntGELU    | n:  7
IntSoftmax | n:  19
IntGELU    | n:  7
IntSoftmax | n:  19
IntGELU    | n:  7
IntSoftmax | n:  19
IntGELU    | n:  7
IntSoftmax | n:  19
IntGELU    | n:  7
IntSoftmax | n:  19
IntGELU    | n:  7
IntSoftmax | n:  19
IntGELU    | n:  7
IntSoftmax | n:  19
IntGELU    | n:  7
IntSoftmax | n:  19
IntGELU    | n:  7
.calib done
Test: [  0/391]	Time  3.875 ( 3.875)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.82
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=19, intgelu_exp_n=8
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=19, intgelu_exp_n=8, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  19
IntGELU    | n:  8
IntSoftmax | n:  19
IntGELU    | n:  8
IntSoftmax | n:  19
IntGELU    | n:  8
IntSoftmax | n:  19
IntGELU    | n:  8
IntSoftmax | n:  19
IntGELU    | n:  8
IntSoftmax | n:  19
IntGELU    | n:  8
IntSoftmax | n:  19
IntGELU    | n:  8
IntSoftmax | n:  19
IntGELU    | n:  8
IntSoftmax | n:  19
IntGELU    | n:  8
IntSoftmax | n:  19
IntGELU    | n:  8
IntSoftmax | n:  19
IntGELU    | n:  8
IntSoftmax | n:  19
IntGELU    | n:  8
.calib done
Test: [  0/391]	Time  3.905 ( 3.905)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.86
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=19, intgelu_exp_n=9
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=19, intgelu_exp_n=9, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  19
IntGELU    | n:  9
IntSoftmax | n:  19
IntGELU    | n:  9
IntSoftmax | n:  19
IntGELU    | n:  9
IntSoftmax | n:  19
IntGELU    | n:  9
IntSoftmax | n:  19
IntGELU    | n:  9
IntSoftmax | n:  19
IntGELU    | n:  9
IntSoftmax | n:  19
IntGELU    | n:  9
IntSoftmax | n:  19
IntGELU    | n:  9
IntSoftmax | n:  19
IntGELU    | n:  9
IntSoftmax | n:  19
IntGELU    | n:  9
IntSoftmax | n:  19
IntGELU    | n:  9
IntSoftmax | n:  19
IntGELU    | n:  9
.calib done
Test: [  0/391]	Time  3.837 ( 3.837)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.81
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=19, intgelu_exp_n=10
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=19, intgelu_exp_n=10, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  19
IntGELU    | n:  10
IntSoftmax | n:  19
IntGELU    | n:  10
IntSoftmax | n:  19
IntGELU    | n:  10
IntSoftmax | n:  19
IntGELU    | n:  10
IntSoftmax | n:  19
IntGELU    | n:  10
IntSoftmax | n:  19
IntGELU    | n:  10
IntSoftmax | n:  19
IntGELU    | n:  10
IntSoftmax | n:  19
IntGELU    | n:  10
IntSoftmax | n:  19
IntGELU    | n:  10
IntSoftmax | n:  19
IntGELU    | n:  10
IntSoftmax | n:  19
IntGELU    | n:  10
IntSoftmax | n:  19
IntGELU    | n:  10
.calib done
Test: [  0/391]	Time  3.773 ( 3.773)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.74
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=19, intgelu_exp_n=11
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=19, intgelu_exp_n=11, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  19
IntGELU    | n:  11
IntSoftmax | n:  19
IntGELU    | n:  11
IntSoftmax | n:  19
IntGELU    | n:  11
IntSoftmax | n:  19
IntGELU    | n:  11
IntSoftmax | n:  19
IntGELU    | n:  11
IntSoftmax | n:  19
IntGELU    | n:  11
IntSoftmax | n:  19
IntGELU    | n:  11
IntSoftmax | n:  19
IntGELU    | n:  11
IntSoftmax | n:  19
IntGELU    | n:  11
IntSoftmax | n:  19
IntGELU    | n:  11
IntSoftmax | n:  19
IntGELU    | n:  11
IntSoftmax | n:  19
IntGELU    | n:  11
.calib done
Test: [  0/391]	Time  3.885 ( 3.885)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.85
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=19, intgelu_exp_n=12
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=19, intgelu_exp_n=12, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  19
IntGELU    | n:  12
IntSoftmax | n:  19
IntGELU    | n:  12
IntSoftmax | n:  19
IntGELU    | n:  12
IntSoftmax | n:  19
IntGELU    | n:  12
IntSoftmax | n:  19
IntGELU    | n:  12
IntSoftmax | n:  19
IntGELU    | n:  12
IntSoftmax | n:  19
IntGELU    | n:  12
IntSoftmax | n:  19
IntGELU    | n:  12
IntSoftmax | n:  19
IntGELU    | n:  12
IntSoftmax | n:  19
IntGELU    | n:  12
IntSoftmax | n:  19
IntGELU    | n:  12
IntSoftmax | n:  19
IntGELU    | n:  12
.calib done
Test: [  0/391]	Time  3.815 ( 3.815)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.81
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=19, intgelu_exp_n=13
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=19, intgelu_exp_n=13, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  19
IntGELU    | n:  13
IntSoftmax | n:  19
IntGELU    | n:  13
IntSoftmax | n:  19
IntGELU    | n:  13
IntSoftmax | n:  19
IntGELU    | n:  13
IntSoftmax | n:  19
IntGELU    | n:  13
IntSoftmax | n:  19
IntGELU    | n:  13
IntSoftmax | n:  19
IntGELU    | n:  13
IntSoftmax | n:  19
IntGELU    | n:  13
IntSoftmax | n:  19
IntGELU    | n:  13
IntSoftmax | n:  19
IntGELU    | n:  13
IntSoftmax | n:  19
IntGELU    | n:  13
IntSoftmax | n:  19
IntGELU    | n:  13
.calib done
Test: [  0/391]	Time  3.835 ( 3.835)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.81
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=19, intgelu_exp_n=14
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=19, intgelu_exp_n=14, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  19
IntGELU    | n:  14
IntSoftmax | n:  19
IntGELU    | n:  14
IntSoftmax | n:  19
IntGELU    | n:  14
IntSoftmax | n:  19
IntGELU    | n:  14
IntSoftmax | n:  19
IntGELU    | n:  14
IntSoftmax | n:  19
IntGELU    | n:  14
IntSoftmax | n:  19
IntGELU    | n:  14
IntSoftmax | n:  19
IntGELU    | n:  14
IntSoftmax | n:  19
IntGELU    | n:  14
IntSoftmax | n:  19
IntGELU    | n:  14
IntSoftmax | n:  19
IntGELU    | n:  14
IntSoftmax | n:  19
IntGELU    | n:  14
.calib done
Test: [  0/391]	Time  3.963 ( 3.963)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.98
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=19, intgelu_exp_n=15
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=19, intgelu_exp_n=15, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  19
IntGELU    | n:  15
IntSoftmax | n:  19
IntGELU    | n:  15
IntSoftmax | n:  19
IntGELU    | n:  15
IntSoftmax | n:  19
IntGELU    | n:  15
IntSoftmax | n:  19
IntGELU    | n:  15
IntSoftmax | n:  19
IntGELU    | n:  15
IntSoftmax | n:  19
IntGELU    | n:  15
IntSoftmax | n:  19
IntGELU    | n:  15
IntSoftmax | n:  19
IntGELU    | n:  15
IntSoftmax | n:  19
IntGELU    | n:  15
IntSoftmax | n:  19
IntGELU    | n:  15
IntSoftmax | n:  19
IntGELU    | n:  15
.calib done
Test: [  0/391]	Time  3.973 ( 3.973)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.98
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=19, intgelu_exp_n=16
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=19, intgelu_exp_n=16, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  19
IntGELU    | n:  16
IntSoftmax | n:  19
IntGELU    | n:  16
IntSoftmax | n:  19
IntGELU    | n:  16
IntSoftmax | n:  19
IntGELU    | n:  16
IntSoftmax | n:  19
IntGELU    | n:  16
IntSoftmax | n:  19
IntGELU    | n:  16
IntSoftmax | n:  19
IntGELU    | n:  16
IntSoftmax | n:  19
IntGELU    | n:  16
IntSoftmax | n:  19
IntGELU    | n:  16
IntSoftmax | n:  19
IntGELU    | n:  16
IntSoftmax | n:  19
IntGELU    | n:  16
IntSoftmax | n:  19
IntGELU    | n:  16
.calib done
Test: [  0/391]	Time  3.866 ( 3.866)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.83
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=19, intgelu_exp_n=17
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=19, intgelu_exp_n=17, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  19
IntGELU    | n:  17
IntSoftmax | n:  19
IntGELU    | n:  17
IntSoftmax | n:  19
IntGELU    | n:  17
IntSoftmax | n:  19
IntGELU    | n:  17
IntSoftmax | n:  19
IntGELU    | n:  17
IntSoftmax | n:  19
IntGELU    | n:  17
IntSoftmax | n:  19
IntGELU    | n:  17
IntSoftmax | n:  19
IntGELU    | n:  17
IntSoftmax | n:  19
IntGELU    | n:  17
IntSoftmax | n:  19
IntGELU    | n:  17
IntSoftmax | n:  19
IntGELU    | n:  17
IntSoftmax | n:  19
IntGELU    | n:  17
.calib done
Test: [  0/391]	Time  3.860 ( 3.860)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.82
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=19, intgelu_exp_n=18
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=19, intgelu_exp_n=18, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  19
IntGELU    | n:  18
IntSoftmax | n:  19
IntGELU    | n:  18
IntSoftmax | n:  19
IntGELU    | n:  18
IntSoftmax | n:  19
IntGELU    | n:  18
IntSoftmax | n:  19
IntGELU    | n:  18
IntSoftmax | n:  19
IntGELU    | n:  18
IntSoftmax | n:  19
IntGELU    | n:  18
IntSoftmax | n:  19
IntGELU    | n:  18
IntSoftmax | n:  19
IntGELU    | n:  18
IntSoftmax | n:  19
IntGELU    | n:  18
IntSoftmax | n:  19
IntGELU    | n:  18
IntSoftmax | n:  19
IntGELU    | n:  18
.calib done
Test: [  0/391]	Time  3.759 ( 3.759)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.73
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=19, intgelu_exp_n=19
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=19, intgelu_exp_n=19, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  19
IntGELU    | n:  19
IntSoftmax | n:  19
IntGELU    | n:  19
IntSoftmax | n:  19
IntGELU    | n:  19
IntSoftmax | n:  19
IntGELU    | n:  19
IntSoftmax | n:  19
IntGELU    | n:  19
IntSoftmax | n:  19
IntGELU    | n:  19
IntSoftmax | n:  19
IntGELU    | n:  19
IntSoftmax | n:  19
IntGELU    | n:  19
IntSoftmax | n:  19
IntGELU    | n:  19
IntSoftmax | n:  19
IntGELU    | n:  19
IntSoftmax | n:  19
IntGELU    | n:  19
IntSoftmax | n:  19
IntGELU    | n:  19
.calib done
Test: [  0/391]	Time  3.906 ( 3.906)	Acc@1   1.56 (  1.56)	Acc@5   7.81 (  7.81)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 1.562 Prec@5 7.812
Time: 8.84
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=19, intgelu_exp_n=20
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=19, intgelu_exp_n=20, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  19
IntGELU    | n:  20
IntSoftmax | n:  19
IntGELU    | n:  20
IntSoftmax | n:  19
IntGELU    | n:  20
IntSoftmax | n:  19
IntGELU    | n:  20
IntSoftmax | n:  19
IntGELU    | n:  20
IntSoftmax | n:  19
IntGELU    | n:  20
IntSoftmax | n:  19
IntGELU    | n:  20
IntSoftmax | n:  19
IntGELU    | n:  20
IntSoftmax | n:  19
IntGELU    | n:  20
IntSoftmax | n:  19
IntGELU    | n:  20
IntSoftmax | n:  19
IntGELU    | n:  20
IntSoftmax | n:  19
IntGELU    | n:  20
.calib done
Test: [  0/391]	Time  3.953 ( 3.953)	Acc@1   3.12 (  3.12)	Acc@5  10.94 ( 10.94)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 3.125 Prec@5 10.938
Time: 8.89
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=19, intgelu_exp_n=21
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=19, intgelu_exp_n=21, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  19
IntGELU    | n:  21
IntSoftmax | n:  19
IntGELU    | n:  21
IntSoftmax | n:  19
IntGELU    | n:  21
IntSoftmax | n:  19
IntGELU    | n:  21
IntSoftmax | n:  19
IntGELU    | n:  21
IntSoftmax | n:  19
IntGELU    | n:  21
IntSoftmax | n:  19
IntGELU    | n:  21
IntSoftmax | n:  19
IntGELU    | n:  21
IntSoftmax | n:  19
IntGELU    | n:  21
IntSoftmax | n:  19
IntGELU    | n:  21
IntSoftmax | n:  19
IntGELU    | n:  21
IntSoftmax | n:  19
IntGELU    | n:  21
.calib done
Test: [  0/391]	Time  4.001 ( 4.001)	Acc@1   4.69 (  4.69)	Acc@5  15.62 ( 15.62)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 4.688 Prec@5 15.625
Time: 8.96
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=19, intgelu_exp_n=22
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=19, intgelu_exp_n=22, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  19
IntGELU    | n:  22
IntSoftmax | n:  19
IntGELU    | n:  22
IntSoftmax | n:  19
IntGELU    | n:  22
IntSoftmax | n:  19
IntGELU    | n:  22
IntSoftmax | n:  19
IntGELU    | n:  22
IntSoftmax | n:  19
IntGELU    | n:  22
IntSoftmax | n:  19
IntGELU    | n:  22
IntSoftmax | n:  19
IntGELU    | n:  22
IntSoftmax | n:  19
IntGELU    | n:  22
IntSoftmax | n:  19
IntGELU    | n:  22
IntSoftmax | n:  19
IntGELU    | n:  22
IntSoftmax | n:  19
IntGELU    | n:  22
.calib done
Test: [  0/391]	Time  3.890 ( 3.890)	Acc@1   8.59 (  8.59)	Acc@5  21.88 ( 21.88)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 8.594 Prec@5 21.875
Time: 8.82
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=19, intgelu_exp_n=23
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=19, intgelu_exp_n=23, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  19
IntGELU    | n:  23
IntSoftmax | n:  19
IntGELU    | n:  23
IntSoftmax | n:  19
IntGELU    | n:  23
IntSoftmax | n:  19
IntGELU    | n:  23
IntSoftmax | n:  19
IntGELU    | n:  23
IntSoftmax | n:  19
IntGELU    | n:  23
IntSoftmax | n:  19
IntGELU    | n:  23
IntSoftmax | n:  19
IntGELU    | n:  23
IntSoftmax | n:  19
IntGELU    | n:  23
IntSoftmax | n:  19
IntGELU    | n:  23
IntSoftmax | n:  19
IntGELU    | n:  23
IntSoftmax | n:  19
IntGELU    | n:  23
.calib done
Test: [  0/391]	Time  4.039 ( 4.039)	Acc@1   8.59 (  8.59)	Acc@5  25.00 ( 25.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 8.594 Prec@5 25.000
Time: 8.98
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=19, intgelu_exp_n=24
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=19, intgelu_exp_n=24, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  19
IntGELU    | n:  24
IntSoftmax | n:  19
IntGELU    | n:  24
IntSoftmax | n:  19
IntGELU    | n:  24
IntSoftmax | n:  19
IntGELU    | n:  24
IntSoftmax | n:  19
IntGELU    | n:  24
IntSoftmax | n:  19
IntGELU    | n:  24
IntSoftmax | n:  19
IntGELU    | n:  24
IntSoftmax | n:  19
IntGELU    | n:  24
IntSoftmax | n:  19
IntGELU    | n:  24
IntSoftmax | n:  19
IntGELU    | n:  24
IntSoftmax | n:  19
IntGELU    | n:  24
IntSoftmax | n:  19
IntGELU    | n:  24
.calib done
Test: [  0/391]	Time  3.823 ( 3.823)	Acc@1  10.94 ( 10.94)	Acc@5  29.69 ( 29.69)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 10.938 Prec@5 29.688
Time: 8.76
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=19, intgelu_exp_n=25
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=19, intgelu_exp_n=25, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  19
IntGELU    | n:  25
IntSoftmax | n:  19
IntGELU    | n:  25
IntSoftmax | n:  19
IntGELU    | n:  25
IntSoftmax | n:  19
IntGELU    | n:  25
IntSoftmax | n:  19
IntGELU    | n:  25
IntSoftmax | n:  19
IntGELU    | n:  25
IntSoftmax | n:  19
IntGELU    | n:  25
IntSoftmax | n:  19
IntGELU    | n:  25
IntSoftmax | n:  19
IntGELU    | n:  25
IntSoftmax | n:  19
IntGELU    | n:  25
IntSoftmax | n:  19
IntGELU    | n:  25
IntSoftmax | n:  19
IntGELU    | n:  25
.calib done
Test: [  0/391]	Time  3.961 ( 3.961)	Acc@1  17.97 ( 17.97)	Acc@5  42.19 ( 42.19)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 17.969 Prec@5 42.188
Time: 8.93
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=19, intgelu_exp_n=26
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=19, intgelu_exp_n=26, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  19
IntGELU    | n:  26
IntSoftmax | n:  19
IntGELU    | n:  26
IntSoftmax | n:  19
IntGELU    | n:  26
IntSoftmax | n:  19
IntGELU    | n:  26
IntSoftmax | n:  19
IntGELU    | n:  26
IntSoftmax | n:  19
IntGELU    | n:  26
IntSoftmax | n:  19
IntGELU    | n:  26
IntSoftmax | n:  19
IntGELU    | n:  26
IntSoftmax | n:  19
IntGELU    | n:  26
IntSoftmax | n:  19
IntGELU    | n:  26
IntSoftmax | n:  19
IntGELU    | n:  26
IntSoftmax | n:  19
IntGELU    | n:  26
.calib done
Test: [  0/391]	Time  3.868 ( 3.868)	Acc@1   1.56 (  1.56)	Acc@5  17.97 ( 17.97)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 1.562 Prec@5 17.969
Time: 8.79
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=19, intgelu_exp_n=27
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=19, intgelu_exp_n=27, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  19
IntGELU    | n:  27
IntSoftmax | n:  19
IntGELU    | n:  27
IntSoftmax | n:  19
IntGELU    | n:  27
IntSoftmax | n:  19
IntGELU    | n:  27
IntSoftmax | n:  19
IntGELU    | n:  27
IntSoftmax | n:  19
IntGELU    | n:  27
IntSoftmax | n:  19
IntGELU    | n:  27
IntSoftmax | n:  19
IntGELU    | n:  27
IntSoftmax | n:  19
IntGELU    | n:  27
IntSoftmax | n:  19
IntGELU    | n:  27
IntSoftmax | n:  19
IntGELU    | n:  27
IntSoftmax | n:  19
IntGELU    | n:  27
.calib done
Test: [  0/391]	Time  3.794 ( 3.794)	Acc@1  26.56 ( 26.56)	Acc@5  46.88 ( 46.88)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 26.562 Prec@5 46.875
Time: 8.75
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=19, intgelu_exp_n=28
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=19, intgelu_exp_n=28, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  19
IntGELU    | n:  28
IntSoftmax | n:  19
IntGELU    | n:  28
IntSoftmax | n:  19
IntGELU    | n:  28
IntSoftmax | n:  19
IntGELU    | n:  28
IntSoftmax | n:  19
IntGELU    | n:  28
IntSoftmax | n:  19
IntGELU    | n:  28
IntSoftmax | n:  19
IntGELU    | n:  28
IntSoftmax | n:  19
IntGELU    | n:  28
IntSoftmax | n:  19
IntGELU    | n:  28
IntSoftmax | n:  19
IntGELU    | n:  28
IntSoftmax | n:  19
IntGELU    | n:  28
IntSoftmax | n:  19
IntGELU    | n:  28
.calib done
Test: [  0/391]	Time  3.879 ( 3.879)	Acc@1  28.12 ( 28.12)	Acc@5  53.91 ( 53.91)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 28.125 Prec@5 53.906
Time: 8.84
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=19, intgelu_exp_n=29
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=19, intgelu_exp_n=29, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  19
IntGELU    | n:  29
IntSoftmax | n:  19
IntGELU    | n:  29
IntSoftmax | n:  19
IntGELU    | n:  29
IntSoftmax | n:  19
IntGELU    | n:  29
IntSoftmax | n:  19
IntGELU    | n:  29
IntSoftmax | n:  19
IntGELU    | n:  29
IntSoftmax | n:  19
IntGELU    | n:  29
IntSoftmax | n:  19
IntGELU    | n:  29
IntSoftmax | n:  19
IntGELU    | n:  29
IntSoftmax | n:  19
IntGELU    | n:  29
IntSoftmax | n:  19
IntGELU    | n:  29
IntSoftmax | n:  19
IntGELU    | n:  29
.calib done
Test: [  0/391]	Time  3.968 ( 3.968)	Acc@1  35.16 ( 35.16)	Acc@5  55.47 ( 55.47)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 35.156 Prec@5 55.469
Time: 8.90
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=19, intgelu_exp_n=30
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=19, intgelu_exp_n=30, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  19
IntGELU    | n:  30
IntSoftmax | n:  19
IntGELU    | n:  30
IntSoftmax | n:  19
IntGELU    | n:  30
IntSoftmax | n:  19
IntGELU    | n:  30
IntSoftmax | n:  19
IntGELU    | n:  30
IntSoftmax | n:  19
IntGELU    | n:  30
IntSoftmax | n:  19
IntGELU    | n:  30
IntSoftmax | n:  19
IntGELU    | n:  30
IntSoftmax | n:  19
IntGELU    | n:  30
IntSoftmax | n:  19
IntGELU    | n:  30
IntSoftmax | n:  19
IntGELU    | n:  30
IntSoftmax | n:  19
IntGELU    | n:  30
.calib done
Test: [  0/391]	Time  3.954 ( 3.954)	Acc@1  88.28 ( 88.28)	Acc@5  96.88 ( 96.88)
Test: [ 10/391]	Time  1.732 ( 1.933)	Acc@1  64.84 ( 81.32)	Acc@5  92.19 ( 94.39)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 81.321 Prec@5 94.389
Time: 26.22
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=19, intgelu_exp_n=31
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=19, intgelu_exp_n=31, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  19
IntGELU    | n:  31
IntSoftmax | n:  19
IntGELU    | n:  31
IntSoftmax | n:  19
IntGELU    | n:  31
IntSoftmax | n:  19
IntGELU    | n:  31
IntSoftmax | n:  19
IntGELU    | n:  31
IntSoftmax | n:  19
IntGELU    | n:  31
IntSoftmax | n:  19
IntGELU    | n:  31
IntSoftmax | n:  19
IntGELU    | n:  31
IntSoftmax | n:  19
IntGELU    | n:  31
IntSoftmax | n:  19
IntGELU    | n:  31
IntSoftmax | n:  19
IntGELU    | n:  31
IntSoftmax | n:  19
IntGELU    | n:  31
.calib done
Test: [  0/391]	Time  3.934 ( 3.934)	Acc@1   4.69 (  4.69)	Acc@5  20.31 ( 20.31)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 4.688 Prec@5 20.312
Time: 8.93
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=20, intgelu_exp_n=0
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=20, intgelu_exp_n=0, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  20
IntGELU    | n:  0
IntSoftmax | n:  20
IntGELU    | n:  0
IntSoftmax | n:  20
IntGELU    | n:  0
IntSoftmax | n:  20
IntGELU    | n:  0
IntSoftmax | n:  20
IntGELU    | n:  0
IntSoftmax | n:  20
IntGELU    | n:  0
IntSoftmax | n:  20
IntGELU    | n:  0
IntSoftmax | n:  20
IntGELU    | n:  0
IntSoftmax | n:  20
IntGELU    | n:  0
IntSoftmax | n:  20
IntGELU    | n:  0
IntSoftmax | n:  20
IntGELU    | n:  0
IntSoftmax | n:  20
IntGELU    | n:  0
.calib done
Test: [  0/391]	Time  3.651 ( 3.651)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.54
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=20, intgelu_exp_n=1
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=20, intgelu_exp_n=1, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  20
IntGELU    | n:  1
IntSoftmax | n:  20
IntGELU    | n:  1
IntSoftmax | n:  20
IntGELU    | n:  1
IntSoftmax | n:  20
IntGELU    | n:  1
IntSoftmax | n:  20
IntGELU    | n:  1
IntSoftmax | n:  20
IntGELU    | n:  1
IntSoftmax | n:  20
IntGELU    | n:  1
IntSoftmax | n:  20
IntGELU    | n:  1
IntSoftmax | n:  20
IntGELU    | n:  1
IntSoftmax | n:  20
IntGELU    | n:  1
IntSoftmax | n:  20
IntGELU    | n:  1
IntSoftmax | n:  20
IntGELU    | n:  1
.calib done
Test: [  0/391]	Time  3.848 ( 3.848)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.82
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=20, intgelu_exp_n=2
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=20, intgelu_exp_n=2, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  20
IntGELU    | n:  2
IntSoftmax | n:  20
IntGELU    | n:  2
IntSoftmax | n:  20
IntGELU    | n:  2
IntSoftmax | n:  20
IntGELU    | n:  2
IntSoftmax | n:  20
IntGELU    | n:  2
IntSoftmax | n:  20
IntGELU    | n:  2
IntSoftmax | n:  20
IntGELU    | n:  2
IntSoftmax | n:  20
IntGELU    | n:  2
IntSoftmax | n:  20
IntGELU    | n:  2
IntSoftmax | n:  20
IntGELU    | n:  2
IntSoftmax | n:  20
IntGELU    | n:  2
IntSoftmax | n:  20
IntGELU    | n:  2
.calib done
Test: [  0/391]	Time  3.810 ( 3.810)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.75
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=20, intgelu_exp_n=3
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=20, intgelu_exp_n=3, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  20
IntGELU    | n:  3
IntSoftmax | n:  20
IntGELU    | n:  3
IntSoftmax | n:  20
IntGELU    | n:  3
IntSoftmax | n:  20
IntGELU    | n:  3
IntSoftmax | n:  20
IntGELU    | n:  3
IntSoftmax | n:  20
IntGELU    | n:  3
IntSoftmax | n:  20
IntGELU    | n:  3
IntSoftmax | n:  20
IntGELU    | n:  3
IntSoftmax | n:  20
IntGELU    | n:  3
IntSoftmax | n:  20
IntGELU    | n:  3
IntSoftmax | n:  20
IntGELU    | n:  3
IntSoftmax | n:  20
IntGELU    | n:  3
.calib done
Test: [  0/391]	Time  3.797 ( 3.797)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.75
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=20, intgelu_exp_n=4
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=20, intgelu_exp_n=4, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  20
IntGELU    | n:  4
IntSoftmax | n:  20
IntGELU    | n:  4
IntSoftmax | n:  20
IntGELU    | n:  4
IntSoftmax | n:  20
IntGELU    | n:  4
IntSoftmax | n:  20
IntGELU    | n:  4
IntSoftmax | n:  20
IntGELU    | n:  4
IntSoftmax | n:  20
IntGELU    | n:  4
IntSoftmax | n:  20
IntGELU    | n:  4
IntSoftmax | n:  20
IntGELU    | n:  4
IntSoftmax | n:  20
IntGELU    | n:  4
IntSoftmax | n:  20
IntGELU    | n:  4
IntSoftmax | n:  20
IntGELU    | n:  4
.calib done
Test: [  0/391]	Time  3.874 ( 3.874)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.78
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=20, intgelu_exp_n=5
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=20, intgelu_exp_n=5, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  20
IntGELU    | n:  5
IntSoftmax | n:  20
IntGELU    | n:  5
IntSoftmax | n:  20
IntGELU    | n:  5
IntSoftmax | n:  20
IntGELU    | n:  5
IntSoftmax | n:  20
IntGELU    | n:  5
IntSoftmax | n:  20
IntGELU    | n:  5
IntSoftmax | n:  20
IntGELU    | n:  5
IntSoftmax | n:  20
IntGELU    | n:  5
IntSoftmax | n:  20
IntGELU    | n:  5
IntSoftmax | n:  20
IntGELU    | n:  5
IntSoftmax | n:  20
IntGELU    | n:  5
IntSoftmax | n:  20
IntGELU    | n:  5
.calib done
Test: [  0/391]	Time  3.782 ( 3.782)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.76
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=20, intgelu_exp_n=6
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=20, intgelu_exp_n=6, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  20
IntGELU    | n:  6
IntSoftmax | n:  20
IntGELU    | n:  6
IntSoftmax | n:  20
IntGELU    | n:  6
IntSoftmax | n:  20
IntGELU    | n:  6
IntSoftmax | n:  20
IntGELU    | n:  6
IntSoftmax | n:  20
IntGELU    | n:  6
IntSoftmax | n:  20
IntGELU    | n:  6
IntSoftmax | n:  20
IntGELU    | n:  6
IntSoftmax | n:  20
IntGELU    | n:  6
IntSoftmax | n:  20
IntGELU    | n:  6
IntSoftmax | n:  20
IntGELU    | n:  6
IntSoftmax | n:  20
IntGELU    | n:  6
.calib done
Test: [  0/391]	Time  3.660 ( 3.660)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.60
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=20, intgelu_exp_n=7
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=20, intgelu_exp_n=7, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  20
IntGELU    | n:  7
IntSoftmax | n:  20
IntGELU    | n:  7
IntSoftmax | n:  20
IntGELU    | n:  7
IntSoftmax | n:  20
IntGELU    | n:  7
IntSoftmax | n:  20
IntGELU    | n:  7
IntSoftmax | n:  20
IntGELU    | n:  7
IntSoftmax | n:  20
IntGELU    | n:  7
IntSoftmax | n:  20
IntGELU    | n:  7
IntSoftmax | n:  20
IntGELU    | n:  7
IntSoftmax | n:  20
IntGELU    | n:  7
IntSoftmax | n:  20
IntGELU    | n:  7
IntSoftmax | n:  20
IntGELU    | n:  7
.calib done
Test: [  0/391]	Time  3.664 ( 3.664)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.59
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=20, intgelu_exp_n=8
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=20, intgelu_exp_n=8, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  20
IntGELU    | n:  8
IntSoftmax | n:  20
IntGELU    | n:  8
IntSoftmax | n:  20
IntGELU    | n:  8
IntSoftmax | n:  20
IntGELU    | n:  8
IntSoftmax | n:  20
IntGELU    | n:  8
IntSoftmax | n:  20
IntGELU    | n:  8
IntSoftmax | n:  20
IntGELU    | n:  8
IntSoftmax | n:  20
IntGELU    | n:  8
IntSoftmax | n:  20
IntGELU    | n:  8
IntSoftmax | n:  20
IntGELU    | n:  8
IntSoftmax | n:  20
IntGELU    | n:  8
IntSoftmax | n:  20
IntGELU    | n:  8
.calib done
Test: [  0/391]	Time  3.813 ( 3.813)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.76
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=20, intgelu_exp_n=9
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=20, intgelu_exp_n=9, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  20
IntGELU    | n:  9
IntSoftmax | n:  20
IntGELU    | n:  9
IntSoftmax | n:  20
IntGELU    | n:  9
IntSoftmax | n:  20
IntGELU    | n:  9
IntSoftmax | n:  20
IntGELU    | n:  9
IntSoftmax | n:  20
IntGELU    | n:  9
IntSoftmax | n:  20
IntGELU    | n:  9
IntSoftmax | n:  20
IntGELU    | n:  9
IntSoftmax | n:  20
IntGELU    | n:  9
IntSoftmax | n:  20
IntGELU    | n:  9
IntSoftmax | n:  20
IntGELU    | n:  9
IntSoftmax | n:  20
IntGELU    | n:  9
.calib done
Test: [  0/391]	Time  3.905 ( 3.905)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.89
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=20, intgelu_exp_n=10
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=20, intgelu_exp_n=10, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  20
IntGELU    | n:  10
IntSoftmax | n:  20
IntGELU    | n:  10
IntSoftmax | n:  20
IntGELU    | n:  10
IntSoftmax | n:  20
IntGELU    | n:  10
IntSoftmax | n:  20
IntGELU    | n:  10
IntSoftmax | n:  20
IntGELU    | n:  10
IntSoftmax | n:  20
IntGELU    | n:  10
IntSoftmax | n:  20
IntGELU    | n:  10
IntSoftmax | n:  20
IntGELU    | n:  10
IntSoftmax | n:  20
IntGELU    | n:  10
IntSoftmax | n:  20
IntGELU    | n:  10
IntSoftmax | n:  20
IntGELU    | n:  10
.calib done
Test: [  0/391]	Time  3.925 ( 3.925)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.92
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=20, intgelu_exp_n=11
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=20, intgelu_exp_n=11, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  20
IntGELU    | n:  11
IntSoftmax | n:  20
IntGELU    | n:  11
IntSoftmax | n:  20
IntGELU    | n:  11
IntSoftmax | n:  20
IntGELU    | n:  11
IntSoftmax | n:  20
IntGELU    | n:  11
IntSoftmax | n:  20
IntGELU    | n:  11
IntSoftmax | n:  20
IntGELU    | n:  11
IntSoftmax | n:  20
IntGELU    | n:  11
IntSoftmax | n:  20
IntGELU    | n:  11
IntSoftmax | n:  20
IntGELU    | n:  11
IntSoftmax | n:  20
IntGELU    | n:  11
IntSoftmax | n:  20
IntGELU    | n:  11
.calib done
Test: [  0/391]	Time  3.894 ( 3.894)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.84
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=20, intgelu_exp_n=12
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=20, intgelu_exp_n=12, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  20
IntGELU    | n:  12
IntSoftmax | n:  20
IntGELU    | n:  12
IntSoftmax | n:  20
IntGELU    | n:  12
IntSoftmax | n:  20
IntGELU    | n:  12
IntSoftmax | n:  20
IntGELU    | n:  12
IntSoftmax | n:  20
IntGELU    | n:  12
IntSoftmax | n:  20
IntGELU    | n:  12
IntSoftmax | n:  20
IntGELU    | n:  12
IntSoftmax | n:  20
IntGELU    | n:  12
IntSoftmax | n:  20
IntGELU    | n:  12
IntSoftmax | n:  20
IntGELU    | n:  12
IntSoftmax | n:  20
IntGELU    | n:  12
.calib done
Test: [  0/391]	Time  3.748 ( 3.748)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.71
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=20, intgelu_exp_n=13
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=20, intgelu_exp_n=13, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  20
IntGELU    | n:  13
IntSoftmax | n:  20
IntGELU    | n:  13
IntSoftmax | n:  20
IntGELU    | n:  13
IntSoftmax | n:  20
IntGELU    | n:  13
IntSoftmax | n:  20
IntGELU    | n:  13
IntSoftmax | n:  20
IntGELU    | n:  13
IntSoftmax | n:  20
IntGELU    | n:  13
IntSoftmax | n:  20
IntGELU    | n:  13
IntSoftmax | n:  20
IntGELU    | n:  13
IntSoftmax | n:  20
IntGELU    | n:  13
IntSoftmax | n:  20
IntGELU    | n:  13
IntSoftmax | n:  20
IntGELU    | n:  13
.calib done
Test: [  0/391]	Time  3.934 ( 3.934)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.90
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=20, intgelu_exp_n=14
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=20, intgelu_exp_n=14, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  20
IntGELU    | n:  14
IntSoftmax | n:  20
IntGELU    | n:  14
IntSoftmax | n:  20
IntGELU    | n:  14
IntSoftmax | n:  20
IntGELU    | n:  14
IntSoftmax | n:  20
IntGELU    | n:  14
IntSoftmax | n:  20
IntGELU    | n:  14
IntSoftmax | n:  20
IntGELU    | n:  14
IntSoftmax | n:  20
IntGELU    | n:  14
IntSoftmax | n:  20
IntGELU    | n:  14
IntSoftmax | n:  20
IntGELU    | n:  14
IntSoftmax | n:  20
IntGELU    | n:  14
IntSoftmax | n:  20
IntGELU    | n:  14
.calib done
Test: [  0/391]	Time  3.768 ( 3.768)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.69
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=20, intgelu_exp_n=15
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=20, intgelu_exp_n=15, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  20
IntGELU    | n:  15
IntSoftmax | n:  20
IntGELU    | n:  15
IntSoftmax | n:  20
IntGELU    | n:  15
IntSoftmax | n:  20
IntGELU    | n:  15
IntSoftmax | n:  20
IntGELU    | n:  15
IntSoftmax | n:  20
IntGELU    | n:  15
IntSoftmax | n:  20
IntGELU    | n:  15
IntSoftmax | n:  20
IntGELU    | n:  15
IntSoftmax | n:  20
IntGELU    | n:  15
IntSoftmax | n:  20
IntGELU    | n:  15
IntSoftmax | n:  20
IntGELU    | n:  15
IntSoftmax | n:  20
IntGELU    | n:  15
.calib done
Test: [  0/391]	Time  4.017 ( 4.017)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.97
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=20, intgelu_exp_n=16
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=20, intgelu_exp_n=16, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  20
IntGELU    | n:  16
IntSoftmax | n:  20
IntGELU    | n:  16
IntSoftmax | n:  20
IntGELU    | n:  16
IntSoftmax | n:  20
IntGELU    | n:  16
IntSoftmax | n:  20
IntGELU    | n:  16
IntSoftmax | n:  20
IntGELU    | n:  16
IntSoftmax | n:  20
IntGELU    | n:  16
IntSoftmax | n:  20
IntGELU    | n:  16
IntSoftmax | n:  20
IntGELU    | n:  16
IntSoftmax | n:  20
IntGELU    | n:  16
IntSoftmax | n:  20
IntGELU    | n:  16
IntSoftmax | n:  20
IntGELU    | n:  16
.calib done
Test: [  0/391]	Time  3.983 ( 3.983)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.92
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=20, intgelu_exp_n=17
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=20, intgelu_exp_n=17, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  20
IntGELU    | n:  17
IntSoftmax | n:  20
IntGELU    | n:  17
IntSoftmax | n:  20
IntGELU    | n:  17
IntSoftmax | n:  20
IntGELU    | n:  17
IntSoftmax | n:  20
IntGELU    | n:  17
IntSoftmax | n:  20
IntGELU    | n:  17
IntSoftmax | n:  20
IntGELU    | n:  17
IntSoftmax | n:  20
IntGELU    | n:  17
IntSoftmax | n:  20
IntGELU    | n:  17
IntSoftmax | n:  20
IntGELU    | n:  17
IntSoftmax | n:  20
IntGELU    | n:  17
IntSoftmax | n:  20
IntGELU    | n:  17
.calib done
Test: [  0/391]	Time  3.951 ( 3.951)	Acc@1   0.00 (  0.00)	Acc@5   1.56 (  1.56)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 1.562
Time: 8.85
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=20, intgelu_exp_n=18
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=20, intgelu_exp_n=18, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  20
IntGELU    | n:  18
IntSoftmax | n:  20
IntGELU    | n:  18
IntSoftmax | n:  20
IntGELU    | n:  18
IntSoftmax | n:  20
IntGELU    | n:  18
IntSoftmax | n:  20
IntGELU    | n:  18
IntSoftmax | n:  20
IntGELU    | n:  18
IntSoftmax | n:  20
IntGELU    | n:  18
IntSoftmax | n:  20
IntGELU    | n:  18
IntSoftmax | n:  20
IntGELU    | n:  18
IntSoftmax | n:  20
IntGELU    | n:  18
IntSoftmax | n:  20
IntGELU    | n:  18
IntSoftmax | n:  20
IntGELU    | n:  18
.calib done
Test: [  0/391]	Time  3.928 ( 3.928)	Acc@1   0.78 (  0.78)	Acc@5   5.47 (  5.47)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.781 Prec@5 5.469
Time: 8.92
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=20, intgelu_exp_n=19
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=20, intgelu_exp_n=19, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  20
IntGELU    | n:  19
IntSoftmax | n:  20
IntGELU    | n:  19
IntSoftmax | n:  20
IntGELU    | n:  19
IntSoftmax | n:  20
IntGELU    | n:  19
IntSoftmax | n:  20
IntGELU    | n:  19
IntSoftmax | n:  20
IntGELU    | n:  19
IntSoftmax | n:  20
IntGELU    | n:  19
IntSoftmax | n:  20
IntGELU    | n:  19
IntSoftmax | n:  20
IntGELU    | n:  19
IntSoftmax | n:  20
IntGELU    | n:  19
IntSoftmax | n:  20
IntGELU    | n:  19
IntSoftmax | n:  20
IntGELU    | n:  19
.calib done
Test: [  0/391]	Time  3.806 ( 3.806)	Acc@1   2.34 (  2.34)	Acc@5   5.47 (  5.47)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 2.344 Prec@5 5.469
Time: 8.72
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=20, intgelu_exp_n=20
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=20, intgelu_exp_n=20, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  20
IntGELU    | n:  20
IntSoftmax | n:  20
IntGELU    | n:  20
IntSoftmax | n:  20
IntGELU    | n:  20
IntSoftmax | n:  20
IntGELU    | n:  20
IntSoftmax | n:  20
IntGELU    | n:  20
IntSoftmax | n:  20
IntGELU    | n:  20
IntSoftmax | n:  20
IntGELU    | n:  20
IntSoftmax | n:  20
IntGELU    | n:  20
IntSoftmax | n:  20
IntGELU    | n:  20
IntSoftmax | n:  20
IntGELU    | n:  20
IntSoftmax | n:  20
IntGELU    | n:  20
IntSoftmax | n:  20
IntGELU    | n:  20
.calib done
Test: [  0/391]	Time  3.854 ( 3.854)	Acc@1   2.34 (  2.34)	Acc@5   7.03 (  7.03)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 2.344 Prec@5 7.031
Time: 8.77
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=20, intgelu_exp_n=21
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=20, intgelu_exp_n=21, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  20
IntGELU    | n:  21
IntSoftmax | n:  20
IntGELU    | n:  21
IntSoftmax | n:  20
IntGELU    | n:  21
IntSoftmax | n:  20
IntGELU    | n:  21
IntSoftmax | n:  20
IntGELU    | n:  21
IntSoftmax | n:  20
IntGELU    | n:  21
IntSoftmax | n:  20
IntGELU    | n:  21
IntSoftmax | n:  20
IntGELU    | n:  21
IntSoftmax | n:  20
IntGELU    | n:  21
IntSoftmax | n:  20
IntGELU    | n:  21
IntSoftmax | n:  20
IntGELU    | n:  21
IntSoftmax | n:  20
IntGELU    | n:  21
.calib done
Test: [  0/391]	Time  3.951 ( 3.951)	Acc@1   7.81 (  7.81)	Acc@5  16.41 ( 16.41)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 7.812 Prec@5 16.406
Time: 8.94
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=20, intgelu_exp_n=22
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=20, intgelu_exp_n=22, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  20
IntGELU    | n:  22
IntSoftmax | n:  20
IntGELU    | n:  22
IntSoftmax | n:  20
IntGELU    | n:  22
IntSoftmax | n:  20
IntGELU    | n:  22
IntSoftmax | n:  20
IntGELU    | n:  22
IntSoftmax | n:  20
IntGELU    | n:  22
IntSoftmax | n:  20
IntGELU    | n:  22
IntSoftmax | n:  20
IntGELU    | n:  22
IntSoftmax | n:  20
IntGELU    | n:  22
IntSoftmax | n:  20
IntGELU    | n:  22
IntSoftmax | n:  20
IntGELU    | n:  22
IntSoftmax | n:  20
IntGELU    | n:  22
.calib done
Test: [  0/391]	Time  3.943 ( 3.943)	Acc@1  12.50 ( 12.50)	Acc@5  24.22 ( 24.22)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 12.500 Prec@5 24.219
Time: 8.89
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=20, intgelu_exp_n=23
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=20, intgelu_exp_n=23, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  20
IntGELU    | n:  23
IntSoftmax | n:  20
IntGELU    | n:  23
IntSoftmax | n:  20
IntGELU    | n:  23
IntSoftmax | n:  20
IntGELU    | n:  23
IntSoftmax | n:  20
IntGELU    | n:  23
IntSoftmax | n:  20
IntGELU    | n:  23
IntSoftmax | n:  20
IntGELU    | n:  23
IntSoftmax | n:  20
IntGELU    | n:  23
IntSoftmax | n:  20
IntGELU    | n:  23
IntSoftmax | n:  20
IntGELU    | n:  23
IntSoftmax | n:  20
IntGELU    | n:  23
IntSoftmax | n:  20
IntGELU    | n:  23
.calib done
Test: [  0/391]	Time  3.787 ( 3.787)	Acc@1   8.59 (  8.59)	Acc@5  23.44 ( 23.44)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 8.594 Prec@5 23.438
Time: 8.71
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=20, intgelu_exp_n=24
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=20, intgelu_exp_n=24, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  20
IntGELU    | n:  24
IntSoftmax | n:  20
IntGELU    | n:  24
IntSoftmax | n:  20
IntGELU    | n:  24
IntSoftmax | n:  20
IntGELU    | n:  24
IntSoftmax | n:  20
IntGELU    | n:  24
IntSoftmax | n:  20
IntGELU    | n:  24
IntSoftmax | n:  20
IntGELU    | n:  24
IntSoftmax | n:  20
IntGELU    | n:  24
IntSoftmax | n:  20
IntGELU    | n:  24
IntSoftmax | n:  20
IntGELU    | n:  24
IntSoftmax | n:  20
IntGELU    | n:  24
IntSoftmax | n:  20
IntGELU    | n:  24
.calib done
Test: [  0/391]	Time  3.793 ( 3.793)	Acc@1   3.12 (  3.12)	Acc@5  11.72 ( 11.72)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 3.125 Prec@5 11.719
Time: 8.74
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=20, intgelu_exp_n=25
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=20, intgelu_exp_n=25, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  20
IntGELU    | n:  25
IntSoftmax | n:  20
IntGELU    | n:  25
IntSoftmax | n:  20
IntGELU    | n:  25
IntSoftmax | n:  20
IntGELU    | n:  25
IntSoftmax | n:  20
IntGELU    | n:  25
IntSoftmax | n:  20
IntGELU    | n:  25
IntSoftmax | n:  20
IntGELU    | n:  25
IntSoftmax | n:  20
IntGELU    | n:  25
IntSoftmax | n:  20
IntGELU    | n:  25
IntSoftmax | n:  20
IntGELU    | n:  25
IntSoftmax | n:  20
IntGELU    | n:  25
IntSoftmax | n:  20
IntGELU    | n:  25
.calib done
Test: [  0/391]	Time  3.929 ( 3.929)	Acc@1  21.88 ( 21.88)	Acc@5  43.75 ( 43.75)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 21.875 Prec@5 43.750
Time: 8.87
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=20, intgelu_exp_n=26
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=20, intgelu_exp_n=26, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  20
IntGELU    | n:  26
IntSoftmax | n:  20
IntGELU    | n:  26
IntSoftmax | n:  20
IntGELU    | n:  26
IntSoftmax | n:  20
IntGELU    | n:  26
IntSoftmax | n:  20
IntGELU    | n:  26
IntSoftmax | n:  20
IntGELU    | n:  26
IntSoftmax | n:  20
IntGELU    | n:  26
IntSoftmax | n:  20
IntGELU    | n:  26
IntSoftmax | n:  20
IntGELU    | n:  26
IntSoftmax | n:  20
IntGELU    | n:  26
IntSoftmax | n:  20
IntGELU    | n:  26
IntSoftmax | n:  20
IntGELU    | n:  26
.calib done
Test: [  0/391]	Time  3.876 ( 3.876)	Acc@1  23.44 ( 23.44)	Acc@5  42.97 ( 42.97)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 23.438 Prec@5 42.969
Time: 8.81
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=20, intgelu_exp_n=27
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=20, intgelu_exp_n=27, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  20
IntGELU    | n:  27
IntSoftmax | n:  20
IntGELU    | n:  27
IntSoftmax | n:  20
IntGELU    | n:  27
IntSoftmax | n:  20
IntGELU    | n:  27
IntSoftmax | n:  20
IntGELU    | n:  27
IntSoftmax | n:  20
IntGELU    | n:  27
IntSoftmax | n:  20
IntGELU    | n:  27
IntSoftmax | n:  20
IntGELU    | n:  27
IntSoftmax | n:  20
IntGELU    | n:  27
IntSoftmax | n:  20
IntGELU    | n:  27
IntSoftmax | n:  20
IntGELU    | n:  27
IntSoftmax | n:  20
IntGELU    | n:  27
.calib done
Test: [  0/391]	Time  3.940 ( 3.940)	Acc@1  26.56 ( 26.56)	Acc@5  51.56 ( 51.56)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 26.562 Prec@5 51.562
Time: 8.84
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=20, intgelu_exp_n=28
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=20, intgelu_exp_n=28, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  20
IntGELU    | n:  28
IntSoftmax | n:  20
IntGELU    | n:  28
IntSoftmax | n:  20
IntGELU    | n:  28
IntSoftmax | n:  20
IntGELU    | n:  28
IntSoftmax | n:  20
IntGELU    | n:  28
IntSoftmax | n:  20
IntGELU    | n:  28
IntSoftmax | n:  20
IntGELU    | n:  28
IntSoftmax | n:  20
IntGELU    | n:  28
IntSoftmax | n:  20
IntGELU    | n:  28
IntSoftmax | n:  20
IntGELU    | n:  28
IntSoftmax | n:  20
IntGELU    | n:  28
IntSoftmax | n:  20
IntGELU    | n:  28
.calib done
Test: [  0/391]	Time  3.950 ( 3.950)	Acc@1  28.91 ( 28.91)	Acc@5  53.12 ( 53.12)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 28.906 Prec@5 53.125
Time: 8.88
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=20, intgelu_exp_n=29
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=20, intgelu_exp_n=29, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  20
IntGELU    | n:  29
IntSoftmax | n:  20
IntGELU    | n:  29
IntSoftmax | n:  20
IntGELU    | n:  29
IntSoftmax | n:  20
IntGELU    | n:  29
IntSoftmax | n:  20
IntGELU    | n:  29
IntSoftmax | n:  20
IntGELU    | n:  29
IntSoftmax | n:  20
IntGELU    | n:  29
IntSoftmax | n:  20
IntGELU    | n:  29
IntSoftmax | n:  20
IntGELU    | n:  29
IntSoftmax | n:  20
IntGELU    | n:  29
IntSoftmax | n:  20
IntGELU    | n:  29
IntSoftmax | n:  20
IntGELU    | n:  29
.calib done
Test: [  0/391]	Time  4.059 ( 4.059)	Acc@1  30.47 ( 30.47)	Acc@5  52.34 ( 52.34)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 30.469 Prec@5 52.344
Time: 8.98
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=20, intgelu_exp_n=30
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=20, intgelu_exp_n=30, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  20
IntGELU    | n:  30
IntSoftmax | n:  20
IntGELU    | n:  30
IntSoftmax | n:  20
IntGELU    | n:  30
IntSoftmax | n:  20
IntGELU    | n:  30
IntSoftmax | n:  20
IntGELU    | n:  30
IntSoftmax | n:  20
IntGELU    | n:  30
IntSoftmax | n:  20
IntGELU    | n:  30
IntSoftmax | n:  20
IntGELU    | n:  30
IntSoftmax | n:  20
IntGELU    | n:  30
IntSoftmax | n:  20
IntGELU    | n:  30
IntSoftmax | n:  20
IntGELU    | n:  30
IntSoftmax | n:  20
IntGELU    | n:  30
.calib done
Test: [  0/391]	Time  3.742 ( 3.742)	Acc@1  60.94 ( 60.94)	Acc@5  85.16 ( 85.16)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 60.938 Prec@5 85.156
Time: 8.69
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=20, intgelu_exp_n=31
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=20, intgelu_exp_n=31, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  20
IntGELU    | n:  31
IntSoftmax | n:  20
IntGELU    | n:  31
IntSoftmax | n:  20
IntGELU    | n:  31
IntSoftmax | n:  20
IntGELU    | n:  31
IntSoftmax | n:  20
IntGELU    | n:  31
IntSoftmax | n:  20
IntGELU    | n:  31
IntSoftmax | n:  20
IntGELU    | n:  31
IntSoftmax | n:  20
IntGELU    | n:  31
IntSoftmax | n:  20
IntGELU    | n:  31
IntSoftmax | n:  20
IntGELU    | n:  31
IntSoftmax | n:  20
IntGELU    | n:  31
IntSoftmax | n:  20
IntGELU    | n:  31
.calib done
Test: [  0/391]	Time  3.995 ( 3.995)	Acc@1   5.47 (  5.47)	Acc@5  17.97 ( 17.97)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 5.469 Prec@5 17.969
Time: 8.92
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=21, intgelu_exp_n=0
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=21, intgelu_exp_n=0, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  21
IntGELU    | n:  0
IntSoftmax | n:  21
IntGELU    | n:  0
IntSoftmax | n:  21
IntGELU    | n:  0
IntSoftmax | n:  21
IntGELU    | n:  0
IntSoftmax | n:  21
IntGELU    | n:  0
IntSoftmax | n:  21
IntGELU    | n:  0
IntSoftmax | n:  21
IntGELU    | n:  0
IntSoftmax | n:  21
IntGELU    | n:  0
IntSoftmax | n:  21
IntGELU    | n:  0
IntSoftmax | n:  21
IntGELU    | n:  0
IntSoftmax | n:  21
IntGELU    | n:  0
IntSoftmax | n:  21
IntGELU    | n:  0
.calib done
Test: [  0/391]	Time  3.910 ( 3.910)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.88
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=21, intgelu_exp_n=1
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=21, intgelu_exp_n=1, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  21
IntGELU    | n:  1
IntSoftmax | n:  21
IntGELU    | n:  1
IntSoftmax | n:  21
IntGELU    | n:  1
IntSoftmax | n:  21
IntGELU    | n:  1
IntSoftmax | n:  21
IntGELU    | n:  1
IntSoftmax | n:  21
IntGELU    | n:  1
IntSoftmax | n:  21
IntGELU    | n:  1
IntSoftmax | n:  21
IntGELU    | n:  1
IntSoftmax | n:  21
IntGELU    | n:  1
IntSoftmax | n:  21
IntGELU    | n:  1
IntSoftmax | n:  21
IntGELU    | n:  1
IntSoftmax | n:  21
IntGELU    | n:  1
.calib done
Test: [  0/391]	Time  3.874 ( 3.874)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.77
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=21, intgelu_exp_n=2
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=21, intgelu_exp_n=2, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  21
IntGELU    | n:  2
IntSoftmax | n:  21
IntGELU    | n:  2
IntSoftmax | n:  21
IntGELU    | n:  2
IntSoftmax | n:  21
IntGELU    | n:  2
IntSoftmax | n:  21
IntGELU    | n:  2
IntSoftmax | n:  21
IntGELU    | n:  2
IntSoftmax | n:  21
IntGELU    | n:  2
IntSoftmax | n:  21
IntGELU    | n:  2
IntSoftmax | n:  21
IntGELU    | n:  2
IntSoftmax | n:  21
IntGELU    | n:  2
IntSoftmax | n:  21
IntGELU    | n:  2
IntSoftmax | n:  21
IntGELU    | n:  2
.calib done
Test: [  0/391]	Time  3.860 ( 3.860)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.85
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=21, intgelu_exp_n=3
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=21, intgelu_exp_n=3, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  21
IntGELU    | n:  3
IntSoftmax | n:  21
IntGELU    | n:  3
IntSoftmax | n:  21
IntGELU    | n:  3
IntSoftmax | n:  21
IntGELU    | n:  3
IntSoftmax | n:  21
IntGELU    | n:  3
IntSoftmax | n:  21
IntGELU    | n:  3
IntSoftmax | n:  21
IntGELU    | n:  3
IntSoftmax | n:  21
IntGELU    | n:  3
IntSoftmax | n:  21
IntGELU    | n:  3
IntSoftmax | n:  21
IntGELU    | n:  3
IntSoftmax | n:  21
IntGELU    | n:  3
IntSoftmax | n:  21
IntGELU    | n:  3
.calib done
Test: [  0/391]	Time  3.932 ( 3.932)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.89
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=21, intgelu_exp_n=4
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=21, intgelu_exp_n=4, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  21
IntGELU    | n:  4
IntSoftmax | n:  21
IntGELU    | n:  4
IntSoftmax | n:  21
IntGELU    | n:  4
IntSoftmax | n:  21
IntGELU    | n:  4
IntSoftmax | n:  21
IntGELU    | n:  4
IntSoftmax | n:  21
IntGELU    | n:  4
IntSoftmax | n:  21
IntGELU    | n:  4
IntSoftmax | n:  21
IntGELU    | n:  4
IntSoftmax | n:  21
IntGELU    | n:  4
IntSoftmax | n:  21
IntGELU    | n:  4
IntSoftmax | n:  21
IntGELU    | n:  4
IntSoftmax | n:  21
IntGELU    | n:  4
.calib done
Test: [  0/391]	Time  3.895 ( 3.895)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.83
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=21, intgelu_exp_n=5
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=21, intgelu_exp_n=5, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  21
IntGELU    | n:  5
IntSoftmax | n:  21
IntGELU    | n:  5
IntSoftmax | n:  21
IntGELU    | n:  5
IntSoftmax | n:  21
IntGELU    | n:  5
IntSoftmax | n:  21
IntGELU    | n:  5
IntSoftmax | n:  21
IntGELU    | n:  5
IntSoftmax | n:  21
IntGELU    | n:  5
IntSoftmax | n:  21
IntGELU    | n:  5
IntSoftmax | n:  21
IntGELU    | n:  5
IntSoftmax | n:  21
IntGELU    | n:  5
IntSoftmax | n:  21
IntGELU    | n:  5
IntSoftmax | n:  21
IntGELU    | n:  5
.calib done
Test: [  0/391]	Time  3.702 ( 3.702)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.68
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=21, intgelu_exp_n=6
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=21, intgelu_exp_n=6, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  21
IntGELU    | n:  6
IntSoftmax | n:  21
IntGELU    | n:  6
IntSoftmax | n:  21
IntGELU    | n:  6
IntSoftmax | n:  21
IntGELU    | n:  6
IntSoftmax | n:  21
IntGELU    | n:  6
IntSoftmax | n:  21
IntGELU    | n:  6
IntSoftmax | n:  21
IntGELU    | n:  6
IntSoftmax | n:  21
IntGELU    | n:  6
IntSoftmax | n:  21
IntGELU    | n:  6
IntSoftmax | n:  21
IntGELU    | n:  6
IntSoftmax | n:  21
IntGELU    | n:  6
IntSoftmax | n:  21
IntGELU    | n:  6
.calib done
Test: [  0/391]	Time  3.788 ( 3.788)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.81
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=21, intgelu_exp_n=7
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=21, intgelu_exp_n=7, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  21
IntGELU    | n:  7
IntSoftmax | n:  21
IntGELU    | n:  7
IntSoftmax | n:  21
IntGELU    | n:  7
IntSoftmax | n:  21
IntGELU    | n:  7
IntSoftmax | n:  21
IntGELU    | n:  7
IntSoftmax | n:  21
IntGELU    | n:  7
IntSoftmax | n:  21
IntGELU    | n:  7
IntSoftmax | n:  21
IntGELU    | n:  7
IntSoftmax | n:  21
IntGELU    | n:  7
IntSoftmax | n:  21
IntGELU    | n:  7
IntSoftmax | n:  21
IntGELU    | n:  7
IntSoftmax | n:  21
IntGELU    | n:  7
.calib done
Test: [  0/391]	Time  3.863 ( 3.863)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.82
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=21, intgelu_exp_n=8
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=21, intgelu_exp_n=8, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  21
IntGELU    | n:  8
IntSoftmax | n:  21
IntGELU    | n:  8
IntSoftmax | n:  21
IntGELU    | n:  8
IntSoftmax | n:  21
IntGELU    | n:  8
IntSoftmax | n:  21
IntGELU    | n:  8
IntSoftmax | n:  21
IntGELU    | n:  8
IntSoftmax | n:  21
IntGELU    | n:  8
IntSoftmax | n:  21
IntGELU    | n:  8
IntSoftmax | n:  21
IntGELU    | n:  8
IntSoftmax | n:  21
IntGELU    | n:  8
IntSoftmax | n:  21
IntGELU    | n:  8
IntSoftmax | n:  21
IntGELU    | n:  8
.calib done
Test: [  0/391]	Time  3.609 ( 3.609)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.52
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=21, intgelu_exp_n=9
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=21, intgelu_exp_n=9, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  21
IntGELU    | n:  9
IntSoftmax | n:  21
IntGELU    | n:  9
IntSoftmax | n:  21
IntGELU    | n:  9
IntSoftmax | n:  21
IntGELU    | n:  9
IntSoftmax | n:  21
IntGELU    | n:  9
IntSoftmax | n:  21
IntGELU    | n:  9
IntSoftmax | n:  21
IntGELU    | n:  9
IntSoftmax | n:  21
IntGELU    | n:  9
IntSoftmax | n:  21
IntGELU    | n:  9
IntSoftmax | n:  21
IntGELU    | n:  9
IntSoftmax | n:  21
IntGELU    | n:  9
IntSoftmax | n:  21
IntGELU    | n:  9
.calib done
Test: [  0/391]	Time  3.663 ( 3.663)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.61
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=21, intgelu_exp_n=10
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=21, intgelu_exp_n=10, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  21
IntGELU    | n:  10
IntSoftmax | n:  21
IntGELU    | n:  10
IntSoftmax | n:  21
IntGELU    | n:  10
IntSoftmax | n:  21
IntGELU    | n:  10
IntSoftmax | n:  21
IntGELU    | n:  10
IntSoftmax | n:  21
IntGELU    | n:  10
IntSoftmax | n:  21
IntGELU    | n:  10
IntSoftmax | n:  21
IntGELU    | n:  10
IntSoftmax | n:  21
IntGELU    | n:  10
IntSoftmax | n:  21
IntGELU    | n:  10
IntSoftmax | n:  21
IntGELU    | n:  10
IntSoftmax | n:  21
IntGELU    | n:  10
.calib done
Test: [  0/391]	Time  3.876 ( 3.876)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.85
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=21, intgelu_exp_n=11
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=21, intgelu_exp_n=11, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  21
IntGELU    | n:  11
IntSoftmax | n:  21
IntGELU    | n:  11
IntSoftmax | n:  21
IntGELU    | n:  11
IntSoftmax | n:  21
IntGELU    | n:  11
IntSoftmax | n:  21
IntGELU    | n:  11
IntSoftmax | n:  21
IntGELU    | n:  11
IntSoftmax | n:  21
IntGELU    | n:  11
IntSoftmax | n:  21
IntGELU    | n:  11
IntSoftmax | n:  21
IntGELU    | n:  11
IntSoftmax | n:  21
IntGELU    | n:  11
IntSoftmax | n:  21
IntGELU    | n:  11
IntSoftmax | n:  21
IntGELU    | n:  11
.calib done
Test: [  0/391]	Time  3.965 ( 3.965)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.97
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=21, intgelu_exp_n=12
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=21, intgelu_exp_n=12, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  21
IntGELU    | n:  12
IntSoftmax | n:  21
IntGELU    | n:  12
IntSoftmax | n:  21
IntGELU    | n:  12
IntSoftmax | n:  21
IntGELU    | n:  12
IntSoftmax | n:  21
IntGELU    | n:  12
IntSoftmax | n:  21
IntGELU    | n:  12
IntSoftmax | n:  21
IntGELU    | n:  12
IntSoftmax | n:  21
IntGELU    | n:  12
IntSoftmax | n:  21
IntGELU    | n:  12
IntSoftmax | n:  21
IntGELU    | n:  12
IntSoftmax | n:  21
IntGELU    | n:  12
IntSoftmax | n:  21
IntGELU    | n:  12
.calib done
Test: [  0/391]	Time  3.875 ( 3.875)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.83
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=21, intgelu_exp_n=13
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=21, intgelu_exp_n=13, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  21
IntGELU    | n:  13
IntSoftmax | n:  21
IntGELU    | n:  13
IntSoftmax | n:  21
IntGELU    | n:  13
IntSoftmax | n:  21
IntGELU    | n:  13
IntSoftmax | n:  21
IntGELU    | n:  13
IntSoftmax | n:  21
IntGELU    | n:  13
IntSoftmax | n:  21
IntGELU    | n:  13
IntSoftmax | n:  21
IntGELU    | n:  13
IntSoftmax | n:  21
IntGELU    | n:  13
IntSoftmax | n:  21
IntGELU    | n:  13
IntSoftmax | n:  21
IntGELU    | n:  13
IntSoftmax | n:  21
IntGELU    | n:  13
.calib done
Test: [  0/391]	Time  3.857 ( 3.857)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.81
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=21, intgelu_exp_n=14
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=21, intgelu_exp_n=14, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  21
IntGELU    | n:  14
IntSoftmax | n:  21
IntGELU    | n:  14
IntSoftmax | n:  21
IntGELU    | n:  14
IntSoftmax | n:  21
IntGELU    | n:  14
IntSoftmax | n:  21
IntGELU    | n:  14
IntSoftmax | n:  21
IntGELU    | n:  14
IntSoftmax | n:  21
IntGELU    | n:  14
IntSoftmax | n:  21
IntGELU    | n:  14
IntSoftmax | n:  21
IntGELU    | n:  14
IntSoftmax | n:  21
IntGELU    | n:  14
IntSoftmax | n:  21
IntGELU    | n:  14
IntSoftmax | n:  21
IntGELU    | n:  14
.calib done
Test: [  0/391]	Time  3.921 ( 3.921)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.83
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=21, intgelu_exp_n=15
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=21, intgelu_exp_n=15, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  21
IntGELU    | n:  15
IntSoftmax | n:  21
IntGELU    | n:  15
IntSoftmax | n:  21
IntGELU    | n:  15
IntSoftmax | n:  21
IntGELU    | n:  15
IntSoftmax | n:  21
IntGELU    | n:  15
IntSoftmax | n:  21
IntGELU    | n:  15
IntSoftmax | n:  21
IntGELU    | n:  15
IntSoftmax | n:  21
IntGELU    | n:  15
IntSoftmax | n:  21
IntGELU    | n:  15
IntSoftmax | n:  21
IntGELU    | n:  15
IntSoftmax | n:  21
IntGELU    | n:  15
IntSoftmax | n:  21
IntGELU    | n:  15
.calib done
Test: [  0/391]	Time  4.031 ( 4.031)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 9.01
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=21, intgelu_exp_n=16
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=21, intgelu_exp_n=16, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  21
IntGELU    | n:  16
IntSoftmax | n:  21
IntGELU    | n:  16
IntSoftmax | n:  21
IntGELU    | n:  16
IntSoftmax | n:  21
IntGELU    | n:  16
IntSoftmax | n:  21
IntGELU    | n:  16
IntSoftmax | n:  21
IntGELU    | n:  16
IntSoftmax | n:  21
IntGELU    | n:  16
IntSoftmax | n:  21
IntGELU    | n:  16
IntSoftmax | n:  21
IntGELU    | n:  16
IntSoftmax | n:  21
IntGELU    | n:  16
IntSoftmax | n:  21
IntGELU    | n:  16
IntSoftmax | n:  21
IntGELU    | n:  16
.calib done
Test: [  0/391]	Time  3.758 ( 3.758)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.68
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=21, intgelu_exp_n=17
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=21, intgelu_exp_n=17, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  21
IntGELU    | n:  17
IntSoftmax | n:  21
IntGELU    | n:  17
IntSoftmax | n:  21
IntGELU    | n:  17
IntSoftmax | n:  21
IntGELU    | n:  17
IntSoftmax | n:  21
IntGELU    | n:  17
IntSoftmax | n:  21
IntGELU    | n:  17
IntSoftmax | n:  21
IntGELU    | n:  17
IntSoftmax | n:  21
IntGELU    | n:  17
IntSoftmax | n:  21
IntGELU    | n:  17
IntSoftmax | n:  21
IntGELU    | n:  17
IntSoftmax | n:  21
IntGELU    | n:  17
IntSoftmax | n:  21
IntGELU    | n:  17
.calib done
Test: [  0/391]	Time  3.697 ( 3.697)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.67
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=21, intgelu_exp_n=18
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=21, intgelu_exp_n=18, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  21
IntGELU    | n:  18
IntSoftmax | n:  21
IntGELU    | n:  18
IntSoftmax | n:  21
IntGELU    | n:  18
IntSoftmax | n:  21
IntGELU    | n:  18
IntSoftmax | n:  21
IntGELU    | n:  18
IntSoftmax | n:  21
IntGELU    | n:  18
IntSoftmax | n:  21
IntGELU    | n:  18
IntSoftmax | n:  21
IntGELU    | n:  18
IntSoftmax | n:  21
IntGELU    | n:  18
IntSoftmax | n:  21
IntGELU    | n:  18
IntSoftmax | n:  21
IntGELU    | n:  18
IntSoftmax | n:  21
IntGELU    | n:  18
.calib done
Test: [  0/391]	Time  4.013 ( 4.013)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 9.01
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=21, intgelu_exp_n=19
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=21, intgelu_exp_n=19, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  21
IntGELU    | n:  19
IntSoftmax | n:  21
IntGELU    | n:  19
IntSoftmax | n:  21
IntGELU    | n:  19
IntSoftmax | n:  21
IntGELU    | n:  19
IntSoftmax | n:  21
IntGELU    | n:  19
IntSoftmax | n:  21
IntGELU    | n:  19
IntSoftmax | n:  21
IntGELU    | n:  19
IntSoftmax | n:  21
IntGELU    | n:  19
IntSoftmax | n:  21
IntGELU    | n:  19
IntSoftmax | n:  21
IntGELU    | n:  19
IntSoftmax | n:  21
IntGELU    | n:  19
IntSoftmax | n:  21
IntGELU    | n:  19
.calib done
Test: [  0/391]	Time  3.823 ( 3.823)	Acc@1   3.91 (  3.91)	Acc@5  10.16 ( 10.16)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 3.906 Prec@5 10.156
Time: 8.83
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=21, intgelu_exp_n=20
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=21, intgelu_exp_n=20, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  21
IntGELU    | n:  20
IntSoftmax | n:  21
IntGELU    | n:  20
IntSoftmax | n:  21
IntGELU    | n:  20
IntSoftmax | n:  21
IntGELU    | n:  20
IntSoftmax | n:  21
IntGELU    | n:  20
IntSoftmax | n:  21
IntGELU    | n:  20
IntSoftmax | n:  21
IntGELU    | n:  20
IntSoftmax | n:  21
IntGELU    | n:  20
IntSoftmax | n:  21
IntGELU    | n:  20
IntSoftmax | n:  21
IntGELU    | n:  20
IntSoftmax | n:  21
IntGELU    | n:  20
IntSoftmax | n:  21
IntGELU    | n:  20
.calib done
Test: [  0/391]	Time  3.973 ( 3.973)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.94
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=21, intgelu_exp_n=21
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=21, intgelu_exp_n=21, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  21
IntGELU    | n:  21
IntSoftmax | n:  21
IntGELU    | n:  21
IntSoftmax | n:  21
IntGELU    | n:  21
IntSoftmax | n:  21
IntGELU    | n:  21
IntSoftmax | n:  21
IntGELU    | n:  21
IntSoftmax | n:  21
IntGELU    | n:  21
IntSoftmax | n:  21
IntGELU    | n:  21
IntSoftmax | n:  21
IntGELU    | n:  21
IntSoftmax | n:  21
IntGELU    | n:  21
IntSoftmax | n:  21
IntGELU    | n:  21
IntSoftmax | n:  21
IntGELU    | n:  21
IntSoftmax | n:  21
IntGELU    | n:  21
.calib done
Test: [  0/391]	Time  4.084 ( 4.084)	Acc@1   6.25 (  6.25)	Acc@5  15.62 ( 15.62)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 6.250 Prec@5 15.625
Time: 9.00
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=21, intgelu_exp_n=22
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=21, intgelu_exp_n=22, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  21
IntGELU    | n:  22
IntSoftmax | n:  21
IntGELU    | n:  22
IntSoftmax | n:  21
IntGELU    | n:  22
IntSoftmax | n:  21
IntGELU    | n:  22
IntSoftmax | n:  21
IntGELU    | n:  22
IntSoftmax | n:  21
IntGELU    | n:  22
IntSoftmax | n:  21
IntGELU    | n:  22
IntSoftmax | n:  21
IntGELU    | n:  22
IntSoftmax | n:  21
IntGELU    | n:  22
IntSoftmax | n:  21
IntGELU    | n:  22
IntSoftmax | n:  21
IntGELU    | n:  22
IntSoftmax | n:  21
IntGELU    | n:  22
.calib done
Test: [  0/391]	Time  3.837 ( 3.837)	Acc@1  10.94 ( 10.94)	Acc@5  25.78 ( 25.78)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 10.938 Prec@5 25.781
Time: 8.80
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=21, intgelu_exp_n=23
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=21, intgelu_exp_n=23, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  21
IntGELU    | n:  23
IntSoftmax | n:  21
IntGELU    | n:  23
IntSoftmax | n:  21
IntGELU    | n:  23
IntSoftmax | n:  21
IntGELU    | n:  23
IntSoftmax | n:  21
IntGELU    | n:  23
IntSoftmax | n:  21
IntGELU    | n:  23
IntSoftmax | n:  21
IntGELU    | n:  23
IntSoftmax | n:  21
IntGELU    | n:  23
IntSoftmax | n:  21
IntGELU    | n:  23
IntSoftmax | n:  21
IntGELU    | n:  23
IntSoftmax | n:  21
IntGELU    | n:  23
IntSoftmax | n:  21
IntGELU    | n:  23
.calib done
Test: [  0/391]	Time  3.871 ( 3.871)	Acc@1  10.16 ( 10.16)	Acc@5  26.56 ( 26.56)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 10.156 Prec@5 26.562
Time: 8.90
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=21, intgelu_exp_n=24
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=21, intgelu_exp_n=24, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  21
IntGELU    | n:  24
IntSoftmax | n:  21
IntGELU    | n:  24
IntSoftmax | n:  21
IntGELU    | n:  24
IntSoftmax | n:  21
IntGELU    | n:  24
IntSoftmax | n:  21
IntGELU    | n:  24
IntSoftmax | n:  21
IntGELU    | n:  24
IntSoftmax | n:  21
IntGELU    | n:  24
IntSoftmax | n:  21
IntGELU    | n:  24
IntSoftmax | n:  21
IntGELU    | n:  24
IntSoftmax | n:  21
IntGELU    | n:  24
IntSoftmax | n:  21
IntGELU    | n:  24
IntSoftmax | n:  21
IntGELU    | n:  24
.calib done
Test: [  0/391]	Time  3.847 ( 3.847)	Acc@1  11.72 ( 11.72)	Acc@5  31.25 ( 31.25)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 11.719 Prec@5 31.250
Time: 8.79
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=21, intgelu_exp_n=25
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=21, intgelu_exp_n=25, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  21
IntGELU    | n:  25
IntSoftmax | n:  21
IntGELU    | n:  25
IntSoftmax | n:  21
IntGELU    | n:  25
IntSoftmax | n:  21
IntGELU    | n:  25
IntSoftmax | n:  21
IntGELU    | n:  25
IntSoftmax | n:  21
IntGELU    | n:  25
IntSoftmax | n:  21
IntGELU    | n:  25
IntSoftmax | n:  21
IntGELU    | n:  25
IntSoftmax | n:  21
IntGELU    | n:  25
IntSoftmax | n:  21
IntGELU    | n:  25
IntSoftmax | n:  21
IntGELU    | n:  25
IntSoftmax | n:  21
IntGELU    | n:  25
.calib done
Test: [  0/391]	Time  4.029 ( 4.029)	Acc@1  16.41 ( 16.41)	Acc@5  36.72 ( 36.72)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 16.406 Prec@5 36.719
Time: 9.01
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=21, intgelu_exp_n=26
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=21, intgelu_exp_n=26, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  21
IntGELU    | n:  26
IntSoftmax | n:  21
IntGELU    | n:  26
IntSoftmax | n:  21
IntGELU    | n:  26
IntSoftmax | n:  21
IntGELU    | n:  26
IntSoftmax | n:  21
IntGELU    | n:  26
IntSoftmax | n:  21
IntGELU    | n:  26
IntSoftmax | n:  21
IntGELU    | n:  26
IntSoftmax | n:  21
IntGELU    | n:  26
IntSoftmax | n:  21
IntGELU    | n:  26
IntSoftmax | n:  21
IntGELU    | n:  26
IntSoftmax | n:  21
IntGELU    | n:  26
IntSoftmax | n:  21
IntGELU    | n:  26
.calib done
Test: [  0/391]	Time  4.101 ( 4.101)	Acc@1  19.53 ( 19.53)	Acc@5  40.62 ( 40.62)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 19.531 Prec@5 40.625
Time: 9.08
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=21, intgelu_exp_n=27
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=21, intgelu_exp_n=27, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  21
IntGELU    | n:  27
IntSoftmax | n:  21
IntGELU    | n:  27
IntSoftmax | n:  21
IntGELU    | n:  27
IntSoftmax | n:  21
IntGELU    | n:  27
IntSoftmax | n:  21
IntGELU    | n:  27
IntSoftmax | n:  21
IntGELU    | n:  27
IntSoftmax | n:  21
IntGELU    | n:  27
IntSoftmax | n:  21
IntGELU    | n:  27
IntSoftmax | n:  21
IntGELU    | n:  27
IntSoftmax | n:  21
IntGELU    | n:  27
IntSoftmax | n:  21
IntGELU    | n:  27
IntSoftmax | n:  21
IntGELU    | n:  27
.calib done
Test: [  0/391]	Time  3.647 ( 3.647)	Acc@1  20.31 ( 20.31)	Acc@5  44.53 ( 44.53)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 20.312 Prec@5 44.531
Time: 8.64
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=21, intgelu_exp_n=28
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=21, intgelu_exp_n=28, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  21
IntGELU    | n:  28
IntSoftmax | n:  21
IntGELU    | n:  28
IntSoftmax | n:  21
IntGELU    | n:  28
IntSoftmax | n:  21
IntGELU    | n:  28
IntSoftmax | n:  21
IntGELU    | n:  28
IntSoftmax | n:  21
IntGELU    | n:  28
IntSoftmax | n:  21
IntGELU    | n:  28
IntSoftmax | n:  21
IntGELU    | n:  28
IntSoftmax | n:  21
IntGELU    | n:  28
IntSoftmax | n:  21
IntGELU    | n:  28
IntSoftmax | n:  21
IntGELU    | n:  28
IntSoftmax | n:  21
IntGELU    | n:  28
.calib done
Test: [  0/391]	Time  3.840 ( 3.840)	Acc@1  21.88 ( 21.88)	Acc@5  52.34 ( 52.34)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 21.875 Prec@5 52.344
Time: 8.80
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=21, intgelu_exp_n=29
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=21, intgelu_exp_n=29, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  21
IntGELU    | n:  29
IntSoftmax | n:  21
IntGELU    | n:  29
IntSoftmax | n:  21
IntGELU    | n:  29
IntSoftmax | n:  21
IntGELU    | n:  29
IntSoftmax | n:  21
IntGELU    | n:  29
IntSoftmax | n:  21
IntGELU    | n:  29
IntSoftmax | n:  21
IntGELU    | n:  29
IntSoftmax | n:  21
IntGELU    | n:  29
IntSoftmax | n:  21
IntGELU    | n:  29
IntSoftmax | n:  21
IntGELU    | n:  29
IntSoftmax | n:  21
IntGELU    | n:  29
IntSoftmax | n:  21
IntGELU    | n:  29
.calib done
Test: [  0/391]	Time  4.075 ( 4.075)	Acc@1  28.91 ( 28.91)	Acc@5  53.91 ( 53.91)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 28.906 Prec@5 53.906
Time: 8.99
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=21, intgelu_exp_n=30
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=21, intgelu_exp_n=30, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  21
IntGELU    | n:  30
IntSoftmax | n:  21
IntGELU    | n:  30
IntSoftmax | n:  21
IntGELU    | n:  30
IntSoftmax | n:  21
IntGELU    | n:  30
IntSoftmax | n:  21
IntGELU    | n:  30
IntSoftmax | n:  21
IntGELU    | n:  30
IntSoftmax | n:  21
IntGELU    | n:  30
IntSoftmax | n:  21
IntGELU    | n:  30
IntSoftmax | n:  21
IntGELU    | n:  30
IntSoftmax | n:  21
IntGELU    | n:  30
IntSoftmax | n:  21
IntGELU    | n:  30
IntSoftmax | n:  21
IntGELU    | n:  30
.calib done
Test: [  0/391]	Time  4.077 ( 4.077)	Acc@1  89.84 ( 89.84)	Acc@5  96.88 ( 96.88)
Test: [ 10/391]	Time  1.736 ( 1.949)	Acc@1  63.28 ( 80.04)	Acc@5  85.94 ( 93.68)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 80.043 Prec@5 93.679
Time: 26.45
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=21, intgelu_exp_n=31
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=21, intgelu_exp_n=31, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  21
IntGELU    | n:  31
IntSoftmax | n:  21
IntGELU    | n:  31
IntSoftmax | n:  21
IntGELU    | n:  31
IntSoftmax | n:  21
IntGELU    | n:  31
IntSoftmax | n:  21
IntGELU    | n:  31
IntSoftmax | n:  21
IntGELU    | n:  31
IntSoftmax | n:  21
IntGELU    | n:  31
IntSoftmax | n:  21
IntGELU    | n:  31
IntSoftmax | n:  21
IntGELU    | n:  31
IntSoftmax | n:  21
IntGELU    | n:  31
IntSoftmax | n:  21
IntGELU    | n:  31
IntSoftmax | n:  21
IntGELU    | n:  31
.calib done
Test: [  0/391]	Time  3.817 ( 3.817)	Acc@1   4.69 (  4.69)	Acc@5  13.28 ( 13.28)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 4.688 Prec@5 13.281
Time: 8.76
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=22, intgelu_exp_n=0
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=22, intgelu_exp_n=0, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  22
IntGELU    | n:  0
IntSoftmax | n:  22
IntGELU    | n:  0
IntSoftmax | n:  22
IntGELU    | n:  0
IntSoftmax | n:  22
IntGELU    | n:  0
IntSoftmax | n:  22
IntGELU    | n:  0
IntSoftmax | n:  22
IntGELU    | n:  0
IntSoftmax | n:  22
IntGELU    | n:  0
IntSoftmax | n:  22
IntGELU    | n:  0
IntSoftmax | n:  22
IntGELU    | n:  0
IntSoftmax | n:  22
IntGELU    | n:  0
IntSoftmax | n:  22
IntGELU    | n:  0
IntSoftmax | n:  22
IntGELU    | n:  0
.calib done
Test: [  0/391]	Time  3.931 ( 3.931)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.86
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=22, intgelu_exp_n=1
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=22, intgelu_exp_n=1, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  22
IntGELU    | n:  1
IntSoftmax | n:  22
IntGELU    | n:  1
IntSoftmax | n:  22
IntGELU    | n:  1
IntSoftmax | n:  22
IntGELU    | n:  1
IntSoftmax | n:  22
IntGELU    | n:  1
IntSoftmax | n:  22
IntGELU    | n:  1
IntSoftmax | n:  22
IntGELU    | n:  1
IntSoftmax | n:  22
IntGELU    | n:  1
IntSoftmax | n:  22
IntGELU    | n:  1
IntSoftmax | n:  22
IntGELU    | n:  1
IntSoftmax | n:  22
IntGELU    | n:  1
IntSoftmax | n:  22
IntGELU    | n:  1
.calib done
Test: [  0/391]	Time  3.865 ( 3.865)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.86
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=22, intgelu_exp_n=2
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=22, intgelu_exp_n=2, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  22
IntGELU    | n:  2
IntSoftmax | n:  22
IntGELU    | n:  2
IntSoftmax | n:  22
IntGELU    | n:  2
IntSoftmax | n:  22
IntGELU    | n:  2
IntSoftmax | n:  22
IntGELU    | n:  2
IntSoftmax | n:  22
IntGELU    | n:  2
IntSoftmax | n:  22
IntGELU    | n:  2
IntSoftmax | n:  22
IntGELU    | n:  2
IntSoftmax | n:  22
IntGELU    | n:  2
IntSoftmax | n:  22
IntGELU    | n:  2
IntSoftmax | n:  22
IntGELU    | n:  2
IntSoftmax | n:  22
IntGELU    | n:  2
.calib done
Test: [  0/391]	Time  3.911 ( 3.911)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.84
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=22, intgelu_exp_n=3
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=22, intgelu_exp_n=3, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  22
IntGELU    | n:  3
IntSoftmax | n:  22
IntGELU    | n:  3
IntSoftmax | n:  22
IntGELU    | n:  3
IntSoftmax | n:  22
IntGELU    | n:  3
IntSoftmax | n:  22
IntGELU    | n:  3
IntSoftmax | n:  22
IntGELU    | n:  3
IntSoftmax | n:  22
IntGELU    | n:  3
IntSoftmax | n:  22
IntGELU    | n:  3
IntSoftmax | n:  22
IntGELU    | n:  3
IntSoftmax | n:  22
IntGELU    | n:  3
IntSoftmax | n:  22
IntGELU    | n:  3
IntSoftmax | n:  22
IntGELU    | n:  3
.calib done
Test: [  0/391]	Time  3.804 ( 3.804)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.71
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=22, intgelu_exp_n=4
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=22, intgelu_exp_n=4, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  22
IntGELU    | n:  4
IntSoftmax | n:  22
IntGELU    | n:  4
IntSoftmax | n:  22
IntGELU    | n:  4
IntSoftmax | n:  22
IntGELU    | n:  4
IntSoftmax | n:  22
IntGELU    | n:  4
IntSoftmax | n:  22
IntGELU    | n:  4
IntSoftmax | n:  22
IntGELU    | n:  4
IntSoftmax | n:  22
IntGELU    | n:  4
IntSoftmax | n:  22
IntGELU    | n:  4
IntSoftmax | n:  22
IntGELU    | n:  4
IntSoftmax | n:  22
IntGELU    | n:  4
IntSoftmax | n:  22
IntGELU    | n:  4
.calib done
Test: [  0/391]	Time  3.793 ( 3.793)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.73
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=22, intgelu_exp_n=5
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=22, intgelu_exp_n=5, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  22
IntGELU    | n:  5
IntSoftmax | n:  22
IntGELU    | n:  5
IntSoftmax | n:  22
IntGELU    | n:  5
IntSoftmax | n:  22
IntGELU    | n:  5
IntSoftmax | n:  22
IntGELU    | n:  5
IntSoftmax | n:  22
IntGELU    | n:  5
IntSoftmax | n:  22
IntGELU    | n:  5
IntSoftmax | n:  22
IntGELU    | n:  5
IntSoftmax | n:  22
IntGELU    | n:  5
IntSoftmax | n:  22
IntGELU    | n:  5
IntSoftmax | n:  22
IntGELU    | n:  5
IntSoftmax | n:  22
IntGELU    | n:  5
.calib done
Test: [  0/391]	Time  3.808 ( 3.808)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.78
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=22, intgelu_exp_n=6
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=22, intgelu_exp_n=6, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  22
IntGELU    | n:  6
IntSoftmax | n:  22
IntGELU    | n:  6
IntSoftmax | n:  22
IntGELU    | n:  6
IntSoftmax | n:  22
IntGELU    | n:  6
IntSoftmax | n:  22
IntGELU    | n:  6
IntSoftmax | n:  22
IntGELU    | n:  6
IntSoftmax | n:  22
IntGELU    | n:  6
IntSoftmax | n:  22
IntGELU    | n:  6
IntSoftmax | n:  22
IntGELU    | n:  6
IntSoftmax | n:  22
IntGELU    | n:  6
IntSoftmax | n:  22
IntGELU    | n:  6
IntSoftmax | n:  22
IntGELU    | n:  6
.calib done
Test: [  0/391]	Time  3.824 ( 3.824)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.77
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=22, intgelu_exp_n=7
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=22, intgelu_exp_n=7, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  22
IntGELU    | n:  7
IntSoftmax | n:  22
IntGELU    | n:  7
IntSoftmax | n:  22
IntGELU    | n:  7
IntSoftmax | n:  22
IntGELU    | n:  7
IntSoftmax | n:  22
IntGELU    | n:  7
IntSoftmax | n:  22
IntGELU    | n:  7
IntSoftmax | n:  22
IntGELU    | n:  7
IntSoftmax | n:  22
IntGELU    | n:  7
IntSoftmax | n:  22
IntGELU    | n:  7
IntSoftmax | n:  22
IntGELU    | n:  7
IntSoftmax | n:  22
IntGELU    | n:  7
IntSoftmax | n:  22
IntGELU    | n:  7
.calib done
Test: [  0/391]	Time  3.912 ( 3.912)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 9.00
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=22, intgelu_exp_n=8
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=22, intgelu_exp_n=8, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  22
IntGELU    | n:  8
IntSoftmax | n:  22
IntGELU    | n:  8
IntSoftmax | n:  22
IntGELU    | n:  8
IntSoftmax | n:  22
IntGELU    | n:  8
IntSoftmax | n:  22
IntGELU    | n:  8
IntSoftmax | n:  22
IntGELU    | n:  8
IntSoftmax | n:  22
IntGELU    | n:  8
IntSoftmax | n:  22
IntGELU    | n:  8
IntSoftmax | n:  22
IntGELU    | n:  8
IntSoftmax | n:  22
IntGELU    | n:  8
IntSoftmax | n:  22
IntGELU    | n:  8
IntSoftmax | n:  22
IntGELU    | n:  8
.calib done
Test: [  0/391]	Time  3.924 ( 3.924)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.87
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=22, intgelu_exp_n=9
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=22, intgelu_exp_n=9, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  22
IntGELU    | n:  9
IntSoftmax | n:  22
IntGELU    | n:  9
IntSoftmax | n:  22
IntGELU    | n:  9
IntSoftmax | n:  22
IntGELU    | n:  9
IntSoftmax | n:  22
IntGELU    | n:  9
IntSoftmax | n:  22
IntGELU    | n:  9
IntSoftmax | n:  22
IntGELU    | n:  9
IntSoftmax | n:  22
IntGELU    | n:  9
IntSoftmax | n:  22
IntGELU    | n:  9
IntSoftmax | n:  22
IntGELU    | n:  9
IntSoftmax | n:  22
IntGELU    | n:  9
IntSoftmax | n:  22
IntGELU    | n:  9
.calib done
Test: [  0/391]	Time  3.811 ( 3.811)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.71
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=22, intgelu_exp_n=10
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=22, intgelu_exp_n=10, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  22
IntGELU    | n:  10
IntSoftmax | n:  22
IntGELU    | n:  10
IntSoftmax | n:  22
IntGELU    | n:  10
IntSoftmax | n:  22
IntGELU    | n:  10
IntSoftmax | n:  22
IntGELU    | n:  10
IntSoftmax | n:  22
IntGELU    | n:  10
IntSoftmax | n:  22
IntGELU    | n:  10
IntSoftmax | n:  22
IntGELU    | n:  10
IntSoftmax | n:  22
IntGELU    | n:  10
IntSoftmax | n:  22
IntGELU    | n:  10
IntSoftmax | n:  22
IntGELU    | n:  10
IntSoftmax | n:  22
IntGELU    | n:  10
.calib done
Test: [  0/391]	Time  3.944 ( 3.944)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.85
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=22, intgelu_exp_n=11
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=22, intgelu_exp_n=11, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  22
IntGELU    | n:  11
IntSoftmax | n:  22
IntGELU    | n:  11
IntSoftmax | n:  22
IntGELU    | n:  11
IntSoftmax | n:  22
IntGELU    | n:  11
IntSoftmax | n:  22
IntGELU    | n:  11
IntSoftmax | n:  22
IntGELU    | n:  11
IntSoftmax | n:  22
IntGELU    | n:  11
IntSoftmax | n:  22
IntGELU    | n:  11
IntSoftmax | n:  22
IntGELU    | n:  11
IntSoftmax | n:  22
IntGELU    | n:  11
IntSoftmax | n:  22
IntGELU    | n:  11
IntSoftmax | n:  22
IntGELU    | n:  11
.calib done
Test: [  0/391]	Time  3.759 ( 3.759)	Acc@1   0.00 (  0.00)	Acc@5   1.56 (  1.56)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 1.562
Time: 8.67
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=22, intgelu_exp_n=12
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=22, intgelu_exp_n=12, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  22
IntGELU    | n:  12
IntSoftmax | n:  22
IntGELU    | n:  12
IntSoftmax | n:  22
IntGELU    | n:  12
IntSoftmax | n:  22
IntGELU    | n:  12
IntSoftmax | n:  22
IntGELU    | n:  12
IntSoftmax | n:  22
IntGELU    | n:  12
IntSoftmax | n:  22
IntGELU    | n:  12
IntSoftmax | n:  22
IntGELU    | n:  12
IntSoftmax | n:  22
IntGELU    | n:  12
IntSoftmax | n:  22
IntGELU    | n:  12
IntSoftmax | n:  22
IntGELU    | n:  12
IntSoftmax | n:  22
IntGELU    | n:  12
.calib done
Test: [  0/391]	Time  3.674 ( 3.674)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.64
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=22, intgelu_exp_n=13
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=22, intgelu_exp_n=13, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  22
IntGELU    | n:  13
IntSoftmax | n:  22
IntGELU    | n:  13
IntSoftmax | n:  22
IntGELU    | n:  13
IntSoftmax | n:  22
IntGELU    | n:  13
IntSoftmax | n:  22
IntGELU    | n:  13
IntSoftmax | n:  22
IntGELU    | n:  13
IntSoftmax | n:  22
IntGELU    | n:  13
IntSoftmax | n:  22
IntGELU    | n:  13
IntSoftmax | n:  22
IntGELU    | n:  13
IntSoftmax | n:  22
IntGELU    | n:  13
IntSoftmax | n:  22
IntGELU    | n:  13
IntSoftmax | n:  22
IntGELU    | n:  13
.calib done
Test: [  0/391]	Time  3.751 ( 3.751)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.69
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=22, intgelu_exp_n=14
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=22, intgelu_exp_n=14, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  22
IntGELU    | n:  14
IntSoftmax | n:  22
IntGELU    | n:  14
IntSoftmax | n:  22
IntGELU    | n:  14
IntSoftmax | n:  22
IntGELU    | n:  14
IntSoftmax | n:  22
IntGELU    | n:  14
IntSoftmax | n:  22
IntGELU    | n:  14
IntSoftmax | n:  22
IntGELU    | n:  14
IntSoftmax | n:  22
IntGELU    | n:  14
IntSoftmax | n:  22
IntGELU    | n:  14
IntSoftmax | n:  22
IntGELU    | n:  14
IntSoftmax | n:  22
IntGELU    | n:  14
IntSoftmax | n:  22
IntGELU    | n:  14
.calib done
Test: [  0/391]	Time  3.856 ( 3.856)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.77
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=22, intgelu_exp_n=15
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=22, intgelu_exp_n=15, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  22
IntGELU    | n:  15
IntSoftmax | n:  22
IntGELU    | n:  15
IntSoftmax | n:  22
IntGELU    | n:  15
IntSoftmax | n:  22
IntGELU    | n:  15
IntSoftmax | n:  22
IntGELU    | n:  15
IntSoftmax | n:  22
IntGELU    | n:  15
IntSoftmax | n:  22
IntGELU    | n:  15
IntSoftmax | n:  22
IntGELU    | n:  15
IntSoftmax | n:  22
IntGELU    | n:  15
IntSoftmax | n:  22
IntGELU    | n:  15
IntSoftmax | n:  22
IntGELU    | n:  15
IntSoftmax | n:  22
IntGELU    | n:  15
.calib done
Test: [  0/391]	Time  3.790 ( 3.790)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.72
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=22, intgelu_exp_n=16
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=22, intgelu_exp_n=16, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  22
IntGELU    | n:  16
IntSoftmax | n:  22
IntGELU    | n:  16
IntSoftmax | n:  22
IntGELU    | n:  16
IntSoftmax | n:  22
IntGELU    | n:  16
IntSoftmax | n:  22
IntGELU    | n:  16
IntSoftmax | n:  22
IntGELU    | n:  16
IntSoftmax | n:  22
IntGELU    | n:  16
IntSoftmax | n:  22
IntGELU    | n:  16
IntSoftmax | n:  22
IntGELU    | n:  16
IntSoftmax | n:  22
IntGELU    | n:  16
IntSoftmax | n:  22
IntGELU    | n:  16
IntSoftmax | n:  22
IntGELU    | n:  16
.calib done
Test: [  0/391]	Time  3.893 ( 3.893)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.87
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=22, intgelu_exp_n=17
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=22, intgelu_exp_n=17, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  22
IntGELU    | n:  17
IntSoftmax | n:  22
IntGELU    | n:  17
IntSoftmax | n:  22
IntGELU    | n:  17
IntSoftmax | n:  22
IntGELU    | n:  17
IntSoftmax | n:  22
IntGELU    | n:  17
IntSoftmax | n:  22
IntGELU    | n:  17
IntSoftmax | n:  22
IntGELU    | n:  17
IntSoftmax | n:  22
IntGELU    | n:  17
IntSoftmax | n:  22
IntGELU    | n:  17
IntSoftmax | n:  22
IntGELU    | n:  17
IntSoftmax | n:  22
IntGELU    | n:  17
IntSoftmax | n:  22
IntGELU    | n:  17
.calib done
Test: [  0/391]	Time  3.970 ( 3.970)	Acc@1   0.78 (  0.78)	Acc@5   2.34 (  2.34)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.781 Prec@5 2.344
Time: 8.91
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=22, intgelu_exp_n=18
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=22, intgelu_exp_n=18, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  22
IntGELU    | n:  18
IntSoftmax | n:  22
IntGELU    | n:  18
IntSoftmax | n:  22
IntGELU    | n:  18
IntSoftmax | n:  22
IntGELU    | n:  18
IntSoftmax | n:  22
IntGELU    | n:  18
IntSoftmax | n:  22
IntGELU    | n:  18
IntSoftmax | n:  22
IntGELU    | n:  18
IntSoftmax | n:  22
IntGELU    | n:  18
IntSoftmax | n:  22
IntGELU    | n:  18
IntSoftmax | n:  22
IntGELU    | n:  18
IntSoftmax | n:  22
IntGELU    | n:  18
IntSoftmax | n:  22
IntGELU    | n:  18
.calib done
Test: [  0/391]	Time  3.778 ( 3.778)	Acc@1   0.00 (  0.00)	Acc@5   4.69 (  4.69)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 4.688
Time: 8.75
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=22, intgelu_exp_n=19
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=22, intgelu_exp_n=19, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  22
IntGELU    | n:  19
IntSoftmax | n:  22
IntGELU    | n:  19
IntSoftmax | n:  22
IntGELU    | n:  19
IntSoftmax | n:  22
IntGELU    | n:  19
IntSoftmax | n:  22
IntGELU    | n:  19
IntSoftmax | n:  22
IntGELU    | n:  19
IntSoftmax | n:  22
IntGELU    | n:  19
IntSoftmax | n:  22
IntGELU    | n:  19
IntSoftmax | n:  22
IntGELU    | n:  19
IntSoftmax | n:  22
IntGELU    | n:  19
IntSoftmax | n:  22
IntGELU    | n:  19
IntSoftmax | n:  22
IntGELU    | n:  19
.calib done
Test: [  0/391]	Time  3.934 ( 3.934)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.92
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=22, intgelu_exp_n=20
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=22, intgelu_exp_n=20, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  22
IntGELU    | n:  20
IntSoftmax | n:  22
IntGELU    | n:  20
IntSoftmax | n:  22
IntGELU    | n:  20
IntSoftmax | n:  22
IntGELU    | n:  20
IntSoftmax | n:  22
IntGELU    | n:  20
IntSoftmax | n:  22
IntGELU    | n:  20
IntSoftmax | n:  22
IntGELU    | n:  20
IntSoftmax | n:  22
IntGELU    | n:  20
IntSoftmax | n:  22
IntGELU    | n:  20
IntSoftmax | n:  22
IntGELU    | n:  20
IntSoftmax | n:  22
IntGELU    | n:  20
IntSoftmax | n:  22
IntGELU    | n:  20
.calib done
Test: [  0/391]	Time  3.946 ( 3.946)	Acc@1   3.91 (  3.91)	Acc@5   9.38 (  9.38)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 3.906 Prec@5 9.375
Time: 8.95
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=22, intgelu_exp_n=21
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=22, intgelu_exp_n=21, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  22
IntGELU    | n:  21
IntSoftmax | n:  22
IntGELU    | n:  21
IntSoftmax | n:  22
IntGELU    | n:  21
IntSoftmax | n:  22
IntGELU    | n:  21
IntSoftmax | n:  22
IntGELU    | n:  21
IntSoftmax | n:  22
IntGELU    | n:  21
IntSoftmax | n:  22
IntGELU    | n:  21
IntSoftmax | n:  22
IntGELU    | n:  21
IntSoftmax | n:  22
IntGELU    | n:  21
IntSoftmax | n:  22
IntGELU    | n:  21
IntSoftmax | n:  22
IntGELU    | n:  21
IntSoftmax | n:  22
IntGELU    | n:  21
.calib done
Test: [  0/391]	Time  3.860 ( 3.860)	Acc@1   5.47 (  5.47)	Acc@5  16.41 ( 16.41)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 5.469 Prec@5 16.406
Time: 8.83
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=22, intgelu_exp_n=22
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=22, intgelu_exp_n=22, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  22
IntGELU    | n:  22
IntSoftmax | n:  22
IntGELU    | n:  22
IntSoftmax | n:  22
IntGELU    | n:  22
IntSoftmax | n:  22
IntGELU    | n:  22
IntSoftmax | n:  22
IntGELU    | n:  22
IntSoftmax | n:  22
IntGELU    | n:  22
IntSoftmax | n:  22
IntGELU    | n:  22
IntSoftmax | n:  22
IntGELU    | n:  22
IntSoftmax | n:  22
IntGELU    | n:  22
IntSoftmax | n:  22
IntGELU    | n:  22
IntSoftmax | n:  22
IntGELU    | n:  22
IntSoftmax | n:  22
IntGELU    | n:  22
.calib done
Test: [  0/391]	Time  3.871 ( 3.871)	Acc@1   7.03 (  7.03)	Acc@5  22.66 ( 22.66)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 7.031 Prec@5 22.656
Time: 8.82
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=22, intgelu_exp_n=23
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=22, intgelu_exp_n=23, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  22
IntGELU    | n:  23
IntSoftmax | n:  22
IntGELU    | n:  23
IntSoftmax | n:  22
IntGELU    | n:  23
IntSoftmax | n:  22
IntGELU    | n:  23
IntSoftmax | n:  22
IntGELU    | n:  23
IntSoftmax | n:  22
IntGELU    | n:  23
IntSoftmax | n:  22
IntGELU    | n:  23
IntSoftmax | n:  22
IntGELU    | n:  23
IntSoftmax | n:  22
IntGELU    | n:  23
IntSoftmax | n:  22
IntGELU    | n:  23
IntSoftmax | n:  22
IntGELU    | n:  23
IntSoftmax | n:  22
IntGELU    | n:  23
.calib done
Test: [  0/391]	Time  3.962 ( 3.962)	Acc@1   7.81 (  7.81)	Acc@5  25.78 ( 25.78)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 7.812 Prec@5 25.781
Time: 8.91
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=22, intgelu_exp_n=24
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=22, intgelu_exp_n=24, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  22
IntGELU    | n:  24
IntSoftmax | n:  22
IntGELU    | n:  24
IntSoftmax | n:  22
IntGELU    | n:  24
IntSoftmax | n:  22
IntGELU    | n:  24
IntSoftmax | n:  22
IntGELU    | n:  24
IntSoftmax | n:  22
IntGELU    | n:  24
IntSoftmax | n:  22
IntGELU    | n:  24
IntSoftmax | n:  22
IntGELU    | n:  24
IntSoftmax | n:  22
IntGELU    | n:  24
IntSoftmax | n:  22
IntGELU    | n:  24
IntSoftmax | n:  22
IntGELU    | n:  24
IntSoftmax | n:  22
IntGELU    | n:  24
.calib done
Test: [  0/391]	Time  3.961 ( 3.961)	Acc@1   7.03 (  7.03)	Acc@5  25.78 ( 25.78)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 7.031 Prec@5 25.781
Time: 8.90
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=22, intgelu_exp_n=25
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=22, intgelu_exp_n=25, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  22
IntGELU    | n:  25
IntSoftmax | n:  22
IntGELU    | n:  25
IntSoftmax | n:  22
IntGELU    | n:  25
IntSoftmax | n:  22
IntGELU    | n:  25
IntSoftmax | n:  22
IntGELU    | n:  25
IntSoftmax | n:  22
IntGELU    | n:  25
IntSoftmax | n:  22
IntGELU    | n:  25
IntSoftmax | n:  22
IntGELU    | n:  25
IntSoftmax | n:  22
IntGELU    | n:  25
IntSoftmax | n:  22
IntGELU    | n:  25
IntSoftmax | n:  22
IntGELU    | n:  25
IntSoftmax | n:  22
IntGELU    | n:  25
.calib done
Test: [  0/391]	Time  3.925 ( 3.925)	Acc@1  14.06 ( 14.06)	Acc@5  39.06 ( 39.06)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 14.062 Prec@5 39.062
Time: 8.91
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=22, intgelu_exp_n=26
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=22, intgelu_exp_n=26, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  22
IntGELU    | n:  26
IntSoftmax | n:  22
IntGELU    | n:  26
IntSoftmax | n:  22
IntGELU    | n:  26
IntSoftmax | n:  22
IntGELU    | n:  26
IntSoftmax | n:  22
IntGELU    | n:  26
IntSoftmax | n:  22
IntGELU    | n:  26
IntSoftmax | n:  22
IntGELU    | n:  26
IntSoftmax | n:  22
IntGELU    | n:  26
IntSoftmax | n:  22
IntGELU    | n:  26
IntSoftmax | n:  22
IntGELU    | n:  26
IntSoftmax | n:  22
IntGELU    | n:  26
IntSoftmax | n:  22
IntGELU    | n:  26
.calib done
Test: [  0/391]	Time  3.972 ( 3.972)	Acc@1  20.31 ( 20.31)	Acc@5  42.19 ( 42.19)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 20.312 Prec@5 42.188
Time: 9.01
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=22, intgelu_exp_n=27
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=22, intgelu_exp_n=27, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  22
IntGELU    | n:  27
IntSoftmax | n:  22
IntGELU    | n:  27
IntSoftmax | n:  22
IntGELU    | n:  27
IntSoftmax | n:  22
IntGELU    | n:  27
IntSoftmax | n:  22
IntGELU    | n:  27
IntSoftmax | n:  22
IntGELU    | n:  27
IntSoftmax | n:  22
IntGELU    | n:  27
IntSoftmax | n:  22
IntGELU    | n:  27
IntSoftmax | n:  22
IntGELU    | n:  27
IntSoftmax | n:  22
IntGELU    | n:  27
IntSoftmax | n:  22
IntGELU    | n:  27
IntSoftmax | n:  22
IntGELU    | n:  27
.calib done
Test: [  0/391]	Time  3.753 ( 3.753)	Acc@1  18.75 ( 18.75)	Acc@5  48.44 ( 48.44)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 18.750 Prec@5 48.438
Time: 8.71
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=22, intgelu_exp_n=28
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=22, intgelu_exp_n=28, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  22
IntGELU    | n:  28
IntSoftmax | n:  22
IntGELU    | n:  28
IntSoftmax | n:  22
IntGELU    | n:  28
IntSoftmax | n:  22
IntGELU    | n:  28
IntSoftmax | n:  22
IntGELU    | n:  28
IntSoftmax | n:  22
IntGELU    | n:  28
IntSoftmax | n:  22
IntGELU    | n:  28
IntSoftmax | n:  22
IntGELU    | n:  28
IntSoftmax | n:  22
IntGELU    | n:  28
IntSoftmax | n:  22
IntGELU    | n:  28
IntSoftmax | n:  22
IntGELU    | n:  28
IntSoftmax | n:  22
IntGELU    | n:  28
.calib done
Test: [  0/391]	Time  3.818 ( 3.818)	Acc@1   1.56 (  1.56)	Acc@5  13.28 ( 13.28)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 1.562 Prec@5 13.281
Time: 8.80
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=22, intgelu_exp_n=29
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=22, intgelu_exp_n=29, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  22
IntGELU    | n:  29
IntSoftmax | n:  22
IntGELU    | n:  29
IntSoftmax | n:  22
IntGELU    | n:  29
IntSoftmax | n:  22
IntGELU    | n:  29
IntSoftmax | n:  22
IntGELU    | n:  29
IntSoftmax | n:  22
IntGELU    | n:  29
IntSoftmax | n:  22
IntGELU    | n:  29
IntSoftmax | n:  22
IntGELU    | n:  29
IntSoftmax | n:  22
IntGELU    | n:  29
IntSoftmax | n:  22
IntGELU    | n:  29
IntSoftmax | n:  22
IntGELU    | n:  29
IntSoftmax | n:  22
IntGELU    | n:  29
.calib done
Test: [  0/391]	Time  3.991 ( 3.991)	Acc@1  21.09 ( 21.09)	Acc@5  46.88 ( 46.88)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 21.094 Prec@5 46.875
Time: 8.98
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=22, intgelu_exp_n=30
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=22, intgelu_exp_n=30, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  22
IntGELU    | n:  30
IntSoftmax | n:  22
IntGELU    | n:  30
IntSoftmax | n:  22
IntGELU    | n:  30
IntSoftmax | n:  22
IntGELU    | n:  30
IntSoftmax | n:  22
IntGELU    | n:  30
IntSoftmax | n:  22
IntGELU    | n:  30
IntSoftmax | n:  22
IntGELU    | n:  30
IntSoftmax | n:  22
IntGELU    | n:  30
IntSoftmax | n:  22
IntGELU    | n:  30
IntSoftmax | n:  22
IntGELU    | n:  30
IntSoftmax | n:  22
IntGELU    | n:  30
IntSoftmax | n:  22
IntGELU    | n:  30
.calib done
Test: [  0/391]	Time  3.932 ( 3.932)	Acc@1  89.06 ( 89.06)	Acc@5  96.88 ( 96.88)
Test: [ 10/391]	Time  1.731 ( 1.931)	Acc@1  61.72 ( 79.83)	Acc@5  82.81 ( 92.83)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 79.830 Prec@5 92.827
Time: 26.21
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=22, intgelu_exp_n=31
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=22, intgelu_exp_n=31, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  22
IntGELU    | n:  31
IntSoftmax | n:  22
IntGELU    | n:  31
IntSoftmax | n:  22
IntGELU    | n:  31
IntSoftmax | n:  22
IntGELU    | n:  31
IntSoftmax | n:  22
IntGELU    | n:  31
IntSoftmax | n:  22
IntGELU    | n:  31
IntSoftmax | n:  22
IntGELU    | n:  31
IntSoftmax | n:  22
IntGELU    | n:  31
IntSoftmax | n:  22
IntGELU    | n:  31
IntSoftmax | n:  22
IntGELU    | n:  31
IntSoftmax | n:  22
IntGELU    | n:  31
IntSoftmax | n:  22
IntGELU    | n:  31
.calib done
Test: [  0/391]	Time  4.019 ( 4.019)	Acc@1  11.72 ( 11.72)	Acc@5  20.31 ( 20.31)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 11.719 Prec@5 20.312
Time: 8.98
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=23, intgelu_exp_n=0
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=23, intgelu_exp_n=0, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  23
IntGELU    | n:  0
IntSoftmax | n:  23
IntGELU    | n:  0
IntSoftmax | n:  23
IntGELU    | n:  0
IntSoftmax | n:  23
IntGELU    | n:  0
IntSoftmax | n:  23
IntGELU    | n:  0
IntSoftmax | n:  23
IntGELU    | n:  0
IntSoftmax | n:  23
IntGELU    | n:  0
IntSoftmax | n:  23
IntGELU    | n:  0
IntSoftmax | n:  23
IntGELU    | n:  0
IntSoftmax | n:  23
IntGELU    | n:  0
IntSoftmax | n:  23
IntGELU    | n:  0
IntSoftmax | n:  23
IntGELU    | n:  0
.calib done
Test: [  0/391]	Time  3.681 ( 3.681)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.59
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=23, intgelu_exp_n=1
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=23, intgelu_exp_n=1, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  23
IntGELU    | n:  1
IntSoftmax | n:  23
IntGELU    | n:  1
IntSoftmax | n:  23
IntGELU    | n:  1
IntSoftmax | n:  23
IntGELU    | n:  1
IntSoftmax | n:  23
IntGELU    | n:  1
IntSoftmax | n:  23
IntGELU    | n:  1
IntSoftmax | n:  23
IntGELU    | n:  1
IntSoftmax | n:  23
IntGELU    | n:  1
IntSoftmax | n:  23
IntGELU    | n:  1
IntSoftmax | n:  23
IntGELU    | n:  1
IntSoftmax | n:  23
IntGELU    | n:  1
IntSoftmax | n:  23
IntGELU    | n:  1
.calib done
Test: [  0/391]	Time  3.912 ( 3.912)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.84
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=23, intgelu_exp_n=2
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=23, intgelu_exp_n=2, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  23
IntGELU    | n:  2
IntSoftmax | n:  23
IntGELU    | n:  2
IntSoftmax | n:  23
IntGELU    | n:  2
IntSoftmax | n:  23
IntGELU    | n:  2
IntSoftmax | n:  23
IntGELU    | n:  2
IntSoftmax | n:  23
IntGELU    | n:  2
IntSoftmax | n:  23
IntGELU    | n:  2
IntSoftmax | n:  23
IntGELU    | n:  2
IntSoftmax | n:  23
IntGELU    | n:  2
IntSoftmax | n:  23
IntGELU    | n:  2
IntSoftmax | n:  23
IntGELU    | n:  2
IntSoftmax | n:  23
IntGELU    | n:  2
.calib done
Test: [  0/391]	Time  3.959 ( 3.959)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.89
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=23, intgelu_exp_n=3
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=23, intgelu_exp_n=3, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  23
IntGELU    | n:  3
IntSoftmax | n:  23
IntGELU    | n:  3
IntSoftmax | n:  23
IntGELU    | n:  3
IntSoftmax | n:  23
IntGELU    | n:  3
IntSoftmax | n:  23
IntGELU    | n:  3
IntSoftmax | n:  23
IntGELU    | n:  3
IntSoftmax | n:  23
IntGELU    | n:  3
IntSoftmax | n:  23
IntGELU    | n:  3
IntSoftmax | n:  23
IntGELU    | n:  3
IntSoftmax | n:  23
IntGELU    | n:  3
IntSoftmax | n:  23
IntGELU    | n:  3
IntSoftmax | n:  23
IntGELU    | n:  3
.calib done
Test: [  0/391]	Time  3.900 ( 3.900)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.83
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=23, intgelu_exp_n=4
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=23, intgelu_exp_n=4, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  23
IntGELU    | n:  4
IntSoftmax | n:  23
IntGELU    | n:  4
IntSoftmax | n:  23
IntGELU    | n:  4
IntSoftmax | n:  23
IntGELU    | n:  4
IntSoftmax | n:  23
IntGELU    | n:  4
IntSoftmax | n:  23
IntGELU    | n:  4
IntSoftmax | n:  23
IntGELU    | n:  4
IntSoftmax | n:  23
IntGELU    | n:  4
IntSoftmax | n:  23
IntGELU    | n:  4
IntSoftmax | n:  23
IntGELU    | n:  4
IntSoftmax | n:  23
IntGELU    | n:  4
IntSoftmax | n:  23
IntGELU    | n:  4
.calib done
Test: [  0/391]	Time  3.792 ( 3.792)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.83
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=23, intgelu_exp_n=5
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=23, intgelu_exp_n=5, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  23
IntGELU    | n:  5
IntSoftmax | n:  23
IntGELU    | n:  5
IntSoftmax | n:  23
IntGELU    | n:  5
IntSoftmax | n:  23
IntGELU    | n:  5
IntSoftmax | n:  23
IntGELU    | n:  5
IntSoftmax | n:  23
IntGELU    | n:  5
IntSoftmax | n:  23
IntGELU    | n:  5
IntSoftmax | n:  23
IntGELU    | n:  5
IntSoftmax | n:  23
IntGELU    | n:  5
IntSoftmax | n:  23
IntGELU    | n:  5
IntSoftmax | n:  23
IntGELU    | n:  5
IntSoftmax | n:  23
IntGELU    | n:  5
.calib done
Test: [  0/391]	Time  3.896 ( 3.896)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.88
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=23, intgelu_exp_n=6
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=23, intgelu_exp_n=6, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  23
IntGELU    | n:  6
IntSoftmax | n:  23
IntGELU    | n:  6
IntSoftmax | n:  23
IntGELU    | n:  6
IntSoftmax | n:  23
IntGELU    | n:  6
IntSoftmax | n:  23
IntGELU    | n:  6
IntSoftmax | n:  23
IntGELU    | n:  6
IntSoftmax | n:  23
IntGELU    | n:  6
IntSoftmax | n:  23
IntGELU    | n:  6
IntSoftmax | n:  23
IntGELU    | n:  6
IntSoftmax | n:  23
IntGELU    | n:  6
IntSoftmax | n:  23
IntGELU    | n:  6
IntSoftmax | n:  23
IntGELU    | n:  6
.calib done
Test: [  0/391]	Time  3.747 ( 3.747)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.76
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=23, intgelu_exp_n=7
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=23, intgelu_exp_n=7, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  23
IntGELU    | n:  7
IntSoftmax | n:  23
IntGELU    | n:  7
IntSoftmax | n:  23
IntGELU    | n:  7
IntSoftmax | n:  23
IntGELU    | n:  7
IntSoftmax | n:  23
IntGELU    | n:  7
IntSoftmax | n:  23
IntGELU    | n:  7
IntSoftmax | n:  23
IntGELU    | n:  7
IntSoftmax | n:  23
IntGELU    | n:  7
IntSoftmax | n:  23
IntGELU    | n:  7
IntSoftmax | n:  23
IntGELU    | n:  7
IntSoftmax | n:  23
IntGELU    | n:  7
IntSoftmax | n:  23
IntGELU    | n:  7
.calib done
Test: [  0/391]	Time  3.905 ( 3.905)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.82
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=23, intgelu_exp_n=8
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=23, intgelu_exp_n=8, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  23
IntGELU    | n:  8
IntSoftmax | n:  23
IntGELU    | n:  8
IntSoftmax | n:  23
IntGELU    | n:  8
IntSoftmax | n:  23
IntGELU    | n:  8
IntSoftmax | n:  23
IntGELU    | n:  8
IntSoftmax | n:  23
IntGELU    | n:  8
IntSoftmax | n:  23
IntGELU    | n:  8
IntSoftmax | n:  23
IntGELU    | n:  8
IntSoftmax | n:  23
IntGELU    | n:  8
IntSoftmax | n:  23
IntGELU    | n:  8
IntSoftmax | n:  23
IntGELU    | n:  8
IntSoftmax | n:  23
IntGELU    | n:  8
.calib done
Test: [  0/391]	Time  4.019 ( 4.019)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 9.00
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=23, intgelu_exp_n=9
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=23, intgelu_exp_n=9, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  23
IntGELU    | n:  9
IntSoftmax | n:  23
IntGELU    | n:  9
IntSoftmax | n:  23
IntGELU    | n:  9
IntSoftmax | n:  23
IntGELU    | n:  9
IntSoftmax | n:  23
IntGELU    | n:  9
IntSoftmax | n:  23
IntGELU    | n:  9
IntSoftmax | n:  23
IntGELU    | n:  9
IntSoftmax | n:  23
IntGELU    | n:  9
IntSoftmax | n:  23
IntGELU    | n:  9
IntSoftmax | n:  23
IntGELU    | n:  9
IntSoftmax | n:  23
IntGELU    | n:  9
IntSoftmax | n:  23
IntGELU    | n:  9
.calib done
Test: [  0/391]	Time  3.676 ( 3.676)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.67
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=23, intgelu_exp_n=10
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=23, intgelu_exp_n=10, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  23
IntGELU    | n:  10
IntSoftmax | n:  23
IntGELU    | n:  10
IntSoftmax | n:  23
IntGELU    | n:  10
IntSoftmax | n:  23
IntGELU    | n:  10
IntSoftmax | n:  23
IntGELU    | n:  10
IntSoftmax | n:  23
IntGELU    | n:  10
IntSoftmax | n:  23
IntGELU    | n:  10
IntSoftmax | n:  23
IntGELU    | n:  10
IntSoftmax | n:  23
IntGELU    | n:  10
IntSoftmax | n:  23
IntGELU    | n:  10
IntSoftmax | n:  23
IntGELU    | n:  10
IntSoftmax | n:  23
IntGELU    | n:  10
.calib done
Test: [  0/391]	Time  3.955 ( 3.955)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.97
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=23, intgelu_exp_n=11
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=23, intgelu_exp_n=11, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  23
IntGELU    | n:  11
IntSoftmax | n:  23
IntGELU    | n:  11
IntSoftmax | n:  23
IntGELU    | n:  11
IntSoftmax | n:  23
IntGELU    | n:  11
IntSoftmax | n:  23
IntGELU    | n:  11
IntSoftmax | n:  23
IntGELU    | n:  11
IntSoftmax | n:  23
IntGELU    | n:  11
IntSoftmax | n:  23
IntGELU    | n:  11
IntSoftmax | n:  23
IntGELU    | n:  11
IntSoftmax | n:  23
IntGELU    | n:  11
IntSoftmax | n:  23
IntGELU    | n:  11
IntSoftmax | n:  23
IntGELU    | n:  11
.calib done
Test: [  0/391]	Time  4.275 ( 4.275)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 9.86
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=23, intgelu_exp_n=12
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=23, intgelu_exp_n=12, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  23
IntGELU    | n:  12
IntSoftmax | n:  23
IntGELU    | n:  12
IntSoftmax | n:  23
IntGELU    | n:  12
IntSoftmax | n:  23
IntGELU    | n:  12
IntSoftmax | n:  23
IntGELU    | n:  12
IntSoftmax | n:  23
IntGELU    | n:  12
IntSoftmax | n:  23
IntGELU    | n:  12
IntSoftmax | n:  23
IntGELU    | n:  12
IntSoftmax | n:  23
IntGELU    | n:  12
IntSoftmax | n:  23
IntGELU    | n:  12
IntSoftmax | n:  23
IntGELU    | n:  12
IntSoftmax | n:  23
IntGELU    | n:  12
.calib done
Test: [  0/391]	Time  3.727 ( 3.727)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.62
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=23, intgelu_exp_n=13
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=23, intgelu_exp_n=13, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  23
IntGELU    | n:  13
IntSoftmax | n:  23
IntGELU    | n:  13
IntSoftmax | n:  23
IntGELU    | n:  13
IntSoftmax | n:  23
IntGELU    | n:  13
IntSoftmax | n:  23
IntGELU    | n:  13
IntSoftmax | n:  23
IntGELU    | n:  13
IntSoftmax | n:  23
IntGELU    | n:  13
IntSoftmax | n:  23
IntGELU    | n:  13
IntSoftmax | n:  23
IntGELU    | n:  13
IntSoftmax | n:  23
IntGELU    | n:  13
IntSoftmax | n:  23
IntGELU    | n:  13
IntSoftmax | n:  23
IntGELU    | n:  13
.calib done
Test: [  0/391]	Time  3.855 ( 3.855)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.87
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=23, intgelu_exp_n=14
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=23, intgelu_exp_n=14, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  23
IntGELU    | n:  14
IntSoftmax | n:  23
IntGELU    | n:  14
IntSoftmax | n:  23
IntGELU    | n:  14
IntSoftmax | n:  23
IntGELU    | n:  14
IntSoftmax | n:  23
IntGELU    | n:  14
IntSoftmax | n:  23
IntGELU    | n:  14
IntSoftmax | n:  23
IntGELU    | n:  14
IntSoftmax | n:  23
IntGELU    | n:  14
IntSoftmax | n:  23
IntGELU    | n:  14
IntSoftmax | n:  23
IntGELU    | n:  14
IntSoftmax | n:  23
IntGELU    | n:  14
IntSoftmax | n:  23
IntGELU    | n:  14
.calib done
Test: [  0/391]	Time  4.028 ( 4.028)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 9.02
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=23, intgelu_exp_n=15
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=23, intgelu_exp_n=15, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  23
IntGELU    | n:  15
IntSoftmax | n:  23
IntGELU    | n:  15
IntSoftmax | n:  23
IntGELU    | n:  15
IntSoftmax | n:  23
IntGELU    | n:  15
IntSoftmax | n:  23
IntGELU    | n:  15
IntSoftmax | n:  23
IntGELU    | n:  15
IntSoftmax | n:  23
IntGELU    | n:  15
IntSoftmax | n:  23
IntGELU    | n:  15
IntSoftmax | n:  23
IntGELU    | n:  15
IntSoftmax | n:  23
IntGELU    | n:  15
IntSoftmax | n:  23
IntGELU    | n:  15
IntSoftmax | n:  23
IntGELU    | n:  15
.calib done
Test: [  0/391]	Time  3.979 ( 3.979)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.98
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=23, intgelu_exp_n=16
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=23, intgelu_exp_n=16, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  23
IntGELU    | n:  16
IntSoftmax | n:  23
IntGELU    | n:  16
IntSoftmax | n:  23
IntGELU    | n:  16
IntSoftmax | n:  23
IntGELU    | n:  16
IntSoftmax | n:  23
IntGELU    | n:  16
IntSoftmax | n:  23
IntGELU    | n:  16
IntSoftmax | n:  23
IntGELU    | n:  16
IntSoftmax | n:  23
IntGELU    | n:  16
IntSoftmax | n:  23
IntGELU    | n:  16
IntSoftmax | n:  23
IntGELU    | n:  16
IntSoftmax | n:  23
IntGELU    | n:  16
IntSoftmax | n:  23
IntGELU    | n:  16
.calib done
Test: [  0/391]	Time  3.784 ( 3.784)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.87
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=23, intgelu_exp_n=17
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=23, intgelu_exp_n=17, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  23
IntGELU    | n:  17
IntSoftmax | n:  23
IntGELU    | n:  17
IntSoftmax | n:  23
IntGELU    | n:  17
IntSoftmax | n:  23
IntGELU    | n:  17
IntSoftmax | n:  23
IntGELU    | n:  17
IntSoftmax | n:  23
IntGELU    | n:  17
IntSoftmax | n:  23
IntGELU    | n:  17
IntSoftmax | n:  23
IntGELU    | n:  17
IntSoftmax | n:  23
IntGELU    | n:  17
IntSoftmax | n:  23
IntGELU    | n:  17
IntSoftmax | n:  23
IntGELU    | n:  17
IntSoftmax | n:  23
IntGELU    | n:  17
.calib done
Test: [  0/391]	Time  4.064 ( 4.064)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.99
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=23, intgelu_exp_n=18
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=23, intgelu_exp_n=18, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  23
IntGELU    | n:  18
IntSoftmax | n:  23
IntGELU    | n:  18
IntSoftmax | n:  23
IntGELU    | n:  18
IntSoftmax | n:  23
IntGELU    | n:  18
IntSoftmax | n:  23
IntGELU    | n:  18
IntSoftmax | n:  23
IntGELU    | n:  18
IntSoftmax | n:  23
IntGELU    | n:  18
IntSoftmax | n:  23
IntGELU    | n:  18
IntSoftmax | n:  23
IntGELU    | n:  18
IntSoftmax | n:  23
IntGELU    | n:  18
IntSoftmax | n:  23
IntGELU    | n:  18
IntSoftmax | n:  23
IntGELU    | n:  18
.calib done
Test: [  0/391]	Time  3.947 ( 3.947)	Acc@1   0.78 (  0.78)	Acc@5   2.34 (  2.34)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.781 Prec@5 2.344
Time: 8.93
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=23, intgelu_exp_n=19
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=23, intgelu_exp_n=19, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  23
IntGELU    | n:  19
IntSoftmax | n:  23
IntGELU    | n:  19
IntSoftmax | n:  23
IntGELU    | n:  19
IntSoftmax | n:  23
IntGELU    | n:  19
IntSoftmax | n:  23
IntGELU    | n:  19
IntSoftmax | n:  23
IntGELU    | n:  19
IntSoftmax | n:  23
IntGELU    | n:  19
IntSoftmax | n:  23
IntGELU    | n:  19
IntSoftmax | n:  23
IntGELU    | n:  19
IntSoftmax | n:  23
IntGELU    | n:  19
IntSoftmax | n:  23
IntGELU    | n:  19
IntSoftmax | n:  23
IntGELU    | n:  19
.calib done
Test: [  0/391]	Time  3.825 ( 3.825)	Acc@1   0.78 (  0.78)	Acc@5   3.91 (  3.91)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.781 Prec@5 3.906
Time: 8.81
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=23, intgelu_exp_n=20
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=23, intgelu_exp_n=20, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  23
IntGELU    | n:  20
IntSoftmax | n:  23
IntGELU    | n:  20
IntSoftmax | n:  23
IntGELU    | n:  20
IntSoftmax | n:  23
IntGELU    | n:  20
IntSoftmax | n:  23
IntGELU    | n:  20
IntSoftmax | n:  23
IntGELU    | n:  20
IntSoftmax | n:  23
IntGELU    | n:  20
IntSoftmax | n:  23
IntGELU    | n:  20
IntSoftmax | n:  23
IntGELU    | n:  20
IntSoftmax | n:  23
IntGELU    | n:  20
IntSoftmax | n:  23
IntGELU    | n:  20
IntSoftmax | n:  23
IntGELU    | n:  20
.calib done
Test: [  0/391]	Time  3.955 ( 3.955)	Acc@1   1.56 (  1.56)	Acc@5  10.16 ( 10.16)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 1.562 Prec@5 10.156
Time: 8.88
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=23, intgelu_exp_n=21
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=23, intgelu_exp_n=21, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  23
IntGELU    | n:  21
IntSoftmax | n:  23
IntGELU    | n:  21
IntSoftmax | n:  23
IntGELU    | n:  21
IntSoftmax | n:  23
IntGELU    | n:  21
IntSoftmax | n:  23
IntGELU    | n:  21
IntSoftmax | n:  23
IntGELU    | n:  21
IntSoftmax | n:  23
IntGELU    | n:  21
IntSoftmax | n:  23
IntGELU    | n:  21
IntSoftmax | n:  23
IntGELU    | n:  21
IntSoftmax | n:  23
IntGELU    | n:  21
IntSoftmax | n:  23
IntGELU    | n:  21
IntSoftmax | n:  23
IntGELU    | n:  21
.calib done
Test: [  0/391]	Time  3.805 ( 3.805)	Acc@1   4.69 (  4.69)	Acc@5  13.28 ( 13.28)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 4.688 Prec@5 13.281
Time: 8.76
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=23, intgelu_exp_n=22
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=23, intgelu_exp_n=22, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  23
IntGELU    | n:  22
IntSoftmax | n:  23
IntGELU    | n:  22
IntSoftmax | n:  23
IntGELU    | n:  22
IntSoftmax | n:  23
IntGELU    | n:  22
IntSoftmax | n:  23
IntGELU    | n:  22
IntSoftmax | n:  23
IntGELU    | n:  22
IntSoftmax | n:  23
IntGELU    | n:  22
IntSoftmax | n:  23
IntGELU    | n:  22
IntSoftmax | n:  23
IntGELU    | n:  22
IntSoftmax | n:  23
IntGELU    | n:  22
IntSoftmax | n:  23
IntGELU    | n:  22
IntSoftmax | n:  23
IntGELU    | n:  22
.calib done
Test: [  0/391]	Time  3.992 ( 3.992)	Acc@1   2.34 (  2.34)	Acc@5  15.62 ( 15.62)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 2.344 Prec@5 15.625
Time: 8.95
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=23, intgelu_exp_n=23
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=23, intgelu_exp_n=23, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  23
IntGELU    | n:  23
IntSoftmax | n:  23
IntGELU    | n:  23
IntSoftmax | n:  23
IntGELU    | n:  23
IntSoftmax | n:  23
IntGELU    | n:  23
IntSoftmax | n:  23
IntGELU    | n:  23
IntSoftmax | n:  23
IntGELU    | n:  23
IntSoftmax | n:  23
IntGELU    | n:  23
IntSoftmax | n:  23
IntGELU    | n:  23
IntSoftmax | n:  23
IntGELU    | n:  23
IntSoftmax | n:  23
IntGELU    | n:  23
IntSoftmax | n:  23
IntGELU    | n:  23
IntSoftmax | n:  23
IntGELU    | n:  23
.calib done
Test: [  0/391]	Time  4.025 ( 4.025)	Acc@1  12.50 ( 12.50)	Acc@5  25.78 ( 25.78)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 12.500 Prec@5 25.781
Time: 8.98
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=23, intgelu_exp_n=24
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=23, intgelu_exp_n=24, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  23
IntGELU    | n:  24
IntSoftmax | n:  23
IntGELU    | n:  24
IntSoftmax | n:  23
IntGELU    | n:  24
IntSoftmax | n:  23
IntGELU    | n:  24
IntSoftmax | n:  23
IntGELU    | n:  24
IntSoftmax | n:  23
IntGELU    | n:  24
IntSoftmax | n:  23
IntGELU    | n:  24
IntSoftmax | n:  23
IntGELU    | n:  24
IntSoftmax | n:  23
IntGELU    | n:  24
IntSoftmax | n:  23
IntGELU    | n:  24
IntSoftmax | n:  23
IntGELU    | n:  24
IntSoftmax | n:  23
IntGELU    | n:  24
.calib done
Test: [  0/391]	Time  3.872 ( 3.872)	Acc@1  11.72 ( 11.72)	Acc@5  25.78 ( 25.78)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 11.719 Prec@5 25.781
Time: 8.81
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=23, intgelu_exp_n=25
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=23, intgelu_exp_n=25, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  23
IntGELU    | n:  25
IntSoftmax | n:  23
IntGELU    | n:  25
IntSoftmax | n:  23
IntGELU    | n:  25
IntSoftmax | n:  23
IntGELU    | n:  25
IntSoftmax | n:  23
IntGELU    | n:  25
IntSoftmax | n:  23
IntGELU    | n:  25
IntSoftmax | n:  23
IntGELU    | n:  25
IntSoftmax | n:  23
IntGELU    | n:  25
IntSoftmax | n:  23
IntGELU    | n:  25
IntSoftmax | n:  23
IntGELU    | n:  25
IntSoftmax | n:  23
IntGELU    | n:  25
IntSoftmax | n:  23
IntGELU    | n:  25
.calib done
Test: [  0/391]	Time  3.889 ( 3.889)	Acc@1  17.97 ( 17.97)	Acc@5  37.50 ( 37.50)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 17.969 Prec@5 37.500
Time: 8.86
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=23, intgelu_exp_n=26
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=23, intgelu_exp_n=26, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  23
IntGELU    | n:  26
IntSoftmax | n:  23
IntGELU    | n:  26
IntSoftmax | n:  23
IntGELU    | n:  26
IntSoftmax | n:  23
IntGELU    | n:  26
IntSoftmax | n:  23
IntGELU    | n:  26
IntSoftmax | n:  23
IntGELU    | n:  26
IntSoftmax | n:  23
IntGELU    | n:  26
IntSoftmax | n:  23
IntGELU    | n:  26
IntSoftmax | n:  23
IntGELU    | n:  26
IntSoftmax | n:  23
IntGELU    | n:  26
IntSoftmax | n:  23
IntGELU    | n:  26
IntSoftmax | n:  23
IntGELU    | n:  26
.calib done
Test: [  0/391]	Time  4.022 ( 4.022)	Acc@1  17.19 ( 17.19)	Acc@5  35.94 ( 35.94)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 17.188 Prec@5 35.938
Time: 9.02
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=23, intgelu_exp_n=27
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=23, intgelu_exp_n=27, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  23
IntGELU    | n:  27
IntSoftmax | n:  23
IntGELU    | n:  27
IntSoftmax | n:  23
IntGELU    | n:  27
IntSoftmax | n:  23
IntGELU    | n:  27
IntSoftmax | n:  23
IntGELU    | n:  27
IntSoftmax | n:  23
IntGELU    | n:  27
IntSoftmax | n:  23
IntGELU    | n:  27
IntSoftmax | n:  23
IntGELU    | n:  27
IntSoftmax | n:  23
IntGELU    | n:  27
IntSoftmax | n:  23
IntGELU    | n:  27
IntSoftmax | n:  23
IntGELU    | n:  27
IntSoftmax | n:  23
IntGELU    | n:  27
.calib done
Test: [  0/391]	Time  3.938 ( 3.938)	Acc@1  35.94 ( 35.94)	Acc@5  55.47 ( 55.47)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 35.938 Prec@5 55.469
Time: 8.89
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=23, intgelu_exp_n=28
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=23, intgelu_exp_n=28, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  23
IntGELU    | n:  28
IntSoftmax | n:  23
IntGELU    | n:  28
IntSoftmax | n:  23
IntGELU    | n:  28
IntSoftmax | n:  23
IntGELU    | n:  28
IntSoftmax | n:  23
IntGELU    | n:  28
IntSoftmax | n:  23
IntGELU    | n:  28
IntSoftmax | n:  23
IntGELU    | n:  28
IntSoftmax | n:  23
IntGELU    | n:  28
IntSoftmax | n:  23
IntGELU    | n:  28
IntSoftmax | n:  23
IntGELU    | n:  28
IntSoftmax | n:  23
IntGELU    | n:  28
IntSoftmax | n:  23
IntGELU    | n:  28
.calib done
Test: [  0/391]	Time  4.005 ( 4.005)	Acc@1   1.56 (  1.56)	Acc@5  11.72 ( 11.72)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 1.562 Prec@5 11.719
Time: 8.99
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=23, intgelu_exp_n=29
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=23, intgelu_exp_n=29, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  23
IntGELU    | n:  29
IntSoftmax | n:  23
IntGELU    | n:  29
IntSoftmax | n:  23
IntGELU    | n:  29
IntSoftmax | n:  23
IntGELU    | n:  29
IntSoftmax | n:  23
IntGELU    | n:  29
IntSoftmax | n:  23
IntGELU    | n:  29
IntSoftmax | n:  23
IntGELU    | n:  29
IntSoftmax | n:  23
IntGELU    | n:  29
IntSoftmax | n:  23
IntGELU    | n:  29
IntSoftmax | n:  23
IntGELU    | n:  29
IntSoftmax | n:  23
IntGELU    | n:  29
IntSoftmax | n:  23
IntGELU    | n:  29
.calib done
Test: [  0/391]	Time  3.908 ( 3.908)	Acc@1  40.62 ( 40.62)	Acc@5  63.28 ( 63.28)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 40.625 Prec@5 63.281
Time: 8.88
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=23, intgelu_exp_n=30
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=23, intgelu_exp_n=30, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  23
IntGELU    | n:  30
IntSoftmax | n:  23
IntGELU    | n:  30
IntSoftmax | n:  23
IntGELU    | n:  30
IntSoftmax | n:  23
IntGELU    | n:  30
IntSoftmax | n:  23
IntGELU    | n:  30
IntSoftmax | n:  23
IntGELU    | n:  30
IntSoftmax | n:  23
IntGELU    | n:  30
IntSoftmax | n:  23
IntGELU    | n:  30
IntSoftmax | n:  23
IntGELU    | n:  30
IntSoftmax | n:  23
IntGELU    | n:  30
IntSoftmax | n:  23
IntGELU    | n:  30
IntSoftmax | n:  23
IntGELU    | n:  30
.calib done
Test: [  0/391]	Time  3.882 ( 3.882)	Acc@1  88.28 ( 88.28)	Acc@5  96.88 ( 96.88)
Test: [ 10/391]	Time  1.734 ( 1.928)	Acc@1  63.28 ( 79.55)	Acc@5  89.06 ( 93.75)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 79.545 Prec@5 93.750
Time: 26.21
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=23, intgelu_exp_n=31
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=23, intgelu_exp_n=31, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  23
IntGELU    | n:  31
IntSoftmax | n:  23
IntGELU    | n:  31
IntSoftmax | n:  23
IntGELU    | n:  31
IntSoftmax | n:  23
IntGELU    | n:  31
IntSoftmax | n:  23
IntGELU    | n:  31
IntSoftmax | n:  23
IntGELU    | n:  31
IntSoftmax | n:  23
IntGELU    | n:  31
IntSoftmax | n:  23
IntGELU    | n:  31
IntSoftmax | n:  23
IntGELU    | n:  31
IntSoftmax | n:  23
IntGELU    | n:  31
IntSoftmax | n:  23
IntGELU    | n:  31
IntSoftmax | n:  23
IntGELU    | n:  31
.calib done
Test: [  0/391]	Time  4.001 ( 4.001)	Acc@1   4.69 (  4.69)	Acc@5  10.94 ( 10.94)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 4.688 Prec@5 10.938
Time: 9.06
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=24, intgelu_exp_n=0
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=24, intgelu_exp_n=0, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  24
IntGELU    | n:  0
IntSoftmax | n:  24
IntGELU    | n:  0
IntSoftmax | n:  24
IntGELU    | n:  0
IntSoftmax | n:  24
IntGELU    | n:  0
IntSoftmax | n:  24
IntGELU    | n:  0
IntSoftmax | n:  24
IntGELU    | n:  0
IntSoftmax | n:  24
IntGELU    | n:  0
IntSoftmax | n:  24
IntGELU    | n:  0
IntSoftmax | n:  24
IntGELU    | n:  0
IntSoftmax | n:  24
IntGELU    | n:  0
IntSoftmax | n:  24
IntGELU    | n:  0
IntSoftmax | n:  24
IntGELU    | n:  0
.calib done
Test: [  0/391]	Time  3.983 ( 3.983)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.91
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=24, intgelu_exp_n=1
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=24, intgelu_exp_n=1, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  24
IntGELU    | n:  1
IntSoftmax | n:  24
IntGELU    | n:  1
IntSoftmax | n:  24
IntGELU    | n:  1
IntSoftmax | n:  24
IntGELU    | n:  1
IntSoftmax | n:  24
IntGELU    | n:  1
IntSoftmax | n:  24
IntGELU    | n:  1
IntSoftmax | n:  24
IntGELU    | n:  1
IntSoftmax | n:  24
IntGELU    | n:  1
IntSoftmax | n:  24
IntGELU    | n:  1
IntSoftmax | n:  24
IntGELU    | n:  1
IntSoftmax | n:  24
IntGELU    | n:  1
IntSoftmax | n:  24
IntGELU    | n:  1
.calib done
Test: [  0/391]	Time  3.884 ( 3.884)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.85
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=24, intgelu_exp_n=2
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=24, intgelu_exp_n=2, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  24
IntGELU    | n:  2
IntSoftmax | n:  24
IntGELU    | n:  2
IntSoftmax | n:  24
IntGELU    | n:  2
IntSoftmax | n:  24
IntGELU    | n:  2
IntSoftmax | n:  24
IntGELU    | n:  2
IntSoftmax | n:  24
IntGELU    | n:  2
IntSoftmax | n:  24
IntGELU    | n:  2
IntSoftmax | n:  24
IntGELU    | n:  2
IntSoftmax | n:  24
IntGELU    | n:  2
IntSoftmax | n:  24
IntGELU    | n:  2
IntSoftmax | n:  24
IntGELU    | n:  2
IntSoftmax | n:  24
IntGELU    | n:  2
.calib done
Test: [  0/391]	Time  3.954 ( 3.954)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.91
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=24, intgelu_exp_n=3
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=24, intgelu_exp_n=3, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  24
IntGELU    | n:  3
IntSoftmax | n:  24
IntGELU    | n:  3
IntSoftmax | n:  24
IntGELU    | n:  3
IntSoftmax | n:  24
IntGELU    | n:  3
IntSoftmax | n:  24
IntGELU    | n:  3
IntSoftmax | n:  24
IntGELU    | n:  3
IntSoftmax | n:  24
IntGELU    | n:  3
IntSoftmax | n:  24
IntGELU    | n:  3
IntSoftmax | n:  24
IntGELU    | n:  3
IntSoftmax | n:  24
IntGELU    | n:  3
IntSoftmax | n:  24
IntGELU    | n:  3
IntSoftmax | n:  24
IntGELU    | n:  3
.calib done
Test: [  0/391]	Time  3.921 ( 3.921)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.84
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=24, intgelu_exp_n=4
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=24, intgelu_exp_n=4, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  24
IntGELU    | n:  4
IntSoftmax | n:  24
IntGELU    | n:  4
IntSoftmax | n:  24
IntGELU    | n:  4
IntSoftmax | n:  24
IntGELU    | n:  4
IntSoftmax | n:  24
IntGELU    | n:  4
IntSoftmax | n:  24
IntGELU    | n:  4
IntSoftmax | n:  24
IntGELU    | n:  4
IntSoftmax | n:  24
IntGELU    | n:  4
IntSoftmax | n:  24
IntGELU    | n:  4
IntSoftmax | n:  24
IntGELU    | n:  4
IntSoftmax | n:  24
IntGELU    | n:  4
IntSoftmax | n:  24
IntGELU    | n:  4
.calib done
Test: [  0/391]	Time  3.719 ( 3.719)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.68
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=24, intgelu_exp_n=5
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=24, intgelu_exp_n=5, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  24
IntGELU    | n:  5
IntSoftmax | n:  24
IntGELU    | n:  5
IntSoftmax | n:  24
IntGELU    | n:  5
IntSoftmax | n:  24
IntGELU    | n:  5
IntSoftmax | n:  24
IntGELU    | n:  5
IntSoftmax | n:  24
IntGELU    | n:  5
IntSoftmax | n:  24
IntGELU    | n:  5
IntSoftmax | n:  24
IntGELU    | n:  5
IntSoftmax | n:  24
IntGELU    | n:  5
IntSoftmax | n:  24
IntGELU    | n:  5
IntSoftmax | n:  24
IntGELU    | n:  5
IntSoftmax | n:  24
IntGELU    | n:  5
.calib done
Test: [  0/391]	Time  3.963 ( 3.963)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.92
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=24, intgelu_exp_n=6
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=24, intgelu_exp_n=6, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  24
IntGELU    | n:  6
IntSoftmax | n:  24
IntGELU    | n:  6
IntSoftmax | n:  24
IntGELU    | n:  6
IntSoftmax | n:  24
IntGELU    | n:  6
IntSoftmax | n:  24
IntGELU    | n:  6
IntSoftmax | n:  24
IntGELU    | n:  6
IntSoftmax | n:  24
IntGELU    | n:  6
IntSoftmax | n:  24
IntGELU    | n:  6
IntSoftmax | n:  24
IntGELU    | n:  6
IntSoftmax | n:  24
IntGELU    | n:  6
IntSoftmax | n:  24
IntGELU    | n:  6
IntSoftmax | n:  24
IntGELU    | n:  6
.calib done
Test: [  0/391]	Time  3.929 ( 3.929)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.86
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=24, intgelu_exp_n=7
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=24, intgelu_exp_n=7, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  24
IntGELU    | n:  7
IntSoftmax | n:  24
IntGELU    | n:  7
IntSoftmax | n:  24
IntGELU    | n:  7
IntSoftmax | n:  24
IntGELU    | n:  7
IntSoftmax | n:  24
IntGELU    | n:  7
IntSoftmax | n:  24
IntGELU    | n:  7
IntSoftmax | n:  24
IntGELU    | n:  7
IntSoftmax | n:  24
IntGELU    | n:  7
IntSoftmax | n:  24
IntGELU    | n:  7
IntSoftmax | n:  24
IntGELU    | n:  7
IntSoftmax | n:  24
IntGELU    | n:  7
IntSoftmax | n:  24
IntGELU    | n:  7
.calib done
Test: [  0/391]	Time  3.976 ( 3.976)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.95
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=24, intgelu_exp_n=8
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=24, intgelu_exp_n=8, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  24
IntGELU    | n:  8
IntSoftmax | n:  24
IntGELU    | n:  8
IntSoftmax | n:  24
IntGELU    | n:  8
IntSoftmax | n:  24
IntGELU    | n:  8
IntSoftmax | n:  24
IntGELU    | n:  8
IntSoftmax | n:  24
IntGELU    | n:  8
IntSoftmax | n:  24
IntGELU    | n:  8
IntSoftmax | n:  24
IntGELU    | n:  8
IntSoftmax | n:  24
IntGELU    | n:  8
IntSoftmax | n:  24
IntGELU    | n:  8
IntSoftmax | n:  24
IntGELU    | n:  8
IntSoftmax | n:  24
IntGELU    | n:  8
.calib done
Test: [  0/391]	Time  3.724 ( 3.724)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.71
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=24, intgelu_exp_n=9
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=24, intgelu_exp_n=9, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  24
IntGELU    | n:  9
IntSoftmax | n:  24
IntGELU    | n:  9
IntSoftmax | n:  24
IntGELU    | n:  9
IntSoftmax | n:  24
IntGELU    | n:  9
IntSoftmax | n:  24
IntGELU    | n:  9
IntSoftmax | n:  24
IntGELU    | n:  9
IntSoftmax | n:  24
IntGELU    | n:  9
IntSoftmax | n:  24
IntGELU    | n:  9
IntSoftmax | n:  24
IntGELU    | n:  9
IntSoftmax | n:  24
IntGELU    | n:  9
IntSoftmax | n:  24
IntGELU    | n:  9
IntSoftmax | n:  24
IntGELU    | n:  9
.calib done
Test: [  0/391]	Time  3.697 ( 3.697)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.63
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=24, intgelu_exp_n=10
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=24, intgelu_exp_n=10, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  24
IntGELU    | n:  10
IntSoftmax | n:  24
IntGELU    | n:  10
IntSoftmax | n:  24
IntGELU    | n:  10
IntSoftmax | n:  24
IntGELU    | n:  10
IntSoftmax | n:  24
IntGELU    | n:  10
IntSoftmax | n:  24
IntGELU    | n:  10
IntSoftmax | n:  24
IntGELU    | n:  10
IntSoftmax | n:  24
IntGELU    | n:  10
IntSoftmax | n:  24
IntGELU    | n:  10
IntSoftmax | n:  24
IntGELU    | n:  10
IntSoftmax | n:  24
IntGELU    | n:  10
IntSoftmax | n:  24
IntGELU    | n:  10
.calib done
Test: [  0/391]	Time  3.757 ( 3.757)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.75
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=24, intgelu_exp_n=11
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=24, intgelu_exp_n=11, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  24
IntGELU    | n:  11
IntSoftmax | n:  24
IntGELU    | n:  11
IntSoftmax | n:  24
IntGELU    | n:  11
IntSoftmax | n:  24
IntGELU    | n:  11
IntSoftmax | n:  24
IntGELU    | n:  11
IntSoftmax | n:  24
IntGELU    | n:  11
IntSoftmax | n:  24
IntGELU    | n:  11
IntSoftmax | n:  24
IntGELU    | n:  11
IntSoftmax | n:  24
IntGELU    | n:  11
IntSoftmax | n:  24
IntGELU    | n:  11
IntSoftmax | n:  24
IntGELU    | n:  11
IntSoftmax | n:  24
IntGELU    | n:  11
.calib done
Test: [  0/391]	Time  4.007 ( 4.007)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 9.00
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=24, intgelu_exp_n=12
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=24, intgelu_exp_n=12, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  24
IntGELU    | n:  12
IntSoftmax | n:  24
IntGELU    | n:  12
IntSoftmax | n:  24
IntGELU    | n:  12
IntSoftmax | n:  24
IntGELU    | n:  12
IntSoftmax | n:  24
IntGELU    | n:  12
IntSoftmax | n:  24
IntGELU    | n:  12
IntSoftmax | n:  24
IntGELU    | n:  12
IntSoftmax | n:  24
IntGELU    | n:  12
IntSoftmax | n:  24
IntGELU    | n:  12
IntSoftmax | n:  24
IntGELU    | n:  12
IntSoftmax | n:  24
IntGELU    | n:  12
IntSoftmax | n:  24
IntGELU    | n:  12
.calib done
Test: [  0/391]	Time  4.008 ( 4.008)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 9.00
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=24, intgelu_exp_n=13
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=24, intgelu_exp_n=13, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  24
IntGELU    | n:  13
IntSoftmax | n:  24
IntGELU    | n:  13
IntSoftmax | n:  24
IntGELU    | n:  13
IntSoftmax | n:  24
IntGELU    | n:  13
IntSoftmax | n:  24
IntGELU    | n:  13
IntSoftmax | n:  24
IntGELU    | n:  13
IntSoftmax | n:  24
IntGELU    | n:  13
IntSoftmax | n:  24
IntGELU    | n:  13
IntSoftmax | n:  24
IntGELU    | n:  13
IntSoftmax | n:  24
IntGELU    | n:  13
IntSoftmax | n:  24
IntGELU    | n:  13
IntSoftmax | n:  24
IntGELU    | n:  13
.calib done
Test: [  0/391]	Time  3.950 ( 3.950)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.91
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=24, intgelu_exp_n=14
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=24, intgelu_exp_n=14, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  24
IntGELU    | n:  14
IntSoftmax | n:  24
IntGELU    | n:  14
IntSoftmax | n:  24
IntGELU    | n:  14
IntSoftmax | n:  24
IntGELU    | n:  14
IntSoftmax | n:  24
IntGELU    | n:  14
IntSoftmax | n:  24
IntGELU    | n:  14
IntSoftmax | n:  24
IntGELU    | n:  14
IntSoftmax | n:  24
IntGELU    | n:  14
IntSoftmax | n:  24
IntGELU    | n:  14
IntSoftmax | n:  24
IntGELU    | n:  14
IntSoftmax | n:  24
IntGELU    | n:  14
IntSoftmax | n:  24
IntGELU    | n:  14
.calib done
Test: [  0/391]	Time  3.757 ( 3.757)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.73
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=24, intgelu_exp_n=15
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=24, intgelu_exp_n=15, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  24
IntGELU    | n:  15
IntSoftmax | n:  24
IntGELU    | n:  15
IntSoftmax | n:  24
IntGELU    | n:  15
IntSoftmax | n:  24
IntGELU    | n:  15
IntSoftmax | n:  24
IntGELU    | n:  15
IntSoftmax | n:  24
IntGELU    | n:  15
IntSoftmax | n:  24
IntGELU    | n:  15
IntSoftmax | n:  24
IntGELU    | n:  15
IntSoftmax | n:  24
IntGELU    | n:  15
IntSoftmax | n:  24
IntGELU    | n:  15
IntSoftmax | n:  24
IntGELU    | n:  15
IntSoftmax | n:  24
IntGELU    | n:  15
.calib done
Test: [  0/391]	Time  3.877 ( 3.877)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.81
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=24, intgelu_exp_n=16
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=24, intgelu_exp_n=16, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  24
IntGELU    | n:  16
IntSoftmax | n:  24
IntGELU    | n:  16
IntSoftmax | n:  24
IntGELU    | n:  16
IntSoftmax | n:  24
IntGELU    | n:  16
IntSoftmax | n:  24
IntGELU    | n:  16
IntSoftmax | n:  24
IntGELU    | n:  16
IntSoftmax | n:  24
IntGELU    | n:  16
IntSoftmax | n:  24
IntGELU    | n:  16
IntSoftmax | n:  24
IntGELU    | n:  16
IntSoftmax | n:  24
IntGELU    | n:  16
IntSoftmax | n:  24
IntGELU    | n:  16
IntSoftmax | n:  24
IntGELU    | n:  16
.calib done
Test: [  0/391]	Time  3.945 ( 3.945)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.90
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=24, intgelu_exp_n=17
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=24, intgelu_exp_n=17, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  24
IntGELU    | n:  17
IntSoftmax | n:  24
IntGELU    | n:  17
IntSoftmax | n:  24
IntGELU    | n:  17
IntSoftmax | n:  24
IntGELU    | n:  17
IntSoftmax | n:  24
IntGELU    | n:  17
IntSoftmax | n:  24
IntGELU    | n:  17
IntSoftmax | n:  24
IntGELU    | n:  17
IntSoftmax | n:  24
IntGELU    | n:  17
IntSoftmax | n:  24
IntGELU    | n:  17
IntSoftmax | n:  24
IntGELU    | n:  17
IntSoftmax | n:  24
IntGELU    | n:  17
IntSoftmax | n:  24
IntGELU    | n:  17
.calib done
Test: [  0/391]	Time  3.994 ( 3.994)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.95
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=24, intgelu_exp_n=18
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=24, intgelu_exp_n=18, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  24
IntGELU    | n:  18
IntSoftmax | n:  24
IntGELU    | n:  18
IntSoftmax | n:  24
IntGELU    | n:  18
IntSoftmax | n:  24
IntGELU    | n:  18
IntSoftmax | n:  24
IntGELU    | n:  18
IntSoftmax | n:  24
IntGELU    | n:  18
IntSoftmax | n:  24
IntGELU    | n:  18
IntSoftmax | n:  24
IntGELU    | n:  18
IntSoftmax | n:  24
IntGELU    | n:  18
IntSoftmax | n:  24
IntGELU    | n:  18
IntSoftmax | n:  24
IntGELU    | n:  18
IntSoftmax | n:  24
IntGELU    | n:  18
.calib done
Test: [  0/391]	Time  3.823 ( 3.823)	Acc@1   0.00 (  0.00)	Acc@5   0.78 (  0.78)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.781
Time: 8.75
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=24, intgelu_exp_n=19
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=24, intgelu_exp_n=19, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  24
IntGELU    | n:  19
IntSoftmax | n:  24
IntGELU    | n:  19
IntSoftmax | n:  24
IntGELU    | n:  19
IntSoftmax | n:  24
IntGELU    | n:  19
IntSoftmax | n:  24
IntGELU    | n:  19
IntSoftmax | n:  24
IntGELU    | n:  19
IntSoftmax | n:  24
IntGELU    | n:  19
IntSoftmax | n:  24
IntGELU    | n:  19
IntSoftmax | n:  24
IntGELU    | n:  19
IntSoftmax | n:  24
IntGELU    | n:  19
IntSoftmax | n:  24
IntGELU    | n:  19
IntSoftmax | n:  24
IntGELU    | n:  19
.calib done
Test: [  0/391]	Time  4.115 ( 4.115)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 9.03
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=24, intgelu_exp_n=20
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=24, intgelu_exp_n=20, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  24
IntGELU    | n:  20
IntSoftmax | n:  24
IntGELU    | n:  20
IntSoftmax | n:  24
IntGELU    | n:  20
IntSoftmax | n:  24
IntGELU    | n:  20
IntSoftmax | n:  24
IntGELU    | n:  20
IntSoftmax | n:  24
IntGELU    | n:  20
IntSoftmax | n:  24
IntGELU    | n:  20
IntSoftmax | n:  24
IntGELU    | n:  20
IntSoftmax | n:  24
IntGELU    | n:  20
IntSoftmax | n:  24
IntGELU    | n:  20
IntSoftmax | n:  24
IntGELU    | n:  20
IntSoftmax | n:  24
IntGELU    | n:  20
.calib done
Test: [  0/391]	Time  3.753 ( 3.753)	Acc@1   0.00 (  0.00)	Acc@5   0.78 (  0.78)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.781
Time: 8.74
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=24, intgelu_exp_n=21
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=24, intgelu_exp_n=21, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  24
IntGELU    | n:  21
IntSoftmax | n:  24
IntGELU    | n:  21
IntSoftmax | n:  24
IntGELU    | n:  21
IntSoftmax | n:  24
IntGELU    | n:  21
IntSoftmax | n:  24
IntGELU    | n:  21
IntSoftmax | n:  24
IntGELU    | n:  21
IntSoftmax | n:  24
IntGELU    | n:  21
IntSoftmax | n:  24
IntGELU    | n:  21
IntSoftmax | n:  24
IntGELU    | n:  21
IntSoftmax | n:  24
IntGELU    | n:  21
IntSoftmax | n:  24
IntGELU    | n:  21
IntSoftmax | n:  24
IntGELU    | n:  21
.calib done
Test: [  0/391]	Time  3.839 ( 3.839)	Acc@1   0.00 (  0.00)	Acc@5   0.78 (  0.78)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.781
Time: 8.81
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=24, intgelu_exp_n=22
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=24, intgelu_exp_n=22, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  24
IntGELU    | n:  22
IntSoftmax | n:  24
IntGELU    | n:  22
IntSoftmax | n:  24
IntGELU    | n:  22
IntSoftmax | n:  24
IntGELU    | n:  22
IntSoftmax | n:  24
IntGELU    | n:  22
IntSoftmax | n:  24
IntGELU    | n:  22
IntSoftmax | n:  24
IntGELU    | n:  22
IntSoftmax | n:  24
IntGELU    | n:  22
IntSoftmax | n:  24
IntGELU    | n:  22
IntSoftmax | n:  24
IntGELU    | n:  22
IntSoftmax | n:  24
IntGELU    | n:  22
IntSoftmax | n:  24
IntGELU    | n:  22
.calib done
Test: [  0/391]	Time  3.849 ( 3.849)	Acc@1   3.91 (  3.91)	Acc@5  13.28 ( 13.28)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 3.906 Prec@5 13.281
Time: 8.83
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=24, intgelu_exp_n=23
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=24, intgelu_exp_n=23, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  24
IntGELU    | n:  23
IntSoftmax | n:  24
IntGELU    | n:  23
IntSoftmax | n:  24
IntGELU    | n:  23
IntSoftmax | n:  24
IntGELU    | n:  23
IntSoftmax | n:  24
IntGELU    | n:  23
IntSoftmax | n:  24
IntGELU    | n:  23
IntSoftmax | n:  24
IntGELU    | n:  23
IntSoftmax | n:  24
IntGELU    | n:  23
IntSoftmax | n:  24
IntGELU    | n:  23
IntSoftmax | n:  24
IntGELU    | n:  23
IntSoftmax | n:  24
IntGELU    | n:  23
IntSoftmax | n:  24
IntGELU    | n:  23
.calib done
Test: [  0/391]	Time  3.725 ( 3.725)	Acc@1   0.78 (  0.78)	Acc@5   4.69 (  4.69)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.781 Prec@5 4.688
Time: 8.67
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=24, intgelu_exp_n=24
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=24, intgelu_exp_n=24, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  24
IntGELU    | n:  24
IntSoftmax | n:  24
IntGELU    | n:  24
IntSoftmax | n:  24
IntGELU    | n:  24
IntSoftmax | n:  24
IntGELU    | n:  24
IntSoftmax | n:  24
IntGELU    | n:  24
IntSoftmax | n:  24
IntGELU    | n:  24
IntSoftmax | n:  24
IntGELU    | n:  24
IntSoftmax | n:  24
IntGELU    | n:  24
IntSoftmax | n:  24
IntGELU    | n:  24
IntSoftmax | n:  24
IntGELU    | n:  24
IntSoftmax | n:  24
IntGELU    | n:  24
IntSoftmax | n:  24
IntGELU    | n:  24
.calib done
Test: [  0/391]	Time  3.741 ( 3.741)	Acc@1  19.53 ( 19.53)	Acc@5  29.69 ( 29.69)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 19.531 Prec@5 29.688
Time: 8.73
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=24, intgelu_exp_n=25
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=24, intgelu_exp_n=25, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  24
IntGELU    | n:  25
IntSoftmax | n:  24
IntGELU    | n:  25
IntSoftmax | n:  24
IntGELU    | n:  25
IntSoftmax | n:  24
IntGELU    | n:  25
IntSoftmax | n:  24
IntGELU    | n:  25
IntSoftmax | n:  24
IntGELU    | n:  25
IntSoftmax | n:  24
IntGELU    | n:  25
IntSoftmax | n:  24
IntGELU    | n:  25
IntSoftmax | n:  24
IntGELU    | n:  25
IntSoftmax | n:  24
IntGELU    | n:  25
IntSoftmax | n:  24
IntGELU    | n:  25
IntSoftmax | n:  24
IntGELU    | n:  25
.calib done
Test: [  0/391]	Time  3.914 ( 3.914)	Acc@1  28.91 ( 28.91)	Acc@5  46.09 ( 46.09)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 28.906 Prec@5 46.094
Time: 8.90
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=24, intgelu_exp_n=26
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=24, intgelu_exp_n=26, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  24
IntGELU    | n:  26
IntSoftmax | n:  24
IntGELU    | n:  26
IntSoftmax | n:  24
IntGELU    | n:  26
IntSoftmax | n:  24
IntGELU    | n:  26
IntSoftmax | n:  24
IntGELU    | n:  26
IntSoftmax | n:  24
IntGELU    | n:  26
IntSoftmax | n:  24
IntGELU    | n:  26
IntSoftmax | n:  24
IntGELU    | n:  26
IntSoftmax | n:  24
IntGELU    | n:  26
IntSoftmax | n:  24
IntGELU    | n:  26
IntSoftmax | n:  24
IntGELU    | n:  26
IntSoftmax | n:  24
IntGELU    | n:  26
.calib done
Test: [  0/391]	Time  3.907 ( 3.907)	Acc@1   2.34 (  2.34)	Acc@5   6.25 (  6.25)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 2.344 Prec@5 6.250
Time: 8.85
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=24, intgelu_exp_n=27
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=24, intgelu_exp_n=27, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  24
IntGELU    | n:  27
IntSoftmax | n:  24
IntGELU    | n:  27
IntSoftmax | n:  24
IntGELU    | n:  27
IntSoftmax | n:  24
IntGELU    | n:  27
IntSoftmax | n:  24
IntGELU    | n:  27
IntSoftmax | n:  24
IntGELU    | n:  27
IntSoftmax | n:  24
IntGELU    | n:  27
IntSoftmax | n:  24
IntGELU    | n:  27
IntSoftmax | n:  24
IntGELU    | n:  27
IntSoftmax | n:  24
IntGELU    | n:  27
IntSoftmax | n:  24
IntGELU    | n:  27
IntSoftmax | n:  24
IntGELU    | n:  27
.calib done
Test: [  0/391]	Time  3.912 ( 3.912)	Acc@1  39.06 ( 39.06)	Acc@5  59.38 ( 59.38)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 39.062 Prec@5 59.375
Time: 8.88
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=24, intgelu_exp_n=28
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=24, intgelu_exp_n=28, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  24
IntGELU    | n:  28
IntSoftmax | n:  24
IntGELU    | n:  28
IntSoftmax | n:  24
IntGELU    | n:  28
IntSoftmax | n:  24
IntGELU    | n:  28
IntSoftmax | n:  24
IntGELU    | n:  28
IntSoftmax | n:  24
IntGELU    | n:  28
IntSoftmax | n:  24
IntGELU    | n:  28
IntSoftmax | n:  24
IntGELU    | n:  28
IntSoftmax | n:  24
IntGELU    | n:  28
IntSoftmax | n:  24
IntGELU    | n:  28
IntSoftmax | n:  24
IntGELU    | n:  28
IntSoftmax | n:  24
IntGELU    | n:  28
.calib done
Test: [  0/391]	Time  3.806 ( 3.806)	Acc@1  51.56 ( 51.56)	Acc@5  70.31 ( 70.31)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 51.562 Prec@5 70.312
Time: 8.76
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=24, intgelu_exp_n=29
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=24, intgelu_exp_n=29, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  24
IntGELU    | n:  29
IntSoftmax | n:  24
IntGELU    | n:  29
IntSoftmax | n:  24
IntGELU    | n:  29
IntSoftmax | n:  24
IntGELU    | n:  29
IntSoftmax | n:  24
IntGELU    | n:  29
IntSoftmax | n:  24
IntGELU    | n:  29
IntSoftmax | n:  24
IntGELU    | n:  29
IntSoftmax | n:  24
IntGELU    | n:  29
IntSoftmax | n:  24
IntGELU    | n:  29
IntSoftmax | n:  24
IntGELU    | n:  29
IntSoftmax | n:  24
IntGELU    | n:  29
IntSoftmax | n:  24
IntGELU    | n:  29
.calib done
Test: [  0/391]	Time  3.954 ( 3.954)	Acc@1  56.25 ( 56.25)	Acc@5  76.56 ( 76.56)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 56.250 Prec@5 76.562
Time: 8.89
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=24, intgelu_exp_n=30
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=24, intgelu_exp_n=30, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  24
IntGELU    | n:  30
IntSoftmax | n:  24
IntGELU    | n:  30
IntSoftmax | n:  24
IntGELU    | n:  30
IntSoftmax | n:  24
IntGELU    | n:  30
IntSoftmax | n:  24
IntGELU    | n:  30
IntSoftmax | n:  24
IntGELU    | n:  30
IntSoftmax | n:  24
IntGELU    | n:  30
IntSoftmax | n:  24
IntGELU    | n:  30
IntSoftmax | n:  24
IntGELU    | n:  30
IntSoftmax | n:  24
IntGELU    | n:  30
IntSoftmax | n:  24
IntGELU    | n:  30
IntSoftmax | n:  24
IntGELU    | n:  30
.calib done
Test: [  0/391]	Time  3.908 ( 3.908)	Acc@1  89.06 ( 89.06)	Acc@5  95.31 ( 95.31)
Test: [  8/391]	Time  1.733 ( 1.975)	Acc@1  66.41 ( 78.21)	Acc@5  87.50 ( 93.23)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 78.212 Prec@5 93.229
Time: 22.77
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=24, intgelu_exp_n=31
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=24, intgelu_exp_n=31, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  24
IntGELU    | n:  31
IntSoftmax | n:  24
IntGELU    | n:  31
IntSoftmax | n:  24
IntGELU    | n:  31
IntSoftmax | n:  24
IntGELU    | n:  31
IntSoftmax | n:  24
IntGELU    | n:  31
IntSoftmax | n:  24
IntGELU    | n:  31
IntSoftmax | n:  24
IntGELU    | n:  31
IntSoftmax | n:  24
IntGELU    | n:  31
IntSoftmax | n:  24
IntGELU    | n:  31
IntSoftmax | n:  24
IntGELU    | n:  31
IntSoftmax | n:  24
IntGELU    | n:  31
IntSoftmax | n:  24
IntGELU    | n:  31
.calib done
Test: [  0/391]	Time  3.686 ( 3.686)	Acc@1   0.78 (  0.78)	Acc@5   4.69 (  4.69)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.781 Prec@5 4.688
Time: 8.71
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=25, intgelu_exp_n=0
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=25, intgelu_exp_n=0, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  25
IntGELU    | n:  0
IntSoftmax | n:  25
IntGELU    | n:  0
IntSoftmax | n:  25
IntGELU    | n:  0
IntSoftmax | n:  25
IntGELU    | n:  0
IntSoftmax | n:  25
IntGELU    | n:  0
IntSoftmax | n:  25
IntGELU    | n:  0
IntSoftmax | n:  25
IntGELU    | n:  0
IntSoftmax | n:  25
IntGELU    | n:  0
IntSoftmax | n:  25
IntGELU    | n:  0
IntSoftmax | n:  25
IntGELU    | n:  0
IntSoftmax | n:  25
IntGELU    | n:  0
IntSoftmax | n:  25
IntGELU    | n:  0
.calib done
Test: [  0/391]	Time  3.840 ( 3.840)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.80
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=25, intgelu_exp_n=1
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=25, intgelu_exp_n=1, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  25
IntGELU    | n:  1
IntSoftmax | n:  25
IntGELU    | n:  1
IntSoftmax | n:  25
IntGELU    | n:  1
IntSoftmax | n:  25
IntGELU    | n:  1
IntSoftmax | n:  25
IntGELU    | n:  1
IntSoftmax | n:  25
IntGELU    | n:  1
IntSoftmax | n:  25
IntGELU    | n:  1
IntSoftmax | n:  25
IntGELU    | n:  1
IntSoftmax | n:  25
IntGELU    | n:  1
IntSoftmax | n:  25
IntGELU    | n:  1
IntSoftmax | n:  25
IntGELU    | n:  1
IntSoftmax | n:  25
IntGELU    | n:  1
.calib done
Test: [  0/391]	Time  3.646 ( 3.646)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.65
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=25, intgelu_exp_n=2
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=25, intgelu_exp_n=2, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  25
IntGELU    | n:  2
IntSoftmax | n:  25
IntGELU    | n:  2
IntSoftmax | n:  25
IntGELU    | n:  2
IntSoftmax | n:  25
IntGELU    | n:  2
IntSoftmax | n:  25
IntGELU    | n:  2
IntSoftmax | n:  25
IntGELU    | n:  2
IntSoftmax | n:  25
IntGELU    | n:  2
IntSoftmax | n:  25
IntGELU    | n:  2
IntSoftmax | n:  25
IntGELU    | n:  2
IntSoftmax | n:  25
IntGELU    | n:  2
IntSoftmax | n:  25
IntGELU    | n:  2
IntSoftmax | n:  25
IntGELU    | n:  2
.calib done
Test: [  0/391]	Time  3.692 ( 3.692)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.64
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=25, intgelu_exp_n=3
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=25, intgelu_exp_n=3, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  25
IntGELU    | n:  3
IntSoftmax | n:  25
IntGELU    | n:  3
IntSoftmax | n:  25
IntGELU    | n:  3
IntSoftmax | n:  25
IntGELU    | n:  3
IntSoftmax | n:  25
IntGELU    | n:  3
IntSoftmax | n:  25
IntGELU    | n:  3
IntSoftmax | n:  25
IntGELU    | n:  3
IntSoftmax | n:  25
IntGELU    | n:  3
IntSoftmax | n:  25
IntGELU    | n:  3
IntSoftmax | n:  25
IntGELU    | n:  3
IntSoftmax | n:  25
IntGELU    | n:  3
IntSoftmax | n:  25
IntGELU    | n:  3
.calib done
Test: [  0/391]	Time  3.765 ( 3.765)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.75
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=25, intgelu_exp_n=4
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=25, intgelu_exp_n=4, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  25
IntGELU    | n:  4
IntSoftmax | n:  25
IntGELU    | n:  4
IntSoftmax | n:  25
IntGELU    | n:  4
IntSoftmax | n:  25
IntGELU    | n:  4
IntSoftmax | n:  25
IntGELU    | n:  4
IntSoftmax | n:  25
IntGELU    | n:  4
IntSoftmax | n:  25
IntGELU    | n:  4
IntSoftmax | n:  25
IntGELU    | n:  4
IntSoftmax | n:  25
IntGELU    | n:  4
IntSoftmax | n:  25
IntGELU    | n:  4
IntSoftmax | n:  25
IntGELU    | n:  4
IntSoftmax | n:  25
IntGELU    | n:  4
.calib done
Test: [  0/391]	Time  3.798 ( 3.798)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.76
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=25, intgelu_exp_n=5
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=25, intgelu_exp_n=5, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  25
IntGELU    | n:  5
IntSoftmax | n:  25
IntGELU    | n:  5
IntSoftmax | n:  25
IntGELU    | n:  5
IntSoftmax | n:  25
IntGELU    | n:  5
IntSoftmax | n:  25
IntGELU    | n:  5
IntSoftmax | n:  25
IntGELU    | n:  5
IntSoftmax | n:  25
IntGELU    | n:  5
IntSoftmax | n:  25
IntGELU    | n:  5
IntSoftmax | n:  25
IntGELU    | n:  5
IntSoftmax | n:  25
IntGELU    | n:  5
IntSoftmax | n:  25
IntGELU    | n:  5
IntSoftmax | n:  25
IntGELU    | n:  5
.calib done
Test: [  0/391]	Time  3.652 ( 3.652)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.64
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=25, intgelu_exp_n=6
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=25, intgelu_exp_n=6, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  25
IntGELU    | n:  6
IntSoftmax | n:  25
IntGELU    | n:  6
IntSoftmax | n:  25
IntGELU    | n:  6
IntSoftmax | n:  25
IntGELU    | n:  6
IntSoftmax | n:  25
IntGELU    | n:  6
IntSoftmax | n:  25
IntGELU    | n:  6
IntSoftmax | n:  25
IntGELU    | n:  6
IntSoftmax | n:  25
IntGELU    | n:  6
IntSoftmax | n:  25
IntGELU    | n:  6
IntSoftmax | n:  25
IntGELU    | n:  6
IntSoftmax | n:  25
IntGELU    | n:  6
IntSoftmax | n:  25
IntGELU    | n:  6
.calib done
Test: [  0/391]	Time  3.964 ( 3.964)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.93
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=25, intgelu_exp_n=7
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=25, intgelu_exp_n=7, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  25
IntGELU    | n:  7
IntSoftmax | n:  25
IntGELU    | n:  7
IntSoftmax | n:  25
IntGELU    | n:  7
IntSoftmax | n:  25
IntGELU    | n:  7
IntSoftmax | n:  25
IntGELU    | n:  7
IntSoftmax | n:  25
IntGELU    | n:  7
IntSoftmax | n:  25
IntGELU    | n:  7
IntSoftmax | n:  25
IntGELU    | n:  7
IntSoftmax | n:  25
IntGELU    | n:  7
IntSoftmax | n:  25
IntGELU    | n:  7
IntSoftmax | n:  25
IntGELU    | n:  7
IntSoftmax | n:  25
IntGELU    | n:  7
.calib done
Test: [  0/391]	Time  3.687 ( 3.687)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.69
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=25, intgelu_exp_n=8
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=25, intgelu_exp_n=8, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  25
IntGELU    | n:  8
IntSoftmax | n:  25
IntGELU    | n:  8
IntSoftmax | n:  25
IntGELU    | n:  8
IntSoftmax | n:  25
IntGELU    | n:  8
IntSoftmax | n:  25
IntGELU    | n:  8
IntSoftmax | n:  25
IntGELU    | n:  8
IntSoftmax | n:  25
IntGELU    | n:  8
IntSoftmax | n:  25
IntGELU    | n:  8
IntSoftmax | n:  25
IntGELU    | n:  8
IntSoftmax | n:  25
IntGELU    | n:  8
IntSoftmax | n:  25
IntGELU    | n:  8
IntSoftmax | n:  25
IntGELU    | n:  8
.calib done
Test: [  0/391]	Time  3.856 ( 3.856)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.81
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=25, intgelu_exp_n=9
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=25, intgelu_exp_n=9, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  25
IntGELU    | n:  9
IntSoftmax | n:  25
IntGELU    | n:  9
IntSoftmax | n:  25
IntGELU    | n:  9
IntSoftmax | n:  25
IntGELU    | n:  9
IntSoftmax | n:  25
IntGELU    | n:  9
IntSoftmax | n:  25
IntGELU    | n:  9
IntSoftmax | n:  25
IntGELU    | n:  9
IntSoftmax | n:  25
IntGELU    | n:  9
IntSoftmax | n:  25
IntGELU    | n:  9
IntSoftmax | n:  25
IntGELU    | n:  9
IntSoftmax | n:  25
IntGELU    | n:  9
IntSoftmax | n:  25
IntGELU    | n:  9
.calib done
Test: [  0/391]	Time  3.962 ( 3.962)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.93
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=25, intgelu_exp_n=10
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=25, intgelu_exp_n=10, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  25
IntGELU    | n:  10
IntSoftmax | n:  25
IntGELU    | n:  10
IntSoftmax | n:  25
IntGELU    | n:  10
IntSoftmax | n:  25
IntGELU    | n:  10
IntSoftmax | n:  25
IntGELU    | n:  10
IntSoftmax | n:  25
IntGELU    | n:  10
IntSoftmax | n:  25
IntGELU    | n:  10
IntSoftmax | n:  25
IntGELU    | n:  10
IntSoftmax | n:  25
IntGELU    | n:  10
IntSoftmax | n:  25
IntGELU    | n:  10
IntSoftmax | n:  25
IntGELU    | n:  10
IntSoftmax | n:  25
IntGELU    | n:  10
.calib done
Test: [  0/391]	Time  3.719 ( 3.719)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.64
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=25, intgelu_exp_n=11
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=25, intgelu_exp_n=11, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  25
IntGELU    | n:  11
IntSoftmax | n:  25
IntGELU    | n:  11
IntSoftmax | n:  25
IntGELU    | n:  11
IntSoftmax | n:  25
IntGELU    | n:  11
IntSoftmax | n:  25
IntGELU    | n:  11
IntSoftmax | n:  25
IntGELU    | n:  11
IntSoftmax | n:  25
IntGELU    | n:  11
IntSoftmax | n:  25
IntGELU    | n:  11
IntSoftmax | n:  25
IntGELU    | n:  11
IntSoftmax | n:  25
IntGELU    | n:  11
IntSoftmax | n:  25
IntGELU    | n:  11
IntSoftmax | n:  25
IntGELU    | n:  11
.calib done
Test: [  0/391]	Time  3.971 ( 3.971)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.92
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=25, intgelu_exp_n=12
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=25, intgelu_exp_n=12, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  25
IntGELU    | n:  12
IntSoftmax | n:  25
IntGELU    | n:  12
IntSoftmax | n:  25
IntGELU    | n:  12
IntSoftmax | n:  25
IntGELU    | n:  12
IntSoftmax | n:  25
IntGELU    | n:  12
IntSoftmax | n:  25
IntGELU    | n:  12
IntSoftmax | n:  25
IntGELU    | n:  12
IntSoftmax | n:  25
IntGELU    | n:  12
IntSoftmax | n:  25
IntGELU    | n:  12
IntSoftmax | n:  25
IntGELU    | n:  12
IntSoftmax | n:  25
IntGELU    | n:  12
IntSoftmax | n:  25
IntGELU    | n:  12
.calib done
Test: [  0/391]	Time  3.766 ( 3.766)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.76
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=25, intgelu_exp_n=13
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=25, intgelu_exp_n=13, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  25
IntGELU    | n:  13
IntSoftmax | n:  25
IntGELU    | n:  13
IntSoftmax | n:  25
IntGELU    | n:  13
IntSoftmax | n:  25
IntGELU    | n:  13
IntSoftmax | n:  25
IntGELU    | n:  13
IntSoftmax | n:  25
IntGELU    | n:  13
IntSoftmax | n:  25
IntGELU    | n:  13
IntSoftmax | n:  25
IntGELU    | n:  13
IntSoftmax | n:  25
IntGELU    | n:  13
IntSoftmax | n:  25
IntGELU    | n:  13
IntSoftmax | n:  25
IntGELU    | n:  13
IntSoftmax | n:  25
IntGELU    | n:  13
.calib done
Test: [  0/391]	Time  4.063 ( 4.063)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 9.04
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=25, intgelu_exp_n=14
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=25, intgelu_exp_n=14, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  25
IntGELU    | n:  14
IntSoftmax | n:  25
IntGELU    | n:  14
IntSoftmax | n:  25
IntGELU    | n:  14
IntSoftmax | n:  25
IntGELU    | n:  14
IntSoftmax | n:  25
IntGELU    | n:  14
IntSoftmax | n:  25
IntGELU    | n:  14
IntSoftmax | n:  25
IntGELU    | n:  14
IntSoftmax | n:  25
IntGELU    | n:  14
IntSoftmax | n:  25
IntGELU    | n:  14
IntSoftmax | n:  25
IntGELU    | n:  14
IntSoftmax | n:  25
IntGELU    | n:  14
IntSoftmax | n:  25
IntGELU    | n:  14
.calib done
Test: [  0/391]	Time  3.683 ( 3.683)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.63
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=25, intgelu_exp_n=15
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=25, intgelu_exp_n=15, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  25
IntGELU    | n:  15
IntSoftmax | n:  25
IntGELU    | n:  15
IntSoftmax | n:  25
IntGELU    | n:  15
IntSoftmax | n:  25
IntGELU    | n:  15
IntSoftmax | n:  25
IntGELU    | n:  15
IntSoftmax | n:  25
IntGELU    | n:  15
IntSoftmax | n:  25
IntGELU    | n:  15
IntSoftmax | n:  25
IntGELU    | n:  15
IntSoftmax | n:  25
IntGELU    | n:  15
IntSoftmax | n:  25
IntGELU    | n:  15
IntSoftmax | n:  25
IntGELU    | n:  15
IntSoftmax | n:  25
IntGELU    | n:  15
.calib done
Test: [  0/391]	Time  3.679 ( 3.679)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.64
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=25, intgelu_exp_n=16
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=25, intgelu_exp_n=16, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  25
IntGELU    | n:  16
IntSoftmax | n:  25
IntGELU    | n:  16
IntSoftmax | n:  25
IntGELU    | n:  16
IntSoftmax | n:  25
IntGELU    | n:  16
IntSoftmax | n:  25
IntGELU    | n:  16
IntSoftmax | n:  25
IntGELU    | n:  16
IntSoftmax | n:  25
IntGELU    | n:  16
IntSoftmax | n:  25
IntGELU    | n:  16
IntSoftmax | n:  25
IntGELU    | n:  16
IntSoftmax | n:  25
IntGELU    | n:  16
IntSoftmax | n:  25
IntGELU    | n:  16
IntSoftmax | n:  25
IntGELU    | n:  16
.calib done
Test: [  0/391]	Time  3.901 ( 3.901)	Acc@1   0.00 (  0.00)	Acc@5   0.78 (  0.78)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.781
Time: 8.80
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=25, intgelu_exp_n=17
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=25, intgelu_exp_n=17, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  25
IntGELU    | n:  17
IntSoftmax | n:  25
IntGELU    | n:  17
IntSoftmax | n:  25
IntGELU    | n:  17
IntSoftmax | n:  25
IntGELU    | n:  17
IntSoftmax | n:  25
IntGELU    | n:  17
IntSoftmax | n:  25
IntGELU    | n:  17
IntSoftmax | n:  25
IntGELU    | n:  17
IntSoftmax | n:  25
IntGELU    | n:  17
IntSoftmax | n:  25
IntGELU    | n:  17
IntSoftmax | n:  25
IntGELU    | n:  17
IntSoftmax | n:  25
IntGELU    | n:  17
IntSoftmax | n:  25
IntGELU    | n:  17
.calib done
Test: [  0/391]	Time  3.941 ( 3.941)	Acc@1   0.00 (  0.00)	Acc@5   0.78 (  0.78)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.781
Time: 8.90
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=25, intgelu_exp_n=18
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=25, intgelu_exp_n=18, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  25
IntGELU    | n:  18
IntSoftmax | n:  25
IntGELU    | n:  18
IntSoftmax | n:  25
IntGELU    | n:  18
IntSoftmax | n:  25
IntGELU    | n:  18
IntSoftmax | n:  25
IntGELU    | n:  18
IntSoftmax | n:  25
IntGELU    | n:  18
IntSoftmax | n:  25
IntGELU    | n:  18
IntSoftmax | n:  25
IntGELU    | n:  18
IntSoftmax | n:  25
IntGELU    | n:  18
IntSoftmax | n:  25
IntGELU    | n:  18
IntSoftmax | n:  25
IntGELU    | n:  18
IntSoftmax | n:  25
IntGELU    | n:  18
.calib done
Test: [  0/391]	Time  3.798 ( 3.798)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.75
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=25, intgelu_exp_n=19
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=25, intgelu_exp_n=19, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  25
IntGELU    | n:  19
IntSoftmax | n:  25
IntGELU    | n:  19
IntSoftmax | n:  25
IntGELU    | n:  19
IntSoftmax | n:  25
IntGELU    | n:  19
IntSoftmax | n:  25
IntGELU    | n:  19
IntSoftmax | n:  25
IntGELU    | n:  19
IntSoftmax | n:  25
IntGELU    | n:  19
IntSoftmax | n:  25
IntGELU    | n:  19
IntSoftmax | n:  25
IntGELU    | n:  19
IntSoftmax | n:  25
IntGELU    | n:  19
IntSoftmax | n:  25
IntGELU    | n:  19
IntSoftmax | n:  25
IntGELU    | n:  19
.calib done
Test: [  0/391]	Time  3.961 ( 3.961)	Acc@1   0.00 (  0.00)	Acc@5   0.78 (  0.78)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.781
Time: 8.95
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=25, intgelu_exp_n=20
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=25, intgelu_exp_n=20, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  25
IntGELU    | n:  20
IntSoftmax | n:  25
IntGELU    | n:  20
IntSoftmax | n:  25
IntGELU    | n:  20
IntSoftmax | n:  25
IntGELU    | n:  20
IntSoftmax | n:  25
IntGELU    | n:  20
IntSoftmax | n:  25
IntGELU    | n:  20
IntSoftmax | n:  25
IntGELU    | n:  20
IntSoftmax | n:  25
IntGELU    | n:  20
IntSoftmax | n:  25
IntGELU    | n:  20
IntSoftmax | n:  25
IntGELU    | n:  20
IntSoftmax | n:  25
IntGELU    | n:  20
IntSoftmax | n:  25
IntGELU    | n:  20
.calib done
Test: [  0/391]	Time  3.662 ( 3.662)	Acc@1   0.78 (  0.78)	Acc@5   2.34 (  2.34)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.781 Prec@5 2.344
Time: 8.65
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=25, intgelu_exp_n=21
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=25, intgelu_exp_n=21, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  25
IntGELU    | n:  21
IntSoftmax | n:  25
IntGELU    | n:  21
IntSoftmax | n:  25
IntGELU    | n:  21
IntSoftmax | n:  25
IntGELU    | n:  21
IntSoftmax | n:  25
IntGELU    | n:  21
IntSoftmax | n:  25
IntGELU    | n:  21
IntSoftmax | n:  25
IntGELU    | n:  21
IntSoftmax | n:  25
IntGELU    | n:  21
IntSoftmax | n:  25
IntGELU    | n:  21
IntSoftmax | n:  25
IntGELU    | n:  21
IntSoftmax | n:  25
IntGELU    | n:  21
IntSoftmax | n:  25
IntGELU    | n:  21
.calib done
Test: [  0/391]	Time  3.884 ( 3.884)	Acc@1   0.00 (  0.00)	Acc@5   1.56 (  1.56)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 1.562
Time: 8.80
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=25, intgelu_exp_n=22
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=25, intgelu_exp_n=22, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  25
IntGELU    | n:  22
IntSoftmax | n:  25
IntGELU    | n:  22
IntSoftmax | n:  25
IntGELU    | n:  22
IntSoftmax | n:  25
IntGELU    | n:  22
IntSoftmax | n:  25
IntGELU    | n:  22
IntSoftmax | n:  25
IntGELU    | n:  22
IntSoftmax | n:  25
IntGELU    | n:  22
IntSoftmax | n:  25
IntGELU    | n:  22
IntSoftmax | n:  25
IntGELU    | n:  22
IntSoftmax | n:  25
IntGELU    | n:  22
IntSoftmax | n:  25
IntGELU    | n:  22
IntSoftmax | n:  25
IntGELU    | n:  22
.calib done
Test: [  0/391]	Time  3.879 ( 3.879)	Acc@1   0.78 (  0.78)	Acc@5   1.56 (  1.56)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.781 Prec@5 1.562
Time: 8.81
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=25, intgelu_exp_n=23
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=25, intgelu_exp_n=23, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  25
IntGELU    | n:  23
IntSoftmax | n:  25
IntGELU    | n:  23
IntSoftmax | n:  25
IntGELU    | n:  23
IntSoftmax | n:  25
IntGELU    | n:  23
IntSoftmax | n:  25
IntGELU    | n:  23
IntSoftmax | n:  25
IntGELU    | n:  23
IntSoftmax | n:  25
IntGELU    | n:  23
IntSoftmax | n:  25
IntGELU    | n:  23
IntSoftmax | n:  25
IntGELU    | n:  23
IntSoftmax | n:  25
IntGELU    | n:  23
IntSoftmax | n:  25
IntGELU    | n:  23
IntSoftmax | n:  25
IntGELU    | n:  23
.calib done
Test: [  0/391]	Time  3.897 ( 3.897)	Acc@1   0.00 (  0.00)	Acc@5   0.78 (  0.78)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.781
Time: 8.85
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=25, intgelu_exp_n=24
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=25, intgelu_exp_n=24, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  25
IntGELU    | n:  24
IntSoftmax | n:  25
IntGELU    | n:  24
IntSoftmax | n:  25
IntGELU    | n:  24
IntSoftmax | n:  25
IntGELU    | n:  24
IntSoftmax | n:  25
IntGELU    | n:  24
IntSoftmax | n:  25
IntGELU    | n:  24
IntSoftmax | n:  25
IntGELU    | n:  24
IntSoftmax | n:  25
IntGELU    | n:  24
IntSoftmax | n:  25
IntGELU    | n:  24
IntSoftmax | n:  25
IntGELU    | n:  24
IntSoftmax | n:  25
IntGELU    | n:  24
IntSoftmax | n:  25
IntGELU    | n:  24
.calib done
Test: [  0/391]	Time  3.860 ( 3.860)	Acc@1   3.91 (  3.91)	Acc@5   9.38 (  9.38)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 3.906 Prec@5 9.375
Time: 8.82
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=25, intgelu_exp_n=25
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=25, intgelu_exp_n=25, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  25
IntGELU    | n:  25
IntSoftmax | n:  25
IntGELU    | n:  25
IntSoftmax | n:  25
IntGELU    | n:  25
IntSoftmax | n:  25
IntGELU    | n:  25
IntSoftmax | n:  25
IntGELU    | n:  25
IntSoftmax | n:  25
IntGELU    | n:  25
IntSoftmax | n:  25
IntGELU    | n:  25
IntSoftmax | n:  25
IntGELU    | n:  25
IntSoftmax | n:  25
IntGELU    | n:  25
IntSoftmax | n:  25
IntGELU    | n:  25
IntSoftmax | n:  25
IntGELU    | n:  25
IntSoftmax | n:  25
IntGELU    | n:  25
.calib done
Test: [  0/391]	Time  3.720 ( 3.720)	Acc@1   1.56 (  1.56)	Acc@5   7.81 (  7.81)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 1.562 Prec@5 7.812
Time: 8.69
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=25, intgelu_exp_n=26
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=25, intgelu_exp_n=26, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  25
IntGELU    | n:  26
IntSoftmax | n:  25
IntGELU    | n:  26
IntSoftmax | n:  25
IntGELU    | n:  26
IntSoftmax | n:  25
IntGELU    | n:  26
IntSoftmax | n:  25
IntGELU    | n:  26
IntSoftmax | n:  25
IntGELU    | n:  26
IntSoftmax | n:  25
IntGELU    | n:  26
IntSoftmax | n:  25
IntGELU    | n:  26
IntSoftmax | n:  25
IntGELU    | n:  26
IntSoftmax | n:  25
IntGELU    | n:  26
IntSoftmax | n:  25
IntGELU    | n:  26
IntSoftmax | n:  25
IntGELU    | n:  26
.calib done
Test: [  0/391]	Time  3.971 ( 3.971)	Acc@1   0.78 (  0.78)	Acc@5  10.94 ( 10.94)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.781 Prec@5 10.938
Time: 8.95
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=25, intgelu_exp_n=27
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=25, intgelu_exp_n=27, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  25
IntGELU    | n:  27
IntSoftmax | n:  25
IntGELU    | n:  27
IntSoftmax | n:  25
IntGELU    | n:  27
IntSoftmax | n:  25
IntGELU    | n:  27
IntSoftmax | n:  25
IntGELU    | n:  27
IntSoftmax | n:  25
IntGELU    | n:  27
IntSoftmax | n:  25
IntGELU    | n:  27
IntSoftmax | n:  25
IntGELU    | n:  27
IntSoftmax | n:  25
IntGELU    | n:  27
IntSoftmax | n:  25
IntGELU    | n:  27
IntSoftmax | n:  25
IntGELU    | n:  27
IntSoftmax | n:  25
IntGELU    | n:  27
.calib done
Test: [  0/391]	Time  3.985 ( 3.985)	Acc@1  11.72 ( 11.72)	Acc@5  23.44 ( 23.44)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 11.719 Prec@5 23.438
Time: 8.96
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=25, intgelu_exp_n=28
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=25, intgelu_exp_n=28, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  25
IntGELU    | n:  28
IntSoftmax | n:  25
IntGELU    | n:  28
IntSoftmax | n:  25
IntGELU    | n:  28
IntSoftmax | n:  25
IntGELU    | n:  28
IntSoftmax | n:  25
IntGELU    | n:  28
IntSoftmax | n:  25
IntGELU    | n:  28
IntSoftmax | n:  25
IntGELU    | n:  28
IntSoftmax | n:  25
IntGELU    | n:  28
IntSoftmax | n:  25
IntGELU    | n:  28
IntSoftmax | n:  25
IntGELU    | n:  28
IntSoftmax | n:  25
IntGELU    | n:  28
IntSoftmax | n:  25
IntGELU    | n:  28
.calib done
Test: [  0/391]	Time  3.939 ( 3.939)	Acc@1  26.56 ( 26.56)	Acc@5  41.41 ( 41.41)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 26.562 Prec@5 41.406
Time: 8.98
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=25, intgelu_exp_n=29
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=25, intgelu_exp_n=29, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  25
IntGELU    | n:  29
IntSoftmax | n:  25
IntGELU    | n:  29
IntSoftmax | n:  25
IntGELU    | n:  29
IntSoftmax | n:  25
IntGELU    | n:  29
IntSoftmax | n:  25
IntGELU    | n:  29
IntSoftmax | n:  25
IntGELU    | n:  29
IntSoftmax | n:  25
IntGELU    | n:  29
IntSoftmax | n:  25
IntGELU    | n:  29
IntSoftmax | n:  25
IntGELU    | n:  29
IntSoftmax | n:  25
IntGELU    | n:  29
IntSoftmax | n:  25
IntGELU    | n:  29
IntSoftmax | n:  25
IntGELU    | n:  29
.calib done
Test: [  0/391]	Time  3.959 ( 3.959)	Acc@1  42.97 ( 42.97)	Acc@5  64.84 ( 64.84)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 42.969 Prec@5 64.844
Time: 8.89
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=25, intgelu_exp_n=30
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=25, intgelu_exp_n=30, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  25
IntGELU    | n:  30
IntSoftmax | n:  25
IntGELU    | n:  30
IntSoftmax | n:  25
IntGELU    | n:  30
IntSoftmax | n:  25
IntGELU    | n:  30
IntSoftmax | n:  25
IntGELU    | n:  30
IntSoftmax | n:  25
IntGELU    | n:  30
IntSoftmax | n:  25
IntGELU    | n:  30
IntSoftmax | n:  25
IntGELU    | n:  30
IntSoftmax | n:  25
IntGELU    | n:  30
IntSoftmax | n:  25
IntGELU    | n:  30
IntSoftmax | n:  25
IntGELU    | n:  30
IntSoftmax | n:  25
IntGELU    | n:  30
.calib done
Test: [  0/391]	Time  4.052 ( 4.052)	Acc@1  57.81 ( 57.81)	Acc@5  73.44 ( 73.44)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 57.812 Prec@5 73.438
Time: 9.00
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=25, intgelu_exp_n=31
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=25, intgelu_exp_n=31, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  25
IntGELU    | n:  31
IntSoftmax | n:  25
IntGELU    | n:  31
IntSoftmax | n:  25
IntGELU    | n:  31
IntSoftmax | n:  25
IntGELU    | n:  31
IntSoftmax | n:  25
IntGELU    | n:  31
IntSoftmax | n:  25
IntGELU    | n:  31
IntSoftmax | n:  25
IntGELU    | n:  31
IntSoftmax | n:  25
IntGELU    | n:  31
IntSoftmax | n:  25
IntGELU    | n:  31
IntSoftmax | n:  25
IntGELU    | n:  31
IntSoftmax | n:  25
IntGELU    | n:  31
IntSoftmax | n:  25
IntGELU    | n:  31
.calib done
Test: [  0/391]	Time  4.002 ( 4.002)	Acc@1   1.56 (  1.56)	Acc@5   4.69 (  4.69)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 1.562 Prec@5 4.688
Time: 8.98
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=26, intgelu_exp_n=0
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=26, intgelu_exp_n=0, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  26
IntGELU    | n:  0
IntSoftmax | n:  26
IntGELU    | n:  0
IntSoftmax | n:  26
IntGELU    | n:  0
IntSoftmax | n:  26
IntGELU    | n:  0
IntSoftmax | n:  26
IntGELU    | n:  0
IntSoftmax | n:  26
IntGELU    | n:  0
IntSoftmax | n:  26
IntGELU    | n:  0
IntSoftmax | n:  26
IntGELU    | n:  0
IntSoftmax | n:  26
IntGELU    | n:  0
IntSoftmax | n:  26
IntGELU    | n:  0
IntSoftmax | n:  26
IntGELU    | n:  0
IntSoftmax | n:  26
IntGELU    | n:  0
.calib done
Test: [  0/391]	Time  3.951 ( 3.951)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.90
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=26, intgelu_exp_n=1
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=26, intgelu_exp_n=1, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  26
IntGELU    | n:  1
IntSoftmax | n:  26
IntGELU    | n:  1
IntSoftmax | n:  26
IntGELU    | n:  1
IntSoftmax | n:  26
IntGELU    | n:  1
IntSoftmax | n:  26
IntGELU    | n:  1
IntSoftmax | n:  26
IntGELU    | n:  1
IntSoftmax | n:  26
IntGELU    | n:  1
IntSoftmax | n:  26
IntGELU    | n:  1
IntSoftmax | n:  26
IntGELU    | n:  1
IntSoftmax | n:  26
IntGELU    | n:  1
IntSoftmax | n:  26
IntGELU    | n:  1
IntSoftmax | n:  26
IntGELU    | n:  1
.calib done
Test: [  0/391]	Time  3.896 ( 3.896)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.84
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=26, intgelu_exp_n=2
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=26, intgelu_exp_n=2, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  26
IntGELU    | n:  2
IntSoftmax | n:  26
IntGELU    | n:  2
IntSoftmax | n:  26
IntGELU    | n:  2
IntSoftmax | n:  26
IntGELU    | n:  2
IntSoftmax | n:  26
IntGELU    | n:  2
IntSoftmax | n:  26
IntGELU    | n:  2
IntSoftmax | n:  26
IntGELU    | n:  2
IntSoftmax | n:  26
IntGELU    | n:  2
IntSoftmax | n:  26
IntGELU    | n:  2
IntSoftmax | n:  26
IntGELU    | n:  2
IntSoftmax | n:  26
IntGELU    | n:  2
IntSoftmax | n:  26
IntGELU    | n:  2
.calib done
Test: [  0/391]	Time  3.753 ( 3.753)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.70
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=26, intgelu_exp_n=3
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=26, intgelu_exp_n=3, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  26
IntGELU    | n:  3
IntSoftmax | n:  26
IntGELU    | n:  3
IntSoftmax | n:  26
IntGELU    | n:  3
IntSoftmax | n:  26
IntGELU    | n:  3
IntSoftmax | n:  26
IntGELU    | n:  3
IntSoftmax | n:  26
IntGELU    | n:  3
IntSoftmax | n:  26
IntGELU    | n:  3
IntSoftmax | n:  26
IntGELU    | n:  3
IntSoftmax | n:  26
IntGELU    | n:  3
IntSoftmax | n:  26
IntGELU    | n:  3
IntSoftmax | n:  26
IntGELU    | n:  3
IntSoftmax | n:  26
IntGELU    | n:  3
.calib done
Test: [  0/391]	Time  3.940 ( 3.940)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.88
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=26, intgelu_exp_n=4
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=26, intgelu_exp_n=4, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  26
IntGELU    | n:  4
IntSoftmax | n:  26
IntGELU    | n:  4
IntSoftmax | n:  26
IntGELU    | n:  4
IntSoftmax | n:  26
IntGELU    | n:  4
IntSoftmax | n:  26
IntGELU    | n:  4
IntSoftmax | n:  26
IntGELU    | n:  4
IntSoftmax | n:  26
IntGELU    | n:  4
IntSoftmax | n:  26
IntGELU    | n:  4
IntSoftmax | n:  26
IntGELU    | n:  4
IntSoftmax | n:  26
IntGELU    | n:  4
IntSoftmax | n:  26
IntGELU    | n:  4
IntSoftmax | n:  26
IntGELU    | n:  4
.calib done
Test: [  0/391]	Time  3.847 ( 3.847)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.79
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=26, intgelu_exp_n=5
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=26, intgelu_exp_n=5, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  26
IntGELU    | n:  5
IntSoftmax | n:  26
IntGELU    | n:  5
IntSoftmax | n:  26
IntGELU    | n:  5
IntSoftmax | n:  26
IntGELU    | n:  5
IntSoftmax | n:  26
IntGELU    | n:  5
IntSoftmax | n:  26
IntGELU    | n:  5
IntSoftmax | n:  26
IntGELU    | n:  5
IntSoftmax | n:  26
IntGELU    | n:  5
IntSoftmax | n:  26
IntGELU    | n:  5
IntSoftmax | n:  26
IntGELU    | n:  5
IntSoftmax | n:  26
IntGELU    | n:  5
IntSoftmax | n:  26
IntGELU    | n:  5
.calib done
Test: [  0/391]	Time  3.991 ( 3.991)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.97
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=26, intgelu_exp_n=6
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=26, intgelu_exp_n=6, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  26
IntGELU    | n:  6
IntSoftmax | n:  26
IntGELU    | n:  6
IntSoftmax | n:  26
IntGELU    | n:  6
IntSoftmax | n:  26
IntGELU    | n:  6
IntSoftmax | n:  26
IntGELU    | n:  6
IntSoftmax | n:  26
IntGELU    | n:  6
IntSoftmax | n:  26
IntGELU    | n:  6
IntSoftmax | n:  26
IntGELU    | n:  6
IntSoftmax | n:  26
IntGELU    | n:  6
IntSoftmax | n:  26
IntGELU    | n:  6
IntSoftmax | n:  26
IntGELU    | n:  6
IntSoftmax | n:  26
IntGELU    | n:  6
.calib done
Test: [  0/391]	Time  3.893 ( 3.893)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.80
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=26, intgelu_exp_n=7
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=26, intgelu_exp_n=7, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  26
IntGELU    | n:  7
IntSoftmax | n:  26
IntGELU    | n:  7
IntSoftmax | n:  26
IntGELU    | n:  7
IntSoftmax | n:  26
IntGELU    | n:  7
IntSoftmax | n:  26
IntGELU    | n:  7
IntSoftmax | n:  26
IntGELU    | n:  7
IntSoftmax | n:  26
IntGELU    | n:  7
IntSoftmax | n:  26
IntGELU    | n:  7
IntSoftmax | n:  26
IntGELU    | n:  7
IntSoftmax | n:  26
IntGELU    | n:  7
IntSoftmax | n:  26
IntGELU    | n:  7
IntSoftmax | n:  26
IntGELU    | n:  7
.calib done
Test: [  0/391]	Time  3.733 ( 3.733)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.68
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=26, intgelu_exp_n=8
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=26, intgelu_exp_n=8, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  26
IntGELU    | n:  8
IntSoftmax | n:  26
IntGELU    | n:  8
IntSoftmax | n:  26
IntGELU    | n:  8
IntSoftmax | n:  26
IntGELU    | n:  8
IntSoftmax | n:  26
IntGELU    | n:  8
IntSoftmax | n:  26
IntGELU    | n:  8
IntSoftmax | n:  26
IntGELU    | n:  8
IntSoftmax | n:  26
IntGELU    | n:  8
IntSoftmax | n:  26
IntGELU    | n:  8
IntSoftmax | n:  26
IntGELU    | n:  8
IntSoftmax | n:  26
IntGELU    | n:  8
IntSoftmax | n:  26
IntGELU    | n:  8
.calib done
Test: [  0/391]	Time  3.870 ( 3.870)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.85
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=26, intgelu_exp_n=9
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=26, intgelu_exp_n=9, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  26
IntGELU    | n:  9
IntSoftmax | n:  26
IntGELU    | n:  9
IntSoftmax | n:  26
IntGELU    | n:  9
IntSoftmax | n:  26
IntGELU    | n:  9
IntSoftmax | n:  26
IntGELU    | n:  9
IntSoftmax | n:  26
IntGELU    | n:  9
IntSoftmax | n:  26
IntGELU    | n:  9
IntSoftmax | n:  26
IntGELU    | n:  9
IntSoftmax | n:  26
IntGELU    | n:  9
IntSoftmax | n:  26
IntGELU    | n:  9
IntSoftmax | n:  26
IntGELU    | n:  9
IntSoftmax | n:  26
IntGELU    | n:  9
.calib done
Test: [  0/391]	Time  3.963 ( 3.963)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.89
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=26, intgelu_exp_n=10
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=26, intgelu_exp_n=10, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  26
IntGELU    | n:  10
IntSoftmax | n:  26
IntGELU    | n:  10
IntSoftmax | n:  26
IntGELU    | n:  10
IntSoftmax | n:  26
IntGELU    | n:  10
IntSoftmax | n:  26
IntGELU    | n:  10
IntSoftmax | n:  26
IntGELU    | n:  10
IntSoftmax | n:  26
IntGELU    | n:  10
IntSoftmax | n:  26
IntGELU    | n:  10
IntSoftmax | n:  26
IntGELU    | n:  10
IntSoftmax | n:  26
IntGELU    | n:  10
IntSoftmax | n:  26
IntGELU    | n:  10
IntSoftmax | n:  26
IntGELU    | n:  10
.calib done
Test: [  0/391]	Time  3.930 ( 3.930)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.86
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=26, intgelu_exp_n=11
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=26, intgelu_exp_n=11, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  26
IntGELU    | n:  11
IntSoftmax | n:  26
IntGELU    | n:  11
IntSoftmax | n:  26
IntGELU    | n:  11
IntSoftmax | n:  26
IntGELU    | n:  11
IntSoftmax | n:  26
IntGELU    | n:  11
IntSoftmax | n:  26
IntGELU    | n:  11
IntSoftmax | n:  26
IntGELU    | n:  11
IntSoftmax | n:  26
IntGELU    | n:  11
IntSoftmax | n:  26
IntGELU    | n:  11
IntSoftmax | n:  26
IntGELU    | n:  11
IntSoftmax | n:  26
IntGELU    | n:  11
IntSoftmax | n:  26
IntGELU    | n:  11
.calib done
Test: [  0/391]	Time  3.931 ( 3.931)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.93
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=26, intgelu_exp_n=12
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=26, intgelu_exp_n=12, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  26
IntGELU    | n:  12
IntSoftmax | n:  26
IntGELU    | n:  12
IntSoftmax | n:  26
IntGELU    | n:  12
IntSoftmax | n:  26
IntGELU    | n:  12
IntSoftmax | n:  26
IntGELU    | n:  12
IntSoftmax | n:  26
IntGELU    | n:  12
IntSoftmax | n:  26
IntGELU    | n:  12
IntSoftmax | n:  26
IntGELU    | n:  12
IntSoftmax | n:  26
IntGELU    | n:  12
IntSoftmax | n:  26
IntGELU    | n:  12
IntSoftmax | n:  26
IntGELU    | n:  12
IntSoftmax | n:  26
IntGELU    | n:  12
.calib done
Test: [  0/391]	Time  3.726 ( 3.726)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.69
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=26, intgelu_exp_n=13
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=26, intgelu_exp_n=13, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  26
IntGELU    | n:  13
IntSoftmax | n:  26
IntGELU    | n:  13
IntSoftmax | n:  26
IntGELU    | n:  13
IntSoftmax | n:  26
IntGELU    | n:  13
IntSoftmax | n:  26
IntGELU    | n:  13
IntSoftmax | n:  26
IntGELU    | n:  13
IntSoftmax | n:  26
IntGELU    | n:  13
IntSoftmax | n:  26
IntGELU    | n:  13
IntSoftmax | n:  26
IntGELU    | n:  13
IntSoftmax | n:  26
IntGELU    | n:  13
IntSoftmax | n:  26
IntGELU    | n:  13
IntSoftmax | n:  26
IntGELU    | n:  13
.calib done
Test: [  0/391]	Time  3.754 ( 3.754)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.75
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=26, intgelu_exp_n=14
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=26, intgelu_exp_n=14, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  26
IntGELU    | n:  14
IntSoftmax | n:  26
IntGELU    | n:  14
IntSoftmax | n:  26
IntGELU    | n:  14
IntSoftmax | n:  26
IntGELU    | n:  14
IntSoftmax | n:  26
IntGELU    | n:  14
IntSoftmax | n:  26
IntGELU    | n:  14
IntSoftmax | n:  26
IntGELU    | n:  14
IntSoftmax | n:  26
IntGELU    | n:  14
IntSoftmax | n:  26
IntGELU    | n:  14
IntSoftmax | n:  26
IntGELU    | n:  14
IntSoftmax | n:  26
IntGELU    | n:  14
IntSoftmax | n:  26
IntGELU    | n:  14
.calib done
Test: [  0/391]	Time  3.701 ( 3.701)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.58
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=26, intgelu_exp_n=15
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=26, intgelu_exp_n=15, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  26
IntGELU    | n:  15
IntSoftmax | n:  26
IntGELU    | n:  15
IntSoftmax | n:  26
IntGELU    | n:  15
IntSoftmax | n:  26
IntGELU    | n:  15
IntSoftmax | n:  26
IntGELU    | n:  15
IntSoftmax | n:  26
IntGELU    | n:  15
IntSoftmax | n:  26
IntGELU    | n:  15
IntSoftmax | n:  26
IntGELU    | n:  15
IntSoftmax | n:  26
IntGELU    | n:  15
IntSoftmax | n:  26
IntGELU    | n:  15
IntSoftmax | n:  26
IntGELU    | n:  15
IntSoftmax | n:  26
IntGELU    | n:  15
.calib done
Test: [  0/391]	Time  3.998 ( 3.998)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.98
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=26, intgelu_exp_n=16
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=26, intgelu_exp_n=16, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  26
IntGELU    | n:  16
IntSoftmax | n:  26
IntGELU    | n:  16
IntSoftmax | n:  26
IntGELU    | n:  16
IntSoftmax | n:  26
IntGELU    | n:  16
IntSoftmax | n:  26
IntGELU    | n:  16
IntSoftmax | n:  26
IntGELU    | n:  16
IntSoftmax | n:  26
IntGELU    | n:  16
IntSoftmax | n:  26
IntGELU    | n:  16
IntSoftmax | n:  26
IntGELU    | n:  16
IntSoftmax | n:  26
IntGELU    | n:  16
IntSoftmax | n:  26
IntGELU    | n:  16
IntSoftmax | n:  26
IntGELU    | n:  16
.calib done
Test: [  0/391]	Time  3.945 ( 3.945)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.86
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=26, intgelu_exp_n=17
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=26, intgelu_exp_n=17, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  26
IntGELU    | n:  17
IntSoftmax | n:  26
IntGELU    | n:  17
IntSoftmax | n:  26
IntGELU    | n:  17
IntSoftmax | n:  26
IntGELU    | n:  17
IntSoftmax | n:  26
IntGELU    | n:  17
IntSoftmax | n:  26
IntGELU    | n:  17
IntSoftmax | n:  26
IntGELU    | n:  17
IntSoftmax | n:  26
IntGELU    | n:  17
IntSoftmax | n:  26
IntGELU    | n:  17
IntSoftmax | n:  26
IntGELU    | n:  17
IntSoftmax | n:  26
IntGELU    | n:  17
IntSoftmax | n:  26
IntGELU    | n:  17
.calib done
Test: [  0/391]	Time  3.858 ( 3.858)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.83
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=26, intgelu_exp_n=18
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=26, intgelu_exp_n=18, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  26
IntGELU    | n:  18
IntSoftmax | n:  26
IntGELU    | n:  18
IntSoftmax | n:  26
IntGELU    | n:  18
IntSoftmax | n:  26
IntGELU    | n:  18
IntSoftmax | n:  26
IntGELU    | n:  18
IntSoftmax | n:  26
IntGELU    | n:  18
IntSoftmax | n:  26
IntGELU    | n:  18
IntSoftmax | n:  26
IntGELU    | n:  18
IntSoftmax | n:  26
IntGELU    | n:  18
IntSoftmax | n:  26
IntGELU    | n:  18
IntSoftmax | n:  26
IntGELU    | n:  18
IntSoftmax | n:  26
IntGELU    | n:  18
.calib done
Test: [  0/391]	Time  4.008 ( 4.008)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.97
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=26, intgelu_exp_n=19
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=26, intgelu_exp_n=19, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  26
IntGELU    | n:  19
IntSoftmax | n:  26
IntGELU    | n:  19
IntSoftmax | n:  26
IntGELU    | n:  19
IntSoftmax | n:  26
IntGELU    | n:  19
IntSoftmax | n:  26
IntGELU    | n:  19
IntSoftmax | n:  26
IntGELU    | n:  19
IntSoftmax | n:  26
IntGELU    | n:  19
IntSoftmax | n:  26
IntGELU    | n:  19
IntSoftmax | n:  26
IntGELU    | n:  19
IntSoftmax | n:  26
IntGELU    | n:  19
IntSoftmax | n:  26
IntGELU    | n:  19
IntSoftmax | n:  26
IntGELU    | n:  19
.calib done
Test: [  0/391]	Time  3.906 ( 3.906)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.87
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=26, intgelu_exp_n=20
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=26, intgelu_exp_n=20, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  26
IntGELU    | n:  20
IntSoftmax | n:  26
IntGELU    | n:  20
IntSoftmax | n:  26
IntGELU    | n:  20
IntSoftmax | n:  26
IntGELU    | n:  20
IntSoftmax | n:  26
IntGELU    | n:  20
IntSoftmax | n:  26
IntGELU    | n:  20
IntSoftmax | n:  26
IntGELU    | n:  20
IntSoftmax | n:  26
IntGELU    | n:  20
IntSoftmax | n:  26
IntGELU    | n:  20
IntSoftmax | n:  26
IntGELU    | n:  20
IntSoftmax | n:  26
IntGELU    | n:  20
IntSoftmax | n:  26
IntGELU    | n:  20
.calib done
Test: [  0/391]	Time  3.844 ( 3.844)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.81
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=26, intgelu_exp_n=21
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=26, intgelu_exp_n=21, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  26
IntGELU    | n:  21
IntSoftmax | n:  26
IntGELU    | n:  21
IntSoftmax | n:  26
IntGELU    | n:  21
IntSoftmax | n:  26
IntGELU    | n:  21
IntSoftmax | n:  26
IntGELU    | n:  21
IntSoftmax | n:  26
IntGELU    | n:  21
IntSoftmax | n:  26
IntGELU    | n:  21
IntSoftmax | n:  26
IntGELU    | n:  21
IntSoftmax | n:  26
IntGELU    | n:  21
IntSoftmax | n:  26
IntGELU    | n:  21
IntSoftmax | n:  26
IntGELU    | n:  21
IntSoftmax | n:  26
IntGELU    | n:  21
.calib done
Test: [  0/391]	Time  3.986 ( 3.986)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.92
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=26, intgelu_exp_n=22
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=26, intgelu_exp_n=22, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  26
IntGELU    | n:  22
IntSoftmax | n:  26
IntGELU    | n:  22
IntSoftmax | n:  26
IntGELU    | n:  22
IntSoftmax | n:  26
IntGELU    | n:  22
IntSoftmax | n:  26
IntGELU    | n:  22
IntSoftmax | n:  26
IntGELU    | n:  22
IntSoftmax | n:  26
IntGELU    | n:  22
IntSoftmax | n:  26
IntGELU    | n:  22
IntSoftmax | n:  26
IntGELU    | n:  22
IntSoftmax | n:  26
IntGELU    | n:  22
IntSoftmax | n:  26
IntGELU    | n:  22
IntSoftmax | n:  26
IntGELU    | n:  22
.calib done
Test: [  0/391]	Time  3.903 ( 3.903)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.83
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=26, intgelu_exp_n=23
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=26, intgelu_exp_n=23, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  26
IntGELU    | n:  23
IntSoftmax | n:  26
IntGELU    | n:  23
IntSoftmax | n:  26
IntGELU    | n:  23
IntSoftmax | n:  26
IntGELU    | n:  23
IntSoftmax | n:  26
IntGELU    | n:  23
IntSoftmax | n:  26
IntGELU    | n:  23
IntSoftmax | n:  26
IntGELU    | n:  23
IntSoftmax | n:  26
IntGELU    | n:  23
IntSoftmax | n:  26
IntGELU    | n:  23
IntSoftmax | n:  26
IntGELU    | n:  23
IntSoftmax | n:  26
IntGELU    | n:  23
IntSoftmax | n:  26
IntGELU    | n:  23
.calib done
Test: [  0/391]	Time  3.985 ( 3.985)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 9.00
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=26, intgelu_exp_n=24
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=26, intgelu_exp_n=24, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  26
IntGELU    | n:  24
IntSoftmax | n:  26
IntGELU    | n:  24
IntSoftmax | n:  26
IntGELU    | n:  24
IntSoftmax | n:  26
IntGELU    | n:  24
IntSoftmax | n:  26
IntGELU    | n:  24
IntSoftmax | n:  26
IntGELU    | n:  24
IntSoftmax | n:  26
IntGELU    | n:  24
IntSoftmax | n:  26
IntGELU    | n:  24
IntSoftmax | n:  26
IntGELU    | n:  24
IntSoftmax | n:  26
IntGELU    | n:  24
IntSoftmax | n:  26
IntGELU    | n:  24
IntSoftmax | n:  26
IntGELU    | n:  24
.calib done
Test: [  0/391]	Time  3.913 ( 3.913)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.82
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=26, intgelu_exp_n=25
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=26, intgelu_exp_n=25, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  26
IntGELU    | n:  25
IntSoftmax | n:  26
IntGELU    | n:  25
IntSoftmax | n:  26
IntGELU    | n:  25
IntSoftmax | n:  26
IntGELU    | n:  25
IntSoftmax | n:  26
IntGELU    | n:  25
IntSoftmax | n:  26
IntGELU    | n:  25
IntSoftmax | n:  26
IntGELU    | n:  25
IntSoftmax | n:  26
IntGELU    | n:  25
IntSoftmax | n:  26
IntGELU    | n:  25
IntSoftmax | n:  26
IntGELU    | n:  25
IntSoftmax | n:  26
IntGELU    | n:  25
IntSoftmax | n:  26
IntGELU    | n:  25
.calib done
Test: [  0/391]	Time  3.925 ( 3.925)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.91
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=26, intgelu_exp_n=26
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=26, intgelu_exp_n=26, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  26
IntGELU    | n:  26
IntSoftmax | n:  26
IntGELU    | n:  26
IntSoftmax | n:  26
IntGELU    | n:  26
IntSoftmax | n:  26
IntGELU    | n:  26
IntSoftmax | n:  26
IntGELU    | n:  26
IntSoftmax | n:  26
IntGELU    | n:  26
IntSoftmax | n:  26
IntGELU    | n:  26
IntSoftmax | n:  26
IntGELU    | n:  26
IntSoftmax | n:  26
IntGELU    | n:  26
IntSoftmax | n:  26
IntGELU    | n:  26
IntSoftmax | n:  26
IntGELU    | n:  26
IntSoftmax | n:  26
IntGELU    | n:  26
.calib done
Test: [  0/391]	Time  3.845 ( 3.845)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.78
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=26, intgelu_exp_n=27
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=26, intgelu_exp_n=27, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  26
IntGELU    | n:  27
IntSoftmax | n:  26
IntGELU    | n:  27
IntSoftmax | n:  26
IntGELU    | n:  27
IntSoftmax | n:  26
IntGELU    | n:  27
IntSoftmax | n:  26
IntGELU    | n:  27
IntSoftmax | n:  26
IntGELU    | n:  27
IntSoftmax | n:  26
IntGELU    | n:  27
IntSoftmax | n:  26
IntGELU    | n:  27
IntSoftmax | n:  26
IntGELU    | n:  27
IntSoftmax | n:  26
IntGELU    | n:  27
IntSoftmax | n:  26
IntGELU    | n:  27
IntSoftmax | n:  26
IntGELU    | n:  27
.calib done
Test: [  0/391]	Time  3.931 ( 3.931)	Acc@1   0.00 (  0.00)	Acc@5   0.78 (  0.78)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.781
Time: 8.87
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=26, intgelu_exp_n=28
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=26, intgelu_exp_n=28, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  26
IntGELU    | n:  28
IntSoftmax | n:  26
IntGELU    | n:  28
IntSoftmax | n:  26
IntGELU    | n:  28
IntSoftmax | n:  26
IntGELU    | n:  28
IntSoftmax | n:  26
IntGELU    | n:  28
IntSoftmax | n:  26
IntGELU    | n:  28
IntSoftmax | n:  26
IntGELU    | n:  28
IntSoftmax | n:  26
IntGELU    | n:  28
IntSoftmax | n:  26
IntGELU    | n:  28
IntSoftmax | n:  26
IntGELU    | n:  28
IntSoftmax | n:  26
IntGELU    | n:  28
IntSoftmax | n:  26
IntGELU    | n:  28
.calib done
Test: [  0/391]	Time  3.962 ( 3.962)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.93
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=26, intgelu_exp_n=29
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=26, intgelu_exp_n=29, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  26
IntGELU    | n:  29
IntSoftmax | n:  26
IntGELU    | n:  29
IntSoftmax | n:  26
IntGELU    | n:  29
IntSoftmax | n:  26
IntGELU    | n:  29
IntSoftmax | n:  26
IntGELU    | n:  29
IntSoftmax | n:  26
IntGELU    | n:  29
IntSoftmax | n:  26
IntGELU    | n:  29
IntSoftmax | n:  26
IntGELU    | n:  29
IntSoftmax | n:  26
IntGELU    | n:  29
IntSoftmax | n:  26
IntGELU    | n:  29
IntSoftmax | n:  26
IntGELU    | n:  29
IntSoftmax | n:  26
IntGELU    | n:  29
.calib done
Test: [  0/391]	Time  3.842 ( 3.842)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.79
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=26, intgelu_exp_n=30
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=26, intgelu_exp_n=30, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  26
IntGELU    | n:  30
IntSoftmax | n:  26
IntGELU    | n:  30
IntSoftmax | n:  26
IntGELU    | n:  30
IntSoftmax | n:  26
IntGELU    | n:  30
IntSoftmax | n:  26
IntGELU    | n:  30
IntSoftmax | n:  26
IntGELU    | n:  30
IntSoftmax | n:  26
IntGELU    | n:  30
IntSoftmax | n:  26
IntGELU    | n:  30
IntSoftmax | n:  26
IntGELU    | n:  30
IntSoftmax | n:  26
IntGELU    | n:  30
IntSoftmax | n:  26
IntGELU    | n:  30
IntSoftmax | n:  26
IntGELU    | n:  30
.calib done
Test: [  0/391]	Time  3.880 ( 3.880)	Acc@1   0.78 (  0.78)	Acc@5   1.56 (  1.56)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.781 Prec@5 1.562
Time: 8.83
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=26, intgelu_exp_n=31
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=26, intgelu_exp_n=31, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  26
IntGELU    | n:  31
IntSoftmax | n:  26
IntGELU    | n:  31
IntSoftmax | n:  26
IntGELU    | n:  31
IntSoftmax | n:  26
IntGELU    | n:  31
IntSoftmax | n:  26
IntGELU    | n:  31
IntSoftmax | n:  26
IntGELU    | n:  31
IntSoftmax | n:  26
IntGELU    | n:  31
IntSoftmax | n:  26
IntGELU    | n:  31
IntSoftmax | n:  26
IntGELU    | n:  31
IntSoftmax | n:  26
IntGELU    | n:  31
IntSoftmax | n:  26
IntGELU    | n:  31
IntSoftmax | n:  26
IntGELU    | n:  31
.calib done
Test: [  0/391]	Time  3.986 ( 3.986)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.94
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=27, intgelu_exp_n=0
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=27, intgelu_exp_n=0, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  27
IntGELU    | n:  0
IntSoftmax | n:  27
IntGELU    | n:  0
IntSoftmax | n:  27
IntGELU    | n:  0
IntSoftmax | n:  27
IntGELU    | n:  0
IntSoftmax | n:  27
IntGELU    | n:  0
IntSoftmax | n:  27
IntGELU    | n:  0
IntSoftmax | n:  27
IntGELU    | n:  0
IntSoftmax | n:  27
IntGELU    | n:  0
IntSoftmax | n:  27
IntGELU    | n:  0
IntSoftmax | n:  27
IntGELU    | n:  0
IntSoftmax | n:  27
IntGELU    | n:  0
IntSoftmax | n:  27
IntGELU    | n:  0
.calib done
Test: [  0/391]	Time  3.997 ( 3.997)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 9.01
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=27, intgelu_exp_n=1
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=27, intgelu_exp_n=1, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  27
IntGELU    | n:  1
IntSoftmax | n:  27
IntGELU    | n:  1
IntSoftmax | n:  27
IntGELU    | n:  1
IntSoftmax | n:  27
IntGELU    | n:  1
IntSoftmax | n:  27
IntGELU    | n:  1
IntSoftmax | n:  27
IntGELU    | n:  1
IntSoftmax | n:  27
IntGELU    | n:  1
IntSoftmax | n:  27
IntGELU    | n:  1
IntSoftmax | n:  27
IntGELU    | n:  1
IntSoftmax | n:  27
IntGELU    | n:  1
IntSoftmax | n:  27
IntGELU    | n:  1
IntSoftmax | n:  27
IntGELU    | n:  1
.calib done
Test: [  0/391]	Time  3.882 ( 3.882)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.84
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=27, intgelu_exp_n=2
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=27, intgelu_exp_n=2, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  27
IntGELU    | n:  2
IntSoftmax | n:  27
IntGELU    | n:  2
IntSoftmax | n:  27
IntGELU    | n:  2
IntSoftmax | n:  27
IntGELU    | n:  2
IntSoftmax | n:  27
IntGELU    | n:  2
IntSoftmax | n:  27
IntGELU    | n:  2
IntSoftmax | n:  27
IntGELU    | n:  2
IntSoftmax | n:  27
IntGELU    | n:  2
IntSoftmax | n:  27
IntGELU    | n:  2
IntSoftmax | n:  27
IntGELU    | n:  2
IntSoftmax | n:  27
IntGELU    | n:  2
IntSoftmax | n:  27
IntGELU    | n:  2
.calib done
Test: [  0/391]	Time  3.715 ( 3.715)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.64
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=27, intgelu_exp_n=3
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=27, intgelu_exp_n=3, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  27
IntGELU    | n:  3
IntSoftmax | n:  27
IntGELU    | n:  3
IntSoftmax | n:  27
IntGELU    | n:  3
IntSoftmax | n:  27
IntGELU    | n:  3
IntSoftmax | n:  27
IntGELU    | n:  3
IntSoftmax | n:  27
IntGELU    | n:  3
IntSoftmax | n:  27
IntGELU    | n:  3
IntSoftmax | n:  27
IntGELU    | n:  3
IntSoftmax | n:  27
IntGELU    | n:  3
IntSoftmax | n:  27
IntGELU    | n:  3
IntSoftmax | n:  27
IntGELU    | n:  3
IntSoftmax | n:  27
IntGELU    | n:  3
.calib done
Test: [  0/391]	Time  3.627 ( 3.627)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.61
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=27, intgelu_exp_n=4
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=27, intgelu_exp_n=4, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  27
IntGELU    | n:  4
IntSoftmax | n:  27
IntGELU    | n:  4
IntSoftmax | n:  27
IntGELU    | n:  4
IntSoftmax | n:  27
IntGELU    | n:  4
IntSoftmax | n:  27
IntGELU    | n:  4
IntSoftmax | n:  27
IntGELU    | n:  4
IntSoftmax | n:  27
IntGELU    | n:  4
IntSoftmax | n:  27
IntGELU    | n:  4
IntSoftmax | n:  27
IntGELU    | n:  4
IntSoftmax | n:  27
IntGELU    | n:  4
IntSoftmax | n:  27
IntGELU    | n:  4
IntSoftmax | n:  27
IntGELU    | n:  4
.calib done
Test: [  0/391]	Time  3.676 ( 3.676)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.67
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=27, intgelu_exp_n=5
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=27, intgelu_exp_n=5, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  27
IntGELU    | n:  5
IntSoftmax | n:  27
IntGELU    | n:  5
IntSoftmax | n:  27
IntGELU    | n:  5
IntSoftmax | n:  27
IntGELU    | n:  5
IntSoftmax | n:  27
IntGELU    | n:  5
IntSoftmax | n:  27
IntGELU    | n:  5
IntSoftmax | n:  27
IntGELU    | n:  5
IntSoftmax | n:  27
IntGELU    | n:  5
IntSoftmax | n:  27
IntGELU    | n:  5
IntSoftmax | n:  27
IntGELU    | n:  5
IntSoftmax | n:  27
IntGELU    | n:  5
IntSoftmax | n:  27
IntGELU    | n:  5
.calib done
Test: [  0/391]	Time  3.801 ( 3.801)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.78
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=27, intgelu_exp_n=6
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=27, intgelu_exp_n=6, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  27
IntGELU    | n:  6
IntSoftmax | n:  27
IntGELU    | n:  6
IntSoftmax | n:  27
IntGELU    | n:  6
IntSoftmax | n:  27
IntGELU    | n:  6
IntSoftmax | n:  27
IntGELU    | n:  6
IntSoftmax | n:  27
IntGELU    | n:  6
IntSoftmax | n:  27
IntGELU    | n:  6
IntSoftmax | n:  27
IntGELU    | n:  6
IntSoftmax | n:  27
IntGELU    | n:  6
IntSoftmax | n:  27
IntGELU    | n:  6
IntSoftmax | n:  27
IntGELU    | n:  6
IntSoftmax | n:  27
IntGELU    | n:  6
.calib done
Test: [  0/391]	Time  3.899 ( 3.899)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.81
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=27, intgelu_exp_n=7
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=27, intgelu_exp_n=7, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  27
IntGELU    | n:  7
IntSoftmax | n:  27
IntGELU    | n:  7
IntSoftmax | n:  27
IntGELU    | n:  7
IntSoftmax | n:  27
IntGELU    | n:  7
IntSoftmax | n:  27
IntGELU    | n:  7
IntSoftmax | n:  27
IntGELU    | n:  7
IntSoftmax | n:  27
IntGELU    | n:  7
IntSoftmax | n:  27
IntGELU    | n:  7
IntSoftmax | n:  27
IntGELU    | n:  7
IntSoftmax | n:  27
IntGELU    | n:  7
IntSoftmax | n:  27
IntGELU    | n:  7
IntSoftmax | n:  27
IntGELU    | n:  7
.calib done
Test: [  0/391]	Time  3.901 ( 3.901)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.84
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=27, intgelu_exp_n=8
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=27, intgelu_exp_n=8, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  27
IntGELU    | n:  8
IntSoftmax | n:  27
IntGELU    | n:  8
IntSoftmax | n:  27
IntGELU    | n:  8
IntSoftmax | n:  27
IntGELU    | n:  8
IntSoftmax | n:  27
IntGELU    | n:  8
IntSoftmax | n:  27
IntGELU    | n:  8
IntSoftmax | n:  27
IntGELU    | n:  8
IntSoftmax | n:  27
IntGELU    | n:  8
IntSoftmax | n:  27
IntGELU    | n:  8
IntSoftmax | n:  27
IntGELU    | n:  8
IntSoftmax | n:  27
IntGELU    | n:  8
IntSoftmax | n:  27
IntGELU    | n:  8
.calib done
Test: [  0/391]	Time  3.975 ( 3.975)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.89
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=27, intgelu_exp_n=9
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=27, intgelu_exp_n=9, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  27
IntGELU    | n:  9
IntSoftmax | n:  27
IntGELU    | n:  9
IntSoftmax | n:  27
IntGELU    | n:  9
IntSoftmax | n:  27
IntGELU    | n:  9
IntSoftmax | n:  27
IntGELU    | n:  9
IntSoftmax | n:  27
IntGELU    | n:  9
IntSoftmax | n:  27
IntGELU    | n:  9
IntSoftmax | n:  27
IntGELU    | n:  9
IntSoftmax | n:  27
IntGELU    | n:  9
IntSoftmax | n:  27
IntGELU    | n:  9
IntSoftmax | n:  27
IntGELU    | n:  9
IntSoftmax | n:  27
IntGELU    | n:  9
.calib done
Test: [  0/391]	Time  3.861 ( 3.861)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.84
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=27, intgelu_exp_n=10
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=27, intgelu_exp_n=10, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  27
IntGELU    | n:  10
IntSoftmax | n:  27
IntGELU    | n:  10
IntSoftmax | n:  27
IntGELU    | n:  10
IntSoftmax | n:  27
IntGELU    | n:  10
IntSoftmax | n:  27
IntGELU    | n:  10
IntSoftmax | n:  27
IntGELU    | n:  10
IntSoftmax | n:  27
IntGELU    | n:  10
IntSoftmax | n:  27
IntGELU    | n:  10
IntSoftmax | n:  27
IntGELU    | n:  10
IntSoftmax | n:  27
IntGELU    | n:  10
IntSoftmax | n:  27
IntGELU    | n:  10
IntSoftmax | n:  27
IntGELU    | n:  10
.calib done
Test: [  0/391]	Time  3.863 ( 3.863)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.86
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=27, intgelu_exp_n=11
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=27, intgelu_exp_n=11, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  27
IntGELU    | n:  11
IntSoftmax | n:  27
IntGELU    | n:  11
IntSoftmax | n:  27
IntGELU    | n:  11
IntSoftmax | n:  27
IntGELU    | n:  11
IntSoftmax | n:  27
IntGELU    | n:  11
IntSoftmax | n:  27
IntGELU    | n:  11
IntSoftmax | n:  27
IntGELU    | n:  11
IntSoftmax | n:  27
IntGELU    | n:  11
IntSoftmax | n:  27
IntGELU    | n:  11
IntSoftmax | n:  27
IntGELU    | n:  11
IntSoftmax | n:  27
IntGELU    | n:  11
IntSoftmax | n:  27
IntGELU    | n:  11
.calib done
Test: [  0/391]	Time  3.898 ( 3.898)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.88
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=27, intgelu_exp_n=12
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=27, intgelu_exp_n=12, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  27
IntGELU    | n:  12
IntSoftmax | n:  27
IntGELU    | n:  12
IntSoftmax | n:  27
IntGELU    | n:  12
IntSoftmax | n:  27
IntGELU    | n:  12
IntSoftmax | n:  27
IntGELU    | n:  12
IntSoftmax | n:  27
IntGELU    | n:  12
IntSoftmax | n:  27
IntGELU    | n:  12
IntSoftmax | n:  27
IntGELU    | n:  12
IntSoftmax | n:  27
IntGELU    | n:  12
IntSoftmax | n:  27
IntGELU    | n:  12
IntSoftmax | n:  27
IntGELU    | n:  12
IntSoftmax | n:  27
IntGELU    | n:  12
.calib done
Test: [  0/391]	Time  3.875 ( 3.875)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.83
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=27, intgelu_exp_n=13
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=27, intgelu_exp_n=13, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  27
IntGELU    | n:  13
IntSoftmax | n:  27
IntGELU    | n:  13
IntSoftmax | n:  27
IntGELU    | n:  13
IntSoftmax | n:  27
IntGELU    | n:  13
IntSoftmax | n:  27
IntGELU    | n:  13
IntSoftmax | n:  27
IntGELU    | n:  13
IntSoftmax | n:  27
IntGELU    | n:  13
IntSoftmax | n:  27
IntGELU    | n:  13
IntSoftmax | n:  27
IntGELU    | n:  13
IntSoftmax | n:  27
IntGELU    | n:  13
IntSoftmax | n:  27
IntGELU    | n:  13
IntSoftmax | n:  27
IntGELU    | n:  13
.calib done
Test: [  0/391]	Time  3.962 ( 3.962)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.99
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=27, intgelu_exp_n=14
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=27, intgelu_exp_n=14, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  27
IntGELU    | n:  14
IntSoftmax | n:  27
IntGELU    | n:  14
IntSoftmax | n:  27
IntGELU    | n:  14
IntSoftmax | n:  27
IntGELU    | n:  14
IntSoftmax | n:  27
IntGELU    | n:  14
IntSoftmax | n:  27
IntGELU    | n:  14
IntSoftmax | n:  27
IntGELU    | n:  14
IntSoftmax | n:  27
IntGELU    | n:  14
IntSoftmax | n:  27
IntGELU    | n:  14
IntSoftmax | n:  27
IntGELU    | n:  14
IntSoftmax | n:  27
IntGELU    | n:  14
IntSoftmax | n:  27
IntGELU    | n:  14
.calib done
Test: [  0/391]	Time  3.903 ( 3.903)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.81
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=27, intgelu_exp_n=15
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=27, intgelu_exp_n=15, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  27
IntGELU    | n:  15
IntSoftmax | n:  27
IntGELU    | n:  15
IntSoftmax | n:  27
IntGELU    | n:  15
IntSoftmax | n:  27
IntGELU    | n:  15
IntSoftmax | n:  27
IntGELU    | n:  15
IntSoftmax | n:  27
IntGELU    | n:  15
IntSoftmax | n:  27
IntGELU    | n:  15
IntSoftmax | n:  27
IntGELU    | n:  15
IntSoftmax | n:  27
IntGELU    | n:  15
IntSoftmax | n:  27
IntGELU    | n:  15
IntSoftmax | n:  27
IntGELU    | n:  15
IntSoftmax | n:  27
IntGELU    | n:  15
.calib done
Test: [  0/391]	Time  3.702 ( 3.702)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.69
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=27, intgelu_exp_n=16
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=27, intgelu_exp_n=16, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  27
IntGELU    | n:  16
IntSoftmax | n:  27
IntGELU    | n:  16
IntSoftmax | n:  27
IntGELU    | n:  16
IntSoftmax | n:  27
IntGELU    | n:  16
IntSoftmax | n:  27
IntGELU    | n:  16
IntSoftmax | n:  27
IntGELU    | n:  16
IntSoftmax | n:  27
IntGELU    | n:  16
IntSoftmax | n:  27
IntGELU    | n:  16
IntSoftmax | n:  27
IntGELU    | n:  16
IntSoftmax | n:  27
IntGELU    | n:  16
IntSoftmax | n:  27
IntGELU    | n:  16
IntSoftmax | n:  27
IntGELU    | n:  16
.calib done
Test: [  0/391]	Time  3.895 ( 3.895)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.89
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=27, intgelu_exp_n=17
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=27, intgelu_exp_n=17, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  27
IntGELU    | n:  17
IntSoftmax | n:  27
IntGELU    | n:  17
IntSoftmax | n:  27
IntGELU    | n:  17
IntSoftmax | n:  27
IntGELU    | n:  17
IntSoftmax | n:  27
IntGELU    | n:  17
IntSoftmax | n:  27
IntGELU    | n:  17
IntSoftmax | n:  27
IntGELU    | n:  17
IntSoftmax | n:  27
IntGELU    | n:  17
IntSoftmax | n:  27
IntGELU    | n:  17
IntSoftmax | n:  27
IntGELU    | n:  17
IntSoftmax | n:  27
IntGELU    | n:  17
IntSoftmax | n:  27
IntGELU    | n:  17
.calib done
Test: [  0/391]	Time  3.909 ( 3.909)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.91
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=27, intgelu_exp_n=18
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=27, intgelu_exp_n=18, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  27
IntGELU    | n:  18
IntSoftmax | n:  27
IntGELU    | n:  18
IntSoftmax | n:  27
IntGELU    | n:  18
IntSoftmax | n:  27
IntGELU    | n:  18
IntSoftmax | n:  27
IntGELU    | n:  18
IntSoftmax | n:  27
IntGELU    | n:  18
IntSoftmax | n:  27
IntGELU    | n:  18
IntSoftmax | n:  27
IntGELU    | n:  18
IntSoftmax | n:  27
IntGELU    | n:  18
IntSoftmax | n:  27
IntGELU    | n:  18
IntSoftmax | n:  27
IntGELU    | n:  18
IntSoftmax | n:  27
IntGELU    | n:  18
.calib done
Test: [  0/391]	Time  4.011 ( 4.011)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.97
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=27, intgelu_exp_n=19
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=27, intgelu_exp_n=19, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  27
IntGELU    | n:  19
IntSoftmax | n:  27
IntGELU    | n:  19
IntSoftmax | n:  27
IntGELU    | n:  19
IntSoftmax | n:  27
IntGELU    | n:  19
IntSoftmax | n:  27
IntGELU    | n:  19
IntSoftmax | n:  27
IntGELU    | n:  19
IntSoftmax | n:  27
IntGELU    | n:  19
IntSoftmax | n:  27
IntGELU    | n:  19
IntSoftmax | n:  27
IntGELU    | n:  19
IntSoftmax | n:  27
IntGELU    | n:  19
IntSoftmax | n:  27
IntGELU    | n:  19
IntSoftmax | n:  27
IntGELU    | n:  19
.calib done
Test: [  0/391]	Time  3.680 ( 3.680)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.66
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=27, intgelu_exp_n=20
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=27, intgelu_exp_n=20, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  27
IntGELU    | n:  20
IntSoftmax | n:  27
IntGELU    | n:  20
IntSoftmax | n:  27
IntGELU    | n:  20
IntSoftmax | n:  27
IntGELU    | n:  20
IntSoftmax | n:  27
IntGELU    | n:  20
IntSoftmax | n:  27
IntGELU    | n:  20
IntSoftmax | n:  27
IntGELU    | n:  20
IntSoftmax | n:  27
IntGELU    | n:  20
IntSoftmax | n:  27
IntGELU    | n:  20
IntSoftmax | n:  27
IntGELU    | n:  20
IntSoftmax | n:  27
IntGELU    | n:  20
IntSoftmax | n:  27
IntGELU    | n:  20
.calib done
Test: [  0/391]	Time  3.919 ( 3.919)	Acc@1   0.00 (  0.00)	Acc@5   0.78 (  0.78)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.781
Time: 8.87
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=27, intgelu_exp_n=21
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=27, intgelu_exp_n=21, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  27
IntGELU    | n:  21
IntSoftmax | n:  27
IntGELU    | n:  21
IntSoftmax | n:  27
IntGELU    | n:  21
IntSoftmax | n:  27
IntGELU    | n:  21
IntSoftmax | n:  27
IntGELU    | n:  21
IntSoftmax | n:  27
IntGELU    | n:  21
IntSoftmax | n:  27
IntGELU    | n:  21
IntSoftmax | n:  27
IntGELU    | n:  21
IntSoftmax | n:  27
IntGELU    | n:  21
IntSoftmax | n:  27
IntGELU    | n:  21
IntSoftmax | n:  27
IntGELU    | n:  21
IntSoftmax | n:  27
IntGELU    | n:  21
.calib done
Test: [  0/391]	Time  3.699 ( 3.699)	Acc@1   0.00 (  0.00)	Acc@5   0.78 (  0.78)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.781
Time: 8.67
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=27, intgelu_exp_n=22
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=27, intgelu_exp_n=22, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  27
IntGELU    | n:  22
IntSoftmax | n:  27
IntGELU    | n:  22
IntSoftmax | n:  27
IntGELU    | n:  22
IntSoftmax | n:  27
IntGELU    | n:  22
IntSoftmax | n:  27
IntGELU    | n:  22
IntSoftmax | n:  27
IntGELU    | n:  22
IntSoftmax | n:  27
IntGELU    | n:  22
IntSoftmax | n:  27
IntGELU    | n:  22
IntSoftmax | n:  27
IntGELU    | n:  22
IntSoftmax | n:  27
IntGELU    | n:  22
IntSoftmax | n:  27
IntGELU    | n:  22
IntSoftmax | n:  27
IntGELU    | n:  22
.calib done
Test: [  0/391]	Time  4.072 ( 4.072)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 9.05
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=27, intgelu_exp_n=23
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=27, intgelu_exp_n=23, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  27
IntGELU    | n:  23
IntSoftmax | n:  27
IntGELU    | n:  23
IntSoftmax | n:  27
IntGELU    | n:  23
IntSoftmax | n:  27
IntGELU    | n:  23
IntSoftmax | n:  27
IntGELU    | n:  23
IntSoftmax | n:  27
IntGELU    | n:  23
IntSoftmax | n:  27
IntGELU    | n:  23
IntSoftmax | n:  27
IntGELU    | n:  23
IntSoftmax | n:  27
IntGELU    | n:  23
IntSoftmax | n:  27
IntGELU    | n:  23
IntSoftmax | n:  27
IntGELU    | n:  23
IntSoftmax | n:  27
IntGELU    | n:  23
.calib done
Test: [  0/391]	Time  3.946 ( 3.946)	Acc@1   0.00 (  0.00)	Acc@5   0.78 (  0.78)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.781
Time: 8.95
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=27, intgelu_exp_n=24
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=27, intgelu_exp_n=24, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  27
IntGELU    | n:  24
IntSoftmax | n:  27
IntGELU    | n:  24
IntSoftmax | n:  27
IntGELU    | n:  24
IntSoftmax | n:  27
IntGELU    | n:  24
IntSoftmax | n:  27
IntGELU    | n:  24
IntSoftmax | n:  27
IntGELU    | n:  24
IntSoftmax | n:  27
IntGELU    | n:  24
IntSoftmax | n:  27
IntGELU    | n:  24
IntSoftmax | n:  27
IntGELU    | n:  24
IntSoftmax | n:  27
IntGELU    | n:  24
IntSoftmax | n:  27
IntGELU    | n:  24
IntSoftmax | n:  27
IntGELU    | n:  24
.calib done
Test: [  0/391]	Time  3.976 ( 3.976)	Acc@1   0.00 (  0.00)	Acc@5   0.78 (  0.78)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.781
Time: 8.96
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=27, intgelu_exp_n=25
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=27, intgelu_exp_n=25, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  27
IntGELU    | n:  25
IntSoftmax | n:  27
IntGELU    | n:  25
IntSoftmax | n:  27
IntGELU    | n:  25
IntSoftmax | n:  27
IntGELU    | n:  25
IntSoftmax | n:  27
IntGELU    | n:  25
IntSoftmax | n:  27
IntGELU    | n:  25
IntSoftmax | n:  27
IntGELU    | n:  25
IntSoftmax | n:  27
IntGELU    | n:  25
IntSoftmax | n:  27
IntGELU    | n:  25
IntSoftmax | n:  27
IntGELU    | n:  25
IntSoftmax | n:  27
IntGELU    | n:  25
IntSoftmax | n:  27
IntGELU    | n:  25
.calib done
Test: [  0/391]	Time  4.035 ( 4.035)	Acc@1   0.00 (  0.00)	Acc@5   0.78 (  0.78)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.781
Time: 9.03
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=27, intgelu_exp_n=26
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=27, intgelu_exp_n=26, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  27
IntGELU    | n:  26
IntSoftmax | n:  27
IntGELU    | n:  26
IntSoftmax | n:  27
IntGELU    | n:  26
IntSoftmax | n:  27
IntGELU    | n:  26
IntSoftmax | n:  27
IntGELU    | n:  26
IntSoftmax | n:  27
IntGELU    | n:  26
IntSoftmax | n:  27
IntGELU    | n:  26
IntSoftmax | n:  27
IntGELU    | n:  26
IntSoftmax | n:  27
IntGELU    | n:  26
IntSoftmax | n:  27
IntGELU    | n:  26
IntSoftmax | n:  27
IntGELU    | n:  26
IntSoftmax | n:  27
IntGELU    | n:  26
.calib done
Test: [  0/391]	Time  3.984 ( 3.984)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.96
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=27, intgelu_exp_n=27
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=27, intgelu_exp_n=27, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  27
IntGELU    | n:  27
IntSoftmax | n:  27
IntGELU    | n:  27
IntSoftmax | n:  27
IntGELU    | n:  27
IntSoftmax | n:  27
IntGELU    | n:  27
IntSoftmax | n:  27
IntGELU    | n:  27
IntSoftmax | n:  27
IntGELU    | n:  27
IntSoftmax | n:  27
IntGELU    | n:  27
IntSoftmax | n:  27
IntGELU    | n:  27
IntSoftmax | n:  27
IntGELU    | n:  27
IntSoftmax | n:  27
IntGELU    | n:  27
IntSoftmax | n:  27
IntGELU    | n:  27
IntSoftmax | n:  27
IntGELU    | n:  27
.calib done
Test: [  0/391]	Time  3.842 ( 3.842)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.83
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=27, intgelu_exp_n=28
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=27, intgelu_exp_n=28, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  27
IntGELU    | n:  28
IntSoftmax | n:  27
IntGELU    | n:  28
IntSoftmax | n:  27
IntGELU    | n:  28
IntSoftmax | n:  27
IntGELU    | n:  28
IntSoftmax | n:  27
IntGELU    | n:  28
IntSoftmax | n:  27
IntGELU    | n:  28
IntSoftmax | n:  27
IntGELU    | n:  28
IntSoftmax | n:  27
IntGELU    | n:  28
IntSoftmax | n:  27
IntGELU    | n:  28
IntSoftmax | n:  27
IntGELU    | n:  28
IntSoftmax | n:  27
IntGELU    | n:  28
IntSoftmax | n:  27
IntGELU    | n:  28
.calib done
Test: [  0/391]	Time  3.704 ( 3.704)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.63
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=27, intgelu_exp_n=29
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=27, intgelu_exp_n=29, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  27
IntGELU    | n:  29
IntSoftmax | n:  27
IntGELU    | n:  29
IntSoftmax | n:  27
IntGELU    | n:  29
IntSoftmax | n:  27
IntGELU    | n:  29
IntSoftmax | n:  27
IntGELU    | n:  29
IntSoftmax | n:  27
IntGELU    | n:  29
IntSoftmax | n:  27
IntGELU    | n:  29
IntSoftmax | n:  27
IntGELU    | n:  29
IntSoftmax | n:  27
IntGELU    | n:  29
IntSoftmax | n:  27
IntGELU    | n:  29
IntSoftmax | n:  27
IntGELU    | n:  29
IntSoftmax | n:  27
IntGELU    | n:  29
.calib done
Test: [  0/391]	Time  3.971 ( 3.971)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.91
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=27, intgelu_exp_n=30
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=27, intgelu_exp_n=30, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  27
IntGELU    | n:  30
IntSoftmax | n:  27
IntGELU    | n:  30
IntSoftmax | n:  27
IntGELU    | n:  30
IntSoftmax | n:  27
IntGELU    | n:  30
IntSoftmax | n:  27
IntGELU    | n:  30
IntSoftmax | n:  27
IntGELU    | n:  30
IntSoftmax | n:  27
IntGELU    | n:  30
IntSoftmax | n:  27
IntGELU    | n:  30
IntSoftmax | n:  27
IntGELU    | n:  30
IntSoftmax | n:  27
IntGELU    | n:  30
IntSoftmax | n:  27
IntGELU    | n:  30
IntSoftmax | n:  27
IntGELU    | n:  30
.calib done
Test: [  0/391]	Time  3.938 ( 3.938)	Acc@1   0.78 (  0.78)	Acc@5   0.78 (  0.78)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.781 Prec@5 0.781
Time: 8.86
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=27, intgelu_exp_n=31
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=27, intgelu_exp_n=31, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  27
IntGELU    | n:  31
IntSoftmax | n:  27
IntGELU    | n:  31
IntSoftmax | n:  27
IntGELU    | n:  31
IntSoftmax | n:  27
IntGELU    | n:  31
IntSoftmax | n:  27
IntGELU    | n:  31
IntSoftmax | n:  27
IntGELU    | n:  31
IntSoftmax | n:  27
IntGELU    | n:  31
IntSoftmax | n:  27
IntGELU    | n:  31
IntSoftmax | n:  27
IntGELU    | n:  31
IntSoftmax | n:  27
IntGELU    | n:  31
IntSoftmax | n:  27
IntGELU    | n:  31
IntSoftmax | n:  27
IntGELU    | n:  31
.calib done
Test: [  0/391]	Time  3.858 ( 3.858)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.85
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=28, intgelu_exp_n=0
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=28, intgelu_exp_n=0, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  28
IntGELU    | n:  0
IntSoftmax | n:  28
IntGELU    | n:  0
IntSoftmax | n:  28
IntGELU    | n:  0
IntSoftmax | n:  28
IntGELU    | n:  0
IntSoftmax | n:  28
IntGELU    | n:  0
IntSoftmax | n:  28
IntGELU    | n:  0
IntSoftmax | n:  28
IntGELU    | n:  0
IntSoftmax | n:  28
IntGELU    | n:  0
IntSoftmax | n:  28
IntGELU    | n:  0
IntSoftmax | n:  28
IntGELU    | n:  0
IntSoftmax | n:  28
IntGELU    | n:  0
IntSoftmax | n:  28
IntGELU    | n:  0
.calib done
Test: [  0/391]	Time  3.693 ( 3.693)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.61
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=28, intgelu_exp_n=1
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=28, intgelu_exp_n=1, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  28
IntGELU    | n:  1
IntSoftmax | n:  28
IntGELU    | n:  1
IntSoftmax | n:  28
IntGELU    | n:  1
IntSoftmax | n:  28
IntGELU    | n:  1
IntSoftmax | n:  28
IntGELU    | n:  1
IntSoftmax | n:  28
IntGELU    | n:  1
IntSoftmax | n:  28
IntGELU    | n:  1
IntSoftmax | n:  28
IntGELU    | n:  1
IntSoftmax | n:  28
IntGELU    | n:  1
IntSoftmax | n:  28
IntGELU    | n:  1
IntSoftmax | n:  28
IntGELU    | n:  1
IntSoftmax | n:  28
IntGELU    | n:  1
.calib done
Test: [  0/391]	Time  3.933 ( 3.933)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.86
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=28, intgelu_exp_n=2
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=28, intgelu_exp_n=2, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  28
IntGELU    | n:  2
IntSoftmax | n:  28
IntGELU    | n:  2
IntSoftmax | n:  28
IntGELU    | n:  2
IntSoftmax | n:  28
IntGELU    | n:  2
IntSoftmax | n:  28
IntGELU    | n:  2
IntSoftmax | n:  28
IntGELU    | n:  2
IntSoftmax | n:  28
IntGELU    | n:  2
IntSoftmax | n:  28
IntGELU    | n:  2
IntSoftmax | n:  28
IntGELU    | n:  2
IntSoftmax | n:  28
IntGELU    | n:  2
IntSoftmax | n:  28
IntGELU    | n:  2
IntSoftmax | n:  28
IntGELU    | n:  2
.calib done
Test: [  0/391]	Time  3.767 ( 3.767)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.68
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=28, intgelu_exp_n=3
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=28, intgelu_exp_n=3, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  28
IntGELU    | n:  3
IntSoftmax | n:  28
IntGELU    | n:  3
IntSoftmax | n:  28
IntGELU    | n:  3
IntSoftmax | n:  28
IntGELU    | n:  3
IntSoftmax | n:  28
IntGELU    | n:  3
IntSoftmax | n:  28
IntGELU    | n:  3
IntSoftmax | n:  28
IntGELU    | n:  3
IntSoftmax | n:  28
IntGELU    | n:  3
IntSoftmax | n:  28
IntGELU    | n:  3
IntSoftmax | n:  28
IntGELU    | n:  3
IntSoftmax | n:  28
IntGELU    | n:  3
IntSoftmax | n:  28
IntGELU    | n:  3
.calib done
Test: [  0/391]	Time  3.829 ( 3.829)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.79
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=28, intgelu_exp_n=4
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=28, intgelu_exp_n=4, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  28
IntGELU    | n:  4
IntSoftmax | n:  28
IntGELU    | n:  4
IntSoftmax | n:  28
IntGELU    | n:  4
IntSoftmax | n:  28
IntGELU    | n:  4
IntSoftmax | n:  28
IntGELU    | n:  4
IntSoftmax | n:  28
IntGELU    | n:  4
IntSoftmax | n:  28
IntGELU    | n:  4
IntSoftmax | n:  28
IntGELU    | n:  4
IntSoftmax | n:  28
IntGELU    | n:  4
IntSoftmax | n:  28
IntGELU    | n:  4
IntSoftmax | n:  28
IntGELU    | n:  4
IntSoftmax | n:  28
IntGELU    | n:  4
.calib done
Test: [  0/391]	Time  3.637 ( 3.637)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.59
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=28, intgelu_exp_n=5
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=28, intgelu_exp_n=5, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  28
IntGELU    | n:  5
IntSoftmax | n:  28
IntGELU    | n:  5
IntSoftmax | n:  28
IntGELU    | n:  5
IntSoftmax | n:  28
IntGELU    | n:  5
IntSoftmax | n:  28
IntGELU    | n:  5
IntSoftmax | n:  28
IntGELU    | n:  5
IntSoftmax | n:  28
IntGELU    | n:  5
IntSoftmax | n:  28
IntGELU    | n:  5
IntSoftmax | n:  28
IntGELU    | n:  5
IntSoftmax | n:  28
IntGELU    | n:  5
IntSoftmax | n:  28
IntGELU    | n:  5
IntSoftmax | n:  28
IntGELU    | n:  5
.calib done
Test: [  0/391]	Time  3.935 ( 3.935)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.93
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=28, intgelu_exp_n=6
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=28, intgelu_exp_n=6, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  28
IntGELU    | n:  6
IntSoftmax | n:  28
IntGELU    | n:  6
IntSoftmax | n:  28
IntGELU    | n:  6
IntSoftmax | n:  28
IntGELU    | n:  6
IntSoftmax | n:  28
IntGELU    | n:  6
IntSoftmax | n:  28
IntGELU    | n:  6
IntSoftmax | n:  28
IntGELU    | n:  6
IntSoftmax | n:  28
IntGELU    | n:  6
IntSoftmax | n:  28
IntGELU    | n:  6
IntSoftmax | n:  28
IntGELU    | n:  6
IntSoftmax | n:  28
IntGELU    | n:  6
IntSoftmax | n:  28
IntGELU    | n:  6
.calib done
Test: [  0/391]	Time  3.951 ( 3.951)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.91
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=28, intgelu_exp_n=7
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=28, intgelu_exp_n=7, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  28
IntGELU    | n:  7
IntSoftmax | n:  28
IntGELU    | n:  7
IntSoftmax | n:  28
IntGELU    | n:  7
IntSoftmax | n:  28
IntGELU    | n:  7
IntSoftmax | n:  28
IntGELU    | n:  7
IntSoftmax | n:  28
IntGELU    | n:  7
IntSoftmax | n:  28
IntGELU    | n:  7
IntSoftmax | n:  28
IntGELU    | n:  7
IntSoftmax | n:  28
IntGELU    | n:  7
IntSoftmax | n:  28
IntGELU    | n:  7
IntSoftmax | n:  28
IntGELU    | n:  7
IntSoftmax | n:  28
IntGELU    | n:  7
.calib done
Test: [  0/391]	Time  3.738 ( 3.738)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.69
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=28, intgelu_exp_n=8
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=28, intgelu_exp_n=8, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  28
IntGELU    | n:  8
IntSoftmax | n:  28
IntGELU    | n:  8
IntSoftmax | n:  28
IntGELU    | n:  8
IntSoftmax | n:  28
IntGELU    | n:  8
IntSoftmax | n:  28
IntGELU    | n:  8
IntSoftmax | n:  28
IntGELU    | n:  8
IntSoftmax | n:  28
IntGELU    | n:  8
IntSoftmax | n:  28
IntGELU    | n:  8
IntSoftmax | n:  28
IntGELU    | n:  8
IntSoftmax | n:  28
IntGELU    | n:  8
IntSoftmax | n:  28
IntGELU    | n:  8
IntSoftmax | n:  28
IntGELU    | n:  8
.calib done
Test: [  0/391]	Time  3.778 ( 3.778)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.73
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=28, intgelu_exp_n=9
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=28, intgelu_exp_n=9, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  28
IntGELU    | n:  9
IntSoftmax | n:  28
IntGELU    | n:  9
IntSoftmax | n:  28
IntGELU    | n:  9
IntSoftmax | n:  28
IntGELU    | n:  9
IntSoftmax | n:  28
IntGELU    | n:  9
IntSoftmax | n:  28
IntGELU    | n:  9
IntSoftmax | n:  28
IntGELU    | n:  9
IntSoftmax | n:  28
IntGELU    | n:  9
IntSoftmax | n:  28
IntGELU    | n:  9
IntSoftmax | n:  28
IntGELU    | n:  9
IntSoftmax | n:  28
IntGELU    | n:  9
IntSoftmax | n:  28
IntGELU    | n:  9
.calib done
Test: [  0/391]	Time  3.916 ( 3.916)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.88
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=28, intgelu_exp_n=10
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=28, intgelu_exp_n=10, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  28
IntGELU    | n:  10
IntSoftmax | n:  28
IntGELU    | n:  10
IntSoftmax | n:  28
IntGELU    | n:  10
IntSoftmax | n:  28
IntGELU    | n:  10
IntSoftmax | n:  28
IntGELU    | n:  10
IntSoftmax | n:  28
IntGELU    | n:  10
IntSoftmax | n:  28
IntGELU    | n:  10
IntSoftmax | n:  28
IntGELU    | n:  10
IntSoftmax | n:  28
IntGELU    | n:  10
IntSoftmax | n:  28
IntGELU    | n:  10
IntSoftmax | n:  28
IntGELU    | n:  10
IntSoftmax | n:  28
IntGELU    | n:  10
.calib done
Test: [  0/391]	Time  3.687 ( 3.687)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.62
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=28, intgelu_exp_n=11
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=28, intgelu_exp_n=11, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  28
IntGELU    | n:  11
IntSoftmax | n:  28
IntGELU    | n:  11
IntSoftmax | n:  28
IntGELU    | n:  11
IntSoftmax | n:  28
IntGELU    | n:  11
IntSoftmax | n:  28
IntGELU    | n:  11
IntSoftmax | n:  28
IntGELU    | n:  11
IntSoftmax | n:  28
IntGELU    | n:  11
IntSoftmax | n:  28
IntGELU    | n:  11
IntSoftmax | n:  28
IntGELU    | n:  11
IntSoftmax | n:  28
IntGELU    | n:  11
IntSoftmax | n:  28
IntGELU    | n:  11
IntSoftmax | n:  28
IntGELU    | n:  11
.calib done
Test: [  0/391]	Time  4.020 ( 4.020)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.93
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=28, intgelu_exp_n=12
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=28, intgelu_exp_n=12, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  28
IntGELU    | n:  12
IntSoftmax | n:  28
IntGELU    | n:  12
IntSoftmax | n:  28
IntGELU    | n:  12
IntSoftmax | n:  28
IntGELU    | n:  12
IntSoftmax | n:  28
IntGELU    | n:  12
IntSoftmax | n:  28
IntGELU    | n:  12
IntSoftmax | n:  28
IntGELU    | n:  12
IntSoftmax | n:  28
IntGELU    | n:  12
IntSoftmax | n:  28
IntGELU    | n:  12
IntSoftmax | n:  28
IntGELU    | n:  12
IntSoftmax | n:  28
IntGELU    | n:  12
IntSoftmax | n:  28
IntGELU    | n:  12
.calib done
Test: [  0/391]	Time  3.878 ( 3.878)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.78
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=28, intgelu_exp_n=13
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=28, intgelu_exp_n=13, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  28
IntGELU    | n:  13
IntSoftmax | n:  28
IntGELU    | n:  13
IntSoftmax | n:  28
IntGELU    | n:  13
IntSoftmax | n:  28
IntGELU    | n:  13
IntSoftmax | n:  28
IntGELU    | n:  13
IntSoftmax | n:  28
IntGELU    | n:  13
IntSoftmax | n:  28
IntGELU    | n:  13
IntSoftmax | n:  28
IntGELU    | n:  13
IntSoftmax | n:  28
IntGELU    | n:  13
IntSoftmax | n:  28
IntGELU    | n:  13
IntSoftmax | n:  28
IntGELU    | n:  13
IntSoftmax | n:  28
IntGELU    | n:  13
.calib done
Test: [  0/391]	Time  3.935 ( 3.935)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.86
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=28, intgelu_exp_n=14
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=28, intgelu_exp_n=14, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  28
IntGELU    | n:  14
IntSoftmax | n:  28
IntGELU    | n:  14
IntSoftmax | n:  28
IntGELU    | n:  14
IntSoftmax | n:  28
IntGELU    | n:  14
IntSoftmax | n:  28
IntGELU    | n:  14
IntSoftmax | n:  28
IntGELU    | n:  14
IntSoftmax | n:  28
IntGELU    | n:  14
IntSoftmax | n:  28
IntGELU    | n:  14
IntSoftmax | n:  28
IntGELU    | n:  14
IntSoftmax | n:  28
IntGELU    | n:  14
IntSoftmax | n:  28
IntGELU    | n:  14
IntSoftmax | n:  28
IntGELU    | n:  14
.calib done
Test: [  0/391]	Time  3.830 ( 3.830)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.79
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=28, intgelu_exp_n=15
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=28, intgelu_exp_n=15, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  28
IntGELU    | n:  15
IntSoftmax | n:  28
IntGELU    | n:  15
IntSoftmax | n:  28
IntGELU    | n:  15
IntSoftmax | n:  28
IntGELU    | n:  15
IntSoftmax | n:  28
IntGELU    | n:  15
IntSoftmax | n:  28
IntGELU    | n:  15
IntSoftmax | n:  28
IntGELU    | n:  15
IntSoftmax | n:  28
IntGELU    | n:  15
IntSoftmax | n:  28
IntGELU    | n:  15
IntSoftmax | n:  28
IntGELU    | n:  15
IntSoftmax | n:  28
IntGELU    | n:  15
IntSoftmax | n:  28
IntGELU    | n:  15
.calib done
Test: [  0/391]	Time  3.872 ( 3.872)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.82
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=28, intgelu_exp_n=16
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=28, intgelu_exp_n=16, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  28
IntGELU    | n:  16
IntSoftmax | n:  28
IntGELU    | n:  16
IntSoftmax | n:  28
IntGELU    | n:  16
IntSoftmax | n:  28
IntGELU    | n:  16
IntSoftmax | n:  28
IntGELU    | n:  16
IntSoftmax | n:  28
IntGELU    | n:  16
IntSoftmax | n:  28
IntGELU    | n:  16
IntSoftmax | n:  28
IntGELU    | n:  16
IntSoftmax | n:  28
IntGELU    | n:  16
IntSoftmax | n:  28
IntGELU    | n:  16
IntSoftmax | n:  28
IntGELU    | n:  16
IntSoftmax | n:  28
IntGELU    | n:  16
.calib done
Test: [  0/391]	Time  3.912 ( 3.912)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.82
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=28, intgelu_exp_n=17
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=28, intgelu_exp_n=17, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  28
IntGELU    | n:  17
IntSoftmax | n:  28
IntGELU    | n:  17
IntSoftmax | n:  28
IntGELU    | n:  17
IntSoftmax | n:  28
IntGELU    | n:  17
IntSoftmax | n:  28
IntGELU    | n:  17
IntSoftmax | n:  28
IntGELU    | n:  17
IntSoftmax | n:  28
IntGELU    | n:  17
IntSoftmax | n:  28
IntGELU    | n:  17
IntSoftmax | n:  28
IntGELU    | n:  17
IntSoftmax | n:  28
IntGELU    | n:  17
IntSoftmax | n:  28
IntGELU    | n:  17
IntSoftmax | n:  28
IntGELU    | n:  17
.calib done
Test: [  0/391]	Time  3.866 ( 3.866)	Acc@1   0.00 (  0.00)	Acc@5   0.78 (  0.78)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.781
Time: 8.75
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=28, intgelu_exp_n=18
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=28, intgelu_exp_n=18, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  28
IntGELU    | n:  18
IntSoftmax | n:  28
IntGELU    | n:  18
IntSoftmax | n:  28
IntGELU    | n:  18
IntSoftmax | n:  28
IntGELU    | n:  18
IntSoftmax | n:  28
IntGELU    | n:  18
IntSoftmax | n:  28
IntGELU    | n:  18
IntSoftmax | n:  28
IntGELU    | n:  18
IntSoftmax | n:  28
IntGELU    | n:  18
IntSoftmax | n:  28
IntGELU    | n:  18
IntSoftmax | n:  28
IntGELU    | n:  18
IntSoftmax | n:  28
IntGELU    | n:  18
IntSoftmax | n:  28
IntGELU    | n:  18
.calib done
Test: [  0/391]	Time  3.922 ( 3.922)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.88
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=28, intgelu_exp_n=19
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=28, intgelu_exp_n=19, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  28
IntGELU    | n:  19
IntSoftmax | n:  28
IntGELU    | n:  19
IntSoftmax | n:  28
IntGELU    | n:  19
IntSoftmax | n:  28
IntGELU    | n:  19
IntSoftmax | n:  28
IntGELU    | n:  19
IntSoftmax | n:  28
IntGELU    | n:  19
IntSoftmax | n:  28
IntGELU    | n:  19
IntSoftmax | n:  28
IntGELU    | n:  19
IntSoftmax | n:  28
IntGELU    | n:  19
IntSoftmax | n:  28
IntGELU    | n:  19
IntSoftmax | n:  28
IntGELU    | n:  19
IntSoftmax | n:  28
IntGELU    | n:  19
.calib done
Test: [  0/391]	Time  3.657 ( 3.657)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.60
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=28, intgelu_exp_n=20
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=28, intgelu_exp_n=20, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  28
IntGELU    | n:  20
IntSoftmax | n:  28
IntGELU    | n:  20
IntSoftmax | n:  28
IntGELU    | n:  20
IntSoftmax | n:  28
IntGELU    | n:  20
IntSoftmax | n:  28
IntGELU    | n:  20
IntSoftmax | n:  28
IntGELU    | n:  20
IntSoftmax | n:  28
IntGELU    | n:  20
IntSoftmax | n:  28
IntGELU    | n:  20
IntSoftmax | n:  28
IntGELU    | n:  20
IntSoftmax | n:  28
IntGELU    | n:  20
IntSoftmax | n:  28
IntGELU    | n:  20
IntSoftmax | n:  28
IntGELU    | n:  20
.calib done
Test: [  0/391]	Time  3.888 ( 3.888)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.89
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=28, intgelu_exp_n=21
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=28, intgelu_exp_n=21, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  28
IntGELU    | n:  21
IntSoftmax | n:  28
IntGELU    | n:  21
IntSoftmax | n:  28
IntGELU    | n:  21
IntSoftmax | n:  28
IntGELU    | n:  21
IntSoftmax | n:  28
IntGELU    | n:  21
IntSoftmax | n:  28
IntGELU    | n:  21
IntSoftmax | n:  28
IntGELU    | n:  21
IntSoftmax | n:  28
IntGELU    | n:  21
IntSoftmax | n:  28
IntGELU    | n:  21
IntSoftmax | n:  28
IntGELU    | n:  21
IntSoftmax | n:  28
IntGELU    | n:  21
IntSoftmax | n:  28
IntGELU    | n:  21
.calib done
Test: [  0/391]	Time  3.835 ( 3.835)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.73
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=28, intgelu_exp_n=22
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=28, intgelu_exp_n=22, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  28
IntGELU    | n:  22
IntSoftmax | n:  28
IntGELU    | n:  22
IntSoftmax | n:  28
IntGELU    | n:  22
IntSoftmax | n:  28
IntGELU    | n:  22
IntSoftmax | n:  28
IntGELU    | n:  22
IntSoftmax | n:  28
IntGELU    | n:  22
IntSoftmax | n:  28
IntGELU    | n:  22
IntSoftmax | n:  28
IntGELU    | n:  22
IntSoftmax | n:  28
IntGELU    | n:  22
IntSoftmax | n:  28
IntGELU    | n:  22
IntSoftmax | n:  28
IntGELU    | n:  22
IntSoftmax | n:  28
IntGELU    | n:  22
.calib done
Test: [  0/391]	Time  3.947 ( 3.947)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.93
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=28, intgelu_exp_n=23
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=28, intgelu_exp_n=23, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  28
IntGELU    | n:  23
IntSoftmax | n:  28
IntGELU    | n:  23
IntSoftmax | n:  28
IntGELU    | n:  23
IntSoftmax | n:  28
IntGELU    | n:  23
IntSoftmax | n:  28
IntGELU    | n:  23
IntSoftmax | n:  28
IntGELU    | n:  23
IntSoftmax | n:  28
IntGELU    | n:  23
IntSoftmax | n:  28
IntGELU    | n:  23
IntSoftmax | n:  28
IntGELU    | n:  23
IntSoftmax | n:  28
IntGELU    | n:  23
IntSoftmax | n:  28
IntGELU    | n:  23
IntSoftmax | n:  28
IntGELU    | n:  23
.calib done
Test: [  0/391]	Time  3.862 ( 3.862)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.80
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=28, intgelu_exp_n=24
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=28, intgelu_exp_n=24, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  28
IntGELU    | n:  24
IntSoftmax | n:  28
IntGELU    | n:  24
IntSoftmax | n:  28
IntGELU    | n:  24
IntSoftmax | n:  28
IntGELU    | n:  24
IntSoftmax | n:  28
IntGELU    | n:  24
IntSoftmax | n:  28
IntGELU    | n:  24
IntSoftmax | n:  28
IntGELU    | n:  24
IntSoftmax | n:  28
IntGELU    | n:  24
IntSoftmax | n:  28
IntGELU    | n:  24
IntSoftmax | n:  28
IntGELU    | n:  24
IntSoftmax | n:  28
IntGELU    | n:  24
IntSoftmax | n:  28
IntGELU    | n:  24
.calib done
Test: [  0/391]	Time  3.973 ( 3.973)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.98
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=28, intgelu_exp_n=25
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=28, intgelu_exp_n=25, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  28
IntGELU    | n:  25
IntSoftmax | n:  28
IntGELU    | n:  25
IntSoftmax | n:  28
IntGELU    | n:  25
IntSoftmax | n:  28
IntGELU    | n:  25
IntSoftmax | n:  28
IntGELU    | n:  25
IntSoftmax | n:  28
IntGELU    | n:  25
IntSoftmax | n:  28
IntGELU    | n:  25
IntSoftmax | n:  28
IntGELU    | n:  25
IntSoftmax | n:  28
IntGELU    | n:  25
IntSoftmax | n:  28
IntGELU    | n:  25
IntSoftmax | n:  28
IntGELU    | n:  25
IntSoftmax | n:  28
IntGELU    | n:  25
.calib done
Test: [  0/391]	Time  3.816 ( 3.816)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.75
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=28, intgelu_exp_n=26
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=28, intgelu_exp_n=26, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  28
IntGELU    | n:  26
IntSoftmax | n:  28
IntGELU    | n:  26
IntSoftmax | n:  28
IntGELU    | n:  26
IntSoftmax | n:  28
IntGELU    | n:  26
IntSoftmax | n:  28
IntGELU    | n:  26
IntSoftmax | n:  28
IntGELU    | n:  26
IntSoftmax | n:  28
IntGELU    | n:  26
IntSoftmax | n:  28
IntGELU    | n:  26
IntSoftmax | n:  28
IntGELU    | n:  26
IntSoftmax | n:  28
IntGELU    | n:  26
IntSoftmax | n:  28
IntGELU    | n:  26
IntSoftmax | n:  28
IntGELU    | n:  26
.calib done
Test: [  0/391]	Time  3.689 ( 3.689)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.66
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=28, intgelu_exp_n=27
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=28, intgelu_exp_n=27, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  28
IntGELU    | n:  27
IntSoftmax | n:  28
IntGELU    | n:  27
IntSoftmax | n:  28
IntGELU    | n:  27
IntSoftmax | n:  28
IntGELU    | n:  27
IntSoftmax | n:  28
IntGELU    | n:  27
IntSoftmax | n:  28
IntGELU    | n:  27
IntSoftmax | n:  28
IntGELU    | n:  27
IntSoftmax | n:  28
IntGELU    | n:  27
IntSoftmax | n:  28
IntGELU    | n:  27
IntSoftmax | n:  28
IntGELU    | n:  27
IntSoftmax | n:  28
IntGELU    | n:  27
IntSoftmax | n:  28
IntGELU    | n:  27
.calib done
Test: [  0/391]	Time  3.917 ( 3.917)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.84
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=28, intgelu_exp_n=28
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=28, intgelu_exp_n=28, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  28
IntGELU    | n:  28
IntSoftmax | n:  28
IntGELU    | n:  28
IntSoftmax | n:  28
IntGELU    | n:  28
IntSoftmax | n:  28
IntGELU    | n:  28
IntSoftmax | n:  28
IntGELU    | n:  28
IntSoftmax | n:  28
IntGELU    | n:  28
IntSoftmax | n:  28
IntGELU    | n:  28
IntSoftmax | n:  28
IntGELU    | n:  28
IntSoftmax | n:  28
IntGELU    | n:  28
IntSoftmax | n:  28
IntGELU    | n:  28
IntSoftmax | n:  28
IntGELU    | n:  28
IntSoftmax | n:  28
IntGELU    | n:  28
.calib done
Test: [  0/391]	Time  3.841 ( 3.841)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.85
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=28, intgelu_exp_n=29
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=28, intgelu_exp_n=29, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  28
IntGELU    | n:  29
IntSoftmax | n:  28
IntGELU    | n:  29
IntSoftmax | n:  28
IntGELU    | n:  29
IntSoftmax | n:  28
IntGELU    | n:  29
IntSoftmax | n:  28
IntGELU    | n:  29
IntSoftmax | n:  28
IntGELU    | n:  29
IntSoftmax | n:  28
IntGELU    | n:  29
IntSoftmax | n:  28
IntGELU    | n:  29
IntSoftmax | n:  28
IntGELU    | n:  29
IntSoftmax | n:  28
IntGELU    | n:  29
IntSoftmax | n:  28
IntGELU    | n:  29
IntSoftmax | n:  28
IntGELU    | n:  29
.calib done
Test: [  0/391]	Time  4.047 ( 4.047)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.93
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=28, intgelu_exp_n=30
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=28, intgelu_exp_n=30, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  28
IntGELU    | n:  30
IntSoftmax | n:  28
IntGELU    | n:  30
IntSoftmax | n:  28
IntGELU    | n:  30
IntSoftmax | n:  28
IntGELU    | n:  30
IntSoftmax | n:  28
IntGELU    | n:  30
IntSoftmax | n:  28
IntGELU    | n:  30
IntSoftmax | n:  28
IntGELU    | n:  30
IntSoftmax | n:  28
IntGELU    | n:  30
IntSoftmax | n:  28
IntGELU    | n:  30
IntSoftmax | n:  28
IntGELU    | n:  30
IntSoftmax | n:  28
IntGELU    | n:  30
IntSoftmax | n:  28
IntGELU    | n:  30
.calib done
Test: [  0/391]	Time  3.952 ( 3.952)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.92
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=28, intgelu_exp_n=31
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=28, intgelu_exp_n=31, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  28
IntGELU    | n:  31
IntSoftmax | n:  28
IntGELU    | n:  31
IntSoftmax | n:  28
IntGELU    | n:  31
IntSoftmax | n:  28
IntGELU    | n:  31
IntSoftmax | n:  28
IntGELU    | n:  31
IntSoftmax | n:  28
IntGELU    | n:  31
IntSoftmax | n:  28
IntGELU    | n:  31
IntSoftmax | n:  28
IntGELU    | n:  31
IntSoftmax | n:  28
IntGELU    | n:  31
IntSoftmax | n:  28
IntGELU    | n:  31
IntSoftmax | n:  28
IntGELU    | n:  31
IntSoftmax | n:  28
IntGELU    | n:  31
.calib done
Test: [  0/391]	Time  3.932 ( 3.932)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.78
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=29, intgelu_exp_n=0
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=29, intgelu_exp_n=0, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  29
IntGELU    | n:  0
IntSoftmax | n:  29
IntGELU    | n:  0
IntSoftmax | n:  29
IntGELU    | n:  0
IntSoftmax | n:  29
IntGELU    | n:  0
IntSoftmax | n:  29
IntGELU    | n:  0
IntSoftmax | n:  29
IntGELU    | n:  0
IntSoftmax | n:  29
IntGELU    | n:  0
IntSoftmax | n:  29
IntGELU    | n:  0
IntSoftmax | n:  29
IntGELU    | n:  0
IntSoftmax | n:  29
IntGELU    | n:  0
IntSoftmax | n:  29
IntGELU    | n:  0
IntSoftmax | n:  29
IntGELU    | n:  0
.calib done
Test: [  0/391]	Time  3.762 ( 3.762)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.74
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=29, intgelu_exp_n=1
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=29, intgelu_exp_n=1, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  29
IntGELU    | n:  1
IntSoftmax | n:  29
IntGELU    | n:  1
IntSoftmax | n:  29
IntGELU    | n:  1
IntSoftmax | n:  29
IntGELU    | n:  1
IntSoftmax | n:  29
IntGELU    | n:  1
IntSoftmax | n:  29
IntGELU    | n:  1
IntSoftmax | n:  29
IntGELU    | n:  1
IntSoftmax | n:  29
IntGELU    | n:  1
IntSoftmax | n:  29
IntGELU    | n:  1
IntSoftmax | n:  29
IntGELU    | n:  1
IntSoftmax | n:  29
IntGELU    | n:  1
IntSoftmax | n:  29
IntGELU    | n:  1
.calib done
Test: [  0/391]	Time  3.987 ( 3.987)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.94
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=29, intgelu_exp_n=2
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=29, intgelu_exp_n=2, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  29
IntGELU    | n:  2
IntSoftmax | n:  29
IntGELU    | n:  2
IntSoftmax | n:  29
IntGELU    | n:  2
IntSoftmax | n:  29
IntGELU    | n:  2
IntSoftmax | n:  29
IntGELU    | n:  2
IntSoftmax | n:  29
IntGELU    | n:  2
IntSoftmax | n:  29
IntGELU    | n:  2
IntSoftmax | n:  29
IntGELU    | n:  2
IntSoftmax | n:  29
IntGELU    | n:  2
IntSoftmax | n:  29
IntGELU    | n:  2
IntSoftmax | n:  29
IntGELU    | n:  2
IntSoftmax | n:  29
IntGELU    | n:  2
.calib done
Test: [  0/391]	Time  3.737 ( 3.737)	Acc@1   0.78 (  0.78)	Acc@5   0.78 (  0.78)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.781 Prec@5 0.781
Time: 8.63
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=29, intgelu_exp_n=3
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=29, intgelu_exp_n=3, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  29
IntGELU    | n:  3
IntSoftmax | n:  29
IntGELU    | n:  3
IntSoftmax | n:  29
IntGELU    | n:  3
IntSoftmax | n:  29
IntGELU    | n:  3
IntSoftmax | n:  29
IntGELU    | n:  3
IntSoftmax | n:  29
IntGELU    | n:  3
IntSoftmax | n:  29
IntGELU    | n:  3
IntSoftmax | n:  29
IntGELU    | n:  3
IntSoftmax | n:  29
IntGELU    | n:  3
IntSoftmax | n:  29
IntGELU    | n:  3
IntSoftmax | n:  29
IntGELU    | n:  3
IntSoftmax | n:  29
IntGELU    | n:  3
.calib done
Test: [  0/391]	Time  3.904 ( 3.904)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.87
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=29, intgelu_exp_n=4
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=29, intgelu_exp_n=4, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  29
IntGELU    | n:  4
IntSoftmax | n:  29
IntGELU    | n:  4
IntSoftmax | n:  29
IntGELU    | n:  4
IntSoftmax | n:  29
IntGELU    | n:  4
IntSoftmax | n:  29
IntGELU    | n:  4
IntSoftmax | n:  29
IntGELU    | n:  4
IntSoftmax | n:  29
IntGELU    | n:  4
IntSoftmax | n:  29
IntGELU    | n:  4
IntSoftmax | n:  29
IntGELU    | n:  4
IntSoftmax | n:  29
IntGELU    | n:  4
IntSoftmax | n:  29
IntGELU    | n:  4
IntSoftmax | n:  29
IntGELU    | n:  4
.calib done
Test: [  0/391]	Time  3.872 ( 3.872)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.82
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=29, intgelu_exp_n=5
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=29, intgelu_exp_n=5, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  29
IntGELU    | n:  5
IntSoftmax | n:  29
IntGELU    | n:  5
IntSoftmax | n:  29
IntGELU    | n:  5
IntSoftmax | n:  29
IntGELU    | n:  5
IntSoftmax | n:  29
IntGELU    | n:  5
IntSoftmax | n:  29
IntGELU    | n:  5
IntSoftmax | n:  29
IntGELU    | n:  5
IntSoftmax | n:  29
IntGELU    | n:  5
IntSoftmax | n:  29
IntGELU    | n:  5
IntSoftmax | n:  29
IntGELU    | n:  5
IntSoftmax | n:  29
IntGELU    | n:  5
IntSoftmax | n:  29
IntGELU    | n:  5
.calib done
Test: [  0/391]	Time  3.685 ( 3.685)	Acc@1   0.00 (  0.00)	Acc@5   0.78 (  0.78)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.781
Time: 8.64
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=29, intgelu_exp_n=6
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=29, intgelu_exp_n=6, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  29
IntGELU    | n:  6
IntSoftmax | n:  29
IntGELU    | n:  6
IntSoftmax | n:  29
IntGELU    | n:  6
IntSoftmax | n:  29
IntGELU    | n:  6
IntSoftmax | n:  29
IntGELU    | n:  6
IntSoftmax | n:  29
IntGELU    | n:  6
IntSoftmax | n:  29
IntGELU    | n:  6
IntSoftmax | n:  29
IntGELU    | n:  6
IntSoftmax | n:  29
IntGELU    | n:  6
IntSoftmax | n:  29
IntGELU    | n:  6
IntSoftmax | n:  29
IntGELU    | n:  6
IntSoftmax | n:  29
IntGELU    | n:  6
.calib done
Test: [  0/391]	Time  3.782 ( 3.782)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.75
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=29, intgelu_exp_n=7
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=29, intgelu_exp_n=7, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  29
IntGELU    | n:  7
IntSoftmax | n:  29
IntGELU    | n:  7
IntSoftmax | n:  29
IntGELU    | n:  7
IntSoftmax | n:  29
IntGELU    | n:  7
IntSoftmax | n:  29
IntGELU    | n:  7
IntSoftmax | n:  29
IntGELU    | n:  7
IntSoftmax | n:  29
IntGELU    | n:  7
IntSoftmax | n:  29
IntGELU    | n:  7
IntSoftmax | n:  29
IntGELU    | n:  7
IntSoftmax | n:  29
IntGELU    | n:  7
IntSoftmax | n:  29
IntGELU    | n:  7
IntSoftmax | n:  29
IntGELU    | n:  7
.calib done
Test: [  0/391]	Time  3.823 ( 3.823)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.83
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=29, intgelu_exp_n=8
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=29, intgelu_exp_n=8, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  29
IntGELU    | n:  8
IntSoftmax | n:  29
IntGELU    | n:  8
IntSoftmax | n:  29
IntGELU    | n:  8
IntSoftmax | n:  29
IntGELU    | n:  8
IntSoftmax | n:  29
IntGELU    | n:  8
IntSoftmax | n:  29
IntGELU    | n:  8
IntSoftmax | n:  29
IntGELU    | n:  8
IntSoftmax | n:  29
IntGELU    | n:  8
IntSoftmax | n:  29
IntGELU    | n:  8
IntSoftmax | n:  29
IntGELU    | n:  8
IntSoftmax | n:  29
IntGELU    | n:  8
IntSoftmax | n:  29
IntGELU    | n:  8
.calib done
Test: [  0/391]	Time  3.797 ( 3.797)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.71
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=29, intgelu_exp_n=9
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=29, intgelu_exp_n=9, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  29
IntGELU    | n:  9
IntSoftmax | n:  29
IntGELU    | n:  9
IntSoftmax | n:  29
IntGELU    | n:  9
IntSoftmax | n:  29
IntGELU    | n:  9
IntSoftmax | n:  29
IntGELU    | n:  9
IntSoftmax | n:  29
IntGELU    | n:  9
IntSoftmax | n:  29
IntGELU    | n:  9
IntSoftmax | n:  29
IntGELU    | n:  9
IntSoftmax | n:  29
IntGELU    | n:  9
IntSoftmax | n:  29
IntGELU    | n:  9
IntSoftmax | n:  29
IntGELU    | n:  9
IntSoftmax | n:  29
IntGELU    | n:  9
.calib done
Test: [  0/391]	Time  3.784 ( 3.784)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.77
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=29, intgelu_exp_n=10
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=29, intgelu_exp_n=10, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  29
IntGELU    | n:  10
IntSoftmax | n:  29
IntGELU    | n:  10
IntSoftmax | n:  29
IntGELU    | n:  10
IntSoftmax | n:  29
IntGELU    | n:  10
IntSoftmax | n:  29
IntGELU    | n:  10
IntSoftmax | n:  29
IntGELU    | n:  10
IntSoftmax | n:  29
IntGELU    | n:  10
IntSoftmax | n:  29
IntGELU    | n:  10
IntSoftmax | n:  29
IntGELU    | n:  10
IntSoftmax | n:  29
IntGELU    | n:  10
IntSoftmax | n:  29
IntGELU    | n:  10
IntSoftmax | n:  29
IntGELU    | n:  10
.calib done
Test: [  0/391]	Time  3.885 ( 3.885)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.81
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=29, intgelu_exp_n=11
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=29, intgelu_exp_n=11, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  29
IntGELU    | n:  11
IntSoftmax | n:  29
IntGELU    | n:  11
IntSoftmax | n:  29
IntGELU    | n:  11
IntSoftmax | n:  29
IntGELU    | n:  11
IntSoftmax | n:  29
IntGELU    | n:  11
IntSoftmax | n:  29
IntGELU    | n:  11
IntSoftmax | n:  29
IntGELU    | n:  11
IntSoftmax | n:  29
IntGELU    | n:  11
IntSoftmax | n:  29
IntGELU    | n:  11
IntSoftmax | n:  29
IntGELU    | n:  11
IntSoftmax | n:  29
IntGELU    | n:  11
IntSoftmax | n:  29
IntGELU    | n:  11
.calib done
Test: [  0/391]	Time  4.050 ( 4.050)	Acc@1   0.00 (  0.00)	Acc@5   0.78 (  0.78)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.781
Time: 9.02
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=29, intgelu_exp_n=12
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=29, intgelu_exp_n=12, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  29
IntGELU    | n:  12
IntSoftmax | n:  29
IntGELU    | n:  12
IntSoftmax | n:  29
IntGELU    | n:  12
IntSoftmax | n:  29
IntGELU    | n:  12
IntSoftmax | n:  29
IntGELU    | n:  12
IntSoftmax | n:  29
IntGELU    | n:  12
IntSoftmax | n:  29
IntGELU    | n:  12
IntSoftmax | n:  29
IntGELU    | n:  12
IntSoftmax | n:  29
IntGELU    | n:  12
IntSoftmax | n:  29
IntGELU    | n:  12
IntSoftmax | n:  29
IntGELU    | n:  12
IntSoftmax | n:  29
IntGELU    | n:  12
.calib done
Test: [  0/391]	Time  3.684 ( 3.684)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.59
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=29, intgelu_exp_n=13
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=29, intgelu_exp_n=13, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  29
IntGELU    | n:  13
IntSoftmax | n:  29
IntGELU    | n:  13
IntSoftmax | n:  29
IntGELU    | n:  13
IntSoftmax | n:  29
IntGELU    | n:  13
IntSoftmax | n:  29
IntGELU    | n:  13
IntSoftmax | n:  29
IntGELU    | n:  13
IntSoftmax | n:  29
IntGELU    | n:  13
IntSoftmax | n:  29
IntGELU    | n:  13
IntSoftmax | n:  29
IntGELU    | n:  13
IntSoftmax | n:  29
IntGELU    | n:  13
IntSoftmax | n:  29
IntGELU    | n:  13
IntSoftmax | n:  29
IntGELU    | n:  13
.calib done
Test: [  0/391]	Time  3.856 ( 3.856)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.88
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=29, intgelu_exp_n=14
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=29, intgelu_exp_n=14, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  29
IntGELU    | n:  14
IntSoftmax | n:  29
IntGELU    | n:  14
IntSoftmax | n:  29
IntGELU    | n:  14
IntSoftmax | n:  29
IntGELU    | n:  14
IntSoftmax | n:  29
IntGELU    | n:  14
IntSoftmax | n:  29
IntGELU    | n:  14
IntSoftmax | n:  29
IntGELU    | n:  14
IntSoftmax | n:  29
IntGELU    | n:  14
IntSoftmax | n:  29
IntGELU    | n:  14
IntSoftmax | n:  29
IntGELU    | n:  14
IntSoftmax | n:  29
IntGELU    | n:  14
IntSoftmax | n:  29
IntGELU    | n:  14
.calib done
Test: [  0/391]	Time  3.900 ( 3.900)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.82
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=29, intgelu_exp_n=15
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=29, intgelu_exp_n=15, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  29
IntGELU    | n:  15
IntSoftmax | n:  29
IntGELU    | n:  15
IntSoftmax | n:  29
IntGELU    | n:  15
IntSoftmax | n:  29
IntGELU    | n:  15
IntSoftmax | n:  29
IntGELU    | n:  15
IntSoftmax | n:  29
IntGELU    | n:  15
IntSoftmax | n:  29
IntGELU    | n:  15
IntSoftmax | n:  29
IntGELU    | n:  15
IntSoftmax | n:  29
IntGELU    | n:  15
IntSoftmax | n:  29
IntGELU    | n:  15
IntSoftmax | n:  29
IntGELU    | n:  15
IntSoftmax | n:  29
IntGELU    | n:  15
.calib done
Test: [  0/391]	Time  3.839 ( 3.839)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.84
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=29, intgelu_exp_n=16
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=29, intgelu_exp_n=16, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  29
IntGELU    | n:  16
IntSoftmax | n:  29
IntGELU    | n:  16
IntSoftmax | n:  29
IntGELU    | n:  16
IntSoftmax | n:  29
IntGELU    | n:  16
IntSoftmax | n:  29
IntGELU    | n:  16
IntSoftmax | n:  29
IntGELU    | n:  16
IntSoftmax | n:  29
IntGELU    | n:  16
IntSoftmax | n:  29
IntGELU    | n:  16
IntSoftmax | n:  29
IntGELU    | n:  16
IntSoftmax | n:  29
IntGELU    | n:  16
IntSoftmax | n:  29
IntGELU    | n:  16
IntSoftmax | n:  29
IntGELU    | n:  16
.calib done
Test: [  0/391]	Time  3.963 ( 3.963)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.89
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=29, intgelu_exp_n=17
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=29, intgelu_exp_n=17, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  29
IntGELU    | n:  17
IntSoftmax | n:  29
IntGELU    | n:  17
IntSoftmax | n:  29
IntGELU    | n:  17
IntSoftmax | n:  29
IntGELU    | n:  17
IntSoftmax | n:  29
IntGELU    | n:  17
IntSoftmax | n:  29
IntGELU    | n:  17
IntSoftmax | n:  29
IntGELU    | n:  17
IntSoftmax | n:  29
IntGELU    | n:  17
IntSoftmax | n:  29
IntGELU    | n:  17
IntSoftmax | n:  29
IntGELU    | n:  17
IntSoftmax | n:  29
IntGELU    | n:  17
IntSoftmax | n:  29
IntGELU    | n:  17
.calib done
Test: [  0/391]	Time  3.881 ( 3.881)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.78
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=29, intgelu_exp_n=18
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=29, intgelu_exp_n=18, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  29
IntGELU    | n:  18
IntSoftmax | n:  29
IntGELU    | n:  18
IntSoftmax | n:  29
IntGELU    | n:  18
IntSoftmax | n:  29
IntGELU    | n:  18
IntSoftmax | n:  29
IntGELU    | n:  18
IntSoftmax | n:  29
IntGELU    | n:  18
IntSoftmax | n:  29
IntGELU    | n:  18
IntSoftmax | n:  29
IntGELU    | n:  18
IntSoftmax | n:  29
IntGELU    | n:  18
IntSoftmax | n:  29
IntGELU    | n:  18
IntSoftmax | n:  29
IntGELU    | n:  18
IntSoftmax | n:  29
IntGELU    | n:  18
.calib done
Test: [  0/391]	Time  3.885 ( 3.885)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.84
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=29, intgelu_exp_n=19
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=29, intgelu_exp_n=19, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  29
IntGELU    | n:  19
IntSoftmax | n:  29
IntGELU    | n:  19
IntSoftmax | n:  29
IntGELU    | n:  19
IntSoftmax | n:  29
IntGELU    | n:  19
IntSoftmax | n:  29
IntGELU    | n:  19
IntSoftmax | n:  29
IntGELU    | n:  19
IntSoftmax | n:  29
IntGELU    | n:  19
IntSoftmax | n:  29
IntGELU    | n:  19
IntSoftmax | n:  29
IntGELU    | n:  19
IntSoftmax | n:  29
IntGELU    | n:  19
IntSoftmax | n:  29
IntGELU    | n:  19
IntSoftmax | n:  29
IntGELU    | n:  19
.calib done
Test: [  0/391]	Time  3.852 ( 3.852)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.79
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=29, intgelu_exp_n=20
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=29, intgelu_exp_n=20, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  29
IntGELU    | n:  20
IntSoftmax | n:  29
IntGELU    | n:  20
IntSoftmax | n:  29
IntGELU    | n:  20
IntSoftmax | n:  29
IntGELU    | n:  20
IntSoftmax | n:  29
IntGELU    | n:  20
IntSoftmax | n:  29
IntGELU    | n:  20
IntSoftmax | n:  29
IntGELU    | n:  20
IntSoftmax | n:  29
IntGELU    | n:  20
IntSoftmax | n:  29
IntGELU    | n:  20
IntSoftmax | n:  29
IntGELU    | n:  20
IntSoftmax | n:  29
IntGELU    | n:  20
IntSoftmax | n:  29
IntGELU    | n:  20
.calib done
Test: [  0/391]	Time  3.970 ( 3.970)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.96
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=29, intgelu_exp_n=21
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=29, intgelu_exp_n=21, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  29
IntGELU    | n:  21
IntSoftmax | n:  29
IntGELU    | n:  21
IntSoftmax | n:  29
IntGELU    | n:  21
IntSoftmax | n:  29
IntGELU    | n:  21
IntSoftmax | n:  29
IntGELU    | n:  21
IntSoftmax | n:  29
IntGELU    | n:  21
IntSoftmax | n:  29
IntGELU    | n:  21
IntSoftmax | n:  29
IntGELU    | n:  21
IntSoftmax | n:  29
IntGELU    | n:  21
IntSoftmax | n:  29
IntGELU    | n:  21
IntSoftmax | n:  29
IntGELU    | n:  21
IntSoftmax | n:  29
IntGELU    | n:  21
.calib done
Test: [  0/391]	Time  3.921 ( 3.921)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.85
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=29, intgelu_exp_n=22
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=29, intgelu_exp_n=22, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  29
IntGELU    | n:  22
IntSoftmax | n:  29
IntGELU    | n:  22
IntSoftmax | n:  29
IntGELU    | n:  22
IntSoftmax | n:  29
IntGELU    | n:  22
IntSoftmax | n:  29
IntGELU    | n:  22
IntSoftmax | n:  29
IntGELU    | n:  22
IntSoftmax | n:  29
IntGELU    | n:  22
IntSoftmax | n:  29
IntGELU    | n:  22
IntSoftmax | n:  29
IntGELU    | n:  22
IntSoftmax | n:  29
IntGELU    | n:  22
IntSoftmax | n:  29
IntGELU    | n:  22
IntSoftmax | n:  29
IntGELU    | n:  22
.calib done
Test: [  0/391]	Time  3.665 ( 3.665)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.72
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=29, intgelu_exp_n=23
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=29, intgelu_exp_n=23, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  29
IntGELU    | n:  23
IntSoftmax | n:  29
IntGELU    | n:  23
IntSoftmax | n:  29
IntGELU    | n:  23
IntSoftmax | n:  29
IntGELU    | n:  23
IntSoftmax | n:  29
IntGELU    | n:  23
IntSoftmax | n:  29
IntGELU    | n:  23
IntSoftmax | n:  29
IntGELU    | n:  23
IntSoftmax | n:  29
IntGELU    | n:  23
IntSoftmax | n:  29
IntGELU    | n:  23
IntSoftmax | n:  29
IntGELU    | n:  23
IntSoftmax | n:  29
IntGELU    | n:  23
IntSoftmax | n:  29
IntGELU    | n:  23
.calib done
Test: [  0/391]	Time  3.763 ( 3.763)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.74
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=29, intgelu_exp_n=24
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=29, intgelu_exp_n=24, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  29
IntGELU    | n:  24
IntSoftmax | n:  29
IntGELU    | n:  24
IntSoftmax | n:  29
IntGELU    | n:  24
IntSoftmax | n:  29
IntGELU    | n:  24
IntSoftmax | n:  29
IntGELU    | n:  24
IntSoftmax | n:  29
IntGELU    | n:  24
IntSoftmax | n:  29
IntGELU    | n:  24
IntSoftmax | n:  29
IntGELU    | n:  24
IntSoftmax | n:  29
IntGELU    | n:  24
IntSoftmax | n:  29
IntGELU    | n:  24
IntSoftmax | n:  29
IntGELU    | n:  24
IntSoftmax | n:  29
IntGELU    | n:  24
.calib done
Test: [  0/391]	Time  3.874 ( 3.874)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.83
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=29, intgelu_exp_n=25
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=29, intgelu_exp_n=25, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  29
IntGELU    | n:  25
IntSoftmax | n:  29
IntGELU    | n:  25
IntSoftmax | n:  29
IntGELU    | n:  25
IntSoftmax | n:  29
IntGELU    | n:  25
IntSoftmax | n:  29
IntGELU    | n:  25
IntSoftmax | n:  29
IntGELU    | n:  25
IntSoftmax | n:  29
IntGELU    | n:  25
IntSoftmax | n:  29
IntGELU    | n:  25
IntSoftmax | n:  29
IntGELU    | n:  25
IntSoftmax | n:  29
IntGELU    | n:  25
IntSoftmax | n:  29
IntGELU    | n:  25
IntSoftmax | n:  29
IntGELU    | n:  25
.calib done
Test: [  0/391]	Time  3.880 ( 3.880)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.83
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=29, intgelu_exp_n=26
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=29, intgelu_exp_n=26, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  29
IntGELU    | n:  26
IntSoftmax | n:  29
IntGELU    | n:  26
IntSoftmax | n:  29
IntGELU    | n:  26
IntSoftmax | n:  29
IntGELU    | n:  26
IntSoftmax | n:  29
IntGELU    | n:  26
IntSoftmax | n:  29
IntGELU    | n:  26
IntSoftmax | n:  29
IntGELU    | n:  26
IntSoftmax | n:  29
IntGELU    | n:  26
IntSoftmax | n:  29
IntGELU    | n:  26
IntSoftmax | n:  29
IntGELU    | n:  26
IntSoftmax | n:  29
IntGELU    | n:  26
IntSoftmax | n:  29
IntGELU    | n:  26
.calib done
Test: [  0/391]	Time  3.860 ( 3.860)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.81
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=29, intgelu_exp_n=27
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=29, intgelu_exp_n=27, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  29
IntGELU    | n:  27
IntSoftmax | n:  29
IntGELU    | n:  27
IntSoftmax | n:  29
IntGELU    | n:  27
IntSoftmax | n:  29
IntGELU    | n:  27
IntSoftmax | n:  29
IntGELU    | n:  27
IntSoftmax | n:  29
IntGELU    | n:  27
IntSoftmax | n:  29
IntGELU    | n:  27
IntSoftmax | n:  29
IntGELU    | n:  27
IntSoftmax | n:  29
IntGELU    | n:  27
IntSoftmax | n:  29
IntGELU    | n:  27
IntSoftmax | n:  29
IntGELU    | n:  27
IntSoftmax | n:  29
IntGELU    | n:  27
.calib done
Test: [  0/391]	Time  3.965 ( 3.965)	Acc@1   0.00 (  0.00)	Acc@5   1.56 (  1.56)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 1.562
Time: 8.93
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=29, intgelu_exp_n=28
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=29, intgelu_exp_n=28, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  29
IntGELU    | n:  28
IntSoftmax | n:  29
IntGELU    | n:  28
IntSoftmax | n:  29
IntGELU    | n:  28
IntSoftmax | n:  29
IntGELU    | n:  28
IntSoftmax | n:  29
IntGELU    | n:  28
IntSoftmax | n:  29
IntGELU    | n:  28
IntSoftmax | n:  29
IntGELU    | n:  28
IntSoftmax | n:  29
IntGELU    | n:  28
IntSoftmax | n:  29
IntGELU    | n:  28
IntSoftmax | n:  29
IntGELU    | n:  28
IntSoftmax | n:  29
IntGELU    | n:  28
IntSoftmax | n:  29
IntGELU    | n:  28
.calib done
Test: [  0/391]	Time  3.792 ( 3.792)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.79
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=29, intgelu_exp_n=29
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=29, intgelu_exp_n=29, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  29
IntGELU    | n:  29
IntSoftmax | n:  29
IntGELU    | n:  29
IntSoftmax | n:  29
IntGELU    | n:  29
IntSoftmax | n:  29
IntGELU    | n:  29
IntSoftmax | n:  29
IntGELU    | n:  29
IntSoftmax | n:  29
IntGELU    | n:  29
IntSoftmax | n:  29
IntGELU    | n:  29
IntSoftmax | n:  29
IntGELU    | n:  29
IntSoftmax | n:  29
IntGELU    | n:  29
IntSoftmax | n:  29
IntGELU    | n:  29
IntSoftmax | n:  29
IntGELU    | n:  29
IntSoftmax | n:  29
IntGELU    | n:  29
.calib done
Test: [  0/391]	Time  3.806 ( 3.806)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.78
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=29, intgelu_exp_n=30
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=29, intgelu_exp_n=30, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  29
IntGELU    | n:  30
IntSoftmax | n:  29
IntGELU    | n:  30
IntSoftmax | n:  29
IntGELU    | n:  30
IntSoftmax | n:  29
IntGELU    | n:  30
IntSoftmax | n:  29
IntGELU    | n:  30
IntSoftmax | n:  29
IntGELU    | n:  30
IntSoftmax | n:  29
IntGELU    | n:  30
IntSoftmax | n:  29
IntGELU    | n:  30
IntSoftmax | n:  29
IntGELU    | n:  30
IntSoftmax | n:  29
IntGELU    | n:  30
IntSoftmax | n:  29
IntGELU    | n:  30
IntSoftmax | n:  29
IntGELU    | n:  30
.calib done
Test: [  0/391]	Time  3.747 ( 3.747)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.77
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=29, intgelu_exp_n=31
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=29, intgelu_exp_n=31, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  29
IntGELU    | n:  31
IntSoftmax | n:  29
IntGELU    | n:  31
IntSoftmax | n:  29
IntGELU    | n:  31
IntSoftmax | n:  29
IntGELU    | n:  31
IntSoftmax | n:  29
IntGELU    | n:  31
IntSoftmax | n:  29
IntGELU    | n:  31
IntSoftmax | n:  29
IntGELU    | n:  31
IntSoftmax | n:  29
IntGELU    | n:  31
IntSoftmax | n:  29
IntGELU    | n:  31
IntSoftmax | n:  29
IntGELU    | n:  31
IntSoftmax | n:  29
IntGELU    | n:  31
IntSoftmax | n:  29
IntGELU    | n:  31
.calib done
Test: [  0/391]	Time  3.762 ( 3.762)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.73
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=30, intgelu_exp_n=0
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=30, intgelu_exp_n=0, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  30
IntGELU    | n:  0
IntSoftmax | n:  30
IntGELU    | n:  0
IntSoftmax | n:  30
IntGELU    | n:  0
IntSoftmax | n:  30
IntGELU    | n:  0
IntSoftmax | n:  30
IntGELU    | n:  0
IntSoftmax | n:  30
IntGELU    | n:  0
IntSoftmax | n:  30
IntGELU    | n:  0
IntSoftmax | n:  30
IntGELU    | n:  0
IntSoftmax | n:  30
IntGELU    | n:  0
IntSoftmax | n:  30
IntGELU    | n:  0
IntSoftmax | n:  30
IntGELU    | n:  0
IntSoftmax | n:  30
IntGELU    | n:  0
.calib done
Test: [  0/391]	Time  3.763 ( 3.763)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.75
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=30, intgelu_exp_n=1
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=30, intgelu_exp_n=1, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  30
IntGELU    | n:  1
IntSoftmax | n:  30
IntGELU    | n:  1
IntSoftmax | n:  30
IntGELU    | n:  1
IntSoftmax | n:  30
IntGELU    | n:  1
IntSoftmax | n:  30
IntGELU    | n:  1
IntSoftmax | n:  30
IntGELU    | n:  1
IntSoftmax | n:  30
IntGELU    | n:  1
IntSoftmax | n:  30
IntGELU    | n:  1
IntSoftmax | n:  30
IntGELU    | n:  1
IntSoftmax | n:  30
IntGELU    | n:  1
IntSoftmax | n:  30
IntGELU    | n:  1
IntSoftmax | n:  30
IntGELU    | n:  1
.calib done
Test: [  0/391]	Time  3.919 ( 3.919)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.90
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=30, intgelu_exp_n=2
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=30, intgelu_exp_n=2, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  30
IntGELU    | n:  2
IntSoftmax | n:  30
IntGELU    | n:  2
IntSoftmax | n:  30
IntGELU    | n:  2
IntSoftmax | n:  30
IntGELU    | n:  2
IntSoftmax | n:  30
IntGELU    | n:  2
IntSoftmax | n:  30
IntGELU    | n:  2
IntSoftmax | n:  30
IntGELU    | n:  2
IntSoftmax | n:  30
IntGELU    | n:  2
IntSoftmax | n:  30
IntGELU    | n:  2
IntSoftmax | n:  30
IntGELU    | n:  2
IntSoftmax | n:  30
IntGELU    | n:  2
IntSoftmax | n:  30
IntGELU    | n:  2
.calib done
Test: [  0/391]	Time  3.778 ( 3.778)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.73
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=30, intgelu_exp_n=3
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=30, intgelu_exp_n=3, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  30
IntGELU    | n:  3
IntSoftmax | n:  30
IntGELU    | n:  3
IntSoftmax | n:  30
IntGELU    | n:  3
IntSoftmax | n:  30
IntGELU    | n:  3
IntSoftmax | n:  30
IntGELU    | n:  3
IntSoftmax | n:  30
IntGELU    | n:  3
IntSoftmax | n:  30
IntGELU    | n:  3
IntSoftmax | n:  30
IntGELU    | n:  3
IntSoftmax | n:  30
IntGELU    | n:  3
IntSoftmax | n:  30
IntGELU    | n:  3
IntSoftmax | n:  30
IntGELU    | n:  3
IntSoftmax | n:  30
IntGELU    | n:  3
.calib done
Test: [  0/391]	Time  4.011 ( 4.011)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.91
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=30, intgelu_exp_n=4
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=30, intgelu_exp_n=4, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  30
IntGELU    | n:  4
IntSoftmax | n:  30
IntGELU    | n:  4
IntSoftmax | n:  30
IntGELU    | n:  4
IntSoftmax | n:  30
IntGELU    | n:  4
IntSoftmax | n:  30
IntGELU    | n:  4
IntSoftmax | n:  30
IntGELU    | n:  4
IntSoftmax | n:  30
IntGELU    | n:  4
IntSoftmax | n:  30
IntGELU    | n:  4
IntSoftmax | n:  30
IntGELU    | n:  4
IntSoftmax | n:  30
IntGELU    | n:  4
IntSoftmax | n:  30
IntGELU    | n:  4
IntSoftmax | n:  30
IntGELU    | n:  4
.calib done
Test: [  0/391]	Time  3.843 ( 3.843)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.79
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=30, intgelu_exp_n=5
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=30, intgelu_exp_n=5, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  30
IntGELU    | n:  5
IntSoftmax | n:  30
IntGELU    | n:  5
IntSoftmax | n:  30
IntGELU    | n:  5
IntSoftmax | n:  30
IntGELU    | n:  5
IntSoftmax | n:  30
IntGELU    | n:  5
IntSoftmax | n:  30
IntGELU    | n:  5
IntSoftmax | n:  30
IntGELU    | n:  5
IntSoftmax | n:  30
IntGELU    | n:  5
IntSoftmax | n:  30
IntGELU    | n:  5
IntSoftmax | n:  30
IntGELU    | n:  5
IntSoftmax | n:  30
IntGELU    | n:  5
IntSoftmax | n:  30
IntGELU    | n:  5
.calib done
Test: [  0/391]	Time  4.009 ( 4.009)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.94
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=30, intgelu_exp_n=6
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=30, intgelu_exp_n=6, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  30
IntGELU    | n:  6
IntSoftmax | n:  30
IntGELU    | n:  6
IntSoftmax | n:  30
IntGELU    | n:  6
IntSoftmax | n:  30
IntGELU    | n:  6
IntSoftmax | n:  30
IntGELU    | n:  6
IntSoftmax | n:  30
IntGELU    | n:  6
IntSoftmax | n:  30
IntGELU    | n:  6
IntSoftmax | n:  30
IntGELU    | n:  6
IntSoftmax | n:  30
IntGELU    | n:  6
IntSoftmax | n:  30
IntGELU    | n:  6
IntSoftmax | n:  30
IntGELU    | n:  6
IntSoftmax | n:  30
IntGELU    | n:  6
.calib done
Test: [  0/391]	Time  3.913 ( 3.913)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.93
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=30, intgelu_exp_n=7
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=30, intgelu_exp_n=7, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  30
IntGELU    | n:  7
IntSoftmax | n:  30
IntGELU    | n:  7
IntSoftmax | n:  30
IntGELU    | n:  7
IntSoftmax | n:  30
IntGELU    | n:  7
IntSoftmax | n:  30
IntGELU    | n:  7
IntSoftmax | n:  30
IntGELU    | n:  7
IntSoftmax | n:  30
IntGELU    | n:  7
IntSoftmax | n:  30
IntGELU    | n:  7
IntSoftmax | n:  30
IntGELU    | n:  7
IntSoftmax | n:  30
IntGELU    | n:  7
IntSoftmax | n:  30
IntGELU    | n:  7
IntSoftmax | n:  30
IntGELU    | n:  7
.calib done
Test: [  0/391]	Time  3.665 ( 3.665)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.68
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=30, intgelu_exp_n=8
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=30, intgelu_exp_n=8, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  30
IntGELU    | n:  8
IntSoftmax | n:  30
IntGELU    | n:  8
IntSoftmax | n:  30
IntGELU    | n:  8
IntSoftmax | n:  30
IntGELU    | n:  8
IntSoftmax | n:  30
IntGELU    | n:  8
IntSoftmax | n:  30
IntGELU    | n:  8
IntSoftmax | n:  30
IntGELU    | n:  8
IntSoftmax | n:  30
IntGELU    | n:  8
IntSoftmax | n:  30
IntGELU    | n:  8
IntSoftmax | n:  30
IntGELU    | n:  8
IntSoftmax | n:  30
IntGELU    | n:  8
IntSoftmax | n:  30
IntGELU    | n:  8
.calib done
Test: [  0/391]	Time  3.730 ( 3.730)	Acc@1   0.00 (  0.00)	Acc@5   0.78 (  0.78)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.781
Time: 8.70
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=30, intgelu_exp_n=9
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=30, intgelu_exp_n=9, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  30
IntGELU    | n:  9
IntSoftmax | n:  30
IntGELU    | n:  9
IntSoftmax | n:  30
IntGELU    | n:  9
IntSoftmax | n:  30
IntGELU    | n:  9
IntSoftmax | n:  30
IntGELU    | n:  9
IntSoftmax | n:  30
IntGELU    | n:  9
IntSoftmax | n:  30
IntGELU    | n:  9
IntSoftmax | n:  30
IntGELU    | n:  9
IntSoftmax | n:  30
IntGELU    | n:  9
IntSoftmax | n:  30
IntGELU    | n:  9
IntSoftmax | n:  30
IntGELU    | n:  9
IntSoftmax | n:  30
IntGELU    | n:  9
.calib done
Test: [  0/391]	Time  3.855 ( 3.855)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.84
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=30, intgelu_exp_n=10
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=30, intgelu_exp_n=10, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  30
IntGELU    | n:  10
IntSoftmax | n:  30
IntGELU    | n:  10
IntSoftmax | n:  30
IntGELU    | n:  10
IntSoftmax | n:  30
IntGELU    | n:  10
IntSoftmax | n:  30
IntGELU    | n:  10
IntSoftmax | n:  30
IntGELU    | n:  10
IntSoftmax | n:  30
IntGELU    | n:  10
IntSoftmax | n:  30
IntGELU    | n:  10
IntSoftmax | n:  30
IntGELU    | n:  10
IntSoftmax | n:  30
IntGELU    | n:  10
IntSoftmax | n:  30
IntGELU    | n:  10
IntSoftmax | n:  30
IntGELU    | n:  10
.calib done
Test: [  0/391]	Time  3.739 ( 3.739)	Acc@1   0.00 (  0.00)	Acc@5   0.78 (  0.78)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.781
Time: 8.69
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=30, intgelu_exp_n=11
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=30, intgelu_exp_n=11, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  30
IntGELU    | n:  11
IntSoftmax | n:  30
IntGELU    | n:  11
IntSoftmax | n:  30
IntGELU    | n:  11
IntSoftmax | n:  30
IntGELU    | n:  11
IntSoftmax | n:  30
IntGELU    | n:  11
IntSoftmax | n:  30
IntGELU    | n:  11
IntSoftmax | n:  30
IntGELU    | n:  11
IntSoftmax | n:  30
IntGELU    | n:  11
IntSoftmax | n:  30
IntGELU    | n:  11
IntSoftmax | n:  30
IntGELU    | n:  11
IntSoftmax | n:  30
IntGELU    | n:  11
IntSoftmax | n:  30
IntGELU    | n:  11
.calib done
Test: [  0/391]	Time  3.688 ( 3.688)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.63
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=30, intgelu_exp_n=12
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=30, intgelu_exp_n=12, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  30
IntGELU    | n:  12
IntSoftmax | n:  30
IntGELU    | n:  12
IntSoftmax | n:  30
IntGELU    | n:  12
IntSoftmax | n:  30
IntGELU    | n:  12
IntSoftmax | n:  30
IntGELU    | n:  12
IntSoftmax | n:  30
IntGELU    | n:  12
IntSoftmax | n:  30
IntGELU    | n:  12
IntSoftmax | n:  30
IntGELU    | n:  12
IntSoftmax | n:  30
IntGELU    | n:  12
IntSoftmax | n:  30
IntGELU    | n:  12
IntSoftmax | n:  30
IntGELU    | n:  12
IntSoftmax | n:  30
IntGELU    | n:  12
.calib done
Test: [  0/391]	Time  3.904 ( 3.904)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.85
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=30, intgelu_exp_n=13
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=30, intgelu_exp_n=13, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  30
IntGELU    | n:  13
IntSoftmax | n:  30
IntGELU    | n:  13
IntSoftmax | n:  30
IntGELU    | n:  13
IntSoftmax | n:  30
IntGELU    | n:  13
IntSoftmax | n:  30
IntGELU    | n:  13
IntSoftmax | n:  30
IntGELU    | n:  13
IntSoftmax | n:  30
IntGELU    | n:  13
IntSoftmax | n:  30
IntGELU    | n:  13
IntSoftmax | n:  30
IntGELU    | n:  13
IntSoftmax | n:  30
IntGELU    | n:  13
IntSoftmax | n:  30
IntGELU    | n:  13
IntSoftmax | n:  30
IntGELU    | n:  13
.calib done
Test: [  0/391]	Time  4.056 ( 4.056)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 9.04
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=30, intgelu_exp_n=14
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=30, intgelu_exp_n=14, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  30
IntGELU    | n:  14
IntSoftmax | n:  30
IntGELU    | n:  14
IntSoftmax | n:  30
IntGELU    | n:  14
IntSoftmax | n:  30
IntGELU    | n:  14
IntSoftmax | n:  30
IntGELU    | n:  14
IntSoftmax | n:  30
IntGELU    | n:  14
IntSoftmax | n:  30
IntGELU    | n:  14
IntSoftmax | n:  30
IntGELU    | n:  14
IntSoftmax | n:  30
IntGELU    | n:  14
IntSoftmax | n:  30
IntGELU    | n:  14
IntSoftmax | n:  30
IntGELU    | n:  14
IntSoftmax | n:  30
IntGELU    | n:  14
.calib done
Test: [  0/391]	Time  3.999 ( 3.999)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.90
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=30, intgelu_exp_n=15
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=30, intgelu_exp_n=15, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  30
IntGELU    | n:  15
IntSoftmax | n:  30
IntGELU    | n:  15
IntSoftmax | n:  30
IntGELU    | n:  15
IntSoftmax | n:  30
IntGELU    | n:  15
IntSoftmax | n:  30
IntGELU    | n:  15
IntSoftmax | n:  30
IntGELU    | n:  15
IntSoftmax | n:  30
IntGELU    | n:  15
IntSoftmax | n:  30
IntGELU    | n:  15
IntSoftmax | n:  30
IntGELU    | n:  15
IntSoftmax | n:  30
IntGELU    | n:  15
IntSoftmax | n:  30
IntGELU    | n:  15
IntSoftmax | n:  30
IntGELU    | n:  15
.calib done
Test: [  0/391]	Time  3.883 ( 3.883)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.88
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=30, intgelu_exp_n=16
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=30, intgelu_exp_n=16, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  30
IntGELU    | n:  16
IntSoftmax | n:  30
IntGELU    | n:  16
IntSoftmax | n:  30
IntGELU    | n:  16
IntSoftmax | n:  30
IntGELU    | n:  16
IntSoftmax | n:  30
IntGELU    | n:  16
IntSoftmax | n:  30
IntGELU    | n:  16
IntSoftmax | n:  30
IntGELU    | n:  16
IntSoftmax | n:  30
IntGELU    | n:  16
IntSoftmax | n:  30
IntGELU    | n:  16
IntSoftmax | n:  30
IntGELU    | n:  16
IntSoftmax | n:  30
IntGELU    | n:  16
IntSoftmax | n:  30
IntGELU    | n:  16
.calib done
Test: [  0/391]	Time  3.927 ( 3.927)	Acc@1   0.00 (  0.00)	Acc@5   0.78 (  0.78)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.781
Time: 8.89
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=30, intgelu_exp_n=17
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=30, intgelu_exp_n=17, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  30
IntGELU    | n:  17
IntSoftmax | n:  30
IntGELU    | n:  17
IntSoftmax | n:  30
IntGELU    | n:  17
IntSoftmax | n:  30
IntGELU    | n:  17
IntSoftmax | n:  30
IntGELU    | n:  17
IntSoftmax | n:  30
IntGELU    | n:  17
IntSoftmax | n:  30
IntGELU    | n:  17
IntSoftmax | n:  30
IntGELU    | n:  17
IntSoftmax | n:  30
IntGELU    | n:  17
IntSoftmax | n:  30
IntGELU    | n:  17
IntSoftmax | n:  30
IntGELU    | n:  17
IntSoftmax | n:  30
IntGELU    | n:  17
.calib done
Test: [  0/391]	Time  3.901 ( 3.901)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.84
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=30, intgelu_exp_n=18
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=30, intgelu_exp_n=18, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  30
IntGELU    | n:  18
IntSoftmax | n:  30
IntGELU    | n:  18
IntSoftmax | n:  30
IntGELU    | n:  18
IntSoftmax | n:  30
IntGELU    | n:  18
IntSoftmax | n:  30
IntGELU    | n:  18
IntSoftmax | n:  30
IntGELU    | n:  18
IntSoftmax | n:  30
IntGELU    | n:  18
IntSoftmax | n:  30
IntGELU    | n:  18
IntSoftmax | n:  30
IntGELU    | n:  18
IntSoftmax | n:  30
IntGELU    | n:  18
IntSoftmax | n:  30
IntGELU    | n:  18
IntSoftmax | n:  30
IntGELU    | n:  18
.calib done
Test: [  0/391]	Time  3.791 ( 3.791)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.81
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=30, intgelu_exp_n=19
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=30, intgelu_exp_n=19, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  30
IntGELU    | n:  19
IntSoftmax | n:  30
IntGELU    | n:  19
IntSoftmax | n:  30
IntGELU    | n:  19
IntSoftmax | n:  30
IntGELU    | n:  19
IntSoftmax | n:  30
IntGELU    | n:  19
IntSoftmax | n:  30
IntGELU    | n:  19
IntSoftmax | n:  30
IntGELU    | n:  19
IntSoftmax | n:  30
IntGELU    | n:  19
IntSoftmax | n:  30
IntGELU    | n:  19
IntSoftmax | n:  30
IntGELU    | n:  19
IntSoftmax | n:  30
IntGELU    | n:  19
IntSoftmax | n:  30
IntGELU    | n:  19
.calib done
Test: [  0/391]	Time  3.917 ( 3.917)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.85
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=30, intgelu_exp_n=20
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=30, intgelu_exp_n=20, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  30
IntGELU    | n:  20
IntSoftmax | n:  30
IntGELU    | n:  20
IntSoftmax | n:  30
IntGELU    | n:  20
IntSoftmax | n:  30
IntGELU    | n:  20
IntSoftmax | n:  30
IntGELU    | n:  20
IntSoftmax | n:  30
IntGELU    | n:  20
IntSoftmax | n:  30
IntGELU    | n:  20
IntSoftmax | n:  30
IntGELU    | n:  20
IntSoftmax | n:  30
IntGELU    | n:  20
IntSoftmax | n:  30
IntGELU    | n:  20
IntSoftmax | n:  30
IntGELU    | n:  20
IntSoftmax | n:  30
IntGELU    | n:  20
.calib done
Test: [  0/391]	Time  3.886 ( 3.886)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.86
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=30, intgelu_exp_n=21
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=30, intgelu_exp_n=21, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  30
IntGELU    | n:  21
IntSoftmax | n:  30
IntGELU    | n:  21
IntSoftmax | n:  30
IntGELU    | n:  21
IntSoftmax | n:  30
IntGELU    | n:  21
IntSoftmax | n:  30
IntGELU    | n:  21
IntSoftmax | n:  30
IntGELU    | n:  21
IntSoftmax | n:  30
IntGELU    | n:  21
IntSoftmax | n:  30
IntGELU    | n:  21
IntSoftmax | n:  30
IntGELU    | n:  21
IntSoftmax | n:  30
IntGELU    | n:  21
IntSoftmax | n:  30
IntGELU    | n:  21
IntSoftmax | n:  30
IntGELU    | n:  21
.calib done
Test: [  0/391]	Time  4.030 ( 4.030)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 9.03
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=30, intgelu_exp_n=22
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=30, intgelu_exp_n=22, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  30
IntGELU    | n:  22
IntSoftmax | n:  30
IntGELU    | n:  22
IntSoftmax | n:  30
IntGELU    | n:  22
IntSoftmax | n:  30
IntGELU    | n:  22
IntSoftmax | n:  30
IntGELU    | n:  22
IntSoftmax | n:  30
IntGELU    | n:  22
IntSoftmax | n:  30
IntGELU    | n:  22
IntSoftmax | n:  30
IntGELU    | n:  22
IntSoftmax | n:  30
IntGELU    | n:  22
IntSoftmax | n:  30
IntGELU    | n:  22
IntSoftmax | n:  30
IntGELU    | n:  22
IntSoftmax | n:  30
IntGELU    | n:  22
.calib done
Test: [  0/391]	Time  3.742 ( 3.742)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.73
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=30, intgelu_exp_n=23
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=30, intgelu_exp_n=23, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  30
IntGELU    | n:  23
IntSoftmax | n:  30
IntGELU    | n:  23
IntSoftmax | n:  30
IntGELU    | n:  23
IntSoftmax | n:  30
IntGELU    | n:  23
IntSoftmax | n:  30
IntGELU    | n:  23
IntSoftmax | n:  30
IntGELU    | n:  23
IntSoftmax | n:  30
IntGELU    | n:  23
IntSoftmax | n:  30
IntGELU    | n:  23
IntSoftmax | n:  30
IntGELU    | n:  23
IntSoftmax | n:  30
IntGELU    | n:  23
IntSoftmax | n:  30
IntGELU    | n:  23
IntSoftmax | n:  30
IntGELU    | n:  23
.calib done
Test: [  0/391]	Time  3.796 ( 3.796)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.76
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=30, intgelu_exp_n=24
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=30, intgelu_exp_n=24, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  30
IntGELU    | n:  24
IntSoftmax | n:  30
IntGELU    | n:  24
IntSoftmax | n:  30
IntGELU    | n:  24
IntSoftmax | n:  30
IntGELU    | n:  24
IntSoftmax | n:  30
IntGELU    | n:  24
IntSoftmax | n:  30
IntGELU    | n:  24
IntSoftmax | n:  30
IntGELU    | n:  24
IntSoftmax | n:  30
IntGELU    | n:  24
IntSoftmax | n:  30
IntGELU    | n:  24
IntSoftmax | n:  30
IntGELU    | n:  24
IntSoftmax | n:  30
IntGELU    | n:  24
IntSoftmax | n:  30
IntGELU    | n:  24
.calib done
Test: [  0/391]	Time  3.682 ( 3.682)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.66
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=30, intgelu_exp_n=25
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=30, intgelu_exp_n=25, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  30
IntGELU    | n:  25
IntSoftmax | n:  30
IntGELU    | n:  25
IntSoftmax | n:  30
IntGELU    | n:  25
IntSoftmax | n:  30
IntGELU    | n:  25
IntSoftmax | n:  30
IntGELU    | n:  25
IntSoftmax | n:  30
IntGELU    | n:  25
IntSoftmax | n:  30
IntGELU    | n:  25
IntSoftmax | n:  30
IntGELU    | n:  25
IntSoftmax | n:  30
IntGELU    | n:  25
IntSoftmax | n:  30
IntGELU    | n:  25
IntSoftmax | n:  30
IntGELU    | n:  25
IntSoftmax | n:  30
IntGELU    | n:  25
.calib done
Test: [  0/391]	Time  3.849 ( 3.849)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.80
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=30, intgelu_exp_n=26
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=30, intgelu_exp_n=26, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  30
IntGELU    | n:  26
IntSoftmax | n:  30
IntGELU    | n:  26
IntSoftmax | n:  30
IntGELU    | n:  26
IntSoftmax | n:  30
IntGELU    | n:  26
IntSoftmax | n:  30
IntGELU    | n:  26
IntSoftmax | n:  30
IntGELU    | n:  26
IntSoftmax | n:  30
IntGELU    | n:  26
IntSoftmax | n:  30
IntGELU    | n:  26
IntSoftmax | n:  30
IntGELU    | n:  26
IntSoftmax | n:  30
IntGELU    | n:  26
IntSoftmax | n:  30
IntGELU    | n:  26
IntSoftmax | n:  30
IntGELU    | n:  26
.calib done
Test: [  0/391]	Time  3.931 ( 3.931)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.91
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=30, intgelu_exp_n=27
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=30, intgelu_exp_n=27, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  30
IntGELU    | n:  27
IntSoftmax | n:  30
IntGELU    | n:  27
IntSoftmax | n:  30
IntGELU    | n:  27
IntSoftmax | n:  30
IntGELU    | n:  27
IntSoftmax | n:  30
IntGELU    | n:  27
IntSoftmax | n:  30
IntGELU    | n:  27
IntSoftmax | n:  30
IntGELU    | n:  27
IntSoftmax | n:  30
IntGELU    | n:  27
IntSoftmax | n:  30
IntGELU    | n:  27
IntSoftmax | n:  30
IntGELU    | n:  27
IntSoftmax | n:  30
IntGELU    | n:  27
IntSoftmax | n:  30
IntGELU    | n:  27
.calib done
Test: [  0/391]	Time  3.746 ( 3.746)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.76
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=30, intgelu_exp_n=28
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=30, intgelu_exp_n=28, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  30
IntGELU    | n:  28
IntSoftmax | n:  30
IntGELU    | n:  28
IntSoftmax | n:  30
IntGELU    | n:  28
IntSoftmax | n:  30
IntGELU    | n:  28
IntSoftmax | n:  30
IntGELU    | n:  28
IntSoftmax | n:  30
IntGELU    | n:  28
IntSoftmax | n:  30
IntGELU    | n:  28
IntSoftmax | n:  30
IntGELU    | n:  28
IntSoftmax | n:  30
IntGELU    | n:  28
IntSoftmax | n:  30
IntGELU    | n:  28
IntSoftmax | n:  30
IntGELU    | n:  28
IntSoftmax | n:  30
IntGELU    | n:  28
.calib done
Test: [  0/391]	Time  3.694 ( 3.694)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.67
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=30, intgelu_exp_n=29
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=30, intgelu_exp_n=29, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  30
IntGELU    | n:  29
IntSoftmax | n:  30
IntGELU    | n:  29
IntSoftmax | n:  30
IntGELU    | n:  29
IntSoftmax | n:  30
IntGELU    | n:  29
IntSoftmax | n:  30
IntGELU    | n:  29
IntSoftmax | n:  30
IntGELU    | n:  29
IntSoftmax | n:  30
IntGELU    | n:  29
IntSoftmax | n:  30
IntGELU    | n:  29
IntSoftmax | n:  30
IntGELU    | n:  29
IntSoftmax | n:  30
IntGELU    | n:  29
IntSoftmax | n:  30
IntGELU    | n:  29
IntSoftmax | n:  30
IntGELU    | n:  29
.calib done
Test: [  0/391]	Time  4.006 ( 4.006)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.98
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=30, intgelu_exp_n=30
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=30, intgelu_exp_n=30, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  30
IntGELU    | n:  30
IntSoftmax | n:  30
IntGELU    | n:  30
IntSoftmax | n:  30
IntGELU    | n:  30
IntSoftmax | n:  30
IntGELU    | n:  30
IntSoftmax | n:  30
IntGELU    | n:  30
IntSoftmax | n:  30
IntGELU    | n:  30
IntSoftmax | n:  30
IntGELU    | n:  30
IntSoftmax | n:  30
IntGELU    | n:  30
IntSoftmax | n:  30
IntGELU    | n:  30
IntSoftmax | n:  30
IntGELU    | n:  30
IntSoftmax | n:  30
IntGELU    | n:  30
IntSoftmax | n:  30
IntGELU    | n:  30
.calib done
Test: [  0/391]	Time  3.802 ( 3.802)	Acc@1   0.00 (  0.00)	Acc@5   0.78 (  0.78)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.781
Time: 8.78
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=30, intgelu_exp_n=31
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=30, intgelu_exp_n=31, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  30
IntGELU    | n:  31
IntSoftmax | n:  30
IntGELU    | n:  31
IntSoftmax | n:  30
IntGELU    | n:  31
IntSoftmax | n:  30
IntGELU    | n:  31
IntSoftmax | n:  30
IntGELU    | n:  31
IntSoftmax | n:  30
IntGELU    | n:  31
IntSoftmax | n:  30
IntGELU    | n:  31
IntSoftmax | n:  30
IntGELU    | n:  31
IntSoftmax | n:  30
IntGELU    | n:  31
IntSoftmax | n:  30
IntGELU    | n:  31
IntSoftmax | n:  30
IntGELU    | n:  31
IntSoftmax | n:  30
IntGELU    | n:  31
.calib done
Test: [  0/391]	Time  3.648 ( 3.648)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.58
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=31, intgelu_exp_n=0
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=31, intgelu_exp_n=0, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  31
IntGELU    | n:  0
IntSoftmax | n:  31
IntGELU    | n:  0
IntSoftmax | n:  31
IntGELU    | n:  0
IntSoftmax | n:  31
IntGELU    | n:  0
IntSoftmax | n:  31
IntGELU    | n:  0
IntSoftmax | n:  31
IntGELU    | n:  0
IntSoftmax | n:  31
IntGELU    | n:  0
IntSoftmax | n:  31
IntGELU    | n:  0
IntSoftmax | n:  31
IntGELU    | n:  0
IntSoftmax | n:  31
IntGELU    | n:  0
IntSoftmax | n:  31
IntGELU    | n:  0
IntSoftmax | n:  31
IntGELU    | n:  0
.calib done
Test: [  0/391]	Time  3.781 ( 3.781)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.69
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=31, intgelu_exp_n=1
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=31, intgelu_exp_n=1, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  31
IntGELU    | n:  1
IntSoftmax | n:  31
IntGELU    | n:  1
IntSoftmax | n:  31
IntGELU    | n:  1
IntSoftmax | n:  31
IntGELU    | n:  1
IntSoftmax | n:  31
IntGELU    | n:  1
IntSoftmax | n:  31
IntGELU    | n:  1
IntSoftmax | n:  31
IntGELU    | n:  1
IntSoftmax | n:  31
IntGELU    | n:  1
IntSoftmax | n:  31
IntGELU    | n:  1
IntSoftmax | n:  31
IntGELU    | n:  1
IntSoftmax | n:  31
IntGELU    | n:  1
IntSoftmax | n:  31
IntGELU    | n:  1
.calib done
Test: [  0/391]	Time  3.941 ( 3.941)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.96
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=31, intgelu_exp_n=2
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=31, intgelu_exp_n=2, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  31
IntGELU    | n:  2
IntSoftmax | n:  31
IntGELU    | n:  2
IntSoftmax | n:  31
IntGELU    | n:  2
IntSoftmax | n:  31
IntGELU    | n:  2
IntSoftmax | n:  31
IntGELU    | n:  2
IntSoftmax | n:  31
IntGELU    | n:  2
IntSoftmax | n:  31
IntGELU    | n:  2
IntSoftmax | n:  31
IntGELU    | n:  2
IntSoftmax | n:  31
IntGELU    | n:  2
IntSoftmax | n:  31
IntGELU    | n:  2
IntSoftmax | n:  31
IntGELU    | n:  2
IntSoftmax | n:  31
IntGELU    | n:  2
.calib done
Test: [  0/391]	Time  3.642 ( 3.642)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.59
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=31, intgelu_exp_n=3
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=31, intgelu_exp_n=3, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  31
IntGELU    | n:  3
IntSoftmax | n:  31
IntGELU    | n:  3
IntSoftmax | n:  31
IntGELU    | n:  3
IntSoftmax | n:  31
IntGELU    | n:  3
IntSoftmax | n:  31
IntGELU    | n:  3
IntSoftmax | n:  31
IntGELU    | n:  3
IntSoftmax | n:  31
IntGELU    | n:  3
IntSoftmax | n:  31
IntGELU    | n:  3
IntSoftmax | n:  31
IntGELU    | n:  3
IntSoftmax | n:  31
IntGELU    | n:  3
IntSoftmax | n:  31
IntGELU    | n:  3
IntSoftmax | n:  31
IntGELU    | n:  3
.calib done
Test: [  0/391]	Time  3.791 ( 3.791)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.76
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=31, intgelu_exp_n=4
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=31, intgelu_exp_n=4, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  31
IntGELU    | n:  4
IntSoftmax | n:  31
IntGELU    | n:  4
IntSoftmax | n:  31
IntGELU    | n:  4
IntSoftmax | n:  31
IntGELU    | n:  4
IntSoftmax | n:  31
IntGELU    | n:  4
IntSoftmax | n:  31
IntGELU    | n:  4
IntSoftmax | n:  31
IntGELU    | n:  4
IntSoftmax | n:  31
IntGELU    | n:  4
IntSoftmax | n:  31
IntGELU    | n:  4
IntSoftmax | n:  31
IntGELU    | n:  4
IntSoftmax | n:  31
IntGELU    | n:  4
IntSoftmax | n:  31
IntGELU    | n:  4
.calib done
Test: [  0/391]	Time  3.706 ( 3.706)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.67
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=31, intgelu_exp_n=5
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=31, intgelu_exp_n=5, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  31
IntGELU    | n:  5
IntSoftmax | n:  31
IntGELU    | n:  5
IntSoftmax | n:  31
IntGELU    | n:  5
IntSoftmax | n:  31
IntGELU    | n:  5
IntSoftmax | n:  31
IntGELU    | n:  5
IntSoftmax | n:  31
IntGELU    | n:  5
IntSoftmax | n:  31
IntGELU    | n:  5
IntSoftmax | n:  31
IntGELU    | n:  5
IntSoftmax | n:  31
IntGELU    | n:  5
IntSoftmax | n:  31
IntGELU    | n:  5
IntSoftmax | n:  31
IntGELU    | n:  5
IntSoftmax | n:  31
IntGELU    | n:  5
.calib done
Test: [  0/391]	Time  3.790 ( 3.790)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.78
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=31, intgelu_exp_n=6
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=31, intgelu_exp_n=6, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  31
IntGELU    | n:  6
IntSoftmax | n:  31
IntGELU    | n:  6
IntSoftmax | n:  31
IntGELU    | n:  6
IntSoftmax | n:  31
IntGELU    | n:  6
IntSoftmax | n:  31
IntGELU    | n:  6
IntSoftmax | n:  31
IntGELU    | n:  6
IntSoftmax | n:  31
IntGELU    | n:  6
IntSoftmax | n:  31
IntGELU    | n:  6
IntSoftmax | n:  31
IntGELU    | n:  6
IntSoftmax | n:  31
IntGELU    | n:  6
IntSoftmax | n:  31
IntGELU    | n:  6
IntSoftmax | n:  31
IntGELU    | n:  6
.calib done
Test: [  0/391]	Time  4.004 ( 4.004)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.90
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=31, intgelu_exp_n=7
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=31, intgelu_exp_n=7, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  31
IntGELU    | n:  7
IntSoftmax | n:  31
IntGELU    | n:  7
IntSoftmax | n:  31
IntGELU    | n:  7
IntSoftmax | n:  31
IntGELU    | n:  7
IntSoftmax | n:  31
IntGELU    | n:  7
IntSoftmax | n:  31
IntGELU    | n:  7
IntSoftmax | n:  31
IntGELU    | n:  7
IntSoftmax | n:  31
IntGELU    | n:  7
IntSoftmax | n:  31
IntGELU    | n:  7
IntSoftmax | n:  31
IntGELU    | n:  7
IntSoftmax | n:  31
IntGELU    | n:  7
IntSoftmax | n:  31
IntGELU    | n:  7
.calib done
Test: [  0/391]	Time  3.838 ( 3.838)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.82
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=31, intgelu_exp_n=8
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=31, intgelu_exp_n=8, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  31
IntGELU    | n:  8
IntSoftmax | n:  31
IntGELU    | n:  8
IntSoftmax | n:  31
IntGELU    | n:  8
IntSoftmax | n:  31
IntGELU    | n:  8
IntSoftmax | n:  31
IntGELU    | n:  8
IntSoftmax | n:  31
IntGELU    | n:  8
IntSoftmax | n:  31
IntGELU    | n:  8
IntSoftmax | n:  31
IntGELU    | n:  8
IntSoftmax | n:  31
IntGELU    | n:  8
IntSoftmax | n:  31
IntGELU    | n:  8
IntSoftmax | n:  31
IntGELU    | n:  8
IntSoftmax | n:  31
IntGELU    | n:  8
.calib done
Test: [  0/391]	Time  3.750 ( 3.750)	Acc@1   0.00 (  0.00)	Acc@5   0.78 (  0.78)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.781
Time: 8.73
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=31, intgelu_exp_n=9
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=31, intgelu_exp_n=9, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  31
IntGELU    | n:  9
IntSoftmax | n:  31
IntGELU    | n:  9
IntSoftmax | n:  31
IntGELU    | n:  9
IntSoftmax | n:  31
IntGELU    | n:  9
IntSoftmax | n:  31
IntGELU    | n:  9
IntSoftmax | n:  31
IntGELU    | n:  9
IntSoftmax | n:  31
IntGELU    | n:  9
IntSoftmax | n:  31
IntGELU    | n:  9
IntSoftmax | n:  31
IntGELU    | n:  9
IntSoftmax | n:  31
IntGELU    | n:  9
IntSoftmax | n:  31
IntGELU    | n:  9
IntSoftmax | n:  31
IntGELU    | n:  9
.calib done
Test: [  0/391]	Time  3.704 ( 3.704)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.70
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=31, intgelu_exp_n=10
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=31, intgelu_exp_n=10, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  31
IntGELU    | n:  10
IntSoftmax | n:  31
IntGELU    | n:  10
IntSoftmax | n:  31
IntGELU    | n:  10
IntSoftmax | n:  31
IntGELU    | n:  10
IntSoftmax | n:  31
IntGELU    | n:  10
IntSoftmax | n:  31
IntGELU    | n:  10
IntSoftmax | n:  31
IntGELU    | n:  10
IntSoftmax | n:  31
IntGELU    | n:  10
IntSoftmax | n:  31
IntGELU    | n:  10
IntSoftmax | n:  31
IntGELU    | n:  10
IntSoftmax | n:  31
IntGELU    | n:  10
IntSoftmax | n:  31
IntGELU    | n:  10
.calib done
Test: [  0/391]	Time  3.822 ( 3.822)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.73
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=31, intgelu_exp_n=11
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=31, intgelu_exp_n=11, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  31
IntGELU    | n:  11
IntSoftmax | n:  31
IntGELU    | n:  11
IntSoftmax | n:  31
IntGELU    | n:  11
IntSoftmax | n:  31
IntGELU    | n:  11
IntSoftmax | n:  31
IntGELU    | n:  11
IntSoftmax | n:  31
IntGELU    | n:  11
IntSoftmax | n:  31
IntGELU    | n:  11
IntSoftmax | n:  31
IntGELU    | n:  11
IntSoftmax | n:  31
IntGELU    | n:  11
IntSoftmax | n:  31
IntGELU    | n:  11
IntSoftmax | n:  31
IntGELU    | n:  11
IntSoftmax | n:  31
IntGELU    | n:  11
.calib done
Test: [  0/391]	Time  3.735 ( 3.735)	Acc@1   0.00 (  0.00)	Acc@5   0.78 (  0.78)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.781
Time: 8.67
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=31, intgelu_exp_n=12
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=31, intgelu_exp_n=12, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  31
IntGELU    | n:  12
IntSoftmax | n:  31
IntGELU    | n:  12
IntSoftmax | n:  31
IntGELU    | n:  12
IntSoftmax | n:  31
IntGELU    | n:  12
IntSoftmax | n:  31
IntGELU    | n:  12
IntSoftmax | n:  31
IntGELU    | n:  12
IntSoftmax | n:  31
IntGELU    | n:  12
IntSoftmax | n:  31
IntGELU    | n:  12
IntSoftmax | n:  31
IntGELU    | n:  12
IntSoftmax | n:  31
IntGELU    | n:  12
IntSoftmax | n:  31
IntGELU    | n:  12
IntSoftmax | n:  31
IntGELU    | n:  12
.calib done
Test: [  0/391]	Time  3.643 ( 3.643)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.63
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=31, intgelu_exp_n=13
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=31, intgelu_exp_n=13, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  31
IntGELU    | n:  13
IntSoftmax | n:  31
IntGELU    | n:  13
IntSoftmax | n:  31
IntGELU    | n:  13
IntSoftmax | n:  31
IntGELU    | n:  13
IntSoftmax | n:  31
IntGELU    | n:  13
IntSoftmax | n:  31
IntGELU    | n:  13
IntSoftmax | n:  31
IntGELU    | n:  13
IntSoftmax | n:  31
IntGELU    | n:  13
IntSoftmax | n:  31
IntGELU    | n:  13
IntSoftmax | n:  31
IntGELU    | n:  13
IntSoftmax | n:  31
IntGELU    | n:  13
IntSoftmax | n:  31
IntGELU    | n:  13
.calib done
Test: [  0/391]	Time  3.759 ( 3.759)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.70
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=31, intgelu_exp_n=14
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=31, intgelu_exp_n=14, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  31
IntGELU    | n:  14
IntSoftmax | n:  31
IntGELU    | n:  14
IntSoftmax | n:  31
IntGELU    | n:  14
IntSoftmax | n:  31
IntGELU    | n:  14
IntSoftmax | n:  31
IntGELU    | n:  14
IntSoftmax | n:  31
IntGELU    | n:  14
IntSoftmax | n:  31
IntGELU    | n:  14
IntSoftmax | n:  31
IntGELU    | n:  14
IntSoftmax | n:  31
IntGELU    | n:  14
IntSoftmax | n:  31
IntGELU    | n:  14
IntSoftmax | n:  31
IntGELU    | n:  14
IntSoftmax | n:  31
IntGELU    | n:  14
.calib done
Test: [  0/391]	Time  3.941 ( 3.941)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.93
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=31, intgelu_exp_n=15
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=31, intgelu_exp_n=15, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  31
IntGELU    | n:  15
IntSoftmax | n:  31
IntGELU    | n:  15
IntSoftmax | n:  31
IntGELU    | n:  15
IntSoftmax | n:  31
IntGELU    | n:  15
IntSoftmax | n:  31
IntGELU    | n:  15
IntSoftmax | n:  31
IntGELU    | n:  15
IntSoftmax | n:  31
IntGELU    | n:  15
IntSoftmax | n:  31
IntGELU    | n:  15
IntSoftmax | n:  31
IntGELU    | n:  15
IntSoftmax | n:  31
IntGELU    | n:  15
IntSoftmax | n:  31
IntGELU    | n:  15
IntSoftmax | n:  31
IntGELU    | n:  15
.calib done
Test: [  0/391]	Time  3.886 ( 3.886)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.85
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=31, intgelu_exp_n=16
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=31, intgelu_exp_n=16, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  31
IntGELU    | n:  16
IntSoftmax | n:  31
IntGELU    | n:  16
IntSoftmax | n:  31
IntGELU    | n:  16
IntSoftmax | n:  31
IntGELU    | n:  16
IntSoftmax | n:  31
IntGELU    | n:  16
IntSoftmax | n:  31
IntGELU    | n:  16
IntSoftmax | n:  31
IntGELU    | n:  16
IntSoftmax | n:  31
IntGELU    | n:  16
IntSoftmax | n:  31
IntGELU    | n:  16
IntSoftmax | n:  31
IntGELU    | n:  16
IntSoftmax | n:  31
IntGELU    | n:  16
IntSoftmax | n:  31
IntGELU    | n:  16
.calib done
Test: [  0/391]	Time  3.914 ( 3.914)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.91
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=31, intgelu_exp_n=17
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=31, intgelu_exp_n=17, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  31
IntGELU    | n:  17
IntSoftmax | n:  31
IntGELU    | n:  17
IntSoftmax | n:  31
IntGELU    | n:  17
IntSoftmax | n:  31
IntGELU    | n:  17
IntSoftmax | n:  31
IntGELU    | n:  17
IntSoftmax | n:  31
IntGELU    | n:  17
IntSoftmax | n:  31
IntGELU    | n:  17
IntSoftmax | n:  31
IntGELU    | n:  17
IntSoftmax | n:  31
IntGELU    | n:  17
IntSoftmax | n:  31
IntGELU    | n:  17
IntSoftmax | n:  31
IntGELU    | n:  17
IntSoftmax | n:  31
IntGELU    | n:  17
.calib done
Test: [  0/391]	Time  3.911 ( 3.911)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.86
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=31, intgelu_exp_n=18
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=31, intgelu_exp_n=18, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  31
IntGELU    | n:  18
IntSoftmax | n:  31
IntGELU    | n:  18
IntSoftmax | n:  31
IntGELU    | n:  18
IntSoftmax | n:  31
IntGELU    | n:  18
IntSoftmax | n:  31
IntGELU    | n:  18
IntSoftmax | n:  31
IntGELU    | n:  18
IntSoftmax | n:  31
IntGELU    | n:  18
IntSoftmax | n:  31
IntGELU    | n:  18
IntSoftmax | n:  31
IntGELU    | n:  18
IntSoftmax | n:  31
IntGELU    | n:  18
IntSoftmax | n:  31
IntGELU    | n:  18
IntSoftmax | n:  31
IntGELU    | n:  18
.calib done
Test: [  0/391]	Time  3.839 ( 3.839)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.74
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=31, intgelu_exp_n=19
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=31, intgelu_exp_n=19, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  31
IntGELU    | n:  19
IntSoftmax | n:  31
IntGELU    | n:  19
IntSoftmax | n:  31
IntGELU    | n:  19
IntSoftmax | n:  31
IntGELU    | n:  19
IntSoftmax | n:  31
IntGELU    | n:  19
IntSoftmax | n:  31
IntGELU    | n:  19
IntSoftmax | n:  31
IntGELU    | n:  19
IntSoftmax | n:  31
IntGELU    | n:  19
IntSoftmax | n:  31
IntGELU    | n:  19
IntSoftmax | n:  31
IntGELU    | n:  19
IntSoftmax | n:  31
IntGELU    | n:  19
IntSoftmax | n:  31
IntGELU    | n:  19
.calib done
Test: [  0/391]	Time  3.904 ( 3.904)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.88
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=31, intgelu_exp_n=20
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=31, intgelu_exp_n=20, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  31
IntGELU    | n:  20
IntSoftmax | n:  31
IntGELU    | n:  20
IntSoftmax | n:  31
IntGELU    | n:  20
IntSoftmax | n:  31
IntGELU    | n:  20
IntSoftmax | n:  31
IntGELU    | n:  20
IntSoftmax | n:  31
IntGELU    | n:  20
IntSoftmax | n:  31
IntGELU    | n:  20
IntSoftmax | n:  31
IntGELU    | n:  20
IntSoftmax | n:  31
IntGELU    | n:  20
IntSoftmax | n:  31
IntGELU    | n:  20
IntSoftmax | n:  31
IntGELU    | n:  20
IntSoftmax | n:  31
IntGELU    | n:  20
.calib done
Test: [  0/391]	Time  3.944 ( 3.944)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.92
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=31, intgelu_exp_n=21
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=31, intgelu_exp_n=21, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  31
IntGELU    | n:  21
IntSoftmax | n:  31
IntGELU    | n:  21
IntSoftmax | n:  31
IntGELU    | n:  21
IntSoftmax | n:  31
IntGELU    | n:  21
IntSoftmax | n:  31
IntGELU    | n:  21
IntSoftmax | n:  31
IntGELU    | n:  21
IntSoftmax | n:  31
IntGELU    | n:  21
IntSoftmax | n:  31
IntGELU    | n:  21
IntSoftmax | n:  31
IntGELU    | n:  21
IntSoftmax | n:  31
IntGELU    | n:  21
IntSoftmax | n:  31
IntGELU    | n:  21
IntSoftmax | n:  31
IntGELU    | n:  21
.calib done
Test: [  0/391]	Time  3.952 ( 3.952)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.93
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=31, intgelu_exp_n=22
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=31, intgelu_exp_n=22, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  31
IntGELU    | n:  22
IntSoftmax | n:  31
IntGELU    | n:  22
IntSoftmax | n:  31
IntGELU    | n:  22
IntSoftmax | n:  31
IntGELU    | n:  22
IntSoftmax | n:  31
IntGELU    | n:  22
IntSoftmax | n:  31
IntGELU    | n:  22
IntSoftmax | n:  31
IntGELU    | n:  22
IntSoftmax | n:  31
IntGELU    | n:  22
IntSoftmax | n:  31
IntGELU    | n:  22
IntSoftmax | n:  31
IntGELU    | n:  22
IntSoftmax | n:  31
IntGELU    | n:  22
IntSoftmax | n:  31
IntGELU    | n:  22
.calib done
Test: [  0/391]	Time  3.996 ( 3.996)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.94
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=31, intgelu_exp_n=23
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=31, intgelu_exp_n=23, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  31
IntGELU    | n:  23
IntSoftmax | n:  31
IntGELU    | n:  23
IntSoftmax | n:  31
IntGELU    | n:  23
IntSoftmax | n:  31
IntGELU    | n:  23
IntSoftmax | n:  31
IntGELU    | n:  23
IntSoftmax | n:  31
IntGELU    | n:  23
IntSoftmax | n:  31
IntGELU    | n:  23
IntSoftmax | n:  31
IntGELU    | n:  23
IntSoftmax | n:  31
IntGELU    | n:  23
IntSoftmax | n:  31
IntGELU    | n:  23
IntSoftmax | n:  31
IntGELU    | n:  23
IntSoftmax | n:  31
IntGELU    | n:  23
.calib done
Test: [  0/391]	Time  3.905 ( 3.905)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.91
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=31, intgelu_exp_n=24
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=31, intgelu_exp_n=24, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  31
IntGELU    | n:  24
IntSoftmax | n:  31
IntGELU    | n:  24
IntSoftmax | n:  31
IntGELU    | n:  24
IntSoftmax | n:  31
IntGELU    | n:  24
IntSoftmax | n:  31
IntGELU    | n:  24
IntSoftmax | n:  31
IntGELU    | n:  24
IntSoftmax | n:  31
IntGELU    | n:  24
IntSoftmax | n:  31
IntGELU    | n:  24
IntSoftmax | n:  31
IntGELU    | n:  24
IntSoftmax | n:  31
IntGELU    | n:  24
IntSoftmax | n:  31
IntGELU    | n:  24
IntSoftmax | n:  31
IntGELU    | n:  24
.calib done
Test: [  0/391]	Time  3.865 ( 3.865)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.81
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=31, intgelu_exp_n=25
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=31, intgelu_exp_n=25, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  31
IntGELU    | n:  25
IntSoftmax | n:  31
IntGELU    | n:  25
IntSoftmax | n:  31
IntGELU    | n:  25
IntSoftmax | n:  31
IntGELU    | n:  25
IntSoftmax | n:  31
IntGELU    | n:  25
IntSoftmax | n:  31
IntGELU    | n:  25
IntSoftmax | n:  31
IntGELU    | n:  25
IntSoftmax | n:  31
IntGELU    | n:  25
IntSoftmax | n:  31
IntGELU    | n:  25
IntSoftmax | n:  31
IntGELU    | n:  25
IntSoftmax | n:  31
IntGELU    | n:  25
IntSoftmax | n:  31
IntGELU    | n:  25
.calib done
Test: [  0/391]	Time  3.821 ( 3.821)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.79
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=31, intgelu_exp_n=26
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=31, intgelu_exp_n=26, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  31
IntGELU    | n:  26
IntSoftmax | n:  31
IntGELU    | n:  26
IntSoftmax | n:  31
IntGELU    | n:  26
IntSoftmax | n:  31
IntGELU    | n:  26
IntSoftmax | n:  31
IntGELU    | n:  26
IntSoftmax | n:  31
IntGELU    | n:  26
IntSoftmax | n:  31
IntGELU    | n:  26
IntSoftmax | n:  31
IntGELU    | n:  26
IntSoftmax | n:  31
IntGELU    | n:  26
IntSoftmax | n:  31
IntGELU    | n:  26
IntSoftmax | n:  31
IntGELU    | n:  26
IntSoftmax | n:  31
IntGELU    | n:  26
.calib done
Test: [  0/391]	Time  3.734 ( 3.734)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.74
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=31, intgelu_exp_n=27
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=31, intgelu_exp_n=27, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  31
IntGELU    | n:  27
IntSoftmax | n:  31
IntGELU    | n:  27
IntSoftmax | n:  31
IntGELU    | n:  27
IntSoftmax | n:  31
IntGELU    | n:  27
IntSoftmax | n:  31
IntGELU    | n:  27
IntSoftmax | n:  31
IntGELU    | n:  27
IntSoftmax | n:  31
IntGELU    | n:  27
IntSoftmax | n:  31
IntGELU    | n:  27
IntSoftmax | n:  31
IntGELU    | n:  27
IntSoftmax | n:  31
IntGELU    | n:  27
IntSoftmax | n:  31
IntGELU    | n:  27
IntSoftmax | n:  31
IntGELU    | n:  27
.calib done
Test: [  0/391]	Time  3.952 ( 3.952)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.92
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=31, intgelu_exp_n=28
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=31, intgelu_exp_n=28, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  31
IntGELU    | n:  28
IntSoftmax | n:  31
IntGELU    | n:  28
IntSoftmax | n:  31
IntGELU    | n:  28
IntSoftmax | n:  31
IntGELU    | n:  28
IntSoftmax | n:  31
IntGELU    | n:  28
IntSoftmax | n:  31
IntGELU    | n:  28
IntSoftmax | n:  31
IntGELU    | n:  28
IntSoftmax | n:  31
IntGELU    | n:  28
IntSoftmax | n:  31
IntGELU    | n:  28
IntSoftmax | n:  31
IntGELU    | n:  28
IntSoftmax | n:  31
IntGELU    | n:  28
IntSoftmax | n:  31
IntGELU    | n:  28
.calib done
Test: [  0/391]	Time  4.095 ( 4.095)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 9.09
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=31, intgelu_exp_n=29
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=31, intgelu_exp_n=29, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  31
IntGELU    | n:  29
IntSoftmax | n:  31
IntGELU    | n:  29
IntSoftmax | n:  31
IntGELU    | n:  29
IntSoftmax | n:  31
IntGELU    | n:  29
IntSoftmax | n:  31
IntGELU    | n:  29
IntSoftmax | n:  31
IntGELU    | n:  29
IntSoftmax | n:  31
IntGELU    | n:  29
IntSoftmax | n:  31
IntGELU    | n:  29
IntSoftmax | n:  31
IntGELU    | n:  29
IntSoftmax | n:  31
IntGELU    | n:  29
IntSoftmax | n:  31
IntGELU    | n:  29
IntSoftmax | n:  31
IntGELU    | n:  29
.calib done
Test: [  0/391]	Time  3.672 ( 3.672)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.65
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=31, intgelu_exp_n=30
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=31, intgelu_exp_n=30, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  31
IntGELU    | n:  30
IntSoftmax | n:  31
IntGELU    | n:  30
IntSoftmax | n:  31
IntGELU    | n:  30
IntSoftmax | n:  31
IntGELU    | n:  30
IntSoftmax | n:  31
IntGELU    | n:  30
IntSoftmax | n:  31
IntGELU    | n:  30
IntSoftmax | n:  31
IntGELU    | n:  30
IntSoftmax | n:  31
IntGELU    | n:  30
IntSoftmax | n:  31
IntGELU    | n:  30
IntSoftmax | n:  31
IntGELU    | n:  30
IntSoftmax | n:  31
IntGELU    | n:  30
IntSoftmax | n:  31
IntGELU    | n:  30
.calib done
Test: [  0/391]	Time  3.862 ( 3.862)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.82
-----------------------------------------------------
Running experiment with attn_quant=NoQuant, intsoftmax_exp_n=31, intgelu_exp_n=31
Namespace(model='deit_base', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=32, val_batchsize=128, num_workers=8, intsoftmax_exp_n=31, intgelu_exp_n=31, attn_quant='NoQuant')
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
Model: deit_base_patch16_224
IntSoftmax | n:  31
IntGELU    | n:  31
IntSoftmax | n:  31
IntGELU    | n:  31
IntSoftmax | n:  31
IntGELU    | n:  31
IntSoftmax | n:  31
IntGELU    | n:  31
IntSoftmax | n:  31
IntGELU    | n:  31
IntSoftmax | n:  31
IntGELU    | n:  31
IntSoftmax | n:  31
IntGELU    | n:  31
IntSoftmax | n:  31
IntGELU    | n:  31
IntSoftmax | n:  31
IntGELU    | n:  31
IntSoftmax | n:  31
IntGELU    | n:  31
IntSoftmax | n:  31
IntGELU    | n:  31
IntSoftmax | n:  31
IntGELU    | n:  31
.calib done
Test: [  0/391]	Time  3.985 ( 3.985)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
NAHNAHANAHNANHHNAHNAHNAHNAHNHNAHNAHN
 * Prec@1 0.000 Prec@5 0.000
Time: 8.98
-----------------------------------------------------
