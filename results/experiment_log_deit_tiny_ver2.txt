Running experiment with attn_quant=Symmetric_UINT4
Namespace(model='deit_tiny', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=1024, val_batchsize=128, num_workers=8, intsoftmax_exp_n=15, intgelu_exp_n=23, attn_quant='Symmetric_UINT4')
Model: deit_tiny_patch16_224
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 149
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : Symmetric_UINT4
    Number of QuantMatMul: 24
................................calib done
Test: [  0/391]	Time  2.804 ( 2.804)	Acc@1  37.50 ( 37.50)	Acc@5  55.47 ( 55.47)
Test: [ 50/391]	Time  1.203 ( 0.761)	Acc@1  28.91 ( 23.19)	Acc@5  60.94 ( 39.75)
Test: [100/391]	Time  1.206 ( 0.985)	Acc@1  30.47 ( 24.24)	Acc@5  57.81 ( 44.93)
Test: [150/391]	Time  1.223 ( 1.061)	Acc@1   5.47 ( 22.68)	Acc@5  18.75 ( 42.23)
Test: [200/391]	Time  1.204 ( 1.100)	Acc@1   1.56 ( 20.17)	Acc@5  13.28 ( 37.78)
Test: [250/391]	Time  1.201 ( 1.123)	Acc@1  12.50 ( 18.04)	Acc@5  28.12 ( 34.55)
Test: [300/391]	Time  1.201 ( 1.138)	Acc@1  16.41 ( 16.77)	Acc@5  32.81 ( 32.55)
Test: [350/391]	Time  1.226 ( 1.149)	Acc@1  13.28 ( 15.92)	Acc@5  31.25 ( 31.08)
Test: [390/391]	Time  0.994 ( 1.155)	Acc@1  10.00 ( 15.12)	Acc@5  18.75 ( 29.76)
 * Prec@1 15.120 Prec@5 29.760
Time: 462.53
-----------------------------------------------------
Running experiment with attn_quant=Symmetric_UINT8
Namespace(model='deit_tiny', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=1024, val_batchsize=128, num_workers=8, intsoftmax_exp_n=15, intgelu_exp_n=23, attn_quant='Symmetric_UINT8')
Model: deit_tiny_patch16_224
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 149
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : Symmetric_UINT8
    Number of QuantMatMul: 24
................................calib done
Test: [  0/391]	Time  3.757 ( 3.757)	Acc@1  89.84 ( 89.84)	Acc@5  96.09 ( 96.09)
Test: [ 50/391]	Time  1.195 ( 1.265)	Acc@1  90.62 ( 77.96)	Acc@5  96.88 ( 92.77)
Test: [100/391]	Time  0.471 ( 1.175)	Acc@1  79.69 ( 75.97)	Acc@5  94.53 ( 93.33)
Test: [150/391]	Time  1.202 ( 1.028)	Acc@1  67.97 ( 75.88)	Acc@5  94.53 ( 93.48)
Test: [200/391]	Time  1.202 ( 1.074)	Acc@1  61.72 ( 72.66)	Acc@5  92.97 ( 91.74)
Test: [250/391]	Time  1.189 ( 1.101)	Acc@1  81.25 ( 71.19)	Acc@5  91.41 ( 90.66)
Test: [300/391]	Time  1.221 ( 1.119)	Acc@1  71.09 ( 69.97)	Acc@5  84.38 ( 89.86)
Test: [350/391]	Time  1.201 ( 1.132)	Acc@1  65.62 ( 68.98)	Acc@5  85.94 ( 89.24)
Test: [390/391]	Time  1.007 ( 1.139)	Acc@1  45.00 ( 69.20)	Acc@5  80.00 ( 89.40)
 * Prec@1 69.198 Prec@5 89.396
Time: 479.45
-----------------------------------------------------
Running experiment with attn_quant=Log2_half_Int_Quantizer
Namespace(model='deit_tiny', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=1024, val_batchsize=128, num_workers=8, intsoftmax_exp_n=15, intgelu_exp_n=23, attn_quant='Log2_half_Int_Quantizer')
Model: deit_tiny_patch16_224
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 12
    - type : Log2_half_Int_Quantizer
    Number of QuantMatMul: 24
................................calib done
Test: [  0/391]	Time  4.075 ( 4.075)	Acc@1  89.84 ( 89.84)	Acc@5  96.88 ( 96.88)
Test: [ 50/391]	Time  1.571 ( 1.618)	Acc@1  89.84 ( 78.20)	Acc@5  98.44 ( 93.23)
Test: [100/391]	Time  1.600 ( 1.598)	Acc@1  80.47 ( 76.21)	Acc@5  93.75 ( 93.70)
Test: [150/391]	Time  1.561 ( 1.591)	Acc@1  71.09 ( 75.94)	Acc@5  96.09 ( 93.93)
Test: [200/391]	Time  1.111 ( 1.474)	Acc@1  60.94 ( 73.03)	Acc@5  91.41 ( 92.20)
Test: [250/391]	Time  1.697 ( 1.494)	Acc@1  83.59 ( 71.69)	Acc@5  92.19 ( 91.16)
Test: [300/391]	Time  1.678 ( 1.527)	Acc@1  73.44 ( 70.43)	Acc@5  85.94 ( 90.36)
Test: [350/391]	Time  1.709 ( 1.552)	Acc@1  69.53 ( 69.53)	Acc@5  85.94 ( 89.68)
Test: [390/391]	Time  1.431 ( 1.566)	Acc@1  46.25 ( 69.68)	Acc@5  81.25 ( 89.77)
 * Prec@1 69.680 Prec@5 89.772
Time: 648.88
-----------------------------------------------------
Running experiment with attn_quant=Log2_Int_Quantizer
Namespace(model='deit_tiny', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=1024, val_batchsize=128, num_workers=8, intsoftmax_exp_n=15, intgelu_exp_n=23, attn_quant='Log2_Int_Quantizer')
Model: deit_tiny_patch16_224
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : Log2_Int_Quantizer
    Number of QuantMatMul: 24
................................calib done
Test: [  0/391]	Time  4.166 ( 4.166)	Acc@1  90.62 ( 90.62)	Acc@5  97.66 ( 97.66)
Test: [ 50/391]	Time  1.695 ( 1.721)	Acc@1  88.28 ( 77.83)	Acc@5  96.09 ( 93.35)
Test: [100/391]	Time  1.655 ( 1.696)	Acc@1  78.12 ( 74.93)	Acc@5  92.19 ( 92.84)
Test: [150/391]	Time  1.687 ( 1.687)	Acc@1  69.53 ( 74.99)	Acc@5  96.88 ( 92.99)
Test: [200/391]	Time  1.658 ( 1.684)	Acc@1  60.94 ( 71.90)	Acc@5  89.06 ( 91.09)
Test: [250/391]	Time  1.639 ( 1.681)	Acc@1  82.81 ( 70.47)	Acc@5  92.97 ( 89.97)
Test: [300/391]	Time  1.694 ( 1.680)	Acc@1  68.75 ( 69.20)	Acc@5  87.50 ( 89.14)
Test: [350/391]	Time  0.682 ( 1.595)	Acc@1  71.09 ( 68.25)	Acc@5  89.06 ( 88.49)
Test: [390/391]	Time  1.419 ( 1.597)	Acc@1  47.50 ( 68.47)	Acc@5  75.00 ( 88.68)
 * Prec@1 68.466 Prec@5 88.676
Time: 665.97
-----------------------------------------------------
Running experiment with attn_quant=Log2_Int_Quantizer_nonscaling
Namespace(model='deit_tiny', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=1024, val_batchsize=128, num_workers=8, intsoftmax_exp_n=15, intgelu_exp_n=23, attn_quant='Log2_Int_Quantizer_nonscaling')
Model: deit_tiny_patch16_224
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : Log2_Int_Quantizer_nonscaling
    Number of QuantMatMul: 24
................................calib done
Test: [  0/391]	Time  4.404 ( 4.404)	Acc@1  91.41 ( 91.41)	Acc@5  97.66 ( 97.66)
Test: [ 50/391]	Time  1.747 ( 1.795)	Acc@1  89.84 ( 76.46)	Acc@5  96.88 ( 92.10)
Test: [100/391]	Time  1.743 ( 1.765)	Acc@1  74.22 ( 69.43)	Acc@5  91.41 ( 87.88)
Test: [150/391]	Time  1.733 ( 1.756)	Acc@1  68.75 ( 68.55)	Acc@5  96.88 ( 86.93)
Test: [200/391]	Time  1.729 ( 1.753)	Acc@1  28.91 ( 64.73)	Acc@5  43.75 ( 83.70)
Test: [250/391]	Time  1.718 ( 1.750)	Acc@1  81.25 ( 63.83)	Acc@5  90.62 ( 83.13)
Test: [300/391]	Time  1.740 ( 1.748)	Acc@1  71.09 ( 62.21)	Acc@5  83.59 ( 81.90)
Test: [350/391]	Time  1.746 ( 1.747)	Acc@1  39.06 ( 61.90)	Acc@5  63.28 ( 81.95)
Test: [390/391]	Time  1.434 ( 1.746)	Acc@1  48.75 ( 62.24)	Acc@5  77.50 ( 82.13)
 * Prec@1 62.238 Prec@5 82.126
Time: 724.83
-----------------------------------------------------
Running experiment with attn_quant=Log2Quantizer
Namespace(model='deit_tiny', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=1024, val_batchsize=128, num_workers=8, intsoftmax_exp_n=15, intgelu_exp_n=23, attn_quant='Log2Quantizer')
Model: deit_tiny_patch16_224
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : Log2Quantizer
    Number of QuantMatMul: 24
................................calib done
Test: [  0/391]	Time  3.706 ( 3.706)	Acc@1  88.28 ( 88.28)	Acc@5  96.09 ( 96.09)
Test: [ 50/391]	Time  0.808 ( 0.819)	Acc@1  89.84 ( 76.41)	Acc@5  96.88 ( 92.31)
Test: [100/391]	Time  1.311 ( 0.955)	Acc@1  77.34 ( 74.75)	Acc@5  95.31 ( 92.84)
Test: [150/391]	Time  1.303 ( 1.073)	Acc@1  66.41 ( 74.69)	Acc@5  94.53 ( 92.96)
Test: [200/391]	Time  1.318 ( 1.132)	Acc@1  57.81 ( 71.42)	Acc@5  89.06 ( 91.06)
Test: [250/391]	Time  1.291 ( 1.167)	Acc@1  79.69 ( 69.86)	Acc@5  92.19 ( 89.87)
Test: [300/391]	Time  1.307 ( 1.191)	Acc@1  72.66 ( 68.57)	Acc@5  84.38 ( 89.02)
Test: [350/391]	Time  1.290 ( 1.208)	Acc@1  63.28 ( 67.54)	Acc@5  84.38 ( 88.31)
Test: [390/391]	Time  1.137 ( 1.218)	Acc@1  43.75 ( 67.69)	Acc@5  81.25 ( 88.50)
 * Prec@1 67.694 Prec@5 88.498
Time: 514.45
-----------------------------------------------------
Running experiment with attn_quant=LogSqrt2Quantizer
Namespace(model='deit_tiny', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=1024, val_batchsize=128, num_workers=8, intsoftmax_exp_n=15, intgelu_exp_n=23, attn_quant='LogSqrt2Quantizer')
Model: deit_tiny_patch16_224
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : LogSqrt2Quantizer
    Number of QuantMatMul: 24
................................calib done
Test: [  0/391]	Time  3.780 ( 3.780)	Acc@1  88.28 ( 88.28)	Acc@5  96.09 ( 96.09)
Test: [ 50/391]	Time  1.322 ( 1.371)	Acc@1  89.06 ( 77.96)	Acc@5  96.88 ( 93.23)
Test: [100/391]	Time  1.302 ( 1.346)	Acc@1  80.47 ( 76.01)	Acc@5  94.53 ( 93.63)
Test: [150/391]	Time  1.294 ( 1.338)	Acc@1  69.53 ( 75.87)	Acc@5  95.31 ( 93.72)
Test: [200/391]	Time  1.290 ( 1.334)	Acc@1  60.94 ( 72.81)	Acc@5  88.28 ( 91.86)
Test: [250/391]	Time  1.334 ( 1.332)	Acc@1  81.25 ( 71.31)	Acc@5  92.97 ( 90.82)
Test: [300/391]	Time  0.773 ( 1.253)	Acc@1  71.88 ( 69.99)	Acc@5  84.38 ( 89.93)
Test: [350/391]	Time  1.209 ( 1.218)	Acc@1  71.09 ( 69.06)	Acc@5  88.28 ( 89.29)
Test: [390/391]	Time  1.029 ( 1.214)	Acc@1  43.75 ( 69.19)	Acc@5  80.00 ( 89.40)
 * Prec@1 69.188 Prec@5 89.396
Time: 513.39
-----------------------------------------------------
Running experiment with attn_quant=NoQuant
Namespace(model='deit_tiny', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=1024, val_batchsize=128, num_workers=8, intsoftmax_exp_n=15, intgelu_exp_n=23, attn_quant='NoQuant')
Model: deit_tiny_patch16_224
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
................................calib done
Test: [  0/391]	Time  3.819 ( 3.819)	Acc@1  89.06 ( 89.06)	Acc@5  96.88 ( 96.88)
Test: [ 50/391]	Time  1.151 ( 1.203)	Acc@1  90.62 ( 77.96)	Acc@5  96.88 ( 93.31)
Test: [100/391]	Time  1.142 ( 1.177)	Acc@1  76.56 ( 76.20)	Acc@5  94.53 ( 93.69)
Test: [150/391]	Time  1.152 ( 1.167)	Acc@1  68.75 ( 76.22)	Acc@5  95.31 ( 93.74)
Test: [200/391]	Time  1.133 ( 1.162)	Acc@1  61.72 ( 73.01)	Acc@5  91.41 ( 92.00)
Test: [250/391]	Time  1.142 ( 1.159)	Acc@1  82.03 ( 71.50)	Acc@5  91.41 ( 91.01)
Test: [300/391]	Time  1.125 ( 1.157)	Acc@1  72.66 ( 70.31)	Acc@5  85.16 ( 90.15)
Test: [350/391]	Time  1.166 ( 1.155)	Acc@1  70.31 ( 69.29)	Acc@5  85.94 ( 89.51)
Test: [390/391]	Time  0.368 ( 1.132)	Acc@1  48.75 ( 69.50)	Acc@5  78.75 ( 89.65)
 * Prec@1 69.498 Prec@5 89.652
Time: 475.20
-----------------------------------------------------
