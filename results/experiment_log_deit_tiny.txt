Running experiment with attn_quant=Symmetric_UINT4
Namespace(model='deit_tiny', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=1024, val_batchsize=128, num_workers=8, intsoftmax_exp_n=15, intgelu_exp_n=23, attn_quant='Symmetric_UINT4')
Model: deit_tiny_patch16_224
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 149
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : Symmetric_UINT4
    Number of QuantMatMul: 24
................................calib done
Test: [  0/391]	Time  2.600 ( 2.600)	Acc@1  37.50 ( 37.50)	Acc@5  55.47 ( 55.47)
Test: [ 50/391]	Time  0.468 ( 0.509)	Acc@1  28.91 ( 23.19)	Acc@5  60.94 ( 39.75)
Test: [100/391]	Time  0.469 ( 0.489)	Acc@1  30.47 ( 24.24)	Acc@5  57.81 ( 44.93)
Test: [150/391]	Time  0.469 ( 0.482)	Acc@1   5.47 ( 22.68)	Acc@5  18.75 ( 42.23)
Test: [200/391]	Time  0.468 ( 0.478)	Acc@1   1.56 ( 20.17)	Acc@5  13.28 ( 37.78)
Test: [250/391]	Time  0.467 ( 0.476)	Acc@1  12.50 ( 18.04)	Acc@5  28.12 ( 34.55)
Test: [300/391]	Time  0.468 ( 0.475)	Acc@1  16.41 ( 16.77)	Acc@5  32.81 ( 32.55)
Test: [350/391]	Time  0.468 ( 0.474)	Acc@1  13.28 ( 15.92)	Acc@5  31.25 ( 31.08)
Test: [390/391]	Time  0.350 ( 0.473)	Acc@1  10.00 ( 15.12)	Acc@5  18.75 ( 29.76)
 * Prec@1 15.120 Prec@5 29.760
Time: 195.40
-----------------------------------------------------
Running experiment with attn_quant=Symmetric_UINT8
Namespace(model='deit_tiny', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=1024, val_batchsize=128, num_workers=8, intsoftmax_exp_n=15, intgelu_exp_n=23, attn_quant='Symmetric_UINT8')
Model: deit_tiny_patch16_224
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 149
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : Symmetric_UINT8
    Number of QuantMatMul: 24
................................calib done
Test: [  0/391]	Time  2.615 ( 2.615)	Acc@1  89.84 ( 89.84)	Acc@5  96.09 ( 96.09)
Test: [ 50/391]	Time  0.466 ( 0.509)	Acc@1  90.62 ( 77.96)	Acc@5  96.88 ( 92.77)
Test: [100/391]	Time  0.469 ( 0.488)	Acc@1  79.69 ( 75.97)	Acc@5  94.53 ( 93.33)
Test: [150/391]	Time  0.468 ( 0.481)	Acc@1  67.97 ( 75.88)	Acc@5  94.53 ( 93.48)
Test: [200/391]	Time  0.467 ( 0.478)	Acc@1  61.72 ( 72.66)	Acc@5  92.97 ( 91.74)
Test: [250/391]	Time  0.468 ( 0.476)	Acc@1  81.25 ( 71.19)	Acc@5  91.41 ( 90.66)
Test: [300/391]	Time  0.469 ( 0.475)	Acc@1  71.09 ( 69.97)	Acc@5  84.38 ( 89.86)
Test: [350/391]	Time  0.468 ( 0.474)	Acc@1  65.62 ( 68.98)	Acc@5  85.94 ( 89.24)
Test: [390/391]	Time  0.352 ( 0.473)	Acc@1  45.00 ( 69.20)	Acc@5  80.00 ( 89.40)
 * Prec@1 69.198 Prec@5 89.396
Time: 195.29
-----------------------------------------------------
Running experiment with attn_quant=Log2_half_Quantizer
Namespace(model='deit_tiny', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=1024, val_batchsize=128, num_workers=8, intsoftmax_exp_n=15, intgelu_exp_n=23, attn_quant='Log2_half_Quantizer')
Model: deit_tiny_patch16_224
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 12
    - type : Log2_half_Quantizer
    Number of QuantMatMul: 24
................................calib done
Test: [  0/391]	Time  2.696 ( 2.696)	Acc@1  91.41 ( 91.41)	Acc@5  96.88 ( 96.88)
Test: [ 50/391]	Time  0.670 ( 0.710)	Acc@1  89.06 ( 78.34)	Acc@5  98.44 ( 93.52)
Test: [100/391]	Time  0.670 ( 0.690)	Acc@1  79.69 ( 76.33)	Acc@5  95.31 ( 93.83)
Test: [150/391]	Time  0.670 ( 0.684)	Acc@1  71.09 ( 76.07)	Acc@5  95.31 ( 93.87)
Test: [200/391]	Time  0.668 ( 0.680)	Acc@1  63.28 ( 73.22)	Acc@5  91.41 ( 92.10)
Test: [250/391]	Time  0.669 ( 0.678)	Acc@1  83.59 ( 71.83)	Acc@5  96.09 ( 91.10)
Test: [300/391]	Time  0.670 ( 0.677)	Acc@1  74.22 ( 70.61)	Acc@5  86.72 ( 90.37)
Test: [350/391]	Time  0.669 ( 0.676)	Acc@1  72.66 ( 69.69)	Acc@5  86.72 ( 89.73)
Test: [390/391]	Time  0.479 ( 0.675)	Acc@1  46.25 ( 69.85)	Acc@5  80.00 ( 89.82)
 * Prec@1 69.850 Prec@5 89.818
Time: 276.30
-----------------------------------------------------
Running experiment with attn_quant=Log2Quantizer
Namespace(model='deit_tiny', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=1024, val_batchsize=128, num_workers=8, intsoftmax_exp_n=15, intgelu_exp_n=23, attn_quant='Log2Quantizer')
Model: deit_tiny_patch16_224
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : Log2Quantizer
    Number of QuantMatMul: 24
................................calib done
Test: [  0/391]	Time  2.419 ( 2.419)	Acc@1  88.28 ( 88.28)	Acc@5  96.09 ( 96.09)
Test: [ 50/391]	Time  0.460 ( 0.498)	Acc@1  89.84 ( 76.41)	Acc@5  96.88 ( 92.31)
Test: [100/391]	Time  0.461 ( 0.479)	Acc@1  77.34 ( 74.75)	Acc@5  95.31 ( 92.84)
Test: [150/391]	Time  0.460 ( 0.473)	Acc@1  66.41 ( 74.69)	Acc@5  94.53 ( 92.96)
Test: [200/391]	Time  0.459 ( 0.469)	Acc@1  57.81 ( 71.42)	Acc@5  89.06 ( 91.06)
Test: [250/391]	Time  0.459 ( 0.467)	Acc@1  79.69 ( 69.86)	Acc@5  92.19 ( 89.87)
Test: [300/391]	Time  0.460 ( 0.466)	Acc@1  72.66 ( 68.57)	Acc@5  84.38 ( 89.02)
Test: [350/391]	Time  0.460 ( 0.465)	Acc@1  63.28 ( 67.54)	Acc@5  84.38 ( 88.31)
Test: [390/391]	Time  0.345 ( 0.464)	Acc@1  43.75 ( 67.69)	Acc@5  81.25 ( 88.50)
 * Prec@1 67.694 Prec@5 88.498
Time: 192.11
-----------------------------------------------------
Running experiment with attn_quant=LogSqrt2Quantizer
Namespace(model='deit_tiny', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=1024, val_batchsize=128, num_workers=8, intsoftmax_exp_n=15, intgelu_exp_n=23, attn_quant='LogSqrt2Quantizer')
Model: deit_tiny_patch16_224
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : LogSqrt2Quantizer
    Number of QuantMatMul: 24
................................calib done
Test: [  0/391]	Time  2.444 ( 2.444)	Acc@1  88.28 ( 88.28)	Acc@5  96.09 ( 96.09)
Test: [ 50/391]	Time  0.474 ( 0.513)	Acc@1  89.06 ( 77.96)	Acc@5  96.88 ( 93.23)
Test: [100/391]	Time  0.475 ( 0.493)	Acc@1  80.47 ( 76.01)	Acc@5  94.53 ( 93.63)
Test: [150/391]	Time  0.475 ( 0.487)	Acc@1  69.53 ( 75.87)	Acc@5  95.31 ( 93.72)
Test: [200/391]	Time  0.472 ( 0.483)	Acc@1  60.94 ( 72.81)	Acc@5  88.28 ( 91.86)
Test: [250/391]	Time  0.474 ( 0.482)	Acc@1  81.25 ( 71.31)	Acc@5  92.97 ( 90.82)
Test: [300/391]	Time  0.474 ( 0.480)	Acc@1  71.88 ( 69.99)	Acc@5  84.38 ( 89.93)
Test: [350/391]	Time  0.473 ( 0.479)	Acc@1  71.09 ( 69.06)	Acc@5  88.28 ( 89.29)
Test: [390/391]	Time  0.355 ( 0.478)	Acc@1  43.75 ( 69.19)	Acc@5  80.00 ( 89.40)
 * Prec@1 69.188 Prec@5 89.396
Time: 197.85
-----------------------------------------------------
Running experiment with attn_quant=NoQuant
Namespace(model='deit_tiny', dataset='data/ImageNet', nb_classes=1000, device='cuda', print_freq=50, seed=0, output_dir='results/', calib_batchsize=32, calib_images=1024, val_batchsize=128, num_workers=8, intsoftmax_exp_n=15, intgelu_exp_n=23, attn_quant='NoQuant')
Model: deit_tiny_patch16_224
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
IntSoftmax | n:  15
IntGELU    | n:  23
    Number of QuantLinear: 49
    Number of QuantConv2d: 1
    Number of QuantAct: 137
    Number of IntLayerNorm: 25
    Number of IntGELU: 12
    Number of IntSoftmax: 12
    Number of Log2_Quantizer: 0
    - type : NoQuant
    Number of QuantMatMul: 24
................................calib done
Test: [  0/391]	Time  2.619 ( 2.619)	Acc@1  89.06 ( 89.06)	Acc@5  96.88 ( 96.88)
Test: [ 50/391]	Time  0.444 ( 0.486)	Acc@1  90.62 ( 77.96)	Acc@5  96.88 ( 93.31)
Test: [100/391]	Time  0.444 ( 0.465)	Acc@1  76.56 ( 76.20)	Acc@5  94.53 ( 93.69)
Test: [150/391]	Time  0.443 ( 0.458)	Acc@1  68.75 ( 76.22)	Acc@5  95.31 ( 93.74)
Test: [200/391]	Time  0.443 ( 0.454)	Acc@1  61.72 ( 73.01)	Acc@5  91.41 ( 92.00)
Test: [250/391]	Time  0.443 ( 0.452)	Acc@1  82.03 ( 71.50)	Acc@5  91.41 ( 91.01)
Test: [300/391]	Time  0.443 ( 0.451)	Acc@1  72.66 ( 70.31)	Acc@5  85.16 ( 90.15)
Test: [350/391]	Time  0.444 ( 0.450)	Acc@1  70.31 ( 69.29)	Acc@5  85.94 ( 89.51)
Test: [390/391]	Time  0.337 ( 0.449)	Acc@1  48.75 ( 69.50)	Acc@5  78.75 ( 89.65)
 * Prec@1 69.498 Prec@5 89.652
Time: 185.62
-----------------------------------------------------
